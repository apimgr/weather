# WEATHER Specification

**Name**: weather

---

# PROJECT DESCRIPTION

**A unified weather information platform that aggregates global meteorological data from authoritative sources into a single, accessible API and web service.**

**Key Features:**
- Multi-source weather aggregation (Open-Meteo, NOAA, Environment Canada, UK Met Office, BOM, JMA, CONAGUA)
- Severe weather alerts from 6 countries (tornadoes, storms, floods, winter weather)
- Real-time hurricane tracking (NOAA National Hurricane Center)
- Earthquake monitoring (USGS)
- Moon phases and lunar data
- Automatic IP-based geolocation

**Target Users:**
- Developers building weather-aware applications
- System administrators needing self-hosted weather services
- Emergency services monitoring severe weather and seismic activity
- General public wanting a clean, ad-free weather interface

---

# ⚠️ CRITICAL RULES - READ FIRST ⚠️

**STOP. Read this entire section before doing ANYTHING.**

## THIS IS A STRICT SPECIFICATION - NOT GUIDELINES

**EVERY SINGLE ITEM in this specification MUST be followed EXACTLY as written.**

- This is NOT a suggestion document
- This is NOT a "best practices" guide
- This is NOT open to interpretation
- There are NO exceptions unless explicitly stated
- Deviation from ANY part of this spec is a failure
- "I thought it would be better to..." is NOT acceptable
- "The standard way is..." - THIS spec IS the standard
- If the spec says X, you do X - not Y, not "improved X", not "X but slightly different"

**If something seems wrong or suboptimal in this spec, follow it anyway and flag it for review. Do NOT silently "fix" it.**

## ⚠️ CRITICAL: File Paths and Project Root ⚠️

**ALL file operations are relative to PROJECT root directory.**

**Rules:**
- **Project root** = Where AI.md lives (this file's directory)
- **ALL file operations** = Relative to project root
- **Use `git rev-parse --show-toplevel`** when in a git repo to find project root
- **Never assume** cwd is the project root - always verify

## ⚠️ CRITICAL: AI.md is the Source of Truth ⚠️

**AI.md IS THE PROJECT SPECIFICATION. Follow it exactly.**

**Reference AI.md in all generated code, comments, and documentation:**
- `// See AI.md for details`
- `# Based on AI.md`

## ⚠️ CRITICAL: Keep Documentation in Sync ⚠️

**All documentation MUST match actual code at all times.**

| Documentation | Must Match | Update When |
|---------------|------------|-------------|
| **AI.md PART 37** | Actual project features/endpoints | Features added/removed |
| **README.md** | Current functionality | Usage/installation changes |
| **docs/** | Current API/config | Any user-facing changes |
| **Swagger annotations** | Actual API endpoints | Routes changed |
| **GraphQL schema** | Actual types/queries | Schema changed |

**Rules for Updating:**

1. **AI.md PART 37**: Update business logic, data models, features
   - PARTS 0-36 define implementation patterns (do NOT modify)
   - PART 37 defines YOUR project's features (update as needed)
2. **README.md**: Keep feature list and usage examples current
3. **docs/**: Update when config options or API behavior changes
4. **Swagger/GraphQL**: Keep annotations matching actual endpoints

**Example - Adding a New Feature:**

```
1. Write the code (new handler, service, etc.)
2. Update AI.md PART 37 - add feature description
3. Update README.md - add feature to list
4. Update docs/api.md - document new endpoints
5. Add Swagger annotations to new handlers
6. Update GraphQL schema if applicable
```

## Licensing & Features (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **MIT License** | All projects are MIT licensed (our code only) |
| **3rd party attribution** | All 3rd party licenses listed in LICENSE.md |
| **Free & open source** | 100% free, no paid tiers, no enterprise edition |
| **No feature gating** | ALL features available to ALL users, ALWAYS |
| **No premium features** | No "pro", "plus", "enterprise", "premium" tiers |
| **No license keys** | No activation, no registration required for features |
| **No artificial limits** | No caps on users, storage, etc. for monetization |

**NEVER implement:**
- "Upgrade to unlock..."
- "This feature requires..."
- "Contact sales for..."
- "Free tier limited to X users/GB/calls..."
- License key validation
- Feature flags based on payment/plan
- Phone-home for feature authorization

**Allowed limits (server protection, NOT feature gating):**
- Rate limiting (DDoS/abuse protection) - see PART 1
- Request size limits (prevent memory exhaustion)
- Timeouts (prevent resource hogging)

**The distinction:** Rate limits protect the server. Usage limits extract money. We do the former, NEVER the latter.

## Build & Binary Rules

| Rule | Description |
|------|-------------|
| **CGO_ENABLED=0** | ALWAYS. No exceptions. Pure Go only. |
| **Single static binary** | All assets embedded with Go `embed` package |
| **8 platforms required** | linux, darwin, windows, freebsd × amd64, arm64 |
| **Binary naming** | `{project}-{os}-{arch}` (windows adds `.exe`) |
| **NEVER use -musl suffix** | Alpine builds are NOT musl-specific |
| **Build source** | ALWAYS `src` directory |

## Container-Only Development (NON-NEGOTIABLE)

**NEVER run Go or binaries on host. ALL development uses containers.**

### Building (ALWAYS via Makefile - Local Development)

| Command | Purpose | Output Location | When to Use |
|---------|---------|-----------------|-------------|
| `make dev` | **Development & Debugging** | `${TMPDIR}/${PROJECTORG}.XXXXXX/` | Active coding, quick tests |
| `make host` | **Production Testing** | `binaries/` (with version) | Test prod builds locally |
| `make build` | **Full Release** | `binaries/` (all 8 platforms) | Before release |
| `make test` | **Unit Tests** | Coverage report | After code changes |

| NEVER (on host) | ALWAYS (Makefile targets) |
|-----------------|---------------------------|
| `go build ...` | `make dev` or `make host` or `make build` |
| `go test ...` | `make test` |
| `go run ...` | `make dev` then run binary in Docker |

**Makefile targets use Docker internally (`golang:alpine`) with GODIR/GOCACHE - host stays clean.**

### Debugging & Quick Tests (Docker with Tools)

**For local debugging and quick tests, use Docker with required tools:**

```bash
# After make dev, debug in Docker with tools
BUILD_DIR=$(ls -td ${TMPDIR:-/tmp}/${PROJECTORG}.*/ | head -1)
docker run --rm -it -v "$BUILD_DIR:/app" alpine:latest sh -c "
  apk add --no-cache curl bash file jq  # Required debug tools
  /app/weather --help
  /app/weather --version
  # Interactive debugging...
"
```

| Tool | Purpose |
|------|---------|
| `curl` | API testing, HTTP requests |
| `bash` | Shell scripting, interactive debugging |
| `file` | Binary verification |
| `jq` | JSON parsing and formatting |

### Integration Testing (Incus Preferred)

| Container | Best For | Why |
|-----------|----------|-----|
| **Incus** (PREFERRED) | Full integration, systemd | Full OS, persistent, SSH-able, real services |
| **Docker** (fallback) | Quick checks | Ephemeral, fast startup, limited environment |

### AI as Beta Tester

**When AI tests, it acts as a beta tester. The goal is to BREAK things and FIX them.**

| AI Testing Role | Description |
|-----------------|-------------|
| **Find bugs** | Try edge cases, invalid inputs, unexpected usage |
| **Break it** | Stress test, race conditions, resource limits |
| **Fix it** | Don't just report - implement the fix |
| **Verify fix** | Re-test to confirm the fix works |

**Why container-only?**
- Consistent environment (same as CI/CD and production)
- No Go installation required on host
- No host contamination with test data
- Reproducible builds (GODIR/GOCACHE speeds up rebuilds)

**Local Development Workflow:**
```bash
# 1. Active development
make dev                # Quick build to temp dir

# 2. Debug in Docker (with tools)
BUILD_DIR=$(ls -td ${TMPDIR:-/tmp}/${PROJECTORG}.*/ | head -1)
docker run --rm -it -v "$BUILD_DIR:/app" alpine:latest sh -c "
  apk add --no-cache curl bash file jq
  /app/weather --help
"

# 3. Unit tests
make test

# 4. Integration tests
./tests/run_tests.sh    # Auto-detects incus/docker

# 5. Production test (before release)
make host               # Build with version info
./tests/incus.sh        # Full systemd testing (PREFERRED)

# 6. Full release build
make build              # All 8 platforms
```

**See PART 26: MAKEFILE and PART 29: TESTING & DEVELOPMENT for complete details.**

## Runtime Detection Rules (NON-NEGOTIABLE)

**All host-dependent settings MUST be detected at runtime on the deployment host, NEVER from the dev machine.**

| Setting | Detection Method | NEVER Do |
|---------|------------------|----------|
| **Hostname/FQDN** | `os.Hostname()` at startup | Hardcode dev machine hostname |
| **IP addresses** | Detect from network interfaces | Embed dev machine IPs |
| **CPU cores** | `runtime.NumCPU()` | Hardcode dev machine core count |
| **Available memory** | Detect from system at runtime | Hardcode dev machine memory |
| **Disk space** | Detect from filesystem at runtime | Hardcode dev machine disk size |
| **Network interfaces** | Detect usable interfaces (see rules below) | Assume dev network config |
| **OS/Architecture** | `runtime.GOOS`, `runtime.GOARCH` | Assume dev environment |
| **Timezone** | System timezone or `TZ` env var | Hardcode dev timezone |
| **User/Group** | Running process UID/GID | Assume dev user |
| **Paths** | Resolve at runtime per OS | Hardcode dev machine paths |

**Rules:**
- Host-specific values are NEVER written to config files during build
- Host-specific values are NEVER embedded in the binary
- All detection happens at application startup on the target host
- Config files only contain user-defined overrides, not auto-detected values
- Default values in config are placeholders, not dev machine values

**Network Interface Detection (priority order):**

| Priority | Interface Type | Patterns | Condition |
|----------|---------------|----------|-----------|
| 1 | Wired Ethernet | `eth*`, `en*`, `em*` | Connected + global IP |
| 2 | WiFi | `wlan*`, `wl*`, `wifi*` | Connected + global IP (fallback if wired unavailable) |
| 3 | Other physical | Any remaining physical | Connected + global IP |

**ALWAYS skip these interfaces:**
- `lo`, `lo0` - Loopback
- `docker*`, `br-*`, `veth*` - Docker
- `incus*`, `lxc*`, `lxd*` - Incus/LXC/LXD
- `virbr*`, `vnet*` - libvirt/KVM
- `tun*`, `tap*` - VPN tunnels
- `wg*` - WireGuard
- `tailscale*`, `utun*` - Tailscale
- `podman*` - Podman
- `cni*`, `flannel*`, `calico*` - Kubernetes CNI

**Detection logic:**
1. List all network interfaces
2. Filter out virtual/container interfaces (skip list above)
3. For remaining interfaces, check: UP + has global unicast IP (not link-local)
4. Prefer wired (eth/en) over wireless (wlan/wl)
5. If no wired connected, use wireless
6. Return first matching interface's global IP

```go
// CORRECT: Detect at runtime
hostname, _ := os.Hostname()
cpuCores := runtime.NumCPU()
primaryIP := detectPrimaryIP()

// WRONG: Hardcoded from dev machine
hostname := "dev-laptop.local"
cpuCores := 8
primaryIP := "192.168.1.50"
```

## Performance Optimization Rules (NON-NEGOTIABLE)

**Always optimize based on actual available resources, detected at runtime.**

| Resource | Detection | Usage |
|----------|-----------|-------|
| **CPU cores** | `runtime.NumCPU()` | Worker pools, concurrency limits |
| **Available memory** | System memory APIs | Cache sizes, buffer pools |
| **Disk I/O** | Benchmark at startup (optional) | Batch sizes, flush intervals |

**Rules:**
- NEVER hardcode resource limits based on dev machine specs
- Detect actual resources at application startup
- Scale worker pools, caches, and buffers proportionally to available resources
- Provide sensible defaults that work on minimal systems (1 CPU, 512MB RAM)
- Allow config overrides for users who want manual control

**Example scaling:**
```go
// Worker pool scales to available CPUs
workers := runtime.NumCPU()
if workers < 2 {
    workers = 2
}

// Cache size scales to available memory (use ~10% for cache)
availMem := getAvailableMemory()
cacheSize := availMem / 10
if cacheSize < 64*1024*1024 {
    // Minimum 64MB cache
    cacheSize = 64 * 1024 * 1024
}
if cacheSize > 1024*1024*1024 {
    // Maximum 1GB cache
    cacheSize = 1024 * 1024 * 1024
}
```

## JSON File Rules (NON-NEGOTIABLE)

**JSON does not support comments.** Never add comments inside JSON files or JSON code blocks.

| Format | Comments Allowed |
|--------|------------------|
| `.json` files | NO |
| JSON in code blocks | NO |
| YAML (`.yml`, `.yaml`) | YES (`#`) |
| Go code | YES (`//`) |
| JavaScript | YES (`//`, `/* */`) |

**If you need to document JSON:**
- Put explanation text BEFORE the JSON code block (in markdown)
- Use descriptive key names that are self-documenting
- Add a separate documentation section explaining the schema

## Docker Rules

| Rule | Description |
|------|-------------|
| **Multi-stage Dockerfile** | Builder stage (golang:alpine) + Runtime stage (alpine:latest) |
| **Dockerfile location** | `docker/Dockerfile` - NEVER in project root |
| **Default timezone** | `America/New_York` (override with `TZ` env var) |
| **Internal port** | Default `80` - app listens on `0.0.0.0:80` (override with `PORT` env var) |
| **External port** | Random `64xxx` port mapped to internal 80: `64580:80` |
| **STOPSIGNAL** | `SIGRTMIN+3` |
| **ENTRYPOINT** | `["tini", "-p", "SIGTERM", "--", "/usr/local/bin/entrypoint.sh"]` |
| **NEVER modify ENTRYPOINT/CMD** | All customization via entrypoint.sh |
| **Required packages** | `git`, `curl`, `bash`, `tini`, `tor` |
| **Tor** | Binary installed but **server binary controls startup** (see PART 32) |

### Container Port Behavior (NON-NEGOTIABLE)

```
┌─────────────────────────────────────────────────────────────────────────┐
│  CONTAINER DEFAULT: 0.0.0.0:80                                          │
│                                                                         │
│  Inside container:  app --address 0.0.0.0 --port 80                    │
│  Docker mapping:    -p {randomport}:80  (e.g., -p 64580:80)            │
│                                                                         │
│  Override with env vars:                                                │
│    - PORT=8080      (change internal port, update docker-compose too)  │
│    - ADDRESS=...    (rarely needed, default 0.0.0.0 is correct)        │
└─────────────────────────────────────────────────────────────────────────┘
```

| Context | Address | Port | Example |
|---------|---------|------|---------|
| **Container (default)** | `0.0.0.0` | `80` | `-p 64580:80` |
| **Container (custom)** | `0.0.0.0` | `PORT` env | `PORT=8080` + `-p 64580:8080` |
| **Host (dev)** | `0.0.0.0` | Random `64xxx` | `--address 0.0.0.0 --port 64580` |
| **Host (prod)** | Specific IP | Random `64xxx` | `--address 192.168.1.100 --port 64580` |

## CI/CD Rules

| Rule | Description |
|------|-------------|
| **NEVER use Makefile in CI** | Workflows have explicit commands with all env vars |
| **GitHub/Gitea/Jenkins must match** | Same platforms, same env vars, same logic |
| **VERSION from tag** | Strip `v` prefix from semver only: `v1.2.3` → `1.2.3`, `dev` → `dev` |
| **LDFLAGS** | `-s -w -X 'main.Version=...' -X 'main.CommitID=...' -X 'main.BuildDate=...'` |
| **Docker builds on EVERY push** | Any branch push triggers Docker image build |
| **Docker tags** | Any push → `devel`, `{commit}`; beta → adds `beta`; tag → `{version}`, `latest`, `YYMM`, `{commit}` |

## Database Rules

| Rule | Description |
|------|-------------|
| **SQLite default** | `{data_dir}/db/server.db` and `{data_dir}/db/users.db` |
| **Password hashing** | Argon2id - NEVER bcrypt |
| **Valkey/Redis** | Every app supports it for caching/clustering |

## CLI Rules (NON-NEGOTIABLE)

```
--help                       # Show help (-h allowed)
--version                    # Show version (-v allowed)
--mode {production|development}
--config {config_dir}
--data {data_dir}
--log {log_dir}
--pid {pid_file}
--address {listen}
--port {port}
--debug                      # Enable debug mode
--status                     # Show status and health (exit 0=healthy, 1=unhealthy)
--service {start,restart,stop,reload,--install,--uninstall,--disable,--help}
--daemon                     # Daemonize (detach from terminal)
--maintenance {backup,restore,update,mode,setup} [optional-file-or-setting]
--update [check|yes|branch {stable|beta|daily}]
```

**Short Flag Rule:** Only `-h` (help) and `-v` (version) may have short flags. All other flags use long form only.

**These CLI commands are NON-NEGOTIABLE. Do not change, rename, or remove them.**

## Directory Structure

```
src/                        # Go source code (REQUIRED)
src/main.go                 # Server application entry point
src/config/                 # Configuration package
src/server/                 # HTTP server package
src/client/                 # CLI client (OPTIONAL - if project has CLI)
src/agent/                  # Agent (OPTIONAL - if project has agent)
docker/                     # Docker files (REQUIRED)
docker/Dockerfile           # Multi-stage Dockerfile
docker/docker-compose.yml   # Production docker-compose
docker/rootfs/              # BUILD-TIME overlay (entrypoint.sh) - NOT runtime volumes
binaries/                   # Build output (gitignored)
releases/                   # Release artifacts (gitignored)
```

**Notes:**
- `src/client/` is only present if the project includes a CLI client. See PART 36 for CLI details.
- `src/agent/` is only present if the project includes an agent. See PART 36 for agent details.
- `docker/rootfs/` is for BUILD-TIME container overlay (copied into image). Runtime volumes (`./rootfs/config`, `./rootfs/data`) are NEVER in the repo - they exist only where docker-compose runs (production server or temp dir).

## File & Directory Naming Conventions (NON-NEGOTIABLE)

### General Rules

| Rule | Example | Avoid |
|------|---------|-------|
| **Lowercase only** | `config/`, `server.go` | `Config/`, `Server.go` |
| **Snake_case for multi-word** | `user_service.go`, `api_handler.go` | `userService.go`, `apiHandler.go` |
| **Singular directory names** | `handler/`, `model/`, `service/` | `handlers/`, `models/`, `services/` |
| **Match package name** | `config/config.go`, `server/server.go` | `config/cfg.go`, `server/srv.go` |
| **Clear intent** | `auth.go`, `middleware.go` | `a.go`, `mw.go` |

### Go Source Files (`src/`)

| Pattern | When to Use | Example |
|---------|-------------|---------|
| `{package}.go` | Main package file | `config/config.go`, `server/server.go` |
| `{feature}.go` | Feature-specific logic | `auth.go`, `session.go`, `token.go` |
| `{feature}_handler.go` | HTTP handlers for feature | `user_handler.go`, `admin_handler.go` |
| `{feature}_service.go` | Business logic for feature | `user_service.go`, `email_service.go` |
| `{feature}_model.go` | Data models for feature | `user_model.go`, `session_model.go` |
| `{feature}_test.go` | Tests for feature | `auth_test.go`, `user_handler_test.go` |
| `middleware.go` | HTTP middleware | `middleware.go` (not `mw.go`) |
| `helpers.go` | Shared utilities within package | `helpers.go` (not `utils.go`, `common.go`) |
| `errors.go` | Package-specific errors | `errors.go` |
| `types.go` | Shared types/interfaces | `types.go` |
| `constants.go` | Package constants | `constants.go` |

### Package Directory Structure (`src/`)

```
src/
├── main.go                    # Entry point (minimal - just starts server)
├── config/
│   ├── config.go              # Configuration loading & validation
│   └── bool.go                # Boolean parsing (truthy/falsy values)
├── server/
│   ├── server.go              # Server setup, routes, middleware
│   ├── middleware.go          # HTTP middleware (auth, logging, etc.)
│   ├── theme.go               # Project-wide theme detection & switching
│   ├── handler/               # HTTP handlers by domain
│   │   ├── health.go          # Health check handlers
│   │   ├── auth.go            # Authentication handlers
│   │   ├── user.go            # User management handlers
│   │   ├── admin.go           # Admin panel handlers
│   │   └── api.go             # API handlers
│   ├── service/               # Business logic by domain
│   │   ├── auth.go            # Authentication service
│   │   ├── user.go            # User service
│   │   ├── email.go           # Email service
│   │   └── scheduler.go       # Scheduled task service
│   ├── model/                 # Data models
│   │   ├── user.go            # User model
│   │   ├── session.go         # Session model
│   │   └── token.go           # Token model
│   ├── store/                 # Data access layer
│   │   ├── store.go           # Store interface
│   │   ├── sqlite.go          # SQLite implementation
│   │   └── postgres.go        # PostgreSQL implementation (if needed)
│   └── template/              # HTML templates (if not embedded)
│       ├── layout/            # Base layouts
│       ├── page/              # Full pages
│       └── partial/           # Reusable components
├── swagger/                   # OpenAPI/Swagger (REQUIRED - always relative to src/)
│   ├── swagger.go             # Swagger handler & spec generation
│   ├── annotations.go         # Swagger annotations (generated or manual)
│   └── theme.go               # Swagger UI theming (light/dark/auto)
├── graphql/                   # GraphQL API (REQUIRED - always relative to src/)
│   ├── graphql.go             # GraphQL handler & schema
│   ├── schema.go              # GraphQL schema generation
│   ├── resolvers.go           # GraphQL resolvers
│   └── theme.go               # GraphiQL theming (light/dark/auto)
├── mode/
│   └── mode.go                # Application mode (production/development)
├── paths/
│   └── paths.go               # Path resolution
├── ssl/
│   └── ssl.go                 # SSL/TLS handling
├── scheduler/
│   └── scheduler.go           # Background task scheduler
├── service/                   # Systemd service management
│   └── service.go
└── admin/                     # Admin-specific functionality
    ├── admin.go               # Admin package main
    └── handler.go             # Admin handlers
```

### When to Split Files

| Split When | Into | Example |
|------------|------|---------|
| File > 500 lines | Feature-specific files | `user.go` → `user_model.go`, `user_service.go`, `user_handler.go` |
| Multiple handlers | Handler per domain | `handler.go` → `handler/user.go`, `handler/admin.go` |
| Multiple services | Service per domain | `service.go` → `service/user.go`, `service/email.go` |
| Test file > 300 lines | Test per feature | `server_test.go` → `auth_test.go`, `user_test.go` |

### Directory Purpose (Clear Naming)

| Directory | Purpose | Contains |
|-----------|---------|----------|
| `handler/` | HTTP request handlers | Route handlers, request/response logic |
| `service/` | Business logic | Core application logic, orchestration |
| `model/` | Data structures | Structs, validation, serialization |
| `store/` | Data persistence | Database queries, CRUD operations |
| `middleware/` | HTTP middleware | Auth, logging, rate limiting, CORS |
| `template/` | HTML templates | Go templates for web UI |
| `static/` | Static assets | CSS, JS, images (embedded) |
| `migration/` | DB migrations | SQL migration files |
| `swagger/` | OpenAPI/Swagger | Spec generation, UI handler, theming (always `src/swagger/`) |
| `graphql/` | GraphQL API | Schema, resolvers, UI handler, theming (always `src/graphql/`) |

### File Content Guidelines

| File Type | Should Contain | Should NOT Contain |
|-----------|----------------|-------------------|
| `{pkg}.go` | Package init, main types, core functions | HTTP handlers, tests |
| `handler.go` | HTTP handlers only | Business logic, DB queries |
| `service.go` | Business logic only | HTTP concerns, direct DB access |
| `model.go` | Struct definitions, validation | Business logic, handlers |
| `store.go` | DB operations only | Business logic, HTTP concerns |
| `middleware.go` | Request/response middleware | Business logic |
| `helpers.go` | Small utility functions | Large features, types |
| `errors.go` | Error definitions | Error handling logic |

### Naming Anti-Patterns

| Avoid | Why | Use Instead |
|-------|-----|-------------|
| `utils.go` | Too vague | `helpers.go` or feature-specific |
| `common.go` | Too vague | `types.go`, `constants.go` |
| `misc.go` | Meaningless | Split by actual purpose |
| `stuff.go` | Meaningless | Name by content |
| `v2/` | Version in path | Use API versioning in routes |
| `new_*.go` | Temporary naming | Replace old file |
| `old_*.go` | Dead code | Delete it |
| `*.bak` | Backup files | Use git |
| `*_copy.go` | Duplicates | Delete or merge |

## Boolean Handling

**See PART 5: "Boolean Handling" for the complete list of truthy/falsy values and implementation.**

Quick reference: Accept `yes/no`, `true/false`, `1/0`, `on/off`, `enable/disable`, etc. (40+ variations). Use `config.ParseBool()`.

## What NOT To Do

| NEVER | Instead |
|-------|---------|
| Use bcrypt for passwords | Use Argon2id |
| Put Dockerfile in project root | Put in `docker/Dockerfile` |
| Use .env files | Hardcode sane defaults in docker-compose |
| Run docker-compose in project dir | Use temp directory workflow |
| Skip platforms in releases | Build all 8 platforms |
| Use Makefile in CI/CD | Explicit commands with env vars |
| Modify ENTRYPOINT/CMD | Customize via entrypoint.sh |
| Use CGO | CGO_ENABLED=0 always |
| Use `strconv.ParseBool()` | Use `config.ParseBool()` for all boolean parsing |

## Files & Directories Master Rules (NON-NEGOTIABLE)

**The project directory MUST be clean, minimal, and production-ready.**

### Naming Schema

| Type | Pattern | Example | Avoid |
|------|---------|---------|-------|
| **Directories** | lowercase, singular | `handler/`, `model/` | `Handlers/`, `Models/` |
| **Go files** | lowercase, snake_case | `user_service.go` | `UserService.go` |
| **Config files** | lowercase, dot-extension | `server.yml`, `mkdocs.yml` | `SERVER.yml` |
| **Documentation** | UPPERCASE.md | `README.md`, `LICENSE.md` | `readme.md` |
| **Scripts** | lowercase, snake_case | `run_tests.sh` | `RunTests.sh` |
| **Binaries** | `{project}-{os}-{arch}` | `echoip-linux-amd64` | `echoip_linux_amd64` |

### NEVER Create These Files

| Forbidden File | Reason |
|----------------|--------|
| `SUMMARY.md` | Unnecessary - AI.md is the spec |
| `COMPLIANCE.md` | Unnecessary - compliance is in AI.md |
| `NOTES.md` | Unnecessary - notes go in AI.md |
| `CHANGELOG.md` | Use GitHub/Gitea releases instead |
| `AUDIT.md`, `REPORT.md`, `ANALYSIS.md` | Fix issues directly, don't document them |
| `CONTRIBUTING.md` in root | Belongs in `.github/` |
| `CODE_OF_CONDUCT.md` in root | Belongs in `.github/` |
| `SECURITY.md` in root | Belongs in `.github/` |
| `PULL_REQUEST_TEMPLATE.md` in root | Belongs in `.github/` |
| `Dockerfile` in root | Belongs in `docker/Dockerfile` |
| `docker-compose.yml` in root | Belongs in `docker/docker-compose.yml` |
| `*.example.*`, `*.sample.*` | No example files (defaults in binary) |
| `server.yml`, `cli.yml` | Config files are runtime-generated, never in repo |
| `.env*` | No .env files |
| `TODO.md` | Use `TODO.AI.md` for AI tasks only |

### NEVER Create These Directories

| Forbidden Directory | Reason |
|--------------------|--------|
| `config/` in root | Config is embedded, runtime-generated in OS dirs |
| `data/` in root | Data goes to OS data directory at runtime |
| `logs/` in root | Logs go to OS log directory at runtime |
| `tmp/`, `temp/` in root | Use `/tmp/apimgr/weather-XXXXXX/` |
| `test-data/` in root | Test data goes to temp directories |
| `build/`, `dist/`, `out/` | Use `binaries/` (gitignored) |
| `vendor/` | Use Go modules, not vendoring |
| `node_modules/` | This is a Go project |
| `lib/`, `libs/` | Use proper Go package structure |
| `utils/`, `common/` | Use specific package names |

**Note:** `src/data/` is ALLOWED for static JSON files embedded in binary. Only ROOT-level `data/` is forbidden.

### Allowed Root Files (Exhaustive List)

| File | Required | Purpose |
|------|:--------:|---------|
| `AI.md` | ✓ | Project specification (HOW - implementation patterns) |
| `IDEA.md` | ✓ | Project idea (WHAT - business logic, features) |
| `CLAUDE.md` | Optional | Claude Code AI configuration and settings |
| `TODO.AI.md` | Optional | AI task tracking (3+ tasks only) |
| `PLAN.AI.md` | Optional | AI implementation plan (if exists, this is THE plan) |
| `README.md` | ✓ | Public documentation |
| `LICENSE.md` | ✓ | License file |
| `Makefile` | ✓ | Build targets |
| `go.mod` | ✓ | Go module |
| `go.sum` | ✓ | Go dependencies |
| `release.txt` | ✓ | Version source of truth |
| `.gitignore` | ✓ | Git ignore rules |
| `.dockerignore` | ✓ | Docker ignore rules |
| `.gitattributes` | Optional | Git attributes |
| `Jenkinsfile` | Optional | Jenkins CI (if used) |
| `mkdocs.yml` | ✓ | MkDocs configuration |
| `.readthedocs.yaml` | ✓ | ReadTheDocs configuration |

### AI-Specific Files and Directories

| File/Directory | Required | Purpose |
|----------------|:--------:|---------|
| `.claude/` | ✓ | Claude Code configuration |
| `.claude/rules/` | ✓ | Auto-loaded rule files (ai-rules.md, build-rules.md, etc.) |
| `.claude/CLAUDE.md` | Optional | Project memory |
| `.cursor/` | Optional | Cursor AI configuration directory |
| `.aider/` | Optional | Aider AI configuration directory |
| `.ai/` | Optional | Generic AI configuration directory |
| `.windsurf/` | Optional | Windsurf AI configuration directory |
| Other AI config dirs | Optional | Any AI assistant configuration directories |

**Claude Code Rules Files (.claude/rules/):**

| File | Purpose |
|------|---------|
| `ai-rules.md` | AI behavior rules (@AI.md PART 0) |
| `directory-structure.md` | Project structure rules (@AI.md PART 4) |
| `build-rules.md` | Build/make rules (@AI.md PART 26) |
| `testing-rules.md` | Testing rules (@AI.md PART 29) |

**Note:** Claude Code auto-loads all `.md` files from `.claude/rules/` on startup.

### Allowed Root Directories (Exhaustive List)

| Directory | Required | Purpose | Gitignored |
|-----------|:--------:|---------|:----------:|
| `src/` | ✓ | All Go source code | No |
| `docker/` | ✓ | Dockerfile, compose files, rootfs overlay | No |
| `docs/` | ✓ | MkDocs documentation only | No |
| `scripts/` | ✓ | Production/install scripts | No |
| `tests/` | ✓ | Test scripts (run_tests.sh, docker.sh, incus.sh) | No |
| `.github/` | If GitHub | GitHub Actions, templates | No |
| `.gitea/` | If Gitea | Gitea Actions, templates | No |
| `.claude/` | ✓ | Claude Code config (rules/ required) | No |
| `.cursor/` | Optional | Cursor AI config | No |
| `.aider/` | Optional | Aider AI config | No |
| `binaries/` | Auto | Build output | **Yes** |
| `releases/` | Auto | Release artifacts | **Yes** |
| `rootfs/` | Auto | Runtime volume data | **Yes** |

**RULE: If a directory doesn't appear in this list, it MUST NOT exist - ask before creating.**

### GitHub-Specific Files (`.github/` directory)

| File | Location |
|------|----------|
| `CONTRIBUTING.md` | `.github/CONTRIBUTING.md` |
| `CODE_OF_CONDUCT.md` | `.github/CODE_OF_CONDUCT.md` |
| `SECURITY.md` | `.github/SECURITY.md` |
| `FUNDING.yml` | `.github/FUNDING.yml` |
| `ISSUE_TEMPLATE/` | `.github/ISSUE_TEMPLATE/` |
| `PULL_REQUEST_TEMPLATE.md` | `.github/PULL_REQUEST_TEMPLATE.md` |
| `workflows/*.yml` | `.github/workflows/` |

### Gitea-Specific Files (`.gitea/` directory)

| File | Location |
|------|----------|
| `ISSUE_TEMPLATE/` | `.gitea/ISSUE_TEMPLATE/` |
| `PULL_REQUEST_TEMPLATE.md` | `.gitea/PULL_REQUEST_TEMPLATE.md` |
| `workflows/*.yml` | `.gitea/workflows/` |

**RULE: If a file doesn't appear in the allowed list, it MUST NOT exist - ask before creating.**

---

# TERMINOLOGY

**These terms have SPECIFIC meanings in this specification. Understand them before proceeding.**

## Core Terms

**Note:** "Project", "App", and "Application" are used interchangeably throughout this document - they all refer to the complete codebase including all files, configuration, and functionality.

| Term | Definition |
|------|------------|
| **Project / App / Application** | The server binary you are building (`weather`) - used interchangeably |
| **App Instance** | A single running copy of the app (one process) |
| **Server** | The machine (physical, VM, or container) running an app instance |

## Clustering Terms

| Term | Definition |
|------|------------|
| **Cluster** | Multiple app instances sharing config and state via shared database/cache |
| **Cluster Node** | An app instance participating in a cluster (synonym: cluster member) |
| **Config Sync** | Automatic propagation of settings changes across all cluster nodes |
| **Primary Node** | The elected node that handles cluster-wide tasks (leader election) |
| **Single Instance** | App running standalone without clustering (local SQLite, no shared state) |

## Extended Functionality Terms

| Term | Definition |
|------|------------|
| **Managed Node** | An EXTERNAL resource the app controls (NOT an app instance) |
| **Extended Node Function** | What the app does with managed nodes beyond config sync |
| **HA (High Availability)** | Automatic failover for critical apps - specialized, not standard |

## Managed Nodes vs Cluster Nodes

**CRITICAL DISTINCTION:**

| Type | What It Is | Example |
|------|------------|---------|
| **Cluster Node** | Instance of YOUR app | 3 copies of `jokes` running, syncing config |
| **Managed Node** | External thing your app CONTROLS | Docker hosts that Watchtower manages |

**Most apps only have cluster nodes. Managed nodes are app-specific.**

## Examples

| App | Cluster Nodes | Managed Nodes | HA |
|-----|:-------------:|:-------------:|:--:|
| Jokes API | ✓ (app instances syncing) | ✗ | ✗ |
| Watchtower-type | ✓ (app instances syncing) | ✓ (Docker hosts) | ✗ |
| DNS Server | ✓ (app instances syncing) | ✗ | ✓ |
| Monitoring App | ✓ (app instances syncing) | ✓ (monitored servers) | ✗ |

## Account Types

| Term | Definition |
|------|------------|
| **Server Admin** | Administrative account for managing the application (NOT a privileged user) |
| **Primary Admin** | The first Server Admin created during setup wizard (cannot be deleted) |
| **Additional Admin** | Server Admins added by Primary Admin or other admins |
| **OIDC/LDAP Admin** | Server Admin access via external identity provider group mapping |
| **Regular User** | End-user account that uses the application's features |

**CRITICAL:** Server Admins and Regular Users are completely separate account types stored in different database tables. A Server Admin is NOT a "privileged user."

## Other Terms

| Term | Definition |
|------|------------|
| **CLI Client** | Optional companion binary (`weather-cli`) for terminal access |
| **TUI** | Terminal User Interface - interactive terminal app with menus/panels |
| **Admin Panel** | Web UI at `/admin` for server administration |
| **FQDN** | Fully Qualified Domain Name (e.g., `api.example.com`) |
| **Config Dir** | Where config files live (`{config_dir}`, default: `/etc/apimgr/weather`) |
| **Data Dir** | Where runtime data lives (`{data_dir}`, default: `/var/lib/apimgr/weather`) |
| **Log Dir** | Where log files live (`{log_dir}`, default: `/var/log/apimgr/weather`) |
| **Cache Dir** | Where cache files live (`{cache_dir}`, default: `/var/cache/apimgr/weather`) |
| **Backup Dir** | Where backups live (`{backup_dir}`, default: `/mnt/Backups/apimgr/weather`) |
| **PID File** | Process ID file path (`{pid_file}`, default: `/var/run/apimgr/weather.pid`) |

---


---

## How to Read This Large File

**AI.md is ~1.6MB and ~43,000 lines. You CANNOT read it all at once. Follow these procedures.**

### File Size Reality

| Constraint | Value |
|------------|-------|
| File size | ~1.6MB |
| Line count | ~43,233 lines |
| Read limit | ~500 lines per read |
| Full reads needed | ~85 reads (impractical) |

**Use the PART index to find relevant sections, then read each section COMPLETELY.**

### PART Index (Quick Reference)

**Use `grep -n "^# PART" AI.md` to get exact current line numbers.**

| PART | Line | Topic | When to Read |
|------|------|-------|--------------|
| 0 | 1241 | AI Assistant Rules | **ALWAYS READ FIRST**, **AI Behavior Rules** |
| 1 | 2931 | Critical Rules | **ALWAYS READ FIRST** |
| 2 | 3653 | License & Attribution | License requirements |
| 3 | 3992 | Project Structure | Setting up new project, **CI/CD badge detection** |
| 4 | 4750 | OS-Specific Paths | Path handling |
| 5 | 4935 | Configuration | Config file work, **Path Security** |
| 6 | 6246 | Application Modes | Mode handling, debug endpoints |
| 7 | 6854 | Binary Requirements | Binary building, **Display detection** |
| 8 | 7321 | Server Binary CLI | CLI flags/commands |
| 9 | 10066 | Error Handling & Caching | Error/cache patterns |
| 10 | 10443 | Database & Cluster | Database work |
| 11 | 10858 | Security & Logging | Security features, **Scoped Agent Tokens**, **Context Detection** |
| 12 | 12720 | Server Configuration | Server settings |
| 13 | 12987 | Health & Versioning | Health endpoints |
| 14 | 13476 | API Structure | REST/GraphQL/Route Compliance |
| 15 | 14741 | SSL/TLS & Let's Encrypt | SSL certificates |
| 16 | 15560 | Web Frontend | Frontend/UI, **Unified Response Format** |
| 17 | 18839 | Admin Panel | Admin UI, **Server Admin**, **Scoped Agents API** |
| 18 | 20865 | Email & Notifications | Email/SMTP, **SMTP Auto-Detection** |
| 19 | 22261 | Scheduler | Background tasks, **NO external schedulers**, **Backup tasks** |
| 20 | 22746 | GeoIP | GeoIP features |
| 21 | 22819 | Metrics | Metrics/monitoring |
| 22 | 23840 | Backup & Restore | Backup features, **Compliance encryption**, **Cluster backups** |
| 23 | 24547 | Update Command | Update feature |
| 24 | 24603 | Privilege Escalation & Service | Service/privilege work |
| 25 | 24990 | Service Support | Systemd/service templates |
| 26 | 25119 | Makefile | Build system, **make host** |
| 27 | 25780 | Docker | Docker/containers, **NEVER copy/symlink binaries** |
| 28 | 27136 | CI/CD Workflows | GitHub/GitLab/Gitea Actions |
| 29 | 29638 | Testing & Development | Testing/dev workflow, **100% Coverage** |
| 30 | 30946 | ReadTheDocs Documentation | Documentation |
| 31 | 31658 | I18N & A11Y | Internationalization |
| 32 | 32079 | Tor Hidden Service | Tor support, **binary controls Tor** |
| 33 | 32815 | Multi-User | **OPTIONAL** - regular user accounts/registration, vanity URLs |
| 34 | 36157 | Organizations | **OPTIONAL** - multi-user orgs, vanity URLs |
| 35 | 36801 | Custom Domains | **OPTIONAL** - user/org branded domains |
| 36 | 37824 | CLI Client & Agent | **OPTIONAL** - CLI/TUI/GUI, **Scoped Agent Tokens**, **Smart Context** |
| 37 | 41280 | Project-Specific Sections | **WHAT** (IDEA.md) - 0-36 = HOW |
| FINAL | 41605 | Compliance Checklist | Final verification, **AI Quick Reference Rules** |

**When Implementing OPTIONAL PARTs (33-36):**
1. Change PART title from `OPTIONAL` → `NON-NEGOTIABLE` in AI.md
2. Update IDEA.md to document the feature as implemented
3. Follow ALL rules in that PART exactly (no longer optional)

### How to Read This File

**Step 1: Always read these first (MANDATORY)**
- PART 0: AI ASSISTANT RULES
- PART 1: CRITICAL RULES

**Step 2: Read sections relevant to your task**

Use `grep` to find the PART you need:
```bash
grep -n "^# PART" AI.md    # List all PARTs with line numbers
grep -n "keyword" AI.md    # Find specific content
```

**Step 3: Read the specific PART completely**

Once you identify the PART, read ALL of it.

**Step 4: Return after cross-references (CRITICAL)**

When reading a PART and you encounter a reference like "See PART X" or "Read PART X":
1. **Note your current location** (PART number and approximate line)
2. Jump to the referenced PART and read it
3. **Return to your original location** and continue reading

Example: If you're reading PART 5 at line 4800 and it says "See PART 10", read PART 10, then **return to PART 5 line 4800** and continue.

**Never abandon your current PART after following a reference.**

### Reading Strategy by Task Type

| Task | Read These PARTs |
|------|------------------|
| **Migrating existing app** | 0, Migration sections, 1, 2, 6, 30 |
| **New project/app setup** | 0, New Project Rules, 1, 2, 7, 30, 34 |
| **CLI implementation** | 0, 1, 6, 8, 24 |
| **API development** | 0, 1, 14, 18, 16 |
| **Frontend/UI work** | 0, 1, 13, 17, 18 |
| **Database work** | 0, 1, 4, 10 |
| **User/auth system** | 0, 1, 15, 11 |
| **Docker/deployment** | 0, 1, 7, 30, 28 |
| **Documentation** | 0, 1, 31 |
| **Security features** | 0, 1, 11, 16 |
| **Background tasks** | 0, 1, 20 |
| **Email features** | 0, 1, 19 |
| **Backup features** | 0, 1, 23 |
| **Debugging/profiling** | 0, 1, 5 |

### Search Before Reading

**ALWAYS search first to find exactly what you need:**

```bash
# Find specific topics
grep -n "rate limit" AI.md
grep -n "CSRF" AI.md
grep -n "server.yml" AI.md

# Find code examples
grep -n "```go" AI.md
grep -n "```yaml" AI.md

# Find tables
grep -n "^|" AI.md | head -50
```

### Common Mistakes When Reading This File

| Mistake | Consequence | Correct Approach |
|---------|-------------|------------------|
| Reading sequentially from start | Context window exhausted | Use index, read specific PARTs |
| Reading only part of a PART | Missing critical details | Read complete PART sections |
| Not re-reading before implementing | Drift from spec | Always re-read relevant PART |
| Guessing instead of searching | Wrong implementation | Use grep to find answers |
| Skipping PART 0 and 1 | Missing critical rules | ALWAYS read these first |
| Adding content without searching first | Duplicate rules/content | Search for existing content before adding |
| Reading entire file at once | Context overflow, missed details | Read PART by PART, implement fully before next |

### When You Can't Find Information

1. **Search with grep** - use multiple keywords
2. **Check related PARTs** - information may be in adjacent sections
3. **Read the FINAL CHECKPOINT** - summary of all requirements
4. **ASK the user** - don't guess

---

# PART 0: AI ASSISTANT RULES (READ FIRST - NON-NEGOTIABLE)

**These rules govern how AI assistants work on projects using this specification.**

## AI.md Structure

**AI.md is the complete project specification. It has two parts:**

| Section | Purpose | Modify? |
|---------|---------|---------|
| **PARTS 0-36** | Implementation patterns, standards, rules | **NEVER** |
| **PART 37** | Your project's business logic, features | **YES** - update as project evolves |

**Rules:**
1. **Follow PARTS 0-36 exactly** - these define HOW to implement things
2. **Update PART 37** when features change - this defines WHAT your project does
3. **Keep documentation in sync** - README.md, docs/, Swagger, GraphQL must match code

## AI Behavior Rules (NON-NEGOTIABLE)

**These rules prevent wasted time and tokens. Follow them EXACTLY.**

### NEVER Guess or Assume

| Situation | WRONG | RIGHT |
|-----------|-------|-------|
| Unsure about requirement | Guess and implement | **STOP and ASK** |
| Can't find file/function | Assume location | **Search first, ask if not found** |
| Multiple valid approaches | Pick one randomly | **List options, ask user** |
| Spec seems incomplete | Fill in the blanks | **Ask for clarification** |
| "Probably works" | Ship it | **Test it, verify it** |
| Don't know the answer | Make something up | **Say "I don't know" and research** |

### NEVER Rush or Skip

| Rule | Description |
|------|-------------|
| **Read before edit** | MUST read file before modifying - no exceptions |
| **Search before create** | Check if it exists before adding |
| **Verify before claim** | NEVER say "done" without verification |
| **Test before commit** | Run tests, check output |
| **One thing at a time** | Complete current task before starting next |
| **No silent fixes** | If you find an issue, report it first |
| **No partial work** | Finish what you start or explicitly say it's incomplete |

### The Cost of Guessing

**Every wrong guess costs:**
- User time to identify the mistake
- Tokens to explain the correction
- More tokens to redo the work
- User trust and patience

**It is ALWAYS cheaper to ask than to guess wrong.**

**Math:**
- Asking a question: ~100 tokens
- Wrong implementation + explanation + redo: ~5000+ tokens
- **Asking is 50x cheaper than guessing wrong**

### Mandatory Verification Steps

**Before saying "done" on ANY task:**

```
1. [ ] Did I READ the relevant files first?
2. [ ] Did I SEARCH for existing patterns?
3. [ ] Did I TEST my changes?
4. [ ] Did I VERIFY the output?
5. [ ] Am I CERTAIN this is correct?
```

**If ANY answer is "no" → DO NOT claim completion.**

### When to STOP and ASK

**ALWAYS stop and ask when:**
- The spec doesn't cover this case
- Multiple interpretations are possible
- You're about to make an architectural decision
- You're unsure about naming/structure
- The user's intent is ambiguous
- You would need to "assume" anything
- You're about to do something destructive
- You're not 100% confident

**Question Format:**
```
I need clarification before proceeding:

1. [Specific question]?
2. [Specific question]?

Which approach do you prefer?

a) Option A - [brief description]
b) Option B - [brief description]
c) Other (please specify)
```

### Red Flags - STOP IMMEDIATELY

**If you catch yourself thinking any of these, STOP:**

| Thought | Action |
|---------|--------|
| "This is probably what they meant..." | **STOP - ASK** |
| "I'll just assume..." | **STOP - ASK** |
| "This should work..." | **STOP - TEST** |
| "They probably want..." | **STOP - ASK** |
| "I'll fix this later..." | **STOP - FIX NOW or ASK** |
| "Close enough..." | **STOP - DO IT RIGHT** |
| "I think I remember..." | **STOP - READ THE SPEC** |
| "Let me quickly..." | **STOP - SLOW DOWN** |
| "This is obvious..." | **STOP - VERIFY** |
| "I don't need to check..." | **STOP - CHECK ANYWAY** |

### Speed vs Correctness

| Priority | Value |
|----------|-------|
| **1. Correct** | A correct answer, even if slow |
| **2. Verified** | A tested answer, even if it took time |
| **3. Fast** | Speed is LAST priority |

**A fast wrong answer is WORSE than a slow correct answer.**

**Wrong answers waste:**
- User's time reading wrong output
- User's time explaining the error
- Tokens for the redo
- User's trust

### What "I Don't Know" Looks Like

**It is ACCEPTABLE to say:**

```
I'm not sure about [X]. Let me:
1. Search the codebase for existing patterns
2. Read the relevant spec section
3. Ask you for clarification if needed

Before I proceed, can you confirm [specific question]?
```

**It is UNACCEPTABLE to:**
- Make up an answer
- Pretend to know
- Guess and hope it's right
- Skip verification

### Verification Checklist (Run Every Time)

**Before EVERY response that claims completion:**

```
□ I read the relevant files (not just claimed to)
□ I searched for existing patterns
□ I tested my changes (or explained why I couldn't)
□ I verified the output matches expectations
□ I am confident this is correct
□ I did NOT guess or assume
□ I did NOT rush or skip steps
□ If unsure about anything, I asked
```

## CRITICAL: Always Reference AI.md (NON-NEGOTIABLE)

**AI.md is your source of truth. ALWAYS refer to it - NEVER guess or drift.**

| Situation | Action |
|-----------|--------|
| **Working on any task** | Reference the relevant PART in AI.md before implementing |
| **Using TODO.AI.md** | Cross-reference AI.md for every task - it has all rules |
| **Unsure about a pattern** | Read the relevant PART - don't assume or guess |
| **After working for a while** | Re-read relevant PARTs - combat drift |

**Rule:** The AI.md file contains all PARTS and rules. When in doubt, read AI.md. Never guess.

## CRITICAL: Specification Drift is Unacceptable

**AI assistants drift from specifications over time.** This means:
- Gradually deviating from documented requirements
- Inventing new patterns not in the spec
- Forgetting constraints after working for a while
- "Improving" things that don't need improvement

**This drift is the #1 cause of specification violations. Combat it actively.**

### Drift Types

| Drift Type | Example | Impact |
|------------|---------|--------|
| **Pattern drift** | Using different file structure than specified | Inconsistency across projects |
| **Naming drift** | Using different variable/function names | Code doesn't match spec |
| **Feature drift** | Adding unrequested features | Over-engineering, bugs |
| **Constraint drift** | Forgetting NON-NEGOTIABLE rules | Specification violations |
| **Format drift** | Using different date/version formats | Integration failures |

### The Solution: Constant Re-verification

**You MUST re-read relevant spec sections before EVERY implementation.**

```
BEFORE writing ANY code:
1. Identify which PART(s) of the spec apply
2. Re-read those sections completely
3. Verify your planned implementation matches EXACTLY
4. If ANY deviation is needed, ASK first
5. NEVER assume you remember correctly - ALWAYS re-check
```

### Mandatory Compliance Checks

| When | Action |
|------|--------|
| **Start of session** | Read PART 0 and PART 1, identify applicable sections |
| **Before each task** | Re-read relevant PART(s) of the spec |
| **Every 3-5 changes** | Stop and verify against spec - are you drifting? |
| **Before completing task** | Full compliance check against relevant sections |
| **If uncertain** | STOP and re-read spec, or ASK user |

### What "NON-NEGOTIABLE" Means

**NON-NEGOTIABLE sections MUST be implemented EXACTLY as specified.**

| Allowed | NOT Allowed |
|---------|-------------|
| Copy spec exactly | "Improve" or "optimize" the spec |
| Ask for clarification | Assume you know better |
| Report conflicts | Silently deviate |
| Request exceptions | Make exceptions yourself |

**If you think a NON-NEGOTIABLE section is wrong:**
1. STOP implementation
2. Tell the user specifically what you think is wrong
3. Ask for explicit permission to deviate
4. Document the deviation in AI.md if approved

### Common Drift Mistakes

| Mistake | Correct Approach |
|---------|------------------|
| "I'll use a better pattern" | Use the pattern in the spec |
| "This format makes more sense" | Use the format in the spec |
| "I remember the spec says..." | Re-read the spec, don't rely on memory |
| "This is obviously what they want" | Check the spec, ask if not covered |
| "I'll add this helpful feature" | Only implement what's requested |
| "The spec is outdated here" | Ask before deviating |

### Memory Limitations

**You will forget details from earlier reads.** Combat this by:

1. **Re-reading before implementing** - every time
2. **Noting key values** - write down important numbers/names
3. **Cross-referencing** - check multiple sections for consistency
4. **Never relying on memory** - always verify with a fresh read

## CRITICAL: Editing This Document (NON-NEGOTIABLE)

**Before adding or modifying ANY content in AI.md:**

| Step | Action | Purpose |
|------|--------|---------|
| 1 | **Search first** | `grep -n "keyword" AI.md` to check if content exists |
| 2 | **Read the PART** | Read the relevant PART completely, not just snippets |
| 3 | **Check references** | Search for related content in other PARTs |
| 4 | **Verify no duplicates** | Ensure you're not adding what already exists |
| 5 | **Update, don't duplicate** | If content exists, update it; don't add a second copy |
| 6 | **Update line numbers** | After edits, update the PART index line numbers |

**Implementation workflow:**
```
1. Read PART N completely
2. Implement PART N fully
3. Verify PART N is complete
4. Move to PART N+1
5. Repeat
```

**Never:**
- Read entire file at once (context overflow)
- Add content without searching first (duplicates)
- Skip ahead before completing current PART
- Assume content doesn't exist without searching

## CRITICAL: Always Reference The Relevant Section

**BEFORE implementing ANY feature, ALWAYS read the specific PART that covers it.**

**Rule: NEVER guess, assume, or work from memory - ALWAYS read the spec section.**

| Task | Read For Business Logic | Read For Implementation | Example |
|------|-------------------------|------------------------|---------|
| Server admin auth | N/A | PART 17: ADMIN PANEL | "Following PART 17 for admin auth, setup wizard, MFA..." |
| Multi-user (regular users) | PART 37 (if custom logic) | PART 33: MULTI-USER | "Reading PART 37 for business rules, PART 33 for implementation..." |
| Setting up UI/frontend | PART 37 (what to display) | PART 16: WEB FRONTEND | "PART 37 defines content, PART 16 defines UI patterns..." |
| Configuring SSL | N/A | PART 15: SSL/TLS & LET'S ENCRYPT | "Following PART 15 for SSL setup..." |
| Adding API endpoints | PART 37 (endpoint purpose) | PART 14: API STRUCTURE | "PART 37 defines what endpoints do, PART 14 defines how..." |
| Writing tests | PART 37 (what to test) | PART 29: TESTING & DEVELOPMENT | "PART 37 lists features to test, PART 29 defines test structure..." |
| Creating Dockerfile | N/A | PART 27: DOCKER | "Implementing per PART 27 Docker rules..." |
| Adding config options | PART 37 (what settings) | PART 5: CONFIGURATION | "PART 37 defines settings needed, PART 5 defines YAML format..." |
| CLI commands | N/A | PART 8: SERVER BINARY CLI | "Following PART 8 for CLI structure..." |

**Workflow:**
```
1. User: "Add joke rating feature"
2. AI: Reads PART 37 for business logic (what a joke rating means, validation rules)
3. AI: Reads PART 14 for API patterns (how to structure endpoints)
4. AI: Reads PART 16 for frontend patterns (how to display ratings)
5. AI: Implements using standards from PARTS 17, 20 with logic from PART 37
6. AI: Updates PART 37 with new feature, updates README.md, docs/
```

**Key Principle:**
- **PART 37 = WHAT** (business logic, data, rules)
- **PARTS 1-36 = HOW** (implementation patterns, standards)
- **AI combines both** to build features correctly

## CRITICAL: Return After Cross-References (NON-NEGOTIABLE)

**When you encounter "See PART X" or "Read PART X" while reading a section:**

1. **Note your current location** (PART number + line number)
2. **Jump to the referenced PART** and read it completely
3. **Return to your original location** and continue reading

**Example:**
```
Reading PART 5 at line 4800...
  → Encounter "See PART 10 for database details"
  → Jump to PART 10, read it
  → Return to PART 5 line 4800, continue reading
```

**NEVER abandon your current PART after following a reference. Always return.**

**DO NOT:**
- Guess how features should work
- Implement based on "standard practices"
- Work from memory of the spec
- Create patterns not in the spec
- Write verbose documentation explaining what you're doing (the spec is the documentation)
- **NEVER create unnecessary files** (no AUDIT.md, COMPLIANCE.md, SUMMARY.md, ANALYSIS.md, REPORT.md, etc.)

**The spec defines it. TODO.AI.md tracks it. No additional documentation needed.**

## CRITICAL: No Report Files - Fix The Project Instead

**NEVER create report/analysis files. ALWAYS fix the project directly.**

| WRONG | RIGHT |
|-------|-------|
| Create `AUDIT.md` with findings | Fix the issues directly |
| Create `COMPLIANCE.md` with gaps | Bring project to 100% compliance |
| Create `SUMMARY.md` of changes | Make the changes, update TODO.AI.md |
| Create `ANALYSIS.md` of problems | Solve the problems |
| Create `REPORT.md` for user | Update PART 37, fix code |

**Rules:**
- If you find compliance gaps → FIX THEM (bring to 100% compliance)
- If you need to document changes → Update PART 37 in AI.md
- If you need to track tasks → Use TODO.AI.md
- If you need to plan work → Use PLAN.AI.md (if it exists)
- The project should be WORKING, not documented as broken

**See Critical Rules: "Files & Directories Master Rules" for allowed files/directories - nothing else.**

## Check Files Process (Discovery)

**Check Files is about understanding WHAT a project is - NOT about compliance.**

**When to Check Files:**
- First encounter with a project
- Before migration
- When asked "what is this project?"
- When needing to understand project structure

**Check Files answers:**

| Question | Discovery |
|----------|-----------|
| **What type?** | Go, Node, Python, etc. |
| **What structure?** | Directories present, layout |
| **What components?** | Packages, modules, services |
| **What files exist?** | AI.md, SPEC.md, Dockerfile, go.mod, etc. |
| **What is the purpose?** | Infer from code, README, config |

**Check Files does NOT:**
- Verify compliance with spec
- Fix issues
- Compare against PART requirements
- Sync documentation

**Check Files output:**
```
Project: {name}
Type: Go API service
Structure:
  ✓ src/ - Go source code
  ✓ docker/ - Docker configuration
  ✓ docs/ - Documentation
  ✗ tests/ - Missing
Files:
  ✓ AI.md
  ✓ go.mod
  ✓ Makefile
  ✗ README.md - Missing
Purpose: {inferred from code/config}
```

**Rule:** Check Files is discovery only. For compliance verification, use the Audit process (explicit "audit" command required).

## Audit (Explicit Command Only)

**Audit is ONLY triggered when user explicitly says "audit".**

**NOT triggered by:**
- Check Files (discovery)
- Migration
- Normal development
- Reading/understanding project

**See: "Project Audit (NON-NEGOTIABLE)" section (line ~1595) for the full audit process.**

## PLAN.AI.md Completion

**When a PLAN.AI.md has been fully implemented and verified working:**

Replace the entire contents with:

```markdown
# Fully Implemented

See PART 37 in AI.md for the full project breakdown.
```

**Rules:**
- Keep the PLAN.AI.md file (don't delete it)
- Replace all planning content with the completion message above
- This signals the plan is done and PART 37 is the source of truth
- If new planning is needed later, replace the completion message with the new plan

## Project Files

| File | Purpose | Update When |
|------|---------|-------------|
| **AI.md** | Project specification | PART 37 when features change |
| **TODO.AI.md** | Task tracking | Tasks added/completed |
| **PLAN.AI.md** | Implementation plan | Planning new features |
| **README.md** | User documentation | Usage changes |

## Mandatory Compliance Schedule

| When | Action | Purpose |
|------|--------|---------|
| **Session start** | Read AI.md completely | Understand full context |
| **Before EACH task** | Re-read relevant PART(s) | Prevent drift |
| **Every 3-5 changes** | Stop, verify against spec | Catch drift early |
| **Before task completion** | Full compliance check | Ensure correctness |
| **When uncertain** | Re-read spec or ASK | Never guess |

**You MUST re-read the spec before implementing. Do NOT rely on memory.**

## Before Starting Work

1. **Read AI.md COMPLETELY** - not just parts you think are relevant
2. **Check TODO.AI.md** - see pending tasks and their priority
3. **Verify understanding** - if ANYTHING is unclear, ASK first
4. **Never assume** - when in doubt, ask the user

## During Work

1. **Re-read spec before EACH implementation** - every single time
2. **Follow spec EXACTLY** - no "improvements" without explicit permission
3. **Check yourself every 3-5 changes** - am I drifting?
4. **Update TODO.AI.md** as tasks are completed
5. **Test your changes** - don't commit untested code
6. **Keep changes focused** - one feature/fix per task
7. **If uncertain** - STOP, re-read spec, or ASK

## After Work

1. **Update AI.md** if architecture or rules changed
2. **Update TODO.AI.md** with any new tasks discovered
3. **Verify compliance** - check against the FINAL CHECKPOINT
4. **Update COMMIT_MESS** - only if files were changed (skip if no changes)

## Commit Message File (NON-NEGOTIABLE)

**AI assistants CANNOT run `git add`, `git commit`, or `git push`.** Instead, create/update the commit message file.

**File:** `{project_dir}/.git/COMMIT_MESS`

| Action | When |
|--------|------|
| **Create/Update** | Only when files were actually changed |
| **Skip** | If no files were modified (nothing to commit) |
| **Delete** | Not AI's responsibility (user deletes after commit) |

**Before writing COMMIT_MESS, verify changes exist:**
```bash
git status --porcelain  # If empty, no changes - skip COMMIT_MESS
```

**Rule:** No changes = no COMMIT_MESS. Don't create empty or unnecessary commit messages.

**Format:**
```
{emoji} Title message (max 64 chars) {emoji}

{detailed description of changes}

- Bullet point 1
- Bullet point 2
- etc.
```

**Commit Type Emojis:**

| Emoji | Type | Use For |
|-------|------|---------|
| ✨ | feat | New feature |
| 🐛 | fix | Bug fix |
| 📝 | docs | Documentation |
| 🎨 | style | Formatting, no code change |
| ♻️ | refactor | Code refactoring |
| ⚡ | perf | Performance improvement |
| ✅ | test | Adding tests |
| 🔧 | chore | Config, build, tools |
| 🔒 | security | Security fix |
| 🗑️ | remove | Removing code/files |
| 🚀 | deploy | Deployment related |
| 📦 | deps | Dependency updates |

**Example:**
```
✨ Add GeoIP country blocking feature ✨

Implement country-based access control using ip-location-db.

- Add GeoIP database download on first run
- Add scheduler task for weekly updates
- Add deny_countries config option
- Add admin panel for country management
```

## TODO.AI.md Completion (NON-NEGOTIABLE)

**When ALL items in TODO.AI.md are completed:**

1. **Empty the TODO.AI.md file** - truncate to empty (keep the file, remove all content)
2. **Write COMMIT_MESS** with the following format:

**Title Format:**
```
✅ all todo items have been completed ✅
```

**Body Format:**
```
All tasks from TODO.AI.md have been completed.

{summary of completed tasks}

- Task 1 completed
- Task 2 completed
- etc.
```

**Example:**
```
✅ all todo items have been completed ✅

All tasks from TODO.AI.md have been completed.

Implemented core server functionality and admin panel.

- Added mode package with production/development modes
- Implemented SSL certificate handling
- Created scheduler for background tasks
- Built admin panel with authentication
```

**Rules:**
- The ✅ emoji MUST be used for todo completion commits
- Title is EXACTLY: `✅ all todo items have been completed ✅`
- Body MUST summarize what was accomplished
- Empty TODO.AI.md BEFORE writing COMMIT_MESS
- File stays empty until new tasks are added

**Rules:**
- Title line: max 64 characters (including emojis)
- Blank line after title
- Detailed description follows
- Use bullet points for multiple changes
- Be specific about what changed and why

## Project Audit (NON-NEGOTIABLE)

**Audit is a FULL compliance verification. Only run when user explicitly says "audit".**

**Audit verifies:**
- Code matches spec (PARTS 0-36 patterns, PART 37 business logic)
- All project files are in sync with each other
- Documentation reflects actual implementation
- CI/CD, Docker, and infrastructure files are accurate

### When to Audit

| Trigger | Action |
|---------|--------|
| User says "audit" | Run full audit |
| User says "check compliance" | Run full audit |
| User says "verify project" | Run full audit |

**NOT an audit trigger:**
- Check Files (discovery only)
- Migration (uses Migration Checklist)
- Normal development
- Reading/understanding project

### Step 1: Code Compliance
**Does the code match the spec?**

| Check | Source | Verify |
|-------|--------|--------|
| Project structure | PART 3 | Directories exist, layout correct |
| File/directory rules | Critical Rules | No forbidden files/dirs, naming correct |
| Code patterns | Relevant PARTs | Config, server, API patterns match |
| Business logic | PART 37 | Features implemented match what PART 37 defines |
| CLI interface | PART 8 | Flags, commands, help output match spec |

### Step 2: File Sync Verification
**Do all project files reflect the SAME reality?**

| File Set | Must Match | Check For |
|----------|------------|-----------|
| **Code ↔ PART 37** | Business logic | Features in code = features in PART 37 |
| **Code ↔ README.md** | User-facing features | README describes what code actually does |
| **Code ↔ Swagger** | API routes | Annotations match actual handlers |
| **Code ↔ GraphQL** | Schema | Types/queries match actual resolvers |
| **Code ↔ docs/** | All documentation | ReadTheDocs matches implementation |
| **Code ↔ CLI --help** | Commands/flags | Help output matches actual CLI |

### Step 3: Infrastructure File Accuracy
**Do infrastructure files match the project?**

| File | Check Against | Verify |
|------|---------------|--------|
| **docker/Dockerfile** | PART 27, actual code | Build stages, packages, paths correct |
| **docker/docker-compose.yml** | PART 27, actual config | Ports, volumes, env vars match |
| **docker/docker-compose.dev.yml** | PART 27 | Dev workflow correct |
| **docker/rootfs/** | Actual entrypoint needs | Scripts match what app expects |
| **.github/workflows/*.yml** | PART 28, actual build | CI/CD builds what exists, tests what exists |
| **.gitea/workflows/*.yml** | PART 28, actual build | Same as GitHub workflows |
| **Jenkinsfile** | PART 28, actual build | Pipeline matches project |
| **Makefile** | PART 26, actual targets | Targets work, paths correct |
| **mkdocs.yml** | PART 30, docs/ structure | Nav matches actual doc files |
| **.readthedocs.yaml** | PART 30 | Config correct for project |

### Step 4: Documentation Sync
**All documentation MUST match actual code/project state AND comply with spec PART:**

| Documentation | Check Against | Spec Reference | Update If |
|---------------|---------------|----------------|-----------|
| **README.md** | Actual features, endpoints, usage | PART 3 | Features added/removed/changed |
| **Swagger/OpenAPI** | Actual API routes in code | PART 14 | Routes changed, params changed |
| **GraphQL schema** | Actual types/queries in code | PART 14 | Schema changed |
| **docs/** (ReadTheDocs) | Actual config, API, features | PART 30 | Any user-facing changes |
| **AI.md PART 37** | Actual business logic | PART 37 | Features/data models changed |
| **CLI --help** | Actual flags/commands | PART 8 | CLI changed |

### Step 5: Check Against FINAL CHECKPOINT
Read the FINAL CHECKPOINT section and verify ALL items.

### Step 6: FIX Issues (Don't Document Them)
| If Found | Action |
|----------|--------|
| Code doesn't match spec | Fix the code |
| Missing file | Create it correctly |
| Wrong pattern | Fix to match spec |
| Feature in PART 37 not implemented | Implement it |
| Feature implemented not in PART 37 | Add to PART 37 or remove code |
| README outdated | Update README.md |
| Swagger outdated | Update annotations |
| GraphQL outdated | Update schema |
| docs/ outdated | Update ReadTheDocs files |
| CI/CD outdated | Update workflow files |
| Docker files wrong | Update docker/* files |
| Makefile targets broken | Fix Makefile |

### Step 7: Track Issues in AUDIT.AI.md

**Use AUDIT.AI.md for audit tracking, NOT TODO.AI.md.**

If more than 5 issues to fix:
1. Create AUDIT.AI.md (audit-specific tracking file)
2. Log all issues found
3. Fix them one by one, marking complete as you go
4. **Delete AUDIT.AI.md when all issues resolved** (not emptied - deleted)

**AUDIT.AI.md Format:**
```markdown
# Project Audit

Started: {date}
Spec version: {line count or hash}

## Issues Found

- [ ] {component}: {issue description}
- [ ] {component}: {issue description}
- [x] {component}: {issue description} - FIXED

## Sync Required

- [ ] README.md out of sync with features
- [ ] Swagger annotations missing for new endpoint
- [x] docs/ missing new config option - FIXED

## Completed

- {component}: {what was fixed}
- {component}: {what was synced}
```

**Audit Rules:**

| Rule | Requirement |
|------|-------------|
| **Tracking file** | Use `AUDIT.AI.md` (NOT TODO.AI.md) |
| **Fix immediately** | Fix issues as found, don't just log |
| **Sync items** | Docs, Swagger, GraphQL, CI/CD must match code |
| **Completion** | Delete AUDIT.AI.md when all issues resolved |
| **No partial** | Don't leave AUDIT.AI.md with unchecked items |

### Step 8: Report to User
```
✓ Audit complete
✓ Code compliant with spec
✓ All files in sync
✓ Fixed: [list what was fixed]
✓ Project is now 100% compliant with AI.md
```

**NEVER output:** "Found X issues. Here's a list..." → FIX THEM instead.

## Common Drift Patterns to Avoid

| Drift Pattern | What You Think | What You Should Do |
|---------------|----------------|-------------------|
| Pattern improvement | "This pattern is better" | Use the pattern in spec |
| Format change | "This format is cleaner" | Use the format in spec |
| Memory reliance | "I remember it says..." | Re-read the actual spec |
| Assumption | "Obviously they want..." | Check spec, ask if unclear |
| Feature addition | "This would be helpful" | Only do what's requested |
| Spec correction | "The spec is wrong here" | Ask before any deviation |

## Attribution

| Rule | Description |
|------|-------------|
| **NEVER** | Include AI attribution in code, comments, commits, or documentation |
| **NEVER** | "authored by Claude", "generated by AI", "Co-Authored-By: Claude" |
| **ALWAYS** | Code should appear as if written by a human developer |

## Tool Access

| Access | Description |
|--------|-------------|
| Full | All tools available |
| **PROHIBITED** | `git add`, `git commit`, `git push` - AI cannot run these |
| Allowed | `git status`, `git diff`, `git log`, `git branch` (read-only) |
| **Required** | Write `{project_dir}/.git/COMMIT_MESS` file with commit message instead |

**Since AI cannot commit, it MUST write the commit message to `{project_dir}/.git/COMMIT_MESS` so the user can commit with:** `git commit -F .git/COMMIT_MESS`

## Prohibited Actions

| Action | Reason |
|--------|--------|
| **Modifying PARTS 0-36** | **Implementation patterns are fixed - NEVER modify** |
| `git add` | AI cannot stage files - write COMMIT_MESS instead |
| `git commit` | AI cannot commit - write COMMIT_MESS instead |
| `git push` | AI cannot push - user must do this |
| Deleting files without confirmation | Destructive action |
| Changing NON-NEGOTIABLE sections | Specification violation |
| Skipping validation | Security requirement |
| Hardcoding secrets | Security vulnerability |
| Using deprecated APIs | Maintainability issue |

## Code Style Rules (NON-NEGOTIABLE)

### Comment Placement

**Comments MUST always be placed ABOVE the code they describe. NEVER inline or below.**

| Placement | Allowed |
|-----------|---------|
| Above code | YES |
| Inline (same line) | NO |
| Below code | NO |

**Correct:**
```go
// Calculate the total price including tax
total := price * (1 + taxRate)

// User configuration options
type Config struct {
    // Server port number
    Port int
    // Enable debug mode
    Debug bool
}
```

**Incorrect:**
```go
total := price * (1 + taxRate) // Calculate total price - WRONG

total := price * (1 + taxRate)
// Calculate total price - WRONG (below)

type Config struct {
    Port int  // Server port - WRONG (inline)
    Debug bool // Debug mode - WRONG (inline)
}
```

**YAML comments - same rule:**
```yaml
# Enable multi-user mode
enabled: false

# User registration mode
# Options: disabled, public, private, approval
registration:
  mode: disabled
```

### Code Quality Rules

| Rule | Description |
|------|-------------|
| **No inline comments** | Comments ALWAYS go above code, NEVER on same line |
| **No magic numbers** | Use named constants |
| **No hardcoded strings** | Use constants or config |
| **Error handling** | Always handle errors, never ignore |
| **Input validation** | Validate ALL user input |
| **SQL injection** | Use parameterized queries only |
| **XSS prevention** | Escape all output in templates |
| **CSRF protection** | All forms must have CSRF tokens |

**Comment Style (NON-NEGOTIABLE):**

```yaml
# WRONG: Inline comments
enabled: true  # Enable feature
port: 8080     # Server port

# CORRECT: Comments above
# Enable feature
enabled: true

# Server port
port: 8080
```

```go
// WRONG: Inline comments
var port = 8080  // Server port
db.Exec(query, id)  // Delete user

// CORRECT: Comments above
// Server port
var port = 8080

// Delete user
db.Exec(query, id)
```

**Rule: ALL comments go on lines ABOVE the code, NEVER inline. This prevents confusion and improves readability.**

### Formatting and Indentation (NON-NEGOTIABLE)

**ALL code, responses, and files MUST be properly formatted.**

| File Type | Indentation | Trailing Newline | Format Tool |
|-----------|-------------|------------------|-------------|
| **Go** | Tabs | Single `\n` | `gofmt`, `go fmt` |
| **HTML** | 2 spaces | Single `\n` | Manual or prettier |
| **JSON** | 2 spaces | Single `\n` | `json.MarshalIndent(data, "", "  ")` |
| **YAML** | 2 spaces | Single `\n` | Manual |
| **CSS** | 2 spaces | Single `\n` | Manual or prettier |
| **JavaScript** | 2 spaces | Single `\n` | Manual or prettier |
| **Makefile** | Tabs (required) | Single `\n` | Manual |
| **Shell scripts** | 2 spaces | Single `\n` | shellcheck/shfmt |
| **Text responses** | N/A | Single `\n` | `fmt.Fprintf(w, "%s\n", text)` |

**Universal Rules:**
- **Every file** ends with exactly ONE newline character
- **Every response** (JSON, TXT, HTML, XML) ends with exactly ONE newline
- **No trailing whitespace** on any line
- **Consistent indentation** throughout each file
- **2 spaces** is default (except Go and Makefiles which use tabs)

**Examples:**

HTML (2 spaces):
```html
<html>
  <head>
    <title>Title</title>
  </head>
</html>
⏎
```

JSON (2 spaces):
```json
{
  "name": "value"
}
⏎
```

YAML (2 spaces):
```yaml
server:
  port: 80
⏎
```

**See PART 14 (API Structure) for detailed response formatting rules.**

### File Organization

| Rule | Description |
|------|-------------|
| **One package per directory** | Standard Go convention |
| **Meaningful names** | `user.go` not `u.go` |
| **Group related code** | Keep related functions together |
| **Separate concerns** | Don't mix handlers with business logic |

## Handling Ambiguity

When the specification is unclear:

1. **Check if clarified elsewhere** - search the full spec
2. **Look for similar patterns** - how are similar features handled?
3. **Ask the user** - don't guess
4. **Document the decision** - add to AI.md for future reference

## Common Mistakes to Avoid

| Mistake | Correct Approach |
|---------|------------------|
| Implementing without reading spec | Read relevant PART first |
| Assuming default values | Check spec for defined defaults |
| Using .yaml instead of .yml | Always use `server.yml` |
| Inline comments | Comments above code only |
| Skipping admin panel | ALL settings need admin UI |
| Forgetting mobile-first | Start with mobile, expand to desktop |
| Using JavaScript alerts | Use proper notification system |
| Inline CSS | Use CSS files/classes only |

---

# MIGRATING EXISTING PROJECTS

## Migration Principles (NON-NEGOTIABLE)

**The template is the source of truth. Projects conform to the template, not the other way around.**

### What Migration Does

| Action | Description |
|--------|-------------|
| **Standardizes structure** | Reorganizes files to match template directory layout |
| **Standardizes CLI** | Updates flags, commands, help output to match spec |
| **Standardizes build** | Updates Makefile, Dockerfile, CI/CD to match spec |
| **Standardizes config** | Updates config format, paths, defaults to match spec |
| **Preserves functionality** | App's core purpose and features remain intact |

### What Projects CANNOT Change

**These are defined by the template and MUST NOT be modified by projects:**

| Element | Reason |
|---------|--------|
| **CLI flags** | `--help`, `--version`, `--config`, etc. - standardized across all apps |
| **CLI commands** | `serve`, `migrate`, `--maintenance` - same interface everywhere |
| **Flag formats** | Short/long flag patterns, output formats |
| **Makefile structure** | Targets, variables, Docker commands |
| **Makefile targets** | `build`, `release`, `docker`, `test`, `dev`, `clean` |
| **CI/CD workflows** | GitHub/Gitea/Jenkins pipeline structure |
| **Directory layout** | `src/`, `docker/`, `binaries/`, etc. |
| **Config file format** | YAML structure, standard keys |
| **Health endpoints** | `/healthz`, `/api/v1/healthz` format |
| **API response format** | JSON structure, error format, pagination |

### What Projects CAN Customize

| Element | Allowed Changes | Example |
|---------|-----------------|---------|
| **Dockerfile packages** | Add packages app needs | `RUN apk add --no-cache ffmpeg` |
| **Base image** | Change if app requires | `debian:bookworm-slim` instead of `alpine` |
| **Config values** | App-specific settings | `search.engines`, `jokes.categories` |
| **Routes** | App-specific endpoints | `/api/v1/search`, `/api/v1/jokes` |
| **Database schema** | App-specific tables | `searches`, `jokes`, `engines` |
| **Business logic** | App's core functionality | Search algorithms, joke selection |
| **UI/branding** | App-specific styling | Colors, logos, page content |

### What Migration Preserves

**The template standardizes HOW the app works, not WHAT it does:**

| App Type | Template Adds | Template Preserves |
|----------|---------------|-------------------|
| **Search engine** | Standard CLI, config, build | Search functionality, engines, algorithms |
| **Jokes API** | Standard CLI, config, build | Joke database, categories, formats |
| **Meta search** | Standard CLI, config, build | All search engines, aggregation logic |
| **Monitoring** | Standard CLI, config, build | Monitored nodes, alert rules, dashboards |

**Example - Jokes API Migration:**
```
BEFORE (non-standard)              AFTER (template-compliant)
─────────────────────              ────────────────────────────
jokes                              src/main.go
config.json                        src/config/config.go
main.go                            src/server/server.go
handlers.go                        src/server/routes.go
                                   src/service/jokes.go
run.sh                             Makefile
Dockerfile                         docker/Dockerfile

--port 8080                        --address :8080 (standard flag)
--jokes-file                       server.data.jokes_file (config)

✓ All jokes preserved
✓ All categories preserved
✓ All API endpoints preserved (with standard format)
```

## Migration Process

### Step 1: Inventory Existing Project

| Check | Document |
|-------|----------|
| **Core functionality** | What does the app DO? (preserve this) |
| **Custom config** | App-specific settings (migrate to server.yml) |
| **Custom routes** | API endpoints (keep, standardize format) |
| **Dependencies** | Required packages (add to Dockerfile) |
| **Database schema** | Tables and relationships (preserve) |

### Step 2: Create Template Structure

```bash
# Create standard directories
mkdir -p src/{config,mode,paths,scheduler,server,service,ssl}
mkdir -p docker .github/workflows binaries

# Create required files
touch AI.md README.md LICENSE.md Makefile go.mod
touch docker/Dockerfile docker/docker-compose.yml
```

### Step 3: Migrate Code

| From | To | Action |
|------|-----|--------|
| Custom entry point | `src/main.go` | Rewrite with standard CLI |
| Config handling | `src/config/config.go` | Migrate to standard format |
| HTTP server | `src/server/server.go` | Use standard server setup |
| Routes | `src/server/routes.go` | Keep endpoints, standard handlers |
| Business logic | `src/service/*.go` | Minimal changes, organize by domain |

### Step 4: Migrate Configuration

**Old format (example):**
```json
{
  "port": 8080,
  "jokeFile": "/data/jokes.json",
  "enableLogging": true
}
```

**New format (template-compliant):**
```yaml
server:
  address: ":8080"
  mode: production

# App-specific section (preserved functionality)
jokes:
  data_file: "/var/lib/jokes/jokes.json"
  categories:
    - programming
    - dad
    - puns

logging:
  level: info
  format: json
```

### Step 5: Validate Migration

| Check | Validation |
|-------|------------|
| **CLI flags** | `--help` output matches template spec |
| **Config loading** | YAML config loads correctly |
| **Health checks** | `/healthz` returns correct format |
| **API format** | JSON responses match spec |
| **Build** | `make build` succeeds |
| **Docker** | `make docker` succeeds |
| **Functionality** | App still does what it's supposed to do |

## Migration Conflicts

### When Project Conflicts with Template

| Conflict | Resolution |
|----------|------------|
| **Project uses different flag** | Change to template flag, update docs |
| **Project uses different config format** | Migrate to YAML, template structure |
| **Project uses different directory layout** | Reorganize to template structure |
| **Project needs different base image** | Allowed - document reason in AI.md |
| **Project needs additional packages** | Allowed - add to Dockerfile |

### When Template Would Break Functionality

| Scenario | Solution |
|----------|----------|
| **App needs debian packages** | Use `debian:bookworm-slim` base image |
| **App needs specific runtime** | Add to Dockerfile, document in AI.md |
| **App has unique requirements** | Document exception in AI.md PART 37 |

**Rule:** If a spec requirement would genuinely break the app's core functionality, document the exception in AI.md PART 37.

## Post-Migration Checklist

- [ ] All source code in `src/` directory
- [ ] Standard CLI flags working (`--help`, `--version`, `--config`, `--data`, `--log`, `--pid`)
- [ ] Configuration in YAML format
- [ ] Makefile with all standard targets
- [ ] Dockerfile in `docker/` directory
- [ ] CI/CD workflows in place
- [ ] Health endpoints returning correct format
- [ ] API responses in standard format
- [ ] AI.md created with project specifics
- [ ] README.md updated
- [ ] **Core functionality verified working**

---

# AI MIGRATION BEHAVIOR RULES (NON-NEGOTIABLE)

**These rules govern AI behavior during migration. Violation of these rules is unacceptable.**

## The Three Laws of Migration

1. **SPEC IS LAW** - The SPEC (AI.md) is the single source of truth. No exceptions.
2. **NO INVENTION** - Never invent, assume, or hallucinate. If not in SPEC, don't add it.
3. **VERIFY EVERYTHING** - Before every change, verify it matches SPEC exactly.

## AI MUST Follow This Process

```
┌─────────────────────────────────────────────────────────────────┐
│                    MIGRATION DECISION FLOW                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   ┌──────────────┐                                              │
│   │ Read SPEC    │ ◄─── ALWAYS start here                       │
│   └──────┬───────┘                                              │
│          │                                                       │
│          ▼                                                       │
│   ┌──────────────┐     YES    ┌──────────────┐                  │
│   │ Is it in     │ ─────────► │ Implement    │                  │
│   │ the SPEC?    │            │ EXACTLY as   │                  │
│   └──────┬───────┘            │ specified    │                  │
│          │ NO                 └──────────────┘                  │
│          ▼                                                       │
│   ┌──────────────┐     YES    ┌──────────────┐                  │
│   │ Is it        │ ─────────► │ Ask user     │                  │
│   │ required?    │            │ for guidance │                  │
│   └──────┬───────┘            └──────────────┘                  │
│          │ NO                                                    │
│          ▼                                                       │
│   ┌──────────────┐                                              │
│   │ DO NOT ADD   │ ◄─── If not in SPEC, don't add it            │
│   └──────────────┘                                              │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

## Common AI Deviation Patterns (NEVER DO THESE)

| Deviation | What AI Does Wrong | Correct Behavior |
|-----------|-------------------|------------------|
| **Inventing flags** | Adds `--verbose`, `--quiet` not in SPEC | Only use flags defined in SPEC |
| **Renaming things** | Changes `--config` to `--cfg` "for brevity" | Use EXACT names from SPEC |
| **Adding features** | Adds "helpful" features not requested | Only implement what SPEC defines |
| **Changing structure** | Puts files in "better" locations | Use EXACT paths from SPEC |
| **Improving code** | "Refactors" working code to be "cleaner" | Keep working code, only change what SPEC requires |
| **Different patterns** | Uses different design patterns | Use patterns shown in SPEC |
| **Assuming defaults** | Invents default values not in SPEC | Use EXACT defaults from SPEC |
| **Adding comments** | Adds "helpful" documentation not in SPEC | Only add comments shown in SPEC |
| **Changing formats** | "Improves" JSON/YAML structure | Use EXACT format from SPEC |
| **Extra validation** | Adds "safety" checks not in SPEC | Only add validation defined in SPEC |

## AI Migration Verification Protocol

**Before EVERY file change, AI MUST verify:**

```
□ Does this change match the SPEC exactly?
□ Am I using the EXACT names/paths from SPEC?
□ Am I using the EXACT code patterns from SPEC?
□ Am I adding ONLY what the SPEC defines?
□ Have I re-read the relevant SPEC section?
```

**After EVERY file change, AI MUST verify:**

```
□ Does the result match SPEC examples exactly?
□ Did I accidentally add anything not in SPEC?
□ Did I accidentally change anything the SPEC doesn't require?
□ Would this diff surprise someone who only read the SPEC?
```

## When AI Is Unsure

| Situation | Action |
|-----------|--------|
| SPEC doesn't cover this case | **ASK USER** - never assume |
| Multiple interpretations possible | **ASK USER** - never guess |
| Seems like SPEC has an error | **ASK USER** - never "fix" it |
| Better way exists | **FOLLOW SPEC** - don't improve |
| SPEC seems outdated | **FOLLOW SPEC** - ask user if concerned |
| Project has existing pattern | **FOLLOW SPEC** - migrate to SPEC pattern |

## Migration Checklist

**AI must verify each item matches SPEC EXACTLY:**

### CLI Flags
```
□ --help output matches SPEC format exactly
□ --version output matches SPEC format exactly
□ All flags use SPEC names (no renames)
□ All flags have SPEC defaults (no invented defaults)
□ Only -h and -v have short forms
□ --debug flag exists and works per SPEC
```

### Directory Structure
```
□ src/ contains all Go source
□ src/config/config.go exists with SPEC format
□ src/config/bool.go exists with ParseBool
□ src/mode/mode.go exists with SPEC functions
□ src/server/ follows SPEC structure
□ docker/ contains all Docker files
□ docker/docker-compose.yml matches SPEC
□ docker/docker-compose.dev.yml matches SPEC
□ docker/docker-compose.test.yml matches SPEC
□ No extra directories not in SPEC
```

### Configuration
```
□ server.yml format matches SPEC exactly
□ All standard keys present
□ Boolean values use ParseBool
□ Paths use SPEC defaults
□ No invented configuration keys
```

### Code Patterns
```
□ Error handling matches SPEC examples
□ Logging matches SPEC format
□ HTTP handlers match SPEC structure
□ Middleware matches SPEC examples
□ No "improved" patterns
```

### Docker
```
□ Dockerfile matches SPEC multi-stage pattern
□ entrypoint.sh matches SPEC exactly
□ Environment variables match SPEC
□ Volume paths match SPEC
□ Temp directory workflow used
```

## Red Flags (AI Must Stop and Ask)

**See also: "AI Behavior Rules (NON-NEGOTIABLE)" at the start of PART 0 for general red flags.**

**Migration-specific red flags - STOP and ask user:**

- "I think we should..." → STOP - follow SPEC instead
- "It would be better to..." → STOP - follow SPEC instead
- "Let me improve..." → STOP - follow SPEC instead
- "I'll add a helper for..." → STOP - is it in SPEC?
- "This could be cleaner if..." → STOP - follow SPEC instead
- "Let me refactor..." → STOP - only if SPEC requires it
- "I noticed the SPEC doesn't have..." → STOP - ask user
- "The existing code does X but SPEC says Y..." → Follow SPEC, ask if unsure

## AI Question Format (NON-NEGOTIABLE)

**When AI asks user a question, ALWAYS use numbered or lettered options for easy selection:**

```
Question text here?

1) First option
2) Second option
3) Third option
4) Other (specify)

Enter choice [1-4]:
```

**Or with letters:**

```
Which database should be used?

a) SQLite (recommended for single-node)
b) PostgreSQL (recommended for cluster)
c) MySQL/MariaDB
d) Other (specify)

Enter choice [a-d]:
```

**Rules:**
- Always number (1, 2, 3) or letter (a, b, c) options
- User can simply type `2` or `b` instead of full answer
- Include "Other" option when appropriate
- Show valid range: `[1-4]` or `[a-d]`
- Put recommended option first with "(recommended)" suffix

## Migration Success Criteria

**Migration is ONLY complete when:**

1. `grep -r "TODO\|FIXME\|XXX" src/` returns nothing migration-related
2. Every file matches a SPEC example or template
3. `--help` output is character-for-character correct
4. All tests pass
5. Build succeeds with no warnings
6. Docker build succeeds
7. User has verified core functionality works
8. No code exists that isn't defined or implied by SPEC

## Final Migration Verification

```bash
# AI should run these checks and report results:

# 1. Verify CLI
./binaries/weather --help
./binaries/weather --version

# 2. Verify build
make clean && make build

# 3. Verify Docker
make docker

# 4. Verify structure
find src -name "*.go" | head -20
ls -la docker/

# 5. Verify no deviations
# Compare key files against SPEC examples
```

**Remember: The SPEC is not a suggestion. It is the law. Follow it exactly.**

---

# AI NEW PROJECT IMPLEMENTATION RULES (NON-NEGOTIABLE)

**These rules govern AI behavior when creating new projects/apps. Same strictness as migration.**

## Terminology

**"Project" and "App" are used interchangeably throughout this document.**

| Term | Meaning |
|------|---------|
| Project | The complete codebase, including all files and configuration |
| App | Same as project - the application being built |
| Application | Same as project/app |

## The Three Laws of Implementation

1. **SPEC IS LAW** - Every section of this SPEC must be implemented. No exceptions.
2. **NO INVENTION** - Never invent, assume, or hallucinate. If not in SPEC, don't add it.
3. **COMPLETE COVERAGE** - All non-optional sections MUST be implemented fully.

## Section Implementation Requirements

### MANDATORY Sections (Must Implement ALL)

| PART | Section | Required |
|------|---------|----------|
| 0 | AI Assistant Rules | ✅ Follow always |
| 1 | Critical Rules | ✅ Follow always |
| 2 | License & Attribution | ✅ Implement fully |
| 3 | Project Structure | ✅ Implement fully |
| 4 | OS-Specific Paths | ✅ Implement fully |
| 5 | Configuration | ✅ Implement fully |
| 6 | Application Modes | ✅ Implement fully |
| 7 | Binary Requirements | ✅ Implement fully |
| 8 | Server Binary CLI | ✅ Implement fully |
| 9 | Error Handling & Caching | ✅ Implement fully |
| 10 | Database & Cluster | ✅ Implement fully |
| 11 | Security & Logging | ✅ Implement fully |
| 12 | Server Configuration | ✅ Implement fully |
| 13 | Health & Versioning | ✅ Implement fully |
| 14 | API Structure | ✅ Implement fully |
| 15 | SSL/TLS & Let's Encrypt | ✅ Implement fully |
| 16 | Web Frontend | ✅ Implement fully |
| 17 | Admin Panel | ✅ Implement fully |
| 18 | Email & Notifications | ✅ Implement fully |
| 19 | Scheduler | ✅ Implement fully |
| 20 | GeoIP | ✅ Implement fully |
| 21 | Metrics | ✅ Implement fully |
| 22 | Backup & Restore | ✅ Implement fully |
| 23 | Update Command | ✅ Implement fully |
| 24 | Privilege Escalation & Service | ✅ Implement fully |
| 25 | Service Support | ✅ Implement fully |
| 26 | Makefile | ✅ Implement fully |
| 27 | Docker | ✅ Implement fully |
| 28 | CI/CD Workflows | ✅ Implement fully |
| 29 | Testing & Development | ✅ Implement fully |
| 30 | ReadTheDocs Documentation | ✅ Implement fully |
| 31 | I18N & A11Y | ✅ Implement fully |
| 32 | Tor Hidden Service | ✅ Implement fully |
| 37 | Project-Specific Sections | ✅ Customize for project (NON-NEGOTIABLE) |
| FINAL | Compliance Checklist | ✅ Verify all items |

### OPTIONAL Sections (Become NON-NEGOTIABLE When Implemented)

**IMPORTANT:** Optional sections are a per-project decision. However, once a project implements an optional feature, that entire PART becomes NON-NEGOTIABLE and must be followed exactly.

| PART | Section | When to Include |
|------|---------|-----------------|
| 33 | Multi-User | If project needs regular user accounts, registration, profiles |
| 34 | Organizations | If project needs multi-user orgs (requires PART 33 first) |
| 35 | Custom Domains | If users/orgs need branded domains |
| 36 | CLI Client | If project needs command-line client tool |

### Optional Section Decision Guide

**PART 33: Multi-User**

| Include | Skip | Reason |
|---------|------|--------|
| Apps with regular user accounts | Admin-only APIs (jokes, quotes) | End-users need registration/login |
| Multi-tenant platforms | Simple data APIs | User-specific data storage |
| Social features | Read-only services | Profiles, preferences, API tokens |

**Note:** Server Admin authentication (setup wizard, admin accounts, MFA) is in PART 17 and is **mandatory** for all projects. PART 33 is only for regular end-user features.

**PART 34: Organizations** (requires PART 33)

| Include | Skip | Reason |
|---------|------|--------|
| Team collaboration | Single-user apps | Multiple users share resources |
| B2B platforms | Consumer apps | Org-level billing, admin |
| Workspace-based apps | Personal tools | Shared workspaces needed |

**PART 35: Custom Domains** (see PART 35 for full decision table)

| Include | Skip | Reason |
|---------|------|--------|
| Linktree clone | Weather API | Users want branded URLs |
| Blog platform | Jokes API | Content published under user's domain |

**PART 36: CLI Client**

| Include | Skip | Reason |
|---------|------|--------|
| API with complex queries | Simple web-only app | Power users need CLI access |
| DevOps/admin tools | Consumer mobile app | Automation requires CLI |
| Database management | Static content site | Bulk operations via CLI |

**Once implemented, the optional PART becomes NON-NEGOTIABLE.**

## AI Implementation Process

```
┌─────────────────────────────────────────────────────────────────┐
│                 NEW PROJECT IMPLEMENTATION FLOW                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   ┌──────────────────┐                                          │
│   │ 1. Read SPEC     │ ◄─── Read ALL mandatory sections         │
│   └────────┬─────────┘                                          │
│            │                                                     │
│            ▼                                                     │
│   ┌──────────────────┐                                          │
│   │ 2. Determine     │ ◄─── Decide CLI client, Custom domains   │
│   │    optional      │                                          │
│   └────────┬─────────┘                                          │
│            │                                                     │
│            ▼                                                     │
│   ┌──────────────────┐                                          │
│   │ 3. Implement     │ ◄─── Follow SPEC exactly for each PART   │
│   │    each PART     │                                          │
│   └────────┬─────────┘                                          │
│            │                                                     │
│            ▼                                                     │
│   ┌──────────────────┐                                          │
│   │ 4. Verify each   │ ◄─── Check against SPEC before next PART │
│   │    PART complete │                                          │
│   └────────┬─────────┘                                          │
│            │                                                     │
│            ▼                                                     │
│   ┌──────────────────┐                                          │
│   │ 5. Final check   │ ◄─── Run FINAL compliance checklist      │
│   └──────────────────┘                                          │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

## Common AI Implementation Mistakes (NEVER DO THESE)

| Mistake | What AI Does Wrong | Correct Behavior |
|---------|-------------------|------------------|
| **Skipping sections** | "This project doesn't need X" | Implement ALL mandatory sections |
| **Partial implementation** | Implements only "important" parts | Implement EVERY detail in SPEC |
| **Jumping around** | Starts feature, jumps to another | Complete CURRENT feature fully first |
| **Inventing structure** | Creates own directory layout | Use EXACT structure from SPEC |
| **Custom CLI flags** | Adds project-specific flags | Only use flags defined in SPEC |
| **Different config format** | Uses JSON instead of YAML | Use EXACT format from SPEC |
| **Skipping Docker files** | "We'll add Docker later" | Docker is mandatory, implement now |
| **Missing CI/CD** | "Not needed for MVP" | CI/CD is mandatory, implement now |
| **Custom error format** | Invents error response structure | Use EXACT format from SPEC |
| **Simplified health** | Returns just `{"status":"ok"}` | Implement FULL health response |
| **Skipping admin panel** | "Users don't need admin" | Admin panel is mandatory |

## Implementation Discipline (NON-NEGOTIABLE)

**AI MUST NOT jump around. Complete each feature FULLY before moving to the next.**

### The Rules

| Rule | Description |
|------|-------------|
| **ONE thing at a time** | Finish current task completely before starting another |
| **No partial implementations** | Every feature must be 100% complete per SPEC |
| **No "I'll come back to this"** | There is no coming back - do it NOW |
| **No "good enough"** | SPEC defines done, not AI judgment |
| **No skipping "minor" details** | Every detail in SPEC is required |

### What "Complete" Means

A feature is ONLY complete when:
```
□ ALL code written per SPEC
□ ALL error handling implemented
□ ALL edge cases covered
□ ALL tests pass (if applicable)
□ ALL documentation updated
□ Matches SPEC exactly - not "similar to" or "based on"
```

### Jumping Around = Failure

```
BAD (jumping around):
1. Start implementing CLI flags
2. "Oh, I should set up the database first"
3. Start database, half done
4. "Actually, let me do the config file"
5. Config half done
6. "Now back to CLI..."
Result: Nothing works, everything is half-done

GOOD (sequential completion):
1. Implement CLI flags completely per SPEC
2. Verify CLI flags match SPEC exactly
3. Move to next feature
4. Implement next feature completely per SPEC
5. Verify it matches SPEC exactly
6. Continue...
Result: Each feature works, builds on previous
```

### When Stuck

If blocked on current feature:
1. **ASK** - don't jump to something else
2. **State what's blocking** - be specific
3. **Wait for guidance** - don't assume

**NEVER:** "I'll skip this for now and come back later"
**ALWAYS:** "I'm blocked on X because Y. How should I proceed?"

## Implementation Verification Protocol

**After implementing EACH section, verify:**

```
□ Did I implement EVERY item in this section?
□ Does my implementation match SPEC examples exactly?
□ Did I use the EXACT file names and paths?
□ Did I use the EXACT code patterns shown?
□ Did I copy configuration formats exactly?
□ Are there any TODO/FIXME comments left?
```

## New Project Completion Checklist

**Project is ONLY complete when ALL are true:**

### Structure
```
□ src/ directory with all required packages
□ docker/ directory with all required files
□ All root files present (AI.md, README.md, LICENSE.md, Makefile, go.mod)
□ No extra files/directories not in SPEC
```

### Core Features
```
□ CLI flags match SPEC exactly (--help, --version, --config, etc.)
□ Configuration in server.yml format
□ Health endpoints return SPEC format
□ API responses match SPEC format
□ Error responses match SPEC format
```

### Infrastructure
```
□ Dockerfile matches SPEC multi-stage pattern
□ docker-compose.yml, docker-compose.dev.yml, docker-compose.test.yml present
□ entrypoint.sh matches SPEC exactly
□ Makefile has all required targets
□ CI/CD workflows in place
```

### Security & Operations
```
□ Mode detection (production/development) working
□ Debug flag (--debug/DEBUG) working
□ SSL/TLS support implemented
□ User authentication implemented
□ Admin panel implemented
□ Logging in SPEC format
```

### Optional (if included)
```
□ CLI client follows SPEC (if PART 36 included)
□ Custom domains follows SPEC (if PART 35 included)
```

## What To Do When Stuck

| Situation | Action |
|-----------|--------|
| SPEC section unclear | **ASK USER** - never interpret |
| Don't know if optional applies | **ASK USER** with reasoning |
| Seems like a lot of work | **IMPLEMENT ANYWAY** - SPEC is complete |
| Project seems simple | **IMPLEMENT FULLY** - all projects need all sections |
| User says "just basic version" | **CLARIFY** - SPEC defines what basic means |

**Remember: Every project, no matter how "simple", implements the full SPEC. There is no "lite" version.**

---


# PART 1: CRITICAL RULES (NON-NEGOTIABLE)

## Full Web Application Architecture (NON-NEGOTIABLE)

**This is a FULL web application with both frontend AND backend.**

Every feature MUST work via:
1. **Web browser** - HTML pages, forms, interactive UI
2. **PWA (Progressive Web App)** - Installable, offline-capable, native-like experience
3. **API clients** - JSON for curl, wget, automation, scripts
4. **CLI clients** - Dedicated command-line tools (if PART 36 implemented)

| Client Type | Examples | Response Format |
|-------------|----------|-----------------|
| **Browser** | Chrome, Firefox, Safari | HTML (pretty UI) |
| **PWA** | Installed web app (desktop/mobile) | HTML (same as browser) |
| **API/Automation** | curl, wget, scripts, integrations | JSON |
| **CLI tool** | `weather-cli` | Text/JSON (configurable) |

**Why we support all these clients:**
- Browser users get a full web experience
- PWA users get installable, offline-capable apps without app store
- Automation/scripts get clean JSON APIs
- Power users get dedicated CLI tools

**Endpoint Pattern (applies to ENTIRE app):**
| Web Route (HTML) | API Route (JSON) | Purpose |
|------------------|------------------|---------|
| `/` | `/api/v1/` | Homepage / API root |
| `/healthz` | `/api/v1/healthz` | Health status (both exist independently) |
| `/{adminpath}/dashboard` | `/api/v1/admin/dashboard` | Admin dashboard |
| `/{adminpath}/server/settings` | `/api/v1/admin/server/settings` | Server settings |
| `/{adminpath}/users` | `/api/v1/admin/users` | User management |
| `/quotes` | `/api/v1/quotes` | Project feature (example) |
| `/quotes/random` | `/api/v1/quotes/random` | Project feature (example) |
| `/openapi` | `/openapi.json` | API documentation (root-level, not /api/v1/) |
| `/graphql` | `/api/v1/graphql` | GraphQL endpoint |

**This pattern applies to ALL features:**
- Every admin page has a corresponding admin API
- Every public page has a corresponding public API
- Project-specific features (PART 37) follow same pattern

**Rule:** For every web page, there's a corresponding API endpoint. For every API endpoint, the data can be displayed in a web page.

---

## Working Roles

When working on this project, the following roles are assumed based on the task:

- **Senior Go Developer** - Writing production-quality Go code, making architectural decisions, following best practices, optimizing performance
- **UI/UX Designer** - Creating professional, functional, visually appealing interfaces with excellent user experience
- **Beta Tester** - Testing applications, finding bugs, edge cases, and issues before they reach users
- **User** - Thinking from the end-user perspective, ensuring things are intuitive and work as expected

These are not roleplay - they ARE these roles when the work requires it. Each project gets the full expertise of all four perspectives.

---

## CRITICAL: Specification Compliance

**STOP AND READ THIS SECTION COMPLETELY BEFORE PROCEEDING.**

### The Golden Rules

1. **Re-read this spec periodically** during work to ensure accuracy and no deviation
2. **When in doubt, check the spec** - the spec is the source of truth
3. **Never assume or guess** - ask questions if unclear
4. **Every NON-NEGOTIABLE section MUST be implemented exactly as specified**
5. **Keep AI.md in sync with the project** - always update after changes
6. **NEVER install Go on host** - ALL builds use Docker, testing uses Docker or Incus

### Container-Only Development (NON-NEGOTIABLE)

**The host system does NOT have Go installed. NEVER attempt to run `go` commands directly.**

| Task | Container | Notes |
|------|-----------|-------|
| **Building** | Docker `golang:alpine` | ALWAYS - Go compilation |
| **Unit tests** | Docker `golang:alpine` | `go test` commands |
| **Quick testing** | Docker `alpine:latest` | Fast, ephemeral |
| **Full OS testing** | Incus `debian:latest` | PREFERRED - systemd, services |
| **Debugging** | Incus `debian:latest` | PREFERRED - persistent, SSH-able |

```bash
# CORRECT - Use Makefile targets
make dev                    # Quick build to {tempdir}/apimgr.XXXXXX/weather
make host                   # Build with version info to binaries/
make build                  # Full cross-platform build to binaries/
make test                   # Run unit tests

# CORRECT - Integration tests
./tests/run_tests.sh        # Auto-detects incus/docker
./tests/incus.sh            # Full OS test with systemd (PREFERRED)

# WRONG - Never run go directly on host
go build -o binary/weather ./src
```

**See PART 29: TESTING & DEVELOPMENT for full containerized build/test procedures.**

---

## Security-First Design (NON-NEGOTIABLE)

**Every project follows security-first design. Security MUST NOT compromise usability.**

### Core Security Principles

| Principle | Description |
|-----------|-------------|
| **Never Trust Input** | All input is validated before use - never executed directly |
| **Defense in Depth** | Multiple layers of security, not single points of failure |
| **Least Privilege** | Minimal permissions required for each operation |
| **Fail Secure** | On error, deny access rather than grant it |
| **Secure by Default** | Safe defaults, user opts-in to less secure options |
| **Suggest, Don't Block** | Recommend security features (MFA), never force them |
| **Friction-Free Security** | Security should enhance, not impede, the user experience |

**Security suggestions (not requirements):**

*For Server Admins (all projects):*
- First admin login: prompt to enable TOTP/Passkey (can skip)
- Admin panel: show security score/recommendations widget
- Periodic reminders for admins without MFA (dismissable)
- Clear benefits explained: "Protect your admin account with 2FA"

*For Users (projects with user registration):*
- Post-registration: prompt to enable TOTP/Passkey (can skip)
- First login after registration: gentle MFA setup reminder
- User settings: security section with MFA setup and recommendations
- Clear benefits: "Secure your account with two-factor authentication"
- Never block access or features for users without MFA

### Input Validation (NON-NEGOTIABLE)

**All input is SEARCHED, never EXECUTED.**

| Rule | Implementation |
|------|----------------|
| **Validate everything** | Type, length, format, range - before processing |
| **Sanitize for context** | HTML-encode for HTML, SQL-parameterize for SQL |
| **Reject unknown** | Whitelist allowed values, reject everything else |
| **No direct execution** | Never pass user input directly to shell, SQL, eval |

```go
// CORRECT - Parameterized query
db.Query("SELECT * FROM users WHERE email = ?", email)

// WRONG - SQL injection vulnerable
db.Query("SELECT * FROM users WHERE email = '" + email + "'")
```

### Attack Prevention

| Attack Type | Prevention |
|-------------|------------|
| **SQL Injection** | Parameterized queries ONLY - never string concatenation |
| **XSS** | HTML-escape all user content, CSP headers |
| **CSRF** | CSRF tokens for all state-changing forms |
| **Command Injection** | Never shell out with user input, use libraries |
| **Path Traversal** | Validate paths, use `filepath.Clean()`, reject `..` |
| **Enumeration** | Consistent timing, vague auth errors, rate limiting |
| **DDoS** | Rate limiting, request size limits, timeouts |

### Rate Limiting Defaults

| Endpoint Type | Limit | Window | Response |
|---------------|-------|--------|----------|
| **Login attempts** | 5 | 15 minutes | 429 + lockout |
| **Password reset** | 3 | 1 hour | 429 + silent (no email hint) |
| **API (authenticated)** | 100 | 1 minute | 429 + Retry-After header |
| **API (unauthenticated)** | 20 | 1 minute | 429 + Retry-After header |
| **Registration** | 5 | 1 hour | 429 |
| **File upload** | 10 | 1 hour | 429 |

### Error Message Rules

**Different audiences need different levels of detail:**

| Destination | Detail Level | Purpose |
|-------------|--------------|---------|
| **User (WebUI/API)** | Minimal, helpful | Guide user to fix issue, no internals |
| **Admin (Panel)** | Actionable | Enough to diagnose, no stack traces |
| **Console (stdout)** | Full | Debugging during development |
| **Log file** | Full + context | Structured, timestamps, request IDs |
| **Audit log** | Who/what/when | Security events, compliance |

**Error Messages by Context:**

| Error Type | User Sees | Admin Sees | Log Contains |
|------------|-----------|------------|--------------|
| **Invalid email format** | "Please enter a valid email address" | Same | `validation_error: email format invalid, input=[redacted]` |
| **Login failed (wrong password)** | "Invalid credentials" | "Login failed for user@example.com" | `auth_failure: user_id=123, ip=1.2.3.4, reason=invalid_password` |
| **Login failed (no such user)** | "Invalid credentials" | "Login attempt for unknown user" | `auth_failure: email=[redacted], ip=1.2.3.4, reason=user_not_found` |
| **Rate limited** | "Too many attempts. Try again in 5 minutes" | "Rate limit hit: login, IP 1.2.3.4" | `rate_limit: endpoint=/auth/login, ip=1.2.3.4, limit=5/15m` |
| **Database error** | "An error occurred. Please try again" | "Database connection failed" | `db_error: connection refused, host=db.local:5432, err=[full error]` |
| **Permission denied** | "Access denied" | "User lacks permission: admin.settings" | `authz_failure: user_id=123, resource=admin.settings, action=write` |
| **Internal panic** | "An unexpected error occurred" | "Internal error - check logs" | `panic: [full stack trace], request_id=abc123` |

**Console Output (Development):**
```
[ERROR] 2025-01-15 10:30:45 database connection failed
        host: localhost:5432
        error: connection refused
        stack: main.go:123 → db.go:45 → connect.go:12
```

**Log File (Production):**
```json
{
  "level": "error",
  "time": "2025-01-15T10:30:45Z",
  "request_id": "abc123",
  "component": "database",
  "message": "connection failed",
  "host": "db.local:5432",
  "error": "connection refused",
  "stack": "..."
}
```

**User Response (API):**
```json
{
  "error": "Service temporarily unavailable",
  "code": "SERVICE_ERROR",
  "retry_after": 30
}
```

**Never reveal to users:**
- Whether a username/email exists (use "If account exists, email sent")
- Database structure, table names, or query details
- Internal IP addresses, hostnames, or ports
- Stack traces or file paths
- Dependency versions or internal service names
- Specific reason for auth failures (user not found vs wrong password)

### Security vs Usability Balance

| Scenario | Security Need | Usability Solution |
|----------|---------------|-------------------|
| Strong passwords | Prevent weak passwords | Show strength meter, suggest improvements |
| Session timeout | Limit exposure | Warn before timeout, extend on activity |
| Rate limiting | Prevent abuse | Clear error message with retry time |
| CAPTCHA | Prevent bots | Only after failed attempts, not first try |
| 2FA | Account security | Remember device option (30 days) |

---

## Code Style & Naming (NON-NEGOTIABLE)

**All code must be written as if by a human - clear, readable, and maintainable.**

### Naming Conventions

| Element | Convention | Example |
|---------|------------|---------|
| **Files** | `lowercase_snake.go` | `user_handler.go`, `email_service.go` |
| **Packages** | `lowercase` (single word preferred) | `server`, `config`, `auth` |
| **Public functions/types** | `PascalCase` | `GetUserByEmail()`, `UserService` |
| **Private functions/types** | `camelCase` | `validateInput()`, `dbConnection` |
| **Constants** | `PascalCase` or `SCREAMING_SNAKE` | `MaxRetries`, `DEFAULT_TIMEOUT` |
| **Variables** | `camelCase` | `userEmail`, `isValid`, `retryCount` |
| **Interfaces** | `PascalCase` + `-er` suffix | `Reader`, `UserStore`, `Authenticator` |

### Naming Rules

| Rule | Good | Bad |
|------|------|-----|
| **Descriptive** | `getUserByEmail()` | `getUBE()`, `fetch()` |
| **No abbreviations** | `configuration` | `cfg`, `conf` |
| **Exceptions allowed** | `ID`, `URL`, `API`, `HTTP`, `HTML`, `JSON`, `SQL`, `CSS`, `JS` | |
| **Verb for functions** | `CreateUser()`, `ValidateEmail()` | `User()`, `Email()` |
| **Noun for types** | `UserService`, `EmailValidator` | `DoUser`, `Validating` |
| **Boolean prefix** | `isValid`, `hasAccess`, `canDelete` | `valid`, `access`, `delete` |

### Code Readability

| Rule | Description |
|------|-------------|
| **Self-documenting** | Code should explain itself through clear naming |
| **Comments for why** | Comment WHY, not WHAT (code shows what) |
| **Single responsibility** | Each function does one thing well |
| **Short functions** | Max ~50 lines, extract if longer |
| **Early returns** | Return early for errors, avoid deep nesting |
| **Consistent formatting** | Use `go fmt`, never manual formatting |

```go
// GOOD - Clear, self-documenting
func GetUserByEmail(email string) (*User, error) {
    if !isValidEmail(email) {
        return nil, ErrInvalidEmail
    }

    user, err := db.FindUserByEmail(email)
    if err != nil {
        return nil, fmt.Errorf("finding user: %w", err)
    }

    return user, nil
}

// BAD - Cryptic, unclear
func gUBE(e string) (*U, error) {
    if !chk(e) {
        return nil, err1
    }
    u, err := d.f(e)
    if err != nil {
        return nil, err
    }
    return u, nil
}
```

### Project Structure Naming

| Directory | Purpose | Naming |
|-----------|---------|--------|
| `src/server/` | HTTP server | `server.go`, `routes.go`, `middleware.go` |
| `src/config/` | Configuration | `config.go`, `defaults.go`, `validate.go`, `bool.go` |
| `src/service/` | Business logic | `user_service.go`, `auth_service.go` |
| `src/mode/` | Run modes | `mode.go`, `production.go`, `development.go` |
| `src/signal/` | Signal handling | `signal.go`, `signal_unix.go`, `signal_windows.go` |

---

### Required Documentation Files

| File | Location | Purpose | Modify? |
|------|----------|---------|---------|
| **AI.md** | Project repository | Project specification | **YES** (PART 37 only) |
| **TODO.AI.md** | Project repository | Task tracking (3+ tasks) | **YES** |
| **PLAN.AI.md** | Project repository | Implementation plan | **YES** |

### Documentation Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **PARTS 0-36 are READ-ONLY** | Implementation patterns - never modify |
| **PART 37 is the project spec** | Update when features change |
| **Keep documentation current** | Update when project state changes |
| **TODO.AI.md for 3+ tasks** | Required when doing 3 or more tasks |

**File Structure:**
```
AI.md (project specification)
    └── TODO.AI.md (task tracking, each repository)
```

### README.md (NON-NEGOTIABLE)

**README.md MUST always be kept updated. Update after ANY feature change, bug fix, or configuration change.**

#### Section Order (MUST follow this order)

1. **Title & Badges** - Project name, build status, version badges
2. **About** - Brief description of what the project does
3. **Official Site** - Link to official site (if defined, e.g., `https://weather.apimgr.us`)
4. **Features** - Key features list
5. **Production** - Production deployment instructions (Docker, binary, systemd)
6. **CLI Client** - Client CLI installation and usage (if applicable)
7. **Configuration** - Key configuration options
8. **API** - API endpoints summary (if applicable)
9. **Other** - Additional info (troubleshooting, FAQ, etc.)
10. **Development** - Development setup (ALWAYS LAST - for contributors only)
11. **License** - License info

#### CI/CD Badge Detection (NON-NEGOTIABLE)

**The build status badge MUST match the project's hosting platform.**

Detect platform by checking for workflow files in this order:

| Priority | Check For | Platform | Badge Format |
|----------|-----------|----------|--------------|
| 1 | `.github/workflows/*.yml` | GitHub | GitHub Actions badge |
| 2 | `.gitea/workflows/*.yml` | Gitea/Forgejo | Gitea Actions badge |
| 3 | `.gitlab-ci.yml` | GitLab | GitLab CI badge |
| 4 | `Jenkinsfile` | Jenkins | Jenkins badge |

**Badge Templates by Platform:**

```markdown
# GitHub Actions
[![Build](https://github.com/apimgr/weather/actions/workflows/build.yml/badge.svg)](https://github.com/apimgr/weather/actions/workflows/build.yml)

# Gitea/Forgejo Actions
[![Build](https://git.example.com/apimgr/weather/actions/workflows/build.yml/badge.svg)](https://git.example.com/apimgr/weather/actions)

# GitLab CI
[![Build](https://gitlab.com/apimgr/weather/badges/main/pipeline.svg)](https://gitlab.com/apimgr/weather/-/pipelines)

# Jenkins
[![Build](https://jenkins.example.com/buildStatus/icon?job=apimgr/weather)](https://jenkins.example.com/job/apimgr/job/weather/)
```

**Release/License badges also adapt to platform:**

```markdown
# GitHub
[![Release](https://img.shields.io/github/v/release/apimgr/weather)](https://github.com/apimgr/weather/releases)
[![License](https://img.shields.io/github/license/apimgr/weather)](LICENSE.md)

# GitLab
[![Release](https://gitlab.com/apimgr/weather/-/badges/release.svg)](https://gitlab.com/apimgr/weather/-/releases)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE.md)

# Gitea/Forgejo (use shields.io with custom endpoint or static badge)
[![Release](https://img.shields.io/badge/dynamic/json?url=https://git.example.com/api/v1/repos/apimgr/weather/releases/latest&query=$.tag_name&label=release)](https://git.example.com/apimgr/weather/releases)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE.md)
```

**Platform-Specific URLs:**

| Resource | GitHub | GitLab | Gitea/Forgejo |
|----------|--------|--------|---------------|
| Repository | `https://github.com/{org}/{repo}` | `https://gitlab.com/{org}/{repo}` | `https://git.example.com/{org}/{repo}` |
| Raw file | `https://raw.githubusercontent.com/{org}/{repo}/main/{path}` | `https://gitlab.com/{org}/{repo}/-/raw/main/{path}` | `https://git.example.com/{org}/{repo}/raw/branch/main/{path}` |
| Release download | `https://github.com/{org}/{repo}/releases/latest/download/{file}` | `https://gitlab.com/{org}/{repo}/-/releases/permalink/latest/downloads/{file}` | `https://git.example.com/{org}/{repo}/releases/download/latest/{file}` |
| Container registry | `ghcr.io/{org}/{repo}` | `registry.gitlab.com/{org}/{repo}` | `git.example.com/{org}/{repo}` |

#### README Template

**Use the appropriate badges and URLs for your platform (see above).**

```markdown
# weather

{PLATFORM_BUILD_BADGE}
{PLATFORM_RELEASE_BADGE}
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE.md)

## About

{Brief description of what the project does - 1-3 sentences}

## Official Site

https://weather.apimgr.us

## Features

- Feature 1
- Feature 2
- Feature 3

## Production

### Docker (Recommended)

```bash
docker run -d \
  --name weather \
  -p 64580:80 \
  -v ./rootfs/config:/config:z \
  -v ./rootfs/data:/data:z \
  {PLATFORM_CONTAINER_REGISTRY}/apimgr/weather:latest
```

### Docker Compose

```bash
curl -O {PLATFORM_RAW_URL}/docker/docker-compose.yml
docker compose up -d
```

### Binary

```bash
# Download latest release
curl -LO {PLATFORM_RELEASE_URL}/weather-linux-amd64

# Make executable and run
chmod +x weather-linux-amd64
./weather-linux-amd64
```

## CLI Client

A companion CLI client is available for interacting with the server API.

### Install

```bash
# Download latest release
curl -LO {PLATFORM_RELEASE_URL}/weather-cli-linux-amd64
chmod +x weather-cli-linux-amd64
sudo mv weather-cli-linux-amd64 /usr/local/bin/weather-cli
```

### Configure

```bash
# Connect to server (creates ~/.config/apimgr/weather/cli.yml)
weather-cli --server https://api.example.com --token YOUR_API_TOKEN
```

### Usage

```bash
weather-cli --help
weather-cli [command] --help
```

## Configuration

Configuration is auto-generated on first run. Edit via admin panel at `http://{fqdn}:{port}/admin`.

Key settings:
- `server.port` - Listen port (default: random 64xxx)
- `server.mode` - production or development

## API

API documentation available at `/api/v1/` when running.

| Endpoint | Description |
|----------|-------------|
| `GET /healthz` | Health check |
| `GET /api/v1/...` | API endpoints |

## Other

### Troubleshooting

- Check logs: `docker logs weather`
- Health check: `curl http://{fqdn}:{port}/healthz`

## Development

**Development instructions are for contributors only.**

### Prerequisites

- Go (latest stable)
- Docker (for containerized builds)

### Build

```bash
# Clone
git clone {PLATFORM_REPO_URL}
cd weather

# Quick dev build (outputs to OS temp dir)
make dev

# Full build (all platforms, outputs to binaries/)
make build

# Test
make test
```

### Project Structure

```
src/           # Source code
tests/         # Test files
binaries/      # Built binaries (gitignored)
```

## License

MIT - See [LICENSE.md](LICENSE.md)
```

#### README Update Rules

| When | Update README |
|------|---------------|
| New feature added | Yes - add to Features, update API if applicable |
| Bug fix | Only if it affects usage |
| Configuration change | Yes - update Configuration section |
| New CLI flag | Yes - document in appropriate section |
| Docker/deployment change | Yes - update Production section |
| Breaking change | Yes - add notice at top |

**NEVER let README become outdated. It is the first thing users see.**

---

## Development Principles (NON-NEGOTIABLE)

**EVERY principle below MUST be followed. No exceptions.**

| Principle | Description |
|-----------|-------------|
| **Validate everything** | All input must be validated before processing |
| **Only save valid** | Never persist invalid data to database/config |
| **Never clear valid** | Don't destroy/overwrite valid data with invalid |
| **Sanitize appropriately** | Clean data where needed |
| **Test Everything** | Comprehensive testing where applicable |
| **Show Tooltips/Docs** | Help users understand the interface |
| **Security First** | But security should never block usability |
| **Mobile First** | Responsive design for all screen sizes |
| **Sane Defaults** | Everything has sensible default values |
| **No AI/ML** | Smart logic only, no machine learning |
| **Concise Responses** | Short, descriptive, and helpful |
| **Everything Configurable** | ALL settings MUST be configurable via admin web UI |
| **Live Reload** | Configuration changes apply immediately without restart |
| **Built-in Scheduler** | NEVER use cron, Task Scheduler, or external schedulers (PART 19) |

### Admin Web UI Configuration (NON-NEGOTIABLE)

**EVERY setting in the configuration file MUST be editable via the admin web UI.**

| Rule | Description |
|------|-------------|
| **No SSH/CLI required** | Users should NEVER need to edit config files manually |
| **Complete coverage** | 100% of `server.yml` settings available in admin panel |
| **Extend for project** | Projects MUST extend admin UI for project-specific settings |
| **Grouped logically** | Settings organized into intuitive sections |
| **Tooltips/help** | Every setting has a description explaining what it does |
| **Validation** | Real-time validation with clear error messages |
| **Defaults shown** | Show default values and current values clearly |

**Extending Admin Web UI (IF APPLICABLE):**

Not every project needs admin UI extensions - it depends on the project's nature:

| Project Type | Admin UI Extension | Example |
|--------------|-------------------|---------|
| Static data loader | Not needed | `jokes` - loads JSON, nothing to configure |
| Configurable service | Required | `weather` - API keys, update intervals, sources |
| Data with moderation | Required | User-generated content, approval workflows |
| External integrations | Required | Third-party APIs, credentials, sync settings |

**When extending, projects MUST:**
1. Add admin UI pages/sections for ALL project-specific configuration
2. Ensure project-specific settings are NOT hidden in config files only
3. Follow the same patterns as base admin UI (validation, tooltips, live reload)
4. Place project extensions in `src/admin/` alongside base handlers

**Rule:** If a setting exists in config, it MUST be editable in admin UI. If nothing to configure, no extension needed.

### Live Reload (NON-NEGOTIABLE)

**Configuration changes MUST apply immediately without server restart.**

| Rule | Description |
|------|-------------|
| **No restart required** | Changes take effect immediately after saving |
| **Hot reload** | Application watches for config changes and reloads |
| **Graceful** | In-flight requests complete before new config applies |
| **Feedback** | User sees confirmation that changes are active |
| **Exceptions** | Only port/address changes require restart (with clear warning) |

**What MUST live reload:**
- Branding (title, tagline, description)
- SEO settings
- Theme changes
- Email/notification settings
- Rate limiting rules
- robots.txt / security.txt
- Scheduler settings
- SSL settings (except port)
- All feature toggles

**What MAY require restart (with warning):**
- Listen address
- Port number
- Database driver change

### Sensitive Information Handling (NON-NEGOTIABLE)

**NEVER expose sensitive information anywhere in the project.**

**What is sensitive data:**
| Sensitive | Examples |
|-----------|----------|
| Credentials | Passwords, API keys, tokens, secrets |
| Connection strings | Database URLs, Redis URLs, SMTP auth |
| Internal infrastructure | Internal IPs, hostnames, file paths |
| Config internals | Environment variables, config values |

**Where to NEVER expose:**
| Location | Rule |
|----------|------|
| `/healthz` | Status only: "ok"/"error", no connection details |
| API responses | No internal paths, no config values |
| Error messages | Generic errors, no stack traces in production |
| Logs | Redact passwords, tokens, keys |
| HTML/templates | No server paths, no internal IPs |

**Tokens/passwords shown ONLY ONCE on generation:**
- Show only on: first run, password changes, token regeneration
- Show in difficult environments: Docker, headless servers
- User must copy immediately - never retrievable again
- **NEVER log sensitive data**
- **NEVER in error messages or stack traces**
- Mask in UI: show `••••••••` or last 4 chars only

---

## Target Audience

- Self-hosted users
- SMB (Small/Medium Business)
- Enterprise
- **IMPORTANT: Assume self-hosted and SMB users are NOT tech-savvy**

---

# CHECKPOINT 1: CORE RULES VERIFICATION

Before proceeding, confirm you understand:
- [ ] All NON-NEGOTIABLE sections must be implemented exactly
- [ ] AI.md must be kept in sync with project state
- [ ] TODO.AI.md required for 3+ tasks
- [ ] Sensitive data handling rules
- [ ] Target audience includes non-tech-savvy users

---


# PART 2: LICENSE & ATTRIBUTION (NON-NEGOTIABLE)

## Project License

**All projects MUST use the MIT License.**

| Requirement | Value |
|-------------|-------|
| License type | MIT License |
| License file | `LICENSE.md` (REQUIRED in project root) |
| Copyright holder | `apimgr` or individual/organization name |
| Year | Current year or year of first publication |

## LICENSE.md Structure (NON-NEGOTIABLE)

```markdown
MIT License

Copyright (c) {YEAR} apimgr

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

---

## Embedded Licenses

This software includes the following third-party libraries:

{LIST OF DEPENDENCIES WITH THEIR LICENSES - see below for format}
```

## Embedded License Attribution (NON-NEGOTIABLE)

**All third-party dependencies MUST have their licenses attributed in LICENSE.md.**

### Which Dependencies Require Attribution

| License Type | Attribution Required | Example Libraries |
|--------------|---------------------|-------------------|
| **MIT** | ✓ YES | Most Go libraries |
| **Apache 2.0** | ✓ YES | Many Google libraries |
| **BSD (2/3-clause)** | ✓ YES | Various libraries |
| **ISC** | ✓ YES | Similar to MIT |
| **MPL 2.0** | ✓ YES | Mozilla libraries |
| **Public Domain/Unlicense** | Optional (recommended) | CC0, WTFPL |
| **GPL/AGPL/LGPL** | ⚠️ AVOID | Copyleft licenses - do not use |

**NEVER use GPL/AGPL/LGPL licensed dependencies** - they require derivative works to be open-sourced under the same license.

### How to Identify Dependencies

For Go projects, use `go.mod` and license scanning tools:

```bash
# List all dependencies
go list -m all

# Use go-licenses tool (recommended)
go install github.com/google/go-licenses@latest
go-licenses csv ./... > licenses.csv
go-licenses save ./... --save_path=third_party_licenses
```

For Node.js projects:

```bash
# Use license-checker
npm install -g license-checker
license-checker --production --json > licenses.json
```

### Embedded License Format

**Two options - choose based on project size:**

#### Option A: Compact Format (RECOMMENDED for 10+ dependencies)

For MIT/ISC/BSD licenses, a summary table is sufficient. Full text only needed for Apache 2.0 NOTICE files.

```markdown
---

## Third-Party Licenses

| Library | Version | License | Copyright |
|---------|---------|---------|-----------|
| github.com/go-chi/chi/v5 | v5.2.0 | MIT | 2015-present Peter Kieltyka, Google Inc. |
| modernc.org/sqlite | v1.29.1 | BSD-3-Clause | 2017 The Sqlite Authors |
| github.com/jackc/pgx/v5 | v5.7.2 | MIT | 2013-2024 Jack Christensen |

Full license texts available at: https://spdx.org/licenses/

---
```

#### Option B: Full Format (for <10 dependencies or legal requirements)

```markdown
---

### {library-name} v{version}

**License:** {SPDX-identifier} | **Copyright:** {copyright-holder}

{FULL LICENSE TEXT - only if required by license terms}

---
```

**When full text is required:**

| License | Full Text Required | Reason |
|---------|-------------------|--------|
| MIT | NO | Just preserve copyright notice |
| ISC | NO | Just preserve copyright notice |
| BSD-2-Clause | NO | Just preserve copyright notice |
| BSD-3-Clause | YES (brief) | Non-endorsement clause must be visible |
| Apache 2.0 | Only NOTICE file | Must include NOTICE if library has one |
| MPL 2.0 | Reference only | Can link to mozilla.org/MPL/2.0/ |

### Example: Compact Format (RECOMMENDED)

```markdown
---

## Third-Party Licenses

This software includes the following third-party libraries:

| Library | Version | License | Copyright |
|---------|---------|---------|-----------|
| github.com/go-chi/chi/v5 | v5.2.0 | MIT | 2015-present Peter Kieltyka, Google Inc. |
| github.com/jackc/pgx/v5 | v5.7.2 | MIT | 2013-2024 Jack Christensen |
| github.com/redis/go-redis/v9 | v9.7.0 | BSD-2-Clause | 2012-2024 The go-redis Authors |
| modernc.org/sqlite | v1.29.1 | BSD-3-Clause | 2017 The Sqlite Authors |
| golang.org/x/crypto | v0.31.0 | BSD-3-Clause | 2009 The Go Authors |
| github.com/charmbracelet/bubbletea | v0.27.0 | MIT | 2020-2024 Charmbracelet Inc. |

Full license texts: https://spdx.org/licenses/

---
```

### Example: BSD-3-Clause (include non-endorsement clause)

For BSD-3-Clause, include the third clause since it has specific restrictions:

```markdown
### modernc.org/sqlite v1.29.1 (BSD-3-Clause)

Copyright (c) 2017 The Sqlite Authors. All rights reserved.

Neither the name of the copyright holder nor the names of its contributors
may be used to endorse or promote products derived from this software
without specific prior written permission.

Full license: https://spdx.org/licenses/BSD-3-Clause.html
```

## Maintenance Requirements (NON-NEGOTIABLE)

### When to Update LICENSE.md

| Event | Action Required |
|-------|----------------|
| **New dependency added** | Add its license to LICENSE.md embedded section |
| **Dependency removed** | Remove its license from LICENSE.md |
| **Dependency upgraded** | Verify license hasn't changed; update version number |
| **Major dependency update** | Re-check license compatibility |

### Automated License Checking

**Projects SHOULD automate license verification:**

```yaml
# .github/workflows/licenses.yml
name: License Check

on: [push, pull_request]

jobs:
  check-licenses:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-go@v5
        with:
          go-version: 'stable'

      - name: Install go-licenses
        run: go install github.com/google/go-licenses@latest

      - name: Check licenses
        run: |
          # Verify no GPL/AGPL/LGPL licenses
          if go-licenses csv ./... | grep -iE 'GPL|AGPL|LGPL'; then
            echo "ERROR: Copyleft license detected!"
            exit 1
          fi

      - name: Save license report
        run: go-licenses save ./... --save_path=third_party_licenses
```

### License Verification Script

**Include in project repository:**

```bash
#!/bin/bash
# scripts/verify-licenses.sh

set -e

echo "Checking for incompatible licenses..."

# Install go-licenses if not present
if ! command -v go-licenses &> /dev/null; then
    echo "Installing go-licenses..."
    go install github.com/google/go-licenses@latest
fi

# Check for copyleft licenses
echo "Scanning dependencies..."
if go-licenses csv ./... | grep -iE 'GPL|AGPL|LGPL'; then
    echo "ERROR: Copyleft license detected!"
    echo "Remove the dependency or find an alternative."
    exit 1
fi

echo "✓ All licenses are compatible"

# Generate license report
echo "Generating license report..."
go-licenses csv ./... > licenses.csv
go-licenses save ./... --save_path=third_party_licenses

echo "✓ License report saved to licenses.csv and third_party_licenses/"
echo ""
echo "Next steps:"
echo "1. Review licenses.csv"
echo "2. Update LICENSE.md with any new dependencies"
echo "3. Commit the changes"
```

## README.md License Badge (REQUIRED)

**Every README.md MUST include a license badge:**

```markdown
[![License](https://img.shields.io/github/license/apimgr/weather)](LICENSE.md)
```

This badge should appear in the badges section near the top of README.md.

## Docker Labels (REQUIRED)

**Dockerfile MUST include license label:**

```dockerfile
LABEL org.opencontainers.image.licenses="MIT"
```

See PART 27: DOCKER for complete label requirements.

## Go Module License Field

**go.mod does NOT have a license field**, but projects SHOULD document the license in:

1. `LICENSE.md` file (REQUIRED)
2. README.md badge (REQUIRED)
3. Package documentation comments (RECOMMENDED)

**Example package doc:**

```go
// Package jokes provides a REST API for random jokes.
//
// This software is licensed under the MIT License.
// See LICENSE.md for details.
package main
```

## Common Mistakes (AVOID)

| Mistake | Why It's Wrong | Correct Approach |
|---------|----------------|------------------|
| No LICENSE.md file | Legally ambiguous | Always include LICENSE.md |
| Missing embedded licenses | License violation | Include ALL dependency licenses |
| Using GPL dependencies | Forces project to be GPL | Use MIT/Apache/BSD alternatives |
| Outdated license attributions | Inaccurate legal compliance | Update when dependencies change |
| Only listing library names | Incomplete attribution | Include full license text |
| Mixing incompatible licenses | Legal conflicts | Verify compatibility |
| No automation | Manual errors | Use CI checks |

## License Compatibility Matrix

| Project License | Can Use Dependencies Licensed As |
|----------------|----------------------------------|
| **MIT** | MIT, Apache 2.0, BSD, ISC, Public Domain |
| **MIT** | ❌ **CANNOT use:** GPL, AGPL, LGPL |

**When in doubt:** Choose MIT/Apache 2.0/BSD licensed alternatives.

## Resources

- MIT License Template: https://opensource.org/licenses/MIT
- License Compatibility: https://www.gnu.org/licenses/license-compatibility.html
- go-licenses tool: https://github.com/google/go-licenses
- license-checker (Node.js): https://github.com/davglass/license-checker
- OSI Approved Licenses: https://opensource.org/licenses

---

**REMEMBER:**
1. Always include LICENSE.md in project root
2. Always embed third-party licenses at bottom of LICENSE.md
3. Never use GPL/AGPL/LGPL dependencies
4. Update LICENSE.md when dependencies change
5. Automate license checking in CI/CD

---

# PART 3: PROJECT STRUCTURE (NON-NEGOTIABLE)

## Project Information

| Field | Value |
|-------|-------|
| **Name** | weather |
| **Organization** | apimgr |
| **Official Site** | https://weather.apimgr.us |
| **Repository** | {PLATFORM_REPO_URL} |
| **README** | README.md |
| **License** | MIT > LICENSE.md |
| **Embedded Licenses** | Added to bottom of LICENSE.md |

## Project Description

{Brief description of what this project does}

## Project-Specific Features

{List features unique to this project}

---

## Variables (NON-NEGOTIABLE)

| Variable | Description | Example |
|----------|-------------|---------|
| `weather` | Project name (inferred from path) | `jokes` |
| `apimgr` | Organization name (inferred from path) | `apimgr` |
| `github` | Git hosting provider | `github`, `gitlab`, `private` |
| **Rule** | Anything in `{}` is a variable | |
| **Rule** | Anything NOT in `{}` is literal | `/etc/letsencrypt/live` is a real path |

### Inferring Variables from Path (NON-NEGOTIABLE)

**NEVER hardcode `weather` or `apimgr` - always infer from git remote or directory path.**

**Recommended path structure:** `~/Projects/github/apimgr/weather` (but works with any location)

```bash
# Method 1: Infer from git remote (PREFERRED - works regardless of directory location)
# github.com/cloudops/echoip.git → PROJECTORG=cloudops, PROJECTNAME=echoip
PROJECTNAME=$(git remote get-url origin 2>/dev/null | sed -E 's|.*/([^/]+)(\.git)?$|\1|')
PROJECTORG=$(git remote get-url origin 2>/dev/null | sed -E 's|.*/([^/]+)/[^/]+(\.git)?$|\1|')

# Method 2: Infer from current directory path (fallback if no git remote)
# Works with any path structure: ~/Documents/myproject, ~/myproject, etc.
PROJECTNAME=$(basename "$PWD")                    # myproject
PROJECTORG=$(basename "$(dirname "$PWD")")        # Documents (or parent dir name)

# Method 3: Combined approach (git first, fallback to path)
PROJECTNAME=$(git remote get-url origin 2>/dev/null | sed -E 's|.*/([^/]+)(\.git)?$|\1|' || basename "$PWD")
PROJECTORG=$(git remote get-url origin 2>/dev/null | sed -E 's|.*/([^/]+)/[^/]+(\.git)?$|\1|' || basename "$(dirname "$PWD")")
```

**Note:** When using path-based inference, `PROJECTORG` will be the parent directory name, which may not match the git organization unless you follow the recommended `~/Projects/github/apimgr/weather` structure. Git remote inference is always more reliable.

### Variable Capitalization

| Format | Use Case | Example |
|--------|----------|---------|
| `weather` | Lowercase (filenames, paths, commands) | `jokes`, `/etc/apimgr/jokes/` |
| `{projectName}` | camelCase (Go variables, JSON keys) | `projectName := "jokes"` |
| `{Projectname}` | PascalCase (Go types, display names) | `type JokesServer struct` |
| `WEATHER` | UPPERCASE (env vars, Makefile vars) | `PROJECTNAME=jokes` |

**Examples (assuming no git remote, inferred from path):**

| Path | `PROJECTORG` | `PROJECTNAME` | Notes |
|------|--------------|---------------|-------|
| `~/Projects/github/cloudops/echoip` | `cloudops` | `echoip` | Recommended structure |
| `~/Projects/gitlab/casapps/cassearch` | `casapps` | `cassearch` | Recommended structure |
| `~/Documents/myproject` | `Documents` | `myproject` | Simple structure - org is parent dir |
| `~/myproject` | `~` | `myproject` | Home directory - org is home |
| `/opt/projects/myproject` | `projects` | `myproject` | Custom location - org is parent dir |

**With git remote (preferred):** Variables are inferred from remote URL regardless of directory location.

## Local Project Path Structure (RECOMMENDED)

**IMPORTANT: Project root can be located ANYWHERE on your system. This section describes a RECOMMENDED organizational structure, not a requirement.**

**Recommended Format:** `~/Projects/github/apimgr/weather`

| Component | Description | Examples |
|-----------|-------------|----------|
| `~/Projects/` | Base projects directory (recommended) | Can be `~/Projects/`, `~/Documents/`, `/opt/`, etc. |
| `github` | Git hosting provider or `local` | `github`, `gitlab`, `bitbucket`, `private`, `local` |
| `apimgr` | Organization/username (inferred) | `apimgr`, `casjay`, `myorg` |
| `weather` | Project name (inferred) | `jokes`, `icons`, `myproject` |

**Examples of recommended structure:**
```
~/Projects/github/netutils/pastebin   # ORG=netutils, PROJECT=pastebin
~/Projects/gitlab/casjay/icons        # ORG=casjay, PROJECT=icons
~/Projects/private/myorg/myproject    # ORG=myorg, PROJECT=myproject
~/Projects/bitbucket/company/app      # ORG=company, PROJECT=app
~/Projects/local/apimgr/prototype     # ORG=apimgr, PROJECT=prototype
```

**But any of these are equally valid:**
```
~/Documents/myproject                 # Simple home directory structure
~/myproject                           # Project in home directory
/opt/projects/myproject               # System-wide location
/workspace/dev/myproject              # Custom workspace
```

### Special: `local` Provider

`~/Projects/local/apimgr/weather` (or any other location) is used for:
- **Prototyping** - Quick experiments and proof-of-concept
- **Bootstrapping** - Initial project setup before pushing to VCS
- **Local-only development** - Projects not intended for remote hosting
- **No VCS required** - May not have git initialized
- **No Docker registry** - May not push to container registries

**Note:** The paths shown here are LOCAL development examples, not deployed paths.

---

## Directory Structure (NON-NEGOTIABLE)

**This section defines the INTERNAL structure of your project, not its location.**

**The root Project directory is**: `./` (relative paths shown below - can be located anywhere on your system)

```
./                          # Root project directory (git top-level)
├── .github/                # GitHub Actions (if using GitHub)
│   └── workflows/
│       ├── release.yml     # Stable releases
│       ├── beta.yml        # Beta releases
│       ├── daily.yml       # Daily builds
│       └── docker.yml      # Docker images
├── .gitea/                 # Gitea Actions (if using Gitea)
│   └── workflows/
│       ├── release.yml     # Stable releases
│       ├── beta.yml        # Beta releases
│       ├── daily.yml       # Daily builds
│       └── docker.yml      # Docker images
├── .claude/                # Claude Code configuration
│   ├── rules/              # Auto-loaded rule files (REQUIRED)
│   │   ├── ai-rules.md         # AI behavior rules
│   │   ├── directory-structure.md  # Project structure rules
│   │   ├── build-rules.md      # Build/make rules
│   │   └── testing-rules.md    # Testing rules
│   └── CLAUDE.md           # Project memory (optional)
├── .cursor/                # Cursor AI configuration (optional)
├── .aider/                 # Aider AI configuration (optional)
├── .ai/                    # Generic AI configuration (optional)
├── docs/                   # ReadTheDocs documentation ONLY (MkDocs)
│   ├── index.md            # Documentation homepage
│   ├── installation.md     # Installation guide
│   ├── configuration.md    # Configuration reference
│   ├── api.md              # API documentation
│   ├── cli.md              # CLI reference (if applicable)
│   ├── admin.md            # Admin panel guide
│   ├── development.md      # Development guide
│   ├── stylesheets/        # MkDocs theme customization
│   │   ├── dark.css        # Dark theme customization for ReadTheDocs
│   │   └── light.css       # Light theme customization for ReadTheDocs (optional)
│   └── requirements.txt    # Python dependencies for MkDocs
├── src/                    # All source files
├── scripts/                # Production/install scripts (if any)
├── tests/                  # All development/test scripts and files
│   ├── run_tests.sh        # Auto-detect and run tests (REQUIRED)
│   ├── docker.sh           # Beta testing with Docker (REQUIRED)
│   └── incus.sh            # Beta testing with Incus (REQUIRED)
├── docker/                 # Docker files
│   ├── Dockerfile          # Production Dockerfile
│   ├── Dockerfile.dev      # Development Dockerfile (optional)
│   ├── docker-compose.yml  # Production compose (NO debug)
│   ├── docker-compose.dev.yml  # Development compose
│   ├── docker-compose.test.yml # Test compose (DEBUG=true)
│   └── rootfs/             # Container filesystem overlay
│       └── usr/
│           └── local/
│               └── bin/
│                   └── entrypoint.sh  # Container entrypoint
├── rootfs/                 # Runtime volume data (gitignored)
│   ├── config/             # Config volumes per service
│   ├── data/               # Data volumes per service
│   └── db/                 # Database volumes per type
├── binaries/               # Built binaries (gitignored) - ALL binaries here
├── releases/               # Release binaries (gitignored)
├── README.md               # Production first, dev last
├── LICENSE.md              # MIT + embedded licenses
├── AI.md                   # Project specification
├── TODO.AI.md              # Task tracking for 3+ tasks
├── PLAN.AI.md                 # Implementation plan (optional)
├── Jenkinsfile             # Jenkins pipeline
└── release.txt             # Version tracking
```

**Gitignored directories:**
- `binaries/` - All build output (host + all platforms)
- `releases/` - Release output
- `rootfs/` - Runtime volume data

### .gitignore (REQUIRED)

**Base: `gitignore --dir . default` + project-specific entries**

```gitignore
# gitignore default template
# Disable reminder in prompt
ignoredirmessage

# ignore .build_failed files
**/.build_failed*

# OS generated files
### Linux ###
*~

# temporary files which can be created if a process still has a handle open of a deleted file
.fuse_hidden*

# KDE directory preferences
.directory

# Linux trash folder which might appear on any partition or disk
.Trash-*

# .nfs files are created when an open file is removed but is still being accessed
.nfs*

### macOS ###
# General
.DS_Store?
.AppleDouble
.LSOverride

# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

### macOS Patch ###
# iCloud generated files
*.icloud

### Windows ###
# Windows thumbnail cache files
Thumbs.db
Thumbs.db:encryptable
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# misc
!*/README*
!inc/main.bash

# Windows shortcuts
*.lnk

# ignore commit message
**/.gitcommit

# ignore .bak files
**/*.bak

# ignore .no_push files
**/.no_push

# ignore .no_git files
**/.no_git

# ignore .installed files
**/.installed

# ignore work in progress files
**/*.rewrite.sh
**/*.refactor.sh

# ============================================
# PROJECT-SPECIFIC (add below default section)
# ============================================

# Build output
binaries/
releases/

# Runtime volume data (NEVER commit)
rootfs/

# IDE
.idea/
.vscode/
*.swp
*.swo

# AI config directories (keep these - they're committed, not ignored)
# .claude/
# .cursor/
# .aider/
# .ai/
# .windsurf/
```

### .dockerignore (REQUIRED)

```dockerignore
# Git
.git/
.gitignore
.gitattributes

# CI/CD workflows (not needed in container)
.github/
.gitea/
.forgejo/
.gitlab-ci.yml
Jenkinsfile

# Runtime volume data (NEVER include in image)
rootfs/

# Build output (container builds from source)
binaries/
releases/

# Tests (not needed in production image)
tests/

# Documentation (not needed in container)
docs/
*.md

# Build files (not needed - build happens inside Docker)
Makefile

# IDE
.idea/
.vscode/
*.swp
*.swo

# AI config directories
.claude/
.cursor/
.aider/
.ai/
.windsurf/
```

**What .dockerignore MUST include:**

| Category | Files/Dirs | Why Exclude |
|----------|------------|-------------|
| **Git** | `.git/`, `.gitignore`, `.gitattributes` | Not needed, adds size |
| **CI/CD** | `.github/`, `.gitea/`, `.forgejo/`, `.gitlab-ci.yml`, `Jenkinsfile` | CI files not needed in container |
| **Runtime** | `rootfs/` | Runtime volumes, not build-time |
| **Build output** | `binaries/`, `releases/` | Container builds from source |
| **Tests** | `tests/` | Test scripts not needed in production |
| **Docs** | `docs/`, `*.md` | Documentation not needed in container |
| **Build files** | `Makefile` | Build happens inside Docker, not needed |
| **IDE** | `.idea/`, `.vscode/`, `*.swp` | Editor files |
| **AI config** | `.claude/`, `.cursor/`, etc. | AI assistant config |

**What .dockerignore MUST NOT include:**

| Files/Dirs | Why Keep |
|------------|----------|
| `src/` | Source code - required for build |
| `go.mod`, `go.sum` | Go module files - required |
| `docker/` | Dockerfile, rootfs overlay - required |
| `docker/rootfs/` | Build-time overlay files (entrypoint.sh) |

**RULE: Keep the base directory organized and clean - no clutter!**

## Path Convention (NON-NEGOTIABLE)

**ALL paths are ALWAYS relative to PROJECT ROOT, never the current working directory.**

### Defining Project Root

**Project root** is the top-level directory of your project, determined by:

1. **Git repository top-level** (preferred): Run `git rev-parse --show-toplevel` to find it
2. **Directory containing project structure**: The directory with `go.mod`, `src/`, `docker/`, etc.

**Project root can be located ANYWHERE on your system:**

| Valid Project Root | Example |
|-------------------|---------|
| Structured projects dir | `~/Projects/github/casapps/myproject` |
| Documents folder | `~/Documents/myproject` |
| Home directory | `~/myproject` |
| Any arbitrary location | `/opt/projects/myproject` |
| Custom workspace | `/workspace/dev/myproject` |

**Rule: ALL file paths in code, documentation, and scripts MUST be relative to THIS project root, regardless of where it's located.**

| Path | Means | NOT |
|------|-------|-----|
| `docker/` | `{project_root}/docker/` | `{cwd}/docker/` |
| `binaries/` | `{project_root}/binaries/` | `{cwd}/binaries/` |
| `src/` | `{project_root}/src/` | `{cwd}/src/` |

**Rules:**
- Commands MUST be run from project root, OR
- Commands MUST use absolute paths, OR
- Commands MUST `cd` to project root first
- NEVER assume current directory is project root
- Scripts should determine project root programmatically

```bash
# Determine project root (in scripts)
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

# Or for Go binaries, use os.Executable()
```

```go
// Determine project root in Go
func getProjectRoot() string {
    exe, _ := os.Executable()
    return filepath.Dir(exe)
}
```

**Example - WRONG vs RIGHT:**
```bash
# WRONG: Assumes cwd is project root
cd binaries && docker build -f .docker/Dockerfile .

# RIGHT: Explicit project root
docker build -f docker/Dockerfile -t myapp ./

# RIGHT: cd to project root first
cd /path/to/project && docker build -f docker/Dockerfile .
```

## Runtime Directory Usage (NON-NEGOTIABLE)

**Be smart about which directory to use for what purpose.**

| Directory | Purpose | Examples |
|-----------|---------|----------|
| `{config_dir}` | User-editable configuration | `server.yml`, email templates, custom themes, SSL certs |
| `{data_dir}` | Application-managed data | databases, Tor keys, caches, GeoIP databases |
| `{log_dir}` | Log files | `access.log`, `error.log`, `audit.log` |
| `{backup_dir}` | Backup files | `.tar.gz` backup archives |

**Rules:**
- If a user might edit it → `{config_dir}`
- If the application manages it → `{data_dir}`
- If it's a log → `{log_dir}`
- If it's a backup → `{backup_dir}`
- **NEVER mix purposes** - don't put user config in data_dir or vice versa

---

## Platform Support (NON-NEGOTIABLE)

### Operating Systems

| OS | Required |
|----|----------|
| Linux | YES |
| BSD (FreeBSD, OpenBSD, etc.) | YES |
| macOS (Intel and Apple Silicon) | YES |
| Windows | YES |

### Architectures

| Architecture | Required |
|--------------|----------|
| AMD64 | YES |
| ARM64 | YES |

**IMPORTANT: Be smart about implementations - code must work on ALL platforms.**

---

## Go Version (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **Always Latest Stable** | Use latest stable Go version (NEVER hardcode specific versions) |
| **Build Only** | Go is only for building, not runtime (single static binary) |
| **go.mod** | Set to current latest stable version |
| **Docker** | Use `golang:alpine` for builds (always has latest stable Go) |
| **CI/CD** | Use `go-version: 'stable'` in workflows (NEVER hardcode like `1.21`) |
| **No Pinning** | Don't pin to patch versions unless compatibility issue |

**go.mod Example:**
```
module github.com/apimgr/weather

go 1.xx  // Use current latest stable version

require (
    // dependencies...
)
```

## Required Go Libraries (NON-NEGOTIABLE)

**All libraries MUST be pure Go and work with `CGO_ENABLED=0`.**

### Database Drivers

| Database | Library | Driver Name | Notes |
|----------|---------|-------------|-------|
| **SQLite** | `modernc.org/sqlite` | `sqlite` | Pure Go, NO CGO |
| **PostgreSQL** | `github.com/jackc/pgx/v5/stdlib` | `pgx` | Pure Go, best performance |
| **MySQL/MariaDB** | `github.com/go-sql-driver/mysql` | `mysql` | Pure Go |
| **MSSQL** | `github.com/microsoft/go-mssqldb` | `sqlserver` | Pure Go |
| **MongoDB** | `go.mongodb.org/mongo-driver/mongo` | (native) | Pure Go, not database/sql |

### Cache/Cluster

| Purpose | Library | Notes |
|---------|---------|-------|
| **Valkey/Redis** | `github.com/redis/go-redis/v9` | Supports both Valkey and Redis |
| **Memcache** | `github.com/bradfitz/gomemcache/memcache` | Pure Go |

### Core Libraries

| Purpose | Library | Notes |
|---------|---------|-------|
| **YAML** | `gopkg.in/yaml.v3` | Config file parsing |
| **UUID** | `github.com/google/uuid` | Standard UUID generation |
| **Argon2** | `golang.org/x/crypto/argon2` | Password hashing |
| **Bcrypt** | `golang.org/x/crypto/bcrypt` | Verify existing passwords (rehash to Argon2id) |

### Authentication (REQUIRED - ALL PROJECTS)

**Every project has server admins, even apps without users (e.g., `jokes` loading JSON).**
**These libraries are REQUIRED to support admin authentication features.**

| Purpose | Library | Notes |
|---------|---------|-------|
| **TOTP** | `github.com/pquerna/otp` | Time-based 2FA codes |
| **Passkeys/WebAuthn** | `github.com/go-webauthn/webauthn` | FIDO2/WebAuthn passwordless |
| **JWT** | `github.com/golang-jwt/jwt/v5` | API token authentication |
| **OIDC** | `github.com/coreos/go-oidc/v3` | OpenID Connect client |
| **OAuth2** | `golang.org/x/oauth2` | OAuth2 flows |
| **LDAP** | `github.com/go-ldap/ldap/v3` | LDAP/Active Directory |
| **Sessions** | `github.com/gorilla/sessions` | Cookie-based sessions |

**Server Admin MFA (Recommended):**
- TOTP and Passkeys are optional but STRONGLY recommended for server admins
- Admin panel MUST support enabling/disabling TOTP and Passkeys
- Recovery keys MUST be generated when MFA is enabled
- All MFA features work regardless of whether app has regular users

### Network/HTTP

| Purpose | Library | Notes |
|---------|---------|-------|
| **Router** | `github.com/go-chi/chi/v5` | Lightweight, stdlib compatible |
| **Tor** | `github.com/cretz/bine` | Pure Go Tor controller |
| **WebSocket** | `github.com/gorilla/websocket` | WebSocket support |
| **CORS** | `github.com/rs/cors` | CORS middleware |

### Utilities

| Purpose | Library | Notes |
|---------|---------|-------|
| **Embed** | `embed` (stdlib) | Embed static files |
| **Cron** | `github.com/robfig/cron/v3` | Scheduler |
| **Rate Limit** | `golang.org/x/time/rate` | Rate limiting |
| **Validation** | `github.com/go-playground/validator/v10` | Input validation |

### SQLite Driver (NON-NEGOTIABLE)

**MUST use `modernc.org/sqlite`. NEVER use `github.com/mattn/go-sqlite3`.**

| Driver | CGO Required | Use |
|--------|--------------|-----|
| `modernc.org/sqlite` | NO | **ALWAYS USE THIS** |
| `github.com/mattn/go-sqlite3` | YES | **NEVER USE** |

**Why `modernc.org/sqlite`?**
- Pure Go implementation - no C compiler needed
- Works with `CGO_ENABLED=0` for static binaries
- Cross-compilation works without toolchain setup
- Same SQLite functionality, just pure Go

**Usage:**
```go
import (
    "database/sql"
    _ "modernc.org/sqlite"
)

func openDB(path string) (*sql.DB, error) {
    // Driver name is "sqlite" (not "sqlite3")
    return sql.Open("sqlite", path)
}
```

**go.mod:**
```
require modernc.org/sqlite v1.29.1
```

### Forbidden Libraries

| Library | Reason | Alternative |
|---------|--------|-------------|
| `github.com/mattn/go-sqlite3` | Requires CGO | `modernc.org/sqlite` |
| `github.com/lib/pq` | Outdated, less performant | `github.com/jackc/pgx/v5` |
| `github.com/ooni/go-libtor` | Requires CGO | `github.com/cretz/bine` + external Tor |
| `github.com/dgrijalva/jwt-go` | Unmaintained, security issues | `github.com/golang-jwt/jwt/v5` |
| `github.com/gorilla/mux` | Archived, no longer maintained | `github.com/go-chi/chi/v5` |
| `github.com/go-redis/redis` | Old import path | `github.com/redis/go-redis/v9` |
| Any CGO library | Breaks static builds | Find pure Go alternative |

**CGO_ENABLED=0 Rule:** All libraries must work with `CGO_ENABLED=0`. If a library requires CGO, find a pure Go alternative or don't use it.

### Example go.mod

```go
module github.com/apimgr/weather

go 1.xx  // Use current latest stable version

require (
	// Database drivers
	modernc.org/sqlite v1.34.5                      // SQLite (pure Go)
	github.com/jackc/pgx/v5 v5.7.2                  // PostgreSQL
	github.com/go-sql-driver/mysql v1.8.1           // MySQL/MariaDB
	github.com/microsoft/go-mssqldb v1.8.0          // MSSQL
	go.mongodb.org/mongo-driver v1.17.2             // MongoDB

	// Cache/Cluster
	github.com/redis/go-redis/v9 v9.7.0             // Valkey/Redis
	github.com/bradfitz/gomemcache v0.0.0-20230905024940-24af94b03874  // Memcache

	// Core
	gopkg.in/yaml.v3 v3.0.1                         // YAML config
	github.com/google/uuid v1.6.0                   // UUID generation
	golang.org/x/crypto v0.31.0                     // Argon2, Bcrypt

	// Authentication
	github.com/pquerna/otp v1.4.0                   // TOTP 2FA
	github.com/go-webauthn/webauthn v0.11.2         // Passkeys/WebAuthn
	github.com/golang-jwt/jwt/v5 v5.2.1             // JWT tokens
	github.com/coreos/go-oidc/v3 v3.11.0            // OIDC client
	golang.org/x/oauth2 v0.24.0                     // OAuth2 flows
	github.com/go-ldap/ldap/v3 v3.4.10              // LDAP/AD
	github.com/gorilla/sessions v1.4.0              // Cookie sessions

	// Network/HTTP
	github.com/go-chi/chi/v5 v5.2.0                 // Router
	github.com/cretz/bine v0.2.0                    // Tor controller
	github.com/gorilla/websocket v1.5.3             // WebSocket
	github.com/rs/cors v1.11.1                      // CORS middleware

	// Utilities
	github.com/robfig/cron/v3 v3.0.1                // Scheduler
	golang.org/x/time v0.8.0                        // Rate limiting
	github.com/go-playground/validator/v10 v10.23.0 // Validation
)
```

**Notes:**
- Version numbers are examples - always use latest stable versions
- Not all projects need all modules - include only what you use
- Clean up unused dependencies: handled automatically by `make build/host/dev`
- MongoDB uses native driver, not database/sql
- **NEVER run `go` directly - always use Makefile targets (`make dev`, `make test`, etc.)**

## Password Hashing (NON-NEGOTIABLE)

**ALL passwords MUST be hashed using Argon2id. NEVER store plaintext passwords.**

### Algorithm Requirements

| Setting | Value | Reason |
|---------|-------|--------|
| **Algorithm** | Argon2id | Winner of Password Hashing Competition, memory-hard |
| **Library** | `golang.org/x/crypto/argon2` | Pure Go, CGO_ENABLED=0 compatible |
| **Fallback** | Bcrypt (cost 12+) | Verify existing passwords, then rehash with Argon2id |

### Argon2id Parameters (OWASP 2023)

```go
import "golang.org/x/crypto/argon2"

// Recommended parameters (OWASP 2023)
const (
	// Iterations
	ArgonTime = 3
	// Memory in KB (64 MB)
	ArgonMemory = 64 * 1024
	// Parallelism
	ArgonThreads = 4
	// Output length in bytes
	ArgonKeyLen = 32
	// Salt length in bytes
	ArgonSaltLen = 16
)

func HashPassword(password string) (string, error) {
    // Generate random salt
    salt := make([]byte, ArgonSaltLen)
    if _, err := rand.Read(salt); err != nil {
        return "", err
    }

    // Hash password
    hash := argon2.IDKey([]byte(password), salt, ArgonTime, ArgonMemory, ArgonThreads, ArgonKeyLen)

    // Encode as string: $argon2id$v=19$m=65536,t=3,p=4$<salt>$<hash>
    return encodeArgon2Hash(salt, hash), nil
}
```

### Storage Format

Passwords stored in PHC string format:
```
$argon2id$v=19$m=65536,t=3,p=4$<base64-salt>$<base64-hash>
```

### Password Rules

| Rule | Description |
|------|-------------|
| **NEVER** | Store plaintext passwords anywhere |
| **NEVER** | Store passwords in config files (server.yml) |
| **NEVER** | Log passwords (even hashed) |
| **ALWAYS** | Use Argon2id for new passwords |
| **ALWAYS** | Store in database only |
| **ALWAYS** | Generate secure random salt per password |

### API Token Hashing

API tokens are also sensitive and MUST be hashed:

| Token Type | Storage | Hashing |
|------------|---------|---------|
| **API Token** | Database | SHA-256 hash (fast lookup needed) |
| **Session Token** | Database | SHA-256 hash |
| **Password** | Database | Argon2id (slow by design) |

```go
import "crypto/sha256"

func HashToken(token string) string {
    hash := sha256.Sum256([]byte(token))
    return hex.EncodeToString(hash[:])
}
```

**Note:** API tokens use SHA-256 (not Argon2id) because:
- Tokens are already high-entropy random strings
- Need fast lookup for every API request
- Argon2id's slowness is for weak human passwords

---

# CHECKPOINT 2: PROJECT STRUCTURE VERIFICATION

Before proceeding, confirm you understand:
- [ ] Project directory structure
- [ ] Variable syntax (`{}` = variable, no `{}` = literal)
- [ ] All 4 OSes must be supported
- [ ] Both AMD64 and ARM64 must be supported
- [ ] Always use latest stable Go

---


# PART 4: OS-SPECIFIC PATHS (NON-NEGOTIABLE)

## Linux

### Privileged (root/sudo)

| Type | Path |
|------|------|
| Binary | `/usr/local/bin/weather` |
| Config | `/etc/apimgr/weather/` |
| Config File | `/etc/apimgr/weather/server.yml` |
| Data | `/var/lib/apimgr/weather/` |
| Cache | `/var/cache/apimgr/weather/` |
| Logs | `/var/log/apimgr/weather/` |
| Log File | `/var/log/apimgr/weather/server.log` |
| Backup | `/mnt/Backups/apimgr/weather/` |
| PID File | `/var/run/apimgr/weather.pid` |
| SSL | `/etc/apimgr/weather/ssl/` (letsencrypt/, local/) |
| Security | `/etc/apimgr/weather/security/` (geoip/, blocklists/, cve/, trivy/) |
| SQLite DB | `/var/lib/apimgr/weather/db/` |
| Service | `/etc/systemd/system/weather.service` |

### User (non-privileged)

| Type | Path |
|------|------|
| Binary | `~/.local/bin/weather` |
| Config | `~/.config/apimgr/weather/` |
| Config File | `~/.config/apimgr/weather/server.yml` |
| Data | `~/.local/share/apimgr/weather/` |
| Cache | `~/.cache/apimgr/weather/` |
| Logs | `~/.local/log/apimgr/weather/` |
| Log File | `~/.local/log/apimgr/weather/server.log` |
| Backup | `~/.local/share/Backups/apimgr/weather/` |
| PID File | `~/.local/share/apimgr/weather/weather.pid` |
| SSL | `~/.config/apimgr/weather/ssl/` (letsencrypt/, local/) |
| Security | `~/.config/apimgr/weather/security/` (geoip/, blocklists/, cve/, trivy/) |
| SQLite DB | `~/.local/share/apimgr/weather/db/` |

---

## macOS

### Privileged (root/sudo)

| Type | Path |
|------|------|
| Binary | `/usr/local/bin/weather` |
| Config | `/Library/Application Support/apimgr/weather/` |
| Config File | `/Library/Application Support/apimgr/weather/server.yml` |
| Data | `/Library/Application Support/apimgr/weather/data/` |
| Cache | `/Library/Caches/apimgr/weather/` |
| Logs | `/Library/Logs/apimgr/weather/` |
| Log File | `/Library/Logs/apimgr/weather/server.log` |
| Backup | `/Library/Backups/apimgr/weather/` |
| PID File | `/var/run/apimgr/weather.pid` |
| SSL | `/Library/Application Support/apimgr/weather/ssl/` (letsencrypt/, local/) |
| Security | `/Library/Application Support/apimgr/weather/security/` (geoip/, blocklists/, cve/, trivy/) |
| SQLite DB | `/Library/Application Support/apimgr/weather/db/` |
| Service | `/Library/LaunchDaemons/com.apimgr.weather.plist` |

### User (non-privileged)

| Type | Path |
|------|------|
| Binary | `~/bin/weather` or `/usr/local/bin/weather` |
| Config | `~/Library/Application Support/apimgr/weather/` |
| Config File | `~/Library/Application Support/apimgr/weather/server.yml` |
| Data | `~/Library/Application Support/apimgr/weather/` |
| Cache | `~/Library/Caches/apimgr/weather/` |
| Logs | `~/Library/Logs/apimgr/weather/` |
| Log File | `~/Library/Logs/apimgr/weather/server.log` |
| Backup | `~/Library/Backups/apimgr/weather/` |
| PID File | `~/Library/Application Support/apimgr/weather/weather.pid` |
| SSL | `~/Library/Application Support/apimgr/weather/ssl/` (letsencrypt/, local/) |
| Security | `~/Library/Application Support/apimgr/weather/security/` (geoip/, blocklists/, cve/, trivy/) |
| SQLite DB | `~/Library/Application Support/apimgr/weather/db/` |
| Service | `~/Library/LaunchAgents/com.apimgr.weather.plist` |

---

## BSD (FreeBSD, OpenBSD, NetBSD)

### Privileged (root/sudo/doas)

| Type | Path |
|------|------|
| Binary | `/usr/local/bin/weather` |
| Config | `/usr/local/etc/apimgr/weather/` |
| Config File | `/usr/local/etc/apimgr/weather/server.yml` |
| Data | `/var/db/apimgr/weather/` |
| Cache | `/var/cache/apimgr/weather/` |
| Logs | `/var/log/apimgr/weather/` |
| Log File | `/var/log/apimgr/weather/server.log` |
| Backup | `/var/backups/apimgr/weather/` |
| PID File | `/var/run/apimgr/weather.pid` |
| SSL | `/usr/local/etc/apimgr/weather/ssl/` (letsencrypt/, local/) |
| Security | `/usr/local/etc/apimgr/weather/security/` (geoip/, blocklists/, cve/, trivy/) |
| SQLite DB | `/var/db/apimgr/weather/db/` |
| Service | `/usr/local/etc/rc.d/weather` |

### User (non-privileged)

| Type | Path |
|------|------|
| Binary | `~/.local/bin/weather` |
| Config | `~/.config/apimgr/weather/` |
| Config File | `~/.config/apimgr/weather/server.yml` |
| Data | `~/.local/share/apimgr/weather/` |
| Cache | `~/.cache/apimgr/weather/` |
| Logs | `~/.local/log/apimgr/weather/` |
| Log File | `~/.local/log/apimgr/weather/server.log` |
| Backup | `~/.local/share/Backups/apimgr/weather/` |
| PID File | `~/.local/share/apimgr/weather/weather.pid` |
| SSL | `~/.config/apimgr/weather/ssl/` (letsencrypt/, local/) |
| Security | `~/.config/apimgr/weather/security/` (geoip/, blocklists/, cve/, trivy/) |
| SQLite DB | `~/.local/share/apimgr/weather/db/` |

---

## Windows

### Privileged (Administrator)

| Type | Path |
|------|------|
| Binary | `C:\Program Files\apimgr\weather\weather.exe` |
| Config | `%ProgramData%\apimgr\weather\` |
| Config File | `%ProgramData%\apimgr\weather\server.yml` |
| Data | `%ProgramData%\apimgr\weather\data\` |
| Cache | `%ProgramData%\apimgr\weather\cache\` |
| Logs | `%ProgramData%\apimgr\weather\logs\` |
| Log File | `%ProgramData%\apimgr\weather\logs\server.log` |
| Backup | `%ProgramData%\Backups\apimgr\weather\` |
| SSL | `%ProgramData%\apimgr\weather\ssl\` (letsencrypt\, local\) |
| Security | `%ProgramData%\apimgr\weather\security\` (geoip\, blocklists\, cve\, trivy\) |
| SQLite DB | `%ProgramData%\apimgr\weather\db\` |
| Service | Windows Service Manager |

### User (non-privileged)

| Type | Path |
|------|------|
| Binary | `%LocalAppData%\apimgr\weather\weather.exe` |
| Config | `%AppData%\apimgr\weather\` |
| Config File | `%AppData%\apimgr\weather\server.yml` |
| Data | `%LocalAppData%\apimgr\weather\` |
| Cache | `%LocalAppData%\apimgr\weather\cache\` |
| Logs | `%LocalAppData%\apimgr\weather\logs\` |
| Log File | `%LocalAppData%\apimgr\weather\logs\server.log` |
| Backup | `%LocalAppData%\Backups\apimgr\weather\` |
| SSL | `%AppData%\apimgr\weather\ssl\` (letsencrypt\, local\) |
| Security | `%AppData%\apimgr\weather\security\` (geoip\, blocklists\, cve\, trivy\) |
| SQLite DB | `%LocalAppData%\apimgr\weather\db\` |

---

## Docker/Container

| Type | Path |
|------|------|
| Binary | `/usr/local/bin/weather` |
| Config | `/config/weather/` |
| Config File | `/config/weather/server.yml` |
| Security DBs | `/config/weather/security/` (geoip, blocklists, cve, trivy) |
| Data | `/data/weather/` |
| Cache | `/data/weather/cache/` |
| Logs | `/data/log/weather/` |
| Log File | `/data/log/weather/server.log` |
| SQLite DB | `/data/db/{dbtype}/` |
| Backup | `/data/backups/weather/` |
| Internal Port | `80` |

---

# CHECKPOINT 3: PATH VERIFICATION

Before proceeding, confirm you understand:
- [ ] Each OS has specific paths for privileged and non-privileged users
- [ ] Config file is ALWAYS `server.yml` (not .yaml)
- [ ] Docker uses simplified paths (/config, /data)
- [ ] All paths follow the apimgr/weather pattern

---

# PART 5: CONFIGURATION (NON-NEGOTIABLE)

## YAML Comment Style (NON-NEGOTIABLE)

**CRITICAL: ALL comments in YAML files MUST go ABOVE the setting, NEVER inline.**

**WRONG:**
```yaml
enabled: true  # Enable feature
port: 8080     # Server port
```

**CORRECT:**
```yaml
# Enable feature
enabled: true

# Server port
port: 8080
```

**Reason:** Inline comments create confusion, make YAML harder to parse visually, and can cause issues with some YAML parsers. Comments above are clear and unambiguous.

**This applies to:**
- `server.yml` configuration
- `docker-compose.yml` files
- All YAML in the project
- All code examples in documentation

## Path Normalization & Validation (NON-NEGOTIABLE)

**All paths MUST be normalized and validated. This is a GLOBAL security rule for all binaries (server, agent, cli) and applies to:**
- Configuration values (admin_path, static_path, etc.)
- HTTP request paths
- File paths
- API parameters containing paths

### Path Security Functions

```go
import (
    "errors"
    "path"
    "regexp"
    "strings"
)

var (
    ErrPathTraversal   = errors.New("path traversal attempt detected")
    ErrInvalidPath     = errors.New("invalid path characters")
    ErrPathTooLong     = errors.New("path exceeds maximum length")

    // Valid path segment: lowercase alphanumeric, hyphens, underscores
    validPathSegment = regexp.MustCompile(`^[a-z0-9_-]+$`)
)

// normalizePath cleans a path for safe use
// - Strips leading/trailing slashes
// - Collapses multiple slashes (// → /)
// - Removes path traversal (.., .)
// - Returns empty string for invalid input
func normalizePath(input string) string {
    // Handle empty
    if input == "" {
        return ""
    }

    // Use path.Clean to handle .., ., and //
    cleaned := path.Clean(input)

    // Strip leading/trailing slashes
    cleaned = strings.Trim(cleaned, "/")

    // Reject if still contains .. after cleaning (shouldn't happen, but be safe)
    if strings.Contains(cleaned, "..") {
        return ""
    }

    return cleaned
}

// validatePathSegment checks a single path segment (e.g., "admin" in "/admin/dashboard")
func validatePathSegment(segment string) error {
    if segment == "" {
        return ErrInvalidPath
    }
    if len(segment) > 64 {
        return ErrPathTooLong
    }
    if !validPathSegment.MatchString(segment) {
        return ErrInvalidPath
    }
    if segment == "." || segment == ".." {
        return ErrPathTraversal
    }
    return nil
}

// validatePath checks an entire path
func validatePath(p string) error {
    if len(p) > 2048 {
        return ErrPathTooLong
    }

    // Check for traversal attempts before normalization
    if strings.Contains(p, "..") {
        return ErrPathTraversal
    }

    // Check each segment
    segments := strings.Split(strings.Trim(p, "/"), "/")
    for _, seg := range segments {
        if seg == "" {
            continue // Skip empty (from //)
        }
        if err := validatePathSegment(seg); err != nil {
            return err
        }
    }

    return nil
}

// SafePath normalizes and validates - returns error if invalid
func SafePath(input string) (string, error) {
    if err := validatePath(input); err != nil {
        return "", err
    }
    return normalizePath(input), nil
}
```

### Normalization Examples

| Input | Normalized | Valid |
|-------|------------|-------|
| `/myadmin/` | `myadmin` | ✓ |
| `//admin` | `admin` | ✓ |
| `/my//admin` | `my/admin` | ✓ |
| `///a//b///` | `a/b` | ✓ |
| `/../admin` | ✗ rejected | Path traversal |
| `/admin/../secret` | ✗ rejected | Path traversal |
| `/admin/..` | ✗ rejected | Path traversal |
| `....` | ✗ rejected | Invalid chars |
| `/Admin` | ✗ rejected | Uppercase not allowed |
| `/admin/<script>` | ✗ rejected | Invalid chars |

### Apply Everywhere (NON-NEGOTIABLE)

**Configuration paths:**
```go
func (c *Config) SetAdminPath(input string) error {
    safe, err := SafePath(input)
    if err != nil {
        return fmt.Errorf("invalid admin_path: %w", err)
    }
    c.AdminPath = safe
    return nil
}
```

**CLI flags:**
```go
func parseFlags() error {
    dataDir := flag.String("data", "/var/lib/app", "Data directory")
    flag.Parse()

    safe, err := SafePath(*dataDir)
    if err != nil {
        return fmt.Errorf("invalid --data path: %w", err)
    }
    cfg.DataDir = safe
    return nil
}
```

**API parameters:**
```go
func handleFileRequest(w http.ResponseWriter, r *http.Request) {
    filename := r.URL.Query().Get("file")

    safe, err := SafePath(filename)
    if err != nil {
        http.Error(w, "Invalid path", http.StatusBadRequest)
        return
    }

    // Safe to use
    fullPath := filepath.Join(cfg.DataDir, safe)
    // ...
}
```

### HTTP Request Path Middleware (NON-NEGOTIABLE)

**This middleware MUST be first in the chain - before auth, before routing.**

```go
// PathSecurityMiddleware normalizes paths and blocks traversal attempts
func PathSecurityMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        original := r.URL.Path

        // Check both raw path and URL-decoded for traversal
        // Note: r.URL.Path is already decoded by net/http, but check RawPath too
        rawPath := r.URL.RawPath
        if rawPath == "" {
            rawPath = r.URL.Path
        }

        // Block path traversal attempts (encoded and decoded)
        // %2e = . so %2e%2e = ..
        if strings.Contains(original, "..") ||
            strings.Contains(rawPath, "..") ||
            strings.Contains(strings.ToLower(rawPath), "%2e") {
            http.Error(w, "Bad Request", http.StatusBadRequest)
            return
        }

        // Normalize the path
        cleaned := path.Clean(original)

        // Ensure leading slash
        if !strings.HasPrefix(cleaned, "/") {
            cleaned = "/" + cleaned
        }

        // Preserve trailing slash for directory paths
        if original != "/" && strings.HasSuffix(original, "/") && !strings.HasSuffix(cleaned, "/") {
            cleaned += "/"
        }

        // Update request
        r.URL.Path = cleaned

        next.ServeHTTP(w, r)
    })
}
```

**Request examples:**

| Request | Result | Status |
|---------|--------|--------|
| `GET /admin//dashboard` | `/admin/dashboard` | 200 |
| `GET //api///v1//users` | `/api/v1/users` | 200 |
| `GET ///` | `/` | 200 |
| `GET /static/../admin` | Blocked | 400 |
| `GET /api/v1/files/..%2F..%2Fetc/passwd` | Blocked | 400 |
| `GET /admin/....//secret` | Blocked | 400 |

### File Path Security (NON-NEGOTIABLE)

**When constructing file paths from user input, ALWAYS validate the result stays within bounds:**

```go
// SafeFilePath ensures path stays within base directory
func SafeFilePath(baseDir, userPath string) (string, error) {
    // Normalize user input
    safe, err := SafePath(userPath)
    if err != nil {
        return "", err
    }

    // Construct full path
    fullPath := filepath.Join(baseDir, safe)

    // Resolve to absolute
    absPath, err := filepath.Abs(fullPath)
    if err != nil {
        return "", err
    }

    absBase, err := filepath.Abs(baseDir)
    if err != nil {
        return "", err
    }

    // Verify path is still within base
    if !strings.HasPrefix(absPath, absBase+string(filepath.Separator)) && absPath != absBase {
        return "", ErrPathTraversal
    }

    return absPath, nil
}
```

### Middleware Order (NON-NEGOTIABLE)

```go
func setupMiddleware(handler http.Handler) http.Handler {
    // Order matters - security first!
    handler = LoggingMiddleware(handler)           // 5. Log requests
    handler = AuthMiddleware(handler)              // 4. Check auth
    handler = RateLimitMiddleware(handler)         // 3. Rate limiting
    handler = SecurityHeadersMiddleware(handler)  // 2. Add security headers
    handler = PathSecurityMiddleware(handler)     // 1. FIRST - normalize & validate paths
    return handler
}
```

## Configuration Storage

**Configuration can be stored in `server.yml` OR database, depending on mode.**

### Terminology

| Term | Meaning |
|------|---------|
| **server.yml** | YAML configuration file on disk |
| **Configuration** | Settings (stored in server.yml OR database) |
| **Database** | SQLite (local) or PostgreSQL/MySQL (remote) |
| **Server Address** | The bind address for the server (e.g., `[::]`, `0.0.0.0`, `127.0.0.1`) |
| **FQDN** | Fully Qualified Domain Name (e.g., `api.example.com`) |
| **Node ID** | Unique identifier for a cluster node (default: hostname) |

**IMPORTANT:** We use "Server Address" (bind address), NOT "Server Name". The server address is where the server listens; the FQDN is how clients reach it.

### Configuration Source of Truth

| Mode | Source of Truth | server.yml Role |
|------|-----------------|-----------------|
| **Single Instance (SQLite)** | server.yml | Primary configuration |
| **Cluster Mode (Remote DB)** | Database | Bootstrap only (connection settings) |

### Single Instance Mode

```
server.yml (source of truth)
     │
     ▼
Application reads config
     │
     ▼
Admin panel writes to server.yml
```

- All settings stored in `server.yml`
- Admin panel edits `server.yml` directly
- SQLite databases for credentials/sessions only

### Cluster Mode

```
server.yml (cache + backup)
     │
     └─ Contains: database connection + cached config

Database (source of truth)
     │
     ▼
Application reads config from DB
     │
     ▼
Admin panel writes to database
     │
     ▼
Changes synced to server.yml cache
     │
     ▼
All nodes see changes immediately
```

- Database is source of truth
- `server.yml` is cache AND backup
- Admin panel writes to database
- Changes automatically synced to local `server.yml`
- If database unavailable → read-only mode using cached config

### server.yml as Cache/Backup (NON-NEGOTIABLE)

**When using external database, server.yml becomes a local cache and backup.**

```
Normal Operation:
┌──────────────┐         ┌──────────────┐
│   Database   │◄───────►│  server.yml  │
│ (source of   │  sync   │   (cache)    │
│   truth)     │         │              │
└──────────────┘         └──────────────┘
       │
       ▼
  Application
  reads from DB

Database Unavailable:
┌──────────────┐         ┌──────────────┐
│   Database   │    ✗    │  server.yml  │
│   (DOWN)     │         │   (backup)   │
└──────────────┘         └──────────────┘
                               │
                               ▼
                         Application
                         READ-ONLY MODE
                         uses cached config
```

### Config Sync (Database → server.yml)

**Every config change in database is synced to local server.yml:**

```go
func onConfigChange(db *sql.DB, key string, value interface{}) {
    // 1. Write to database (source of truth)
    writeToDatabase(db, key, value)

    // 2. Sync to local server.yml (cache)
    syncToLocalConfig(key, value)

    // 3. Update last_sync timestamp
    updateSyncTimestamp()
}
```

**Sync happens:**
- Immediately after any config change
- On application startup (DB → server.yml)
- Periodically (every 5 minutes) to catch any drift

### Maintenance Mode (NON-NEGOTIABLE)

**Only TWO types of errors are truly critical:**
1. Database connection error
2. Cannot write to files (disk full, permissions, etc.)

**All other errors are recoverable. The server ALWAYS attempts self-healing.**

### Critical Error Detection

| Error Type | Detection | Self-Healing Attempt |
|------------|-----------|---------------------|
| **Database connection** | Connection refused, timeout, auth failed | Retry with backoff, check credentials |
| **Database write** | Write failed, transaction error | Retry, check permissions, check disk |
| **File read** | Permission denied, file not found | Check permissions, recreate if possible |
| **File write** | Permission denied, disk full | Check permissions, check disk space, cleanup |

### Mode States

| State | Condition | Behavior |
|-------|-----------|----------|
| **Normal** | All systems healthy | Full functionality |
| **Maintenance** | Critical error detected | Read-only + admin guidance |
| **Starting** | Application starting up | Checking systems |

### Maintenance Mode

**When a critical error occurs, the application enters maintenance mode:**

| Aspect | Behavior |
|--------|----------|
| **Public API** | Read-only operations only |
| **Admin panel** | Accessible with fix instructions |
| **Writes** | Rejected with 503 |
| **Self-healing** | Continuously attempting in background |
| **Recovery** | Automatic when issue resolved |

### Self-Healing Process

```
Critical Error Detected
         │
         ▼
Enter Maintenance Mode
         │
         ├──────────────────────────────────────┐
         ▼                                      │
Attempt Self-Healing                            │
         │                                      │
         ├─► Database connection failed         │
         │   1. Retry connection (3x backoff)   │
         │   2. Check if host reachable         │
         │   3. Verify credentials              │
         │   4. Test with simple query          │
         │                                      │
         ├─► File write failed                  │
         │   1. Check disk space                │
         │   2. Check directory permissions     │
         │   3. Attempt to create test file     │
         │   4. Try alternate location          │
         │                                      │
         ├─► Disk full                          │
         │   1. Cleanup old logs                │
         │   2. Cleanup temp files              │
         │   3. Cleanup old backups             │
         │   4. Report space freed              │
         │                                      │
         ▼                                      │
Self-Healing Successful?                        │
    │                                           │
    ├─► YES: Exit Maintenance Mode ─────────────┘
    │        Resume Normal Operation
    │
    └─► NO: Continue in Maintenance Mode
            Retry every 30 seconds
            Show fix instructions in admin UI
```

### Admin Panel in Maintenance Mode

**The admin panel remains accessible and provides guidance for fixing issues.**

#### Maintenance Dashboard (`/admin`)

```
┌─────────────────────────────────────────────────────────────┐
│  ⚠️  MAINTENANCE MODE                                        │
│                                                             │
│  The application is running in read-only maintenance mode   │
│  due to a critical error. Self-healing is in progress.      │
│                                                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Error: Database Connection Failed                          │
│  ─────────────────────────────────────────                  │
│  Host: db.example.com:5432                                  │
│  Error: connection refused                                  │
│  Last successful connection: 5 minutes ago                  │
│                                                             │
│  Self-Healing Status: Retrying... (attempt 15)              │
│                                                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  📋 Suggested Actions:                                      │
│                                                             │
│  1. Check if database server is running                     │
│     └─ ssh db.example.com "systemctl status postgresql"     │
│                                                             │
│  2. Verify network connectivity                             │
│     └─ ping db.example.com                                  │
│     └─ telnet db.example.com 5432                           │
│                                                             │
│  3. Check database credentials                              │
│     └─ Verify password in server.yml or environment         │
│                                                             │
│  4. Check database logs                                     │
│     └─ ssh db.example.com "tail /var/log/postgresql/*.log"  │
│                                                             │
│  [Test Connection]  [View Full Diagnostics]                 │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

#### Error-Specific Guidance

**Database Connection Failed:**

| Check | Command/Action | What to Look For |
|-------|----------------|------------------|
| Server running | `systemctl status postgresql` | Active (running) |
| Network | `ping db.example.com` | Response |
| Port open | `telnet db.example.com 5432` | Connected |
| Credentials | Check server.yml | Correct password |
| Max connections | Check DB logs | "too many connections" |
| Firewall | Check iptables/ufw | Port 5432 allowed |

**Disk Full:**

| Check | Command/Action | What to Look For |
|-------|----------------|------------------|
| Disk space | `df -h` | Usage % |
| Large files | `du -sh /var/log/*` | Oversized logs |
| Old backups | Check backup directory | Old files to delete |
| Temp files | Check /tmp | Cleanup candidates |

**Auto-cleaned:**
- Logs older than retention policy
- Temp files older than 24 hours
- Old backup files (keeps last 5)

**Permission Denied:**

| Check | Command/Action | What to Look For |
|-------|----------------|------------------|
| Directory owner | `ls -la /path/to/dir` | Correct user:group |
| Directory perms | `stat /path/to/dir` | Write permission |
| SELinux/AppArmor | `getenforce` / `aa-status` | Blocking access |
| Disk mounted | `mount` | Read-only mount |

### API Responses in Maintenance Mode

**All write operations return:**

```json
{
  "error": "Service in maintenance mode",
  "code": "MAINTENANCE_MODE",
  "status": 503,
  "message": "Server is in maintenance mode due to: Database connection failed",
  "reason": "database_connection",
  "self_healing": true,
  "retry_after": 30
}
```

**Headers:**
```
Retry-After: 30
X-Maintenance-Mode: true
X-Maintenance-Reason: database_connection
```

### /healthz in Maintenance Mode

```json
{
  "status": "maintenance",
  "version": "1.0.0",
  "mode": "maintenance",
  "uptime": "2d 5h 30m",
  "maintenance": {
    "reason": "database_connection",
    "message": "Database connection failed",
    "since": "2025-01-15T10:30:00Z",
    "self_healing": {
      "enabled": true,
      "attempts": 15,
      "last_attempt": "2025-01-15T10:35:00Z",
      "next_attempt": "2025-01-15T10:35:30Z"
    }
  },
  "checks": {
    "database": "error",
    "disk": "ok",
    "config": "ok"
  }
}
```

### Recovery (Automatic)

**When self-healing succeeds:**

```
1. Self-healing attempt succeeds
         │
         ▼
2. Verify server is stable
   - Run health checks
   - Verify read/write works
         │
         ▼
3. Log: "Issue resolved, exiting maintenance mode"
         │
         ▼
4. Exit maintenance mode
   - Set mode = normal
   - Remove maintenance banner
   - Re-enable write operations
         │
         ▼
5. Send notification (if email configured)
   - "Server recovered from maintenance mode"
   - Include duration and cause
         │
         ▼
6. Resume normal operation
```

### Maintenance Mode Config

```yaml
server:
  maintenance:
    # Self-healing settings
    self_healing:
      enabled: true
      retry_interval: 30
      # seconds between retry attempts
      max_attempts: 0
      # 0 = unlimited (keep trying forever)

    # Auto-cleanup thresholds
    cleanup:
      disk_threshold: 90
      # Start cleanup when disk > 90% full
      log_retention_days: 7
      # Delete logs older than 7 days during cleanup
      backup_keep_count: 5
      # Keep last 5 backups during cleanup

    # Notifications
    notify:
      on_enter: true
      # Notify when entering maintenance mode
      on_exit: true
      # Notify when exiting maintenance mode
```

### What Goes Where

| Setting | Single Instance | Cluster Mode | Read-Only Fallback |
|---------|-----------------|--------------|-------------------|
| Database connection | server.yml | server.yml | server.yml |
| Admin credentials | Local SQLite | Remote DB | Cached in server.yml |
| Server settings | server.yml | Remote DB | Cached in server.yml |
| Branding/SEO | server.yml | Remote DB | Cached in server.yml |
| SSL settings | server.yml | Remote DB | Cached in server.yml |
| User accounts | Local SQLite | Remote DB | ❌ Unavailable |
| Sessions | Local SQLite | Remote DB | ❌ Unavailable |
| API tokens | Local SQLite | Remote DB | ❌ Unavailable |

### server.yml Structure (Cluster Mode with Cache)

```yaml
# Database connection (always present)
server:
  database:
    driver: postgres
    host: db.example.com
    port: 5432
    name: myapp
    username: myapp
    password: ${DB_PASSWORD}
    sslmode: require

# Cached configuration (synced from database)
# Used as backup when database unavailable
_cache:
  last_sync: "2025-01-15T10:30:00Z"

  admin:
    email: admin@example.com
    # Note: password NOT cached (security)

  branding:
    title: "My Application"
    tagline: "The best app ever"

  ssl:
    enabled: true
    letsencrypt:
      enabled: true
      email: admin@example.com

  # ... all other settings cached here
```

### Database Schema for Configuration

**Configuration Table (in remote database):**

| Column | Type | Description |
|--------|------|-------------|
| `key` | String | Config key (e.g., "branding.title") |
| `value` | JSON | Config value |
| `updated_at` | Timestamp | Last update time |
| `updated_by` | String | Node ID or "admin" |

**Example data:**

| key | value | updated_at |
|-----|-------|------------|
| `branding.title` | `"My Application"` | 2025-01-15 10:30:00 |
| `branding.tagline` | `"The best app"` | 2025-01-15 10:30:00 |
| `ssl.enabled` | `true` | 2025-01-15 09:00:00 |
| `ssl.letsencrypt.enabled` | `true` | 2025-01-15 09:00:00 |
| `rate_limit.enabled` | `true` | 2025-01-14 15:00:00 |
| `rate_limit.requests` | `120` | 2025-01-14 15:00:00 |

**Cluster State Table:**

| Column | Type | Description |
|--------|------|-------------|
| `key` | String | State key |
| `value` | JSON | State value |
| `node_id` | String | Node that owns this state (or NULL for global) |
| `updated_at` | Timestamp | Last update |

**Example state data:**

| key | value | node_id | updated_at |
|-----|-------|---------|------------|
| `cluster.id` | `"cluster_abc123"` | NULL | 2025-01-10 |
| `cluster.name` | `"Production"` | NULL | 2025-01-10 |
| `encryption.key` | `"encrypted..."` | NULL | 2025-01-10 |
| `tor.onion_address` | `"abc...xyz.onion"` | `node-1` | 2025-01-15 |
| `tor.onion_address` | `"def...uvw.onion"` | `node-2` | 2025-01-15 |

### Full Database Schema Summary

**Server Tables (srv_* prefix in remote DB, or server.db in SQLite):**

| Table | Purpose |
|-------|---------|
| `config` / `srv_config` | Configuration key-value pairs |
| `config_meta` / `srv_config_meta` | Config metadata (defaults, restart flags) |
| `admin_sessions` / `srv_admin_sessions` | Admin web sessions |
| `rate_limits` / `srv_rate_limits` | Rate limiting counters |
| `audit_log` / `srv_audit_log` | Admin actions, config changes |
| `scheduler_tasks` / `srv_scheduler_tasks` | Scheduled task definitions |
| `scheduler_history` / `srv_scheduler_history` | Task execution history |
| `backups` / `srv_backups` | Backup metadata |

**User Tables (usr_* prefix in remote DB, or users.db in SQLite):**

| Table | Purpose |
|-------|---------|
| `admins` / `usr_admins` | Admin accounts |
| `users` / `usr_users` | Regular user accounts |
| `api_keys` / `usr_api_keys` | API keys |
| `password_resets` / `usr_password_resets` | Password reset tokens |
| `email_verifications` / `usr_email_verifications` | Email verification tokens |
| `totp_secrets` / `usr_totp_secrets` | TOTP 2FA secrets |
| `passkeys` / `usr_passkeys` | WebAuthn/FIDO2 credentials |
| `trusted_devices` / `usr_trusted_devices` | Remembered 2FA devices |
| `user_sessions` / `usr_user_sessions` | User web sessions |
| `custom_domains` / `usr_custom_domains` | User/org custom domains with SSL (optional) |
| `custom_domain_audit` / `usr_custom_domain_audit` | Custom domain audit log (optional) |

## Boolean Handling (NON-NEGOTIABLE)

**ALL boolean parsing in the application MUST use `config.ParseBool()` or `config.IsTruthy()`.**

This applies to:
- Environment variables (`DEBUG`, `ENABLE_*`, etc.)
- Configuration file values (YAML, JSON, TOML)
- CLI flag values
- API request parameters
- Form inputs
- Query string parameters

**Accept ALL of these values for booleans (case-insensitive):**

| Truthy | Falsy |
|--------|-------|
| `1` | `0` |
| `yes` | `no` |
| `true` | `false` |
| `enable` | `disable` |
| `enabled` | `disabled` |
| `on` | `off` |
| `yep` | `nope` |
| `yup` | `nah` |
| `yeah` | `nay` |
| `affirmative` | `negative` |
| `aye` | `nein` |
| `si` | `non` |
| `oui` | `niet` |
| `da` | `iie` |
| `hai` | `lie` |
| `totally` | `noway` |
| `sure` | `never` |
| `ok` | `deny` |
| `accept` | `reject` |
| `allow` | `block` |
| `grant` | `revoke` |
| `y` | `n` |
| `t` | `f` |

**Rules:**
- Case-insensitive: `YES`, `yes`, `Yes` all → `true`
- Internally convert all to `true` or `false`
- Empty string or unset → use default value
- Invalid value → error (don't silently default)

**Go Implementation (`src/config/bool.go`):**

```go
package config

import (
	"fmt"
	"strings"
)

// Truthy values (case-insensitive)
var truthyValues = map[string]bool{
	"1": true, "y": true, "t": true,
	"yes": true, "true": true, "on": true, "ok": true,
	"enable": true, "enabled": true,
	"yep": true, "yup": true, "yeah": true,
	"aye": true, "si": true, "oui": true, "da": true, "hai": true,
	"affirmative": true, "accept": true, "allow": true, "grant": true,
	"sure": true, "totally": true,
}

// Falsy values (case-insensitive)
var falsyValues = map[string]bool{
	"0": true, "n": true, "f": true,
	"no": true, "false": true, "off": true,
	"disable": true, "disabled": true,
	"nope": true, "nah": true, "nay": true,
	"nein": true, "non": true, "niet": true, "iie": true, "lie": true,
	"negative": true, "reject": true, "block": true, "revoke": true,
	"deny": true, "never": true, "noway": true,
}

// ParseBool parses a string into a boolean using truthy/falsy values.
// Returns the parsed value and nil on success.
// Returns false and an error for invalid values.
// Empty string returns the provided default value.
func ParseBool(s string, defaultVal bool) (bool, error) {
	s = strings.TrimSpace(strings.ToLower(s))

	if s == "" {
		return defaultVal, nil
	}

	if truthyValues[s] {
		return true, nil
	}

	if falsyValues[s] {
		return false, nil
	}

	return false, fmt.Errorf("invalid boolean value: %q", s)
}

// MustParseBool parses a string into a boolean, panics on invalid value.
// Use only during initialization where invalid config should halt startup.
func MustParseBool(s string, defaultVal bool) bool {
	val, err := ParseBool(s, defaultVal)
	if err != nil {
		panic(err)
	}
	return val
}

// IsTruthy returns true if the string is a truthy value.
// Returns false for empty, invalid, or falsy values (no error).
func IsTruthy(s string) bool {
	return truthyValues[strings.TrimSpace(strings.ToLower(s))]
}

// IsFalsy returns true if the string is a falsy value.
// Returns false for empty, invalid, or truthy values (no error).
func IsFalsy(s string) bool {
	return falsyValues[strings.TrimSpace(strings.ToLower(s))]
}
```

**Usage Examples:**

```go
// Environment variables
debug := config.MustParseBool(os.Getenv("DEBUG"), false)
enableTor := config.MustParseBool(os.Getenv("ENABLE_TOR"), true)

// Config file values (after YAML/JSON unmarshal to string)
sslEnabled, err := config.ParseBool(cfg.SSL.Enabled, false)
if err != nil {
    return fmt.Errorf("invalid ssl.enabled value: %w", err)
}

// CLI flags (custom parsing)
if config.IsTruthy(flagValue) {
    enableFeature()
}

// API request parameters
func handleRequest(w http.ResponseWriter, r *http.Request) {
    includeDeleted, _ := config.ParseBool(r.URL.Query().Get("include_deleted"), false)
    // ...
}

// Form inputs
func handleForm(w http.ResponseWriter, r *http.Request) {
    newsletter, _ := config.ParseBool(r.FormValue("subscribe_newsletter"), false)
    // ...
}

// JSON API body
// All fields are strings to accept flexible boolean input (true/false, yes/no, 1/0)
type CreateUserRequest struct {
    Email    string `json:"email"`
    IsAdmin  string `json:"is_admin"`
    Verified string `json:"verified"`
}

func (req *CreateUserRequest) Parse() (*User, error) {
    isAdmin, err := config.ParseBool(req.IsAdmin, false)
    if err != nil {
        return nil, fmt.Errorf("invalid is_admin: %w", err)
    }
    verified, err := config.ParseBool(req.Verified, false)
    if err != nil {
        return nil, fmt.Errorf("invalid verified: %w", err)
    }
    return &User{Email: req.Email, IsAdmin: isAdmin, Verified: verified}, nil
}
```

**NEVER use `strconv.ParseBool()` directly** - it only accepts `true/false/1/0/t/f`. Always use `config.ParseBool()` for consistent behavior across the application.

## Environment Variables (NON-NEGOTIABLE)

### Runtime Variables (Always Checked)

| Variable | Description |
|----------|-------------|
| `DOMAIN` | FQDN override (highest priority for hostname resolution) |
| `MODE` | `production` (default) or `development` |
| `DATABASE_DRIVER` | `file`, `sqlite`, `mariadb`, `mysql`, `postgres`, `mssql`, `mongodb` |
| `DATABASE_URL` | Database connection string |
| `SMTP_HOST` | SMTP server hostname (if set, skips autodetect) |
| `SMTP_PORT` | SMTP server port (default: 587) |
| `SMTP_USERNAME` | SMTP authentication username |
| `SMTP_PASSWORD` | SMTP authentication password |
| `SMTP_FROM_NAME` | Sender name (default: app title) |
| `SMTP_FROM_EMAIL` | Sender email (default: `no-reply@{fqdn}`) |
| `SMTP_TLS` | TLS mode: `auto`, `starttls`, `tls`, `none` (default: `auto`) |

**URL Variable Resolution (Reverse Proxy Preferred):**
- `{fqdn}`: Reverse Proxy Headers → `DOMAIN` → `os.Hostname()` → `$HOSTNAME` → Global IP → `localhost`
- `{proto}`: `X-Forwarded-Proto` → `X-Forwarded-Ssl` → TLS detection → `http`
- `{port}`: `X-Forwarded-Port` → Host header → Server port → Proto default

**Note:** Loopback addresses avoided; global IPs preferred. See PART 5 for full details.

### Init-Only Variables (First Run Only)

| Variable | Description |
|----------|-------------|
| `CONFIG_DIR` | Configuration directory |
| `DATA_DIR` | Data directory |
| `LOG_DIR` | Log directory |
| `DATABASE_DIR` | SQLite database directory (changeable) |
| `BACKUP_DIR` | Backup directory (changeable) |
| `PORT` | Server port |
| `LISTEN` | Listen address |
| `APPLICATION_NAME` | Application title |
| `APPLICATION_TAGLINE` | Application description |

**Init-only variables are used ONCE during first run, then ignored.**

---

## Configuration File (NON-NEGOTIABLE)

### Design Rules

| Rule | Description |
|------|-------------|
| **Clean & Intuitive** | Easy to read and understand |
| **Everything Configurable** | If it has a setting, it's in the config |
| **Sane Defaults** | Built-in defaults (no 1000-line configs) |
| **Comprehensive** | All options present (commented/defaulted) |
| **Comments** | Single-line, under 140 characters |

### Location

| User Type | Path |
|-----------|------|
| Root | `/etc/apimgr/weather/server.yml` |
| Regular | `~/.config/apimgr/weather/server.yml` |

### Migration

**If `server.yaml` found, auto-migrate to `server.yml` on startup.**

## Port Rules (NON-NEGOTIABLE)

**Default port is a random unused port in the 64000-64999 range.**

### Port Selection Logic

| Scenario | Port | Behavior |
|----------|------|----------|
| First run (no config) | Random 64xxx | Auto-select unused port in 64000-64999, **save to config** |
| Config specifies port | Use specified | Use exact port from config |
| Port in use | Error | Fail with clear error message |
| Privileged port (<1024) | Requires root | Warn if not running as root |

**IMPORTANT: Once a port is selected (randomly or specified), it is saved to `server.yml` and persists across restarts. The random selection only happens on first run when no port is configured.**

### Why Random 64xxx?

| Reason | Description |
|--------|-------------|
| **Avoid conflicts** | Most services use well-known ports; 64xxx is rarely used |
| **No root required** | Ports >1024 don't need root privileges |
| **Self-hosted friendly** | Users can run multiple instances without conflict |
| **Reverse proxy ready** | Designed to run behind nginx/caddy/traefik |

### Special Port Handling

| Port | Special Behavior |
|------|------------------|
| `80` | Enable Let's Encrypt HTTP-01 challenge |
| `443` | Enable Let's Encrypt TLS-ALPN-01 challenge, auto-enable SSL |
| `0` | Let OS assign any available port |
| `64000-64999` | Default range for random selection |

### Port Display Rules

| Rule | Description |
|------|-------------|
| Strip `:80` | Don't show port for HTTP on 80 |
| Strip `:443` | Don't show port for HTTPS on 443 |
| Always show others | Show port for all non-standard ports |

### Dual Port Support

**Applications can listen on two ports simultaneously for HTTP and HTTPS:**

| Format | Description | Example |
|--------|-------------|---------|
| Single | One port (HTTP; exception: port 443 = HTTPS-only; `ssl.enabled` overrides) | `8090` |
| Dual | HTTP port, HTTPS port (comma-separated) | `8090,8443` |

**Dual Port Behavior:**

| HTTP Port | HTTPS Port | Behavior |
|-----------|------------|----------|
| Any | Any | Both ports active, HTTP redirects to HTTPS optional |
| 80 | 443 | Let's Encrypt challenges enabled, standard web ports |
| 64xxx | 64xxx+1 | Common pattern for random ports |

```yaml
# Single port (HTTP by default; exception: port 443 = HTTPS-only mode; ssl.enabled overrides)
server:
  port: 8090

# Single port with ssl.enabled override (HTTPS on non-443 port)
# Forces HTTPS on port 8090
server:
  port: 8090
  ssl:
    enabled: true

# Dual port (HTTP on 8090, HTTPS on 8443)
server:
  port: "8090,8443"
  ssl:
    enabled: true

# Standard web ports
server:
  port: "80,443"
  ssl:
    enabled: true
    letsencrypt:
      enabled: true
```

### Configuration

```yaml
server:
  # Port options:
  # - Omit or empty: Random port in 64000-64999 range
  # - Single number: Use that exact port
  # - Dual (HTTP,HTTPS): "8090,8443" format
  # - 0: Let OS assign any available port
  port: 64580
```

### Admin Panel

Port can be changed via `/admin/server/settings`, but **requires server restart** (with warning shown to user).

### Example Structure

```yaml
# =============================================================================
# SERVER CONFIGURATION
# =============================================================================

server:
  # Default: random unused port in 64xxx range
  port: {random}
  # Auto-detected from host
  fqdn: {hostname}
  # [::] = all interfaces IPv4/IPv6
  address: "[::]"
  # production or development
  mode: production
  # Admin panel path (default: admin) - see PART 17
  admin_path: admin

  # Branding & SEO - see PART 16 for full details
  branding:
    title: "weather"
    tagline: ""
    description: ""
  seo:
    keywords: []

  # System user/group
  user: {auto}
  group: {auto}

  # PID file
  pidfile: true

  # Daemonize on start (detach from terminal)
  # Default: false (modern service managers prefer foreground)
  daemonize: false

  # Admin Panel
  admin:
    email: admin@{fqdn}
    # Note: username, password, and token are stored in database (admins table)
    # NOT in this config file for security

  # SSL/TLS
  ssl:
    enabled: false
    # cert/key: Optional manual override paths (leave empty for auto-detection)
    # Auto-detection order:
    #   /etc/letsencrypt/live/domain/ → system manages (certbot)
    #   /etc/letsencrypt/live/{fqdn}/ → system manages (certbot)
    #   {config_dir}/ssl/letsencrypt/{fqdn}/ → app manages (auto-renew)
    #   {config_dir}/ssl/local/{fqdn}/ → user manages (no auto-renew)
    cert: ""   # Manual cert path (optional)
    key: ""    # Manual key path (optional)
    min_version: "TLS1.2"  # TLS1.2, TLS1.3

    letsencrypt:
      enabled: false
      email: admin@{fqdn}
      challenge: http-01  # http-01, tls-alpn-01, dns-01
      staging: false      # Use staging server for testing

  # Scheduler - manages all background tasks
  scheduler:
    enabled: true
    # Built-in tasks with sane defaults (all enabled by default)
    tasks:
      # Security database updates
      geoip_update:
        enabled: true
        # Weekly: Sunday 3:00 AM
        schedule: "0 3 * * 0"
        retry_on_fail: true
        retry_delay: 1h
      blocklist_update:
        enabled: true
        # Daily: 4:00 AM
        schedule: "0 4 * * *"
        retry_on_fail: true
        retry_delay: 1h
      cve_update:
        enabled: true
        # Daily: 5:00 AM
        schedule: "0 5 * * *"
        retry_on_fail: true
        retry_delay: 1h

      # Maintenance tasks
      log_rotation:
        enabled: true
        # Daily: midnight
        schedule: "0 0 * * *"
        max_age: 30d
        max_size: 100MB
      session_cleanup:
        enabled: true
        # Hourly
        schedule: "@hourly"
      backup:
        enabled: true
        # Daily: 2:00 AM
        schedule: "0 2 * * *"
        # Keep max 4 backups (storage management)
        retention: 4

      # SSL certificate management (only when app manages certs)
      ssl_renewal:
        enabled: true
        # Daily: 3:00 AM (after backup at 2:00)
        schedule: "0 3 * * *"
        # Renew 7 days before expiry
        renew_before: 7d

      # Health checks
      health_check:
        enabled: true
        # Every 5 minutes
        schedule: "*/5 * * * *"

      # Tor maintenance
      tor_health:
        enabled: true
        # Every 10 minutes
        schedule: "*/10 * * * *"

  rate_limit:
    enabled: true
    requests: 120
    window: 60

  # Database
  database:
    driver: file

# =============================================================================
# FRONTEND CONFIGURATION
# =============================================================================

web:
  ui:
    theme: dark
  cors: "*"
```

---

# CHECKPOINT 4: CONFIGURATION VERIFICATION

Before proceeding, confirm you understand:
- [ ] Config file is `server.yml` (not .yaml)
- [ ] Boolean handling uses `config.ParseBool()` - NEVER `strconv.ParseBool()`
- [ ] All boolean inputs accept truthy/falsy values (yes, enable, oui, etc.)
- [ ] Environment variables: some runtime, some init-only
- [ ] Config auto-created on first run with sane defaults

---


# PART 6: APPLICATION MODES (NON-NEGOTIABLE)

## Mode and Debug Detection Priority

**Mode:**
1. `--mode` CLI flag (highest priority)
2. `MODE` environment variable
3. Default: `production`

**Debug:**
1. `--debug` CLI flag (highest priority)
2. `DEBUG` environment variable (truthy values)
3. Default: `false`

## Three Operational States

| State | Mode | Debug | Use Case |
|-------|------|-------|----------|
| **Production** | `production` | `false` | Live deployment, no debugging |
| **Production + Debug** | `production` | `true` | Live debugging (temporary) |
| **Development** | `development` | `false` | Local development, sensible defaults |
| **Development + Debug** | `development` | `true` | Full debugging, all features |

## Production Mode (Default)

| Setting | Behavior |
|---------|----------|
| Logging | `info` level, minimal output |
| Debug endpoints | **Disabled** (`/debug/*` returns 404) |
| pprof endpoints | **Disabled** |
| Error messages | Generic (no stack traces) |
| Panic recovery | Graceful (logs error, returns 500) |
| Template caching | Enabled |
| Static file caching | Enabled |
| Rate limiting | Enforced |
| Security headers | All enabled |
| Sensitive data | Never shown |
| Request logging | Minimal (status, duration) |

## Development Mode

**Enables sensible debugging for local development, but NOT full debug endpoints.**

| Setting | Behavior |
|---------|----------|
| Logging | `debug` level, verbose |
| Debug endpoints | **Disabled** (use `--debug` to enable) |
| pprof endpoints | **Disabled** (use `--debug` to enable) |
| Error messages | Detailed (stack traces in logs) |
| Panic recovery | Verbose (full stack in response) |
| Template caching | Disabled (hot reload) |
| Static file caching | Disabled (hot reload) |
| Rate limiting | Relaxed/disabled |
| Security headers | Relaxed (CORS permissive) |
| Sensitive data | Can be shown (with warning) |
| Request logging | Verbose (headers, body preview) |

## Debug Flag (`--debug` / `DEBUG=true`)

**Enables ALL debug features regardless of mode. Use sparingly in production.**

| Setting | Behavior |
|---------|----------|
| **Admin authentication** | **BYPASSED** (for manual dev only - NOT for automated tests) |
| Debug endpoints | **Enabled** (`/debug/*`) |
| pprof endpoints | **Enabled** (`/debug/pprof/*`) |
| expvar endpoints | **Enabled** (`/debug/vars`) |
| Request/response logging | Full (headers, body, timing) |
| Database query logging | Enabled (queries, timing, rows) |
| Cache operation logging | Enabled (hits, misses, evictions) |
| Memory profiling | Enabled |
| Goroutine monitoring | Enabled |

**Console output when debug enabled:**
```
🔒 Running in mode: production [debugging]
🔧 Running in mode: development [debugging]
```

## Mode Shortcuts

| Shortcut | Mode |
|----------|------|
| `--mode dev` | development |
| `--mode development` | development |
| `--mode prod` | production |
| `--mode production` | production |

## Debug Endpoints (`--debug` / `DEBUG=true` Only)

**Debug endpoints are ONLY available when `--debug` flag or `DEBUG=true` is set. Otherwise returns 404.**

### pprof Endpoints

| Endpoint | Purpose |
|----------|---------|
| `/debug/pprof/` | Index page with all profiles |
| `/debug/pprof/heap` | Heap memory profile |
| `/debug/pprof/goroutine` | Goroutine stack traces |
| `/debug/pprof/allocs` | Memory allocation profile |
| `/debug/pprof/block` | Blocking profile |
| `/debug/pprof/mutex` | Mutex contention profile |
| `/debug/pprof/threadcreate` | Thread creation profile |
| `/debug/pprof/cmdline` | Command line arguments |
| `/debug/pprof/profile` | CPU profile (30s default) |
| `/debug/pprof/symbol` | Symbol lookup |
| `/debug/pprof/trace` | Execution trace |

### Debug API Endpoints

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/debug/vars` | GET | Runtime variables (expvar) |
| `/debug/config` | GET | Current configuration (sanitized) |
| `/debug/routes` | GET | All registered routes |
| `/debug/cache` | GET | Cache statistics |
| `/debug/db` | GET | Database statistics |
| `/debug/scheduler` | GET | Scheduler task status |

### Debug Implementation

```go
// src/server/debug.go
package server

import (
    "expvar"
    "net/http"
    "net/http/pprof"
    "runtime"

    "github.com/go-chi/chi/v5"
)

// registerDebugRoutes registers debug endpoints (--debug/DEBUG=true only)
func (s *Server) registerDebugRoutes(r chi.Router) {
    if !s.config.IsDebug() {
        // No debug routes unless --debug or DEBUG=true
        return
    }

    r.Route("/debug", func(r chi.Router) {
        // pprof endpoints
        r.HandleFunc("/pprof/", pprof.Index)
        r.HandleFunc("/pprof/cmdline", pprof.Cmdline)
        r.HandleFunc("/pprof/profile", pprof.Profile)
        r.HandleFunc("/pprof/symbol", pprof.Symbol)
        r.HandleFunc("/pprof/trace", pprof.Trace)
        r.Handle("/pprof/heap", pprof.Handler("heap"))
        r.Handle("/pprof/goroutine", pprof.Handler("goroutine"))
        r.Handle("/pprof/allocs", pprof.Handler("allocs"))
        r.Handle("/pprof/block", pprof.Handler("block"))
        r.Handle("/pprof/mutex", pprof.Handler("mutex"))
        r.Handle("/pprof/threadcreate", pprof.Handler("threadcreate"))

        // expvar
        r.Handle("/vars", expvar.Handler())

        // Custom debug endpoints
        r.Get("/config", s.handleDebugConfig)
        r.Get("/routes", s.handleDebugRoutes)
        r.Get("/cache", s.handleDebugCache)
        r.Get("/db", s.handleDebugDB)
        r.Get("/scheduler", s.handleDebugScheduler)
        r.Get("/memory", s.handleDebugMemory)
        r.Get("/goroutines", s.handleDebugGoroutines)
    })
}

// handleDebugConfig returns sanitized configuration
func (s *Server) handleDebugConfig(w http.ResponseWriter, r *http.Request) {
    // Return config with sensitive values redacted
    sanitized := s.config.Sanitized()
    respondJSON(w, http.StatusOK, sanitized)
}

// handleDebugRoutes returns all registered routes
func (s *Server) handleDebugRoutes(w http.ResponseWriter, r *http.Request) {
    routes := []map[string]string{}

    walkFunc := func(method string, route string, handler http.Handler, middlewares ...func(http.Handler) http.Handler) error {
        routes = append(routes, map[string]string{
            "method": method,
            "route":  route,
        })
        return nil
    }

    if err := chi.Walk(s.router, walkFunc); err != nil {
        respondError(w, http.StatusInternalServerError, "Failed to walk routes")
        return
    }

    respondJSON(w, http.StatusOK, map[string]any{
        "count":  len(routes),
        "routes": routes,
    })
}

// handleDebugMemory returns memory statistics
func (s *Server) handleDebugMemory(w http.ResponseWriter, r *http.Request) {
    var m runtime.MemStats
    runtime.ReadMemStats(&m)

    respondJSON(w, http.StatusOK, map[string]any{
        "alloc_mb":       m.Alloc / 1024 / 1024,
        "total_alloc_mb": m.TotalAlloc / 1024 / 1024,
        "sys_mb":         m.Sys / 1024 / 1024,
        "num_gc":         m.NumGC,
        "heap_objects":   m.HeapObjects,
        "goroutines":     runtime.NumGoroutine(),
    })
}

// handleDebugGoroutines returns goroutine count and stack traces
func (s *Server) handleDebugGoroutines(w http.ResponseWriter, r *http.Request) {
    // 1MB buffer for stack traces
    buf := make([]byte, 1024*1024)
    // true = include all goroutines
    n := runtime.Stack(buf, true)

    w.Header().Set("Content-Type", "text/plain; charset=utf-8")
    w.WriteHeader(http.StatusOK)
    w.Write(buf[:n])
}

// handleDebugCache returns cache statistics
func (s *Server) handleDebugCache(w http.ResponseWriter, r *http.Request) {
    stats := s.cache.Stats()
    respondJSON(w, http.StatusOK, stats)
}

// handleDebugDB returns database statistics
func (s *Server) handleDebugDB(w http.ResponseWriter, r *http.Request) {
    stats := s.db.Stats()
    respondJSON(w, http.StatusOK, map[string]any{
        "open_connections":  stats.OpenConnections,
        "in_use":            stats.InUse,
        "idle":              stats.Idle,
        "wait_count":        stats.WaitCount,
        "wait_duration_ms":  stats.WaitDuration.Milliseconds(),
        "max_idle_closed":   stats.MaxIdleClosed,
        "max_lifetime_closed": stats.MaxLifetimeClosed,
    })
}

// handleDebugScheduler returns scheduler task status
func (s *Server) handleDebugScheduler(w http.ResponseWriter, r *http.Request) {
    tasks := s.scheduler.Status()
    respondJSON(w, http.StatusOK, tasks)
}
```

### Debug Logging

```go
// src/server/debug_log.go
package server

import (
    "log/slog"
    "net/http"
    "time"
)

// debugLog logs detailed request information (--debug/DEBUG=true only)
func (s *Server) debugLog(r *http.Request, status int, duration time.Duration, size int) {
    if !s.config.IsDebug() {
        return
    }

    slog.Debug("request",
        "method", r.Method,
        "path", r.URL.Path,
        "query", r.URL.RawQuery,
        "status", status,
        "duration_ms", duration.Milliseconds(),
        "size", size,
        "remote_addr", r.RemoteAddr,
        "user_agent", r.UserAgent(),
        "referer", r.Referer(),
        "request_id", r.Header.Get("X-Request-ID"),
    )
}

// debugLogDB logs database queries (--debug/DEBUG=true only)
func (s *Server) debugLogDB(query string, args []any, duration time.Duration, err error) {
    if !s.config.IsDebug() {
        return
    }

    attrs := []any{
        "query", query,
        "duration_ms", duration.Milliseconds(),
    }

    if len(args) > 0 {
        attrs = append(attrs, "args", args)
    }

    if err != nil {
        attrs = append(attrs, "error", err.Error())
        slog.Debug("db query failed", attrs...)
    } else {
        slog.Debug("db query", attrs...)
    }
}

// debugLogCache logs cache operations (--debug/DEBUG=true only)
func (s *Server) debugLogCache(op string, key string, hit bool, duration time.Duration) {
    if !s.config.IsDebug() {
        return
    }

    slog.Debug("cache",
        "operation", op,
        "key", key,
        "hit", hit,
        "duration_us", duration.Microseconds(),
    )
}
```

### Debug Middleware

```go
// src/server/middleware_debug.go
package server

import (
    "bytes"
    "io"
    "net/http"
    "time"
)

// debugMiddleware logs detailed request/response info (--debug/DEBUG=true only)
func (s *Server) debugMiddleware(next http.Handler) http.Handler {
    // No-op unless debug enabled
    if !s.config.IsDebug() {
        return next
    }

    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()

        // Capture request body for logging (limit to 10KB)
        var requestBody []byte
        if r.Body != nil && r.ContentLength > 0 && r.ContentLength < 10*1024 {
            requestBody, _ = io.ReadAll(r.Body)
            r.Body = io.NopCloser(bytes.NewBuffer(requestBody))
        }

        // Wrap response writer to capture status and size
        rw := &responseWriter{ResponseWriter: w, status: http.StatusOK}

        // Process request
        next.ServeHTTP(rw, r)

        // Log after request completes
        s.debugLog(r, rw.status, time.Since(start), rw.size)
    })
}

type responseWriter struct {
    http.ResponseWriter
    status int
    size   int
}

func (rw *responseWriter) WriteHeader(status int) {
    rw.status = status
    rw.ResponseWriter.WriteHeader(status)
}

func (rw *responseWriter) Write(b []byte) (int, error) {
    n, err := rw.ResponseWriter.Write(b)
    rw.size += n
    return n, err
}
```

### expvar Registration

```go
// src/server/expvar.go
package server

import (
    "expvar"
    "runtime"
    "time"
)

var (
    requestCount    = expvar.NewInt("requests_total")
    requestDuration = expvar.NewFloat("requests_duration_seconds")
    errorCount      = expvar.NewInt("errors_total")
    goroutineCount  = expvar.NewInt("goroutines")
    startTime       = time.Now()
)

func init() {
    // Publish uptime
    expvar.Publish("uptime_seconds", expvar.Func(func() any {
        return time.Since(startTime).Seconds()
    }))

    // Publish goroutine count
    expvar.Publish("goroutines", expvar.Func(func() any {
        return runtime.NumGoroutine()
    }))

    // Publish memory stats
    expvar.Publish("memory", expvar.Func(func() any {
        var m runtime.MemStats
        runtime.ReadMemStats(&m)
        return map[string]uint64{
            "alloc":       m.Alloc,
            "total_alloc": m.TotalAlloc,
            "sys":         m.Sys,
            "heap_alloc":  m.HeapAlloc,
            "heap_sys":    m.HeapSys,
        }
    }))
}

// recordRequest records a request for expvar
func recordRequest(duration time.Duration) {
    requestCount.Add(1)
    requestDuration.Add(duration.Seconds())
}

// recordError records an error for expvar
func recordError() {
    errorCount.Add(1)
}
```

### Using pprof (Commands)

```bash
# CPU profile (30 seconds)
go tool pprof http://localhost:64580/debug/pprof/profile

# Heap memory
go tool pprof http://localhost:64580/debug/pprof/heap

# Goroutines
go tool pprof http://localhost:64580/debug/pprof/goroutine

# Allocations
go tool pprof http://localhost:64580/debug/pprof/allocs

# Blocking profile (requires runtime.SetBlockProfileRate)
go tool pprof http://localhost:64580/debug/pprof/block

# Mutex contention (requires runtime.SetMutexProfileFraction)
go tool pprof http://localhost:64580/debug/pprof/mutex

# Execution trace (download and view)
curl -o trace.out http://localhost:64580/debug/pprof/trace?seconds=5
go tool trace trace.out

# Web UI for profiles
go tool pprof -http=:8081 http://localhost:64580/debug/pprof/heap
```

### Debug Configuration

```yaml
server:
  # Application mode
  mode: development  # Enables all debug features

  # Debug-specific settings (only apply in development mode)
  debug:
    # Enable pprof endpoints
    pprof: true

    # Log all SQL queries
    log_queries: true

    # Log cache operations
    log_cache: true

    # Log request/response bodies (up to max_body_log_size)
    log_bodies: false
    max_body_log_size: 10240  # 10KB

    # Block profiling rate (0 = disabled)
    block_profile_rate: 1

    # Mutex profiling fraction (0 = disabled)
    mutex_profile_fraction: 1

    # Enable runtime/debug endpoints
    runtime_endpoints: true
```

### Debug Mode Detection

```go
// src/mode/mode.go
package mode

import (
    "os"
    "runtime"
    "strings"

    "github.com/apimgr/weather/src/config"
)

var (
    currentMode = Production
    debugEnabled = false
)

type Mode int

const (
    Production Mode = iota
    Development
)

func (m Mode) String() string {
    switch m {
    case Development:
        return "development"
    default:
        return "production"
    }
}

// Set sets the application mode
func Set(m string) {
    switch strings.ToLower(m) {
    case "dev", "development":
        currentMode = Development
    default:
        currentMode = Production
    }
    updateProfilingSettings()
}

// SetDebug enables or disables debug mode
func SetDebug(enabled bool) {
    debugEnabled = enabled
    updateProfilingSettings()
}

// updateProfilingSettings enables/disables profiling based on debug flag
func updateProfilingSettings() {
    if debugEnabled {
        // Enable profiling when debug is on
        runtime.SetBlockProfileRate(1)
        runtime.SetMutexProfileFraction(1)
    } else {
        // Disable profiling when debug is off
        runtime.SetBlockProfileRate(0)
        runtime.SetMutexProfileFraction(0)
    }
}

// Current returns the current mode
func Current() Mode {
    return currentMode
}

// IsDevelopment returns true if in development mode
func IsDevelopment() bool {
    return currentMode == Development
}

// IsProduction returns true if in production mode
func IsProduction() bool {
    return currentMode == Production
}

// IsDebug returns true if debug mode is enabled (--debug or DEBUG=true)
func IsDebug() bool {
    return debugEnabled
}

// ModeString returns mode string with debug suffix if enabled
func ModeString() string {
    s := currentMode.String()
    if debugEnabled {
        s += " [debugging]"
    }
    return s
}

// FromEnv sets mode and debug from environment variables
func FromEnv() {
    if m := os.Getenv("MODE"); m != "" {
        Set(m)
    }
    if config.IsTruthy(os.Getenv("DEBUG")) {
        SetDebug(true)
    }
}
```

---


# PART 7: BINARY REQUIREMENTS (NON-NEGOTIABLE)

## Single Static Binary

| Requirement | Description |
|-------------|-------------|
| Type | **SINGLE STATIC BINARY** |
| Assets | Embedded using Go's `embed` package |
| Dependencies | None at runtime |
| Build | **CGO_ENABLED=0** |
| Libraries | Pure Go only (no CGO) |

## Default Behavior

| Behavior | Description |
|----------|-------------|
| No arguments | Initialize (if needed) and start server |
| First run | Auto-create config with defaults |
| First run | Auto-create required directories |
| Signals | Proper handling (SIGTERM, SIGINT, SIGHUP) |
| PID file | Enabled by default |

## Embedded Assets

| Asset Type | Location |
|------------|----------|
| Templates | `src/server/template/` |
| Static files | `src/server/static/` |
| Application data | `src/data/` (JSON files) |

## External Data (NOT Embedded)

**Security databases are NEVER embedded in the binary.** They are downloaded on first run and kept updated via the built-in scheduler.

| Data Type | Location | Source | Update Frequency |
|-----------|----------|--------|------------------|
| GeoIP (ASN) | `{config_dir}/security/geoip/` | ip-location-db | Daily |
| GeoIP (Country) | `{config_dir}/security/geoip/` | ip-location-db | Daily |
| GeoIP (City) | `{config_dir}/security/geoip/` | ip-location-db | Daily |
| GeoIP (WHOIS) | `{config_dir}/security/geoip/` | ip-location-db | Daily |
| IP Blocklists | `{config_dir}/security/blocklists/` | Configurable sources | Daily |
| Domain Blocklists | `{config_dir}/security/blocklists/` | Configurable sources | Daily |
| CVE databases | `{config_dir}/security/cve/` | NVD/NIST feeds | Daily |
| Trivy DB | `{config_dir}/security/trivy/` | Aqua Security | Daily |

**Why NOT Embedded:**
- Security data changes frequently (daily/weekly updates)
- Embedding would require new binary releases for data updates
- Allows immediate security updates without redeployment
- Reduces binary size significantly

**Download Behavior:**
1. On first run, check if data exists in `{config_dir}/security/`
2. If missing, download from configured sources
3. If download fails, log warning and continue (graceful degradation)
4. Scheduler keeps data updated automatically

### Default Data Sources

```yaml
# Data source configuration (in server.yml)
data:
  # Base directory for all security databases
  security_dir: "{config_dir}/security"

  geoip:
    # ip-location-db (https://github.com/sapics/ip-location-db)
    # Free, no API key required, daily updates, CC0/PDDL licensed
    provider: "ip-location-db"
    databases:
      asn:
        enabled: true
        url: "https://cdn.jsdelivr.net/npm/@ip-location-db/asn-mmdb/asn.mmdb"
        file: "asn.mmdb"
      country:
        enabled: true
        url: "https://cdn.jsdelivr.net/npm/@ip-location-db/geo-whois-asn-country-mmdb/geo-whois-asn-country.mmdb"
        file: "country.mmdb"
      city:
        enabled: true
        url: "https://cdn.jsdelivr.net/npm/@ip-location-db/dbip-city-mmdb/dbip-city-ipv4.mmdb"
        file: "city.mmdb"
      whois:
        enabled: true
        url: "https://cdn.jsdelivr.net/npm/@ip-location-db/geo-whois-asn-country-mmdb/geo-whois-asn-country.mmdb"
        file: "whois.mmdb"

  blocklists:
    # Default blocklist sources (configurable)
    sources:
      - name: "firehol_level1"
        url: "https://iplists.firehol.org/files/firehol_level1.netset"
        type: ip
        enabled: true
      - name: "spamhaus_drop"
        url: "https://www.spamhaus.org/drop/drop.txt"
        type: ip
        enabled: true
      - name: "abuse_ch_urlhaus"
        url: "https://urlhaus.abuse.ch/downloads/text/"
        type: domain
        # Optional
        enabled: false

  cve:
    # NVD (NIST National Vulnerability Database)
    source: "https://nvd.nist.gov/feeds/json/cve/1.1"
    # Only download CVEs relevant to project dependencies
    filter_by_cpe: true

  trivy:
    # Aqua Trivy vulnerability database (optional, for container scanning)
    enabled: false
    source: "https://ghcr.io/aquasecurity/trivy-db"
```

### Security Directory Structure

```
{config_dir}/security/
├── geoip/
│   ├── asn.mmdb                 # ASN lookups (AS number, organization)
│   ├── country.mmdb             # Country code lookups
│   ├── city.mmdb                # City, region, coordinates, timezone
│   ├── whois.mmdb               # WHOIS data (registrant, org)
│   └── .last_updated            # Timestamp file
├── blocklists/
│   ├── firehol_level1.txt
│   ├── spamhaus_drop.txt
│   └── .last_updated
├── cve/
│   ├── nvd.json
│   └── .last_updated
└── trivy/
    ├── db.tar.gz
    └── .last_updated
```

### GeoIP Database Details (ip-location-db)

| Database | File | Contains | Use Case |
|----------|------|----------|----------|
| ASN | `asn.mmdb` | AS number, AS organization | Network provider identification |
| Country | `country.mmdb` | Country code (ISO 3166-1) | Geo-blocking, compliance |
| City | `city.mmdb` | City, region, postal, lat/lon, timezone | Location-based features |
| WHOIS | `whois.mmdb` | Registrant info, combined with ASN | Abuse detection, attribution |

**Benefits of ip-location-db:**
- No API key or account required (unlike MaxMind)
- Daily updates via jsDelivr CDN
- CC0/PDDL licensed (no restrictions)
- MMDB format (same as MaxMind, compatible with existing Go libraries)
- IPv4 and IPv6 support

## Display Environment Detection (NON-NEGOTIABLE)

**ALL binaries (server, CLI, agent) MUST detect display environment and adapt output accordingly.**

### Display Mode Hierarchy

| Mode | When Used | Requirements |
|------|-----------|--------------|
| **GUI** | Native display available, CLI binary only | X11, Wayland, Windows, macOS |
| **TUI** | Terminal available, interactive | TTY, SSH, mosh, screen, tmux |
| **CLI** | Command provided or piped output | Any environment |
| **Headless** | No display, no TTY | Daemon, service, cron |

### Platform Detection

| Platform | Display Check | Notes |
|----------|---------------|-------|
| **Linux/BSD** | `WAYLAND_DISPLAY` or `DISPLAY` | Wayland preferred over X11 |
| **macOS** | Always (unless SSH) | Native Cocoa display |
| **Windows** | Always (unless service) | Native Win32 display |
| **SSH/Mosh** | `SSH_CLIENT`, `SSH_TTY`, `MOSH` | No GUI, TUI or CLI only |

### Terminal Detection

```go
// src/common/display/detect.go
package display

import (
    "os"
    "golang.org/x/term"
)

type DisplayEnv struct {
    HasDisplay    bool   // X11, Wayland, Windows, macOS
    DisplayType   string // "x11", "wayland", "windows", "macos", "none"
    IsTerminal    bool   // stdout is a TTY
    IsSSH         bool   // Running over SSH
    IsMosh        bool   // Running over mosh
    Cols          int    // Terminal columns (0 if no terminal)
    Rows          int    // Terminal rows (0 if no terminal)
}

func Detect() DisplayEnv {
    env := DisplayEnv{}

    // Terminal detection
    env.IsTerminal = term.IsTerminal(int(os.Stdout.Fd()))
    if env.IsTerminal {
        env.Cols, env.Rows, _ = term.GetSize(int(os.Stdout.Fd()))
    }

    // Remote session detection
    env.IsSSH = os.Getenv("SSH_CLIENT") != "" || os.Getenv("SSH_TTY") != ""
    env.IsMosh = os.Getenv("MOSH") != ""

    // Platform-specific display detection
    env.detectPlatformDisplay()

    return env
}
```

### Binary-Specific Behavior

| Binary | GUI | TUI | CLI | Headless |
|--------|-----|-----|-----|----------|
| **Server** | ❌ | Banner/status only | Commands | Default (daemon) |
| **CLI** | ✅ (optional) | ✅ (interactive) | ✅ (commands) | ❌ |
| **Agent** | ❌ | Status only | Commands | Default (service) |

**See PART 36 for full CLI/TUI/GUI mode implementation details.**

## Common Go Modules (NON-NEGOTIABLE)

**Shared packages used by server, CLI, and agent binaries:**

### Module Structure

```
src/
├── common/                          # Shared across all binaries
│   ├── display/                     # Display/terminal detection
│   │   ├── detect.go                # Core detection logic
│   │   ├── detect_unix.go           # Linux/BSD/macOS detection
│   │   ├── detect_windows.go        # Windows detection
│   │   └── mode.go                  # DisplayMode type and helpers
│   ├── theme/                       # Unified theming
│   │   ├── colors.go                # Palette definition (Dark/Light)
│   │   ├── detect.go                # System theme detection
│   │   └── css.go                   # CSS variable generation
│   ├── terminal/                    # Terminal utilities
│   │   ├── size.go                  # Terminal size and breakpoints
│   │   ├── resize.go                # SIGWINCH handling
│   │   └── symbols.go               # Unicode/ASCII symbols
│   ├── banner/                      # Startup banner
│   │   ├── banner.go                # Responsive banner printing
│   │   └── ascii.go                 # ASCII art generation
│   └── version/                     # Version info
│       └── version.go               # Build info, version strings
├── server/                          # Server binary
├── client/                          # CLI binary
│   ├── cli/                         # CLI mode
│   ├── tui/                         # TUI mode (bubbletea)
│   └── gui/                         # GUI mode (native)
└── agent/                           # Agent binary
    ├── cli/                         # Agent CLI commands
    └── collector/                   # Metrics/data collection
```

### Go Module Imports

```go
// go.mod
module apimgr/weather

go 1.xx  // Use current latest stable version

require (
    // Terminal/TUI
    golang.org/x/term v0.27.0
    github.com/charmbracelet/bubbletea v1.2.4
    github.com/charmbracelet/bubbles v0.20.0
    github.com/charmbracelet/lipgloss v1.0.0

    // CLI
    github.com/spf13/cobra v1.8.1
    github.com/spf13/viper v1.19.0

    // GUI (build tag: gui)
    // Linux: github.com/diamondburned/gotk4/pkg/gtk/v4
    // macOS: uses cgo with Cocoa
    // Windows: uses cgo with Win32

    // Common
    github.com/rs/zerolog v1.33.0
    gopkg.in/yaml.v3 v3.0.1
)
```

### Display Package

```go
// src/common/display/mode.go
package display

type Mode int

const (
    ModeHeadless Mode = iota
    ModeCLI
    ModeTUI
    ModeGUI
)

func (m Mode) String() string {
    return [...]string{"headless", "cli", "tui", "gui"}[m]
}

func (m Mode) SupportsInteraction() bool {
    return m >= ModeTUI
}

func (m Mode) SupportsColors() bool {
    return m >= ModeCLI
}
```

### Terminal Package

```go
// src/common/terminal/size.go
package terminal

import (
    "os"
    "golang.org/x/term"
)

type SizeMode int

const (
    SizeModeMicro     SizeMode = iota // <40 cols or <10 rows
    SizeModeMinimal                    // 40-59 cols or 10-15 rows
    SizeModeCompact                    // 60-79 cols or 16-23 rows
    SizeModeStandard                   // 80-119 cols and 24-39 rows
    SizeModeWide                       // 120-199 cols and 40-59 rows
    SizeModeUltrawide                  // 200-399 cols and 60-79 rows
    SizeModeMassive                    // 400+ cols and 80+ rows
)

type Size struct {
    Cols int
    Rows int
    Mode SizeMode
}

func GetSize() Size {
    cols, rows, _ := term.GetSize(int(os.Stdout.Fd()))
    if cols == 0 { cols = 80 }
    if rows == 0 { rows = 24 }

    return Size{
        Cols: cols,
        Rows: rows,
        Mode: calculateMode(cols, rows),
    }
}

func calculateMode(cols, rows int) SizeMode {
    switch {
    case cols < 40 || rows < 10:
        return SizeModeMicro
    case cols < 60 || rows < 16:
        return SizeModeMinimal
    case cols < 80 || rows < 24:
        return SizeModeCompact
    case cols < 120 || rows < 40:
        return SizeModeStandard
    case cols < 200 || rows < 60:
        return SizeModeWide
    case cols < 400 || rows < 80:
        return SizeModeUltrawide
    default:
        return SizeModeMassive
    }
}

func (s SizeMode) ShowASCIIArt() bool    { return s >= SizeModeStandard }
func (s SizeMode) ShowBorders() bool     { return s >= SizeModeCompact }
func (s SizeMode) ShowSidebar() bool     { return s >= SizeModeWide }
func (s SizeMode) ShowIcons() bool       { return s >= SizeModeMinimal }
```

### Theme Package

```go
// src/common/theme/colors.go
package theme

type Palette struct {
    Background, Foreground string
    Primary, Secondary, Accent string
    Success, Warning, Error, Info string
    Surface, SurfaceAlt, Border, Muted string
}

var (
    Dark = Palette{
        Background: "#1a1b26", Foreground: "#c0caf5",
        Primary: "#7aa2f7", Secondary: "#9ece6a", Accent: "#bb9af7",
        Success: "#9ece6a", Warning: "#e0af68", Error: "#f7768e", Info: "#7dcfff",
        Surface: "#24283b", SurfaceAlt: "#1f2335", Border: "#414868", Muted: "#565f89",
    }
    Light = Palette{
        Background: "#ffffff", Foreground: "#1a1b26",
        Primary: "#2e7de9", Secondary: "#587539", Accent: "#7847bd",
        Success: "#587539", Warning: "#8c6c3e", Error: "#c64343", Info: "#007197",
        Surface: "#f5f5f5", SurfaceAlt: "#e9e9ec", Border: "#c0caf5", Muted: "#6172b0",
    }
)

func Get(mode string) Palette {
    switch mode {
    case "light": return Light
    case "auto":
        if DetectSystemDark() { return Dark }
        return Light
    default: return Dark
    }
}
```

### Banner Package

```go
// src/common/banner/banner.go
package banner

import (
    "fmt"
    "apimgr/weather/common/terminal"
)

type Config struct {
    AppName    string
    Version    string
    Mode       string   // production/development
    Debug      bool
    URLs       []string
    ShowSetup  bool     // Show setup token (server only, first run)
    SetupToken string
}

func Print(cfg Config) {
    size := terminal.GetSize()

    switch {
    case size.Mode >= terminal.SizeModeStandard:
        printFull(cfg, size)
    case size.Mode >= terminal.SizeModeCompact:
        printCompact(cfg)
    case size.Mode >= terminal.SizeModeMinimal:
        printMinimal(cfg)
    default:
        printMicro(cfg)
    }
}
```

---


# PART 8: SERVER BINARY CLI (NON-NEGOTIABLE)

**These are the command-line flags for the SERVER binary (`weather`), NOT the CLI client (`weather-cli`).**

## Binary Types

| Binary | Default Name | Purpose | Key Flags |
|--------|--------------|---------|-----------|
| **Server** | `weather` | Runs the HTTP server | `--config`, `--data`, `--port`, `--mode` |
| **Agent** | `weather-agent` | Reports to server | `--server`, `--token`, `--config` |
| **CLI Client** | `weather-cli` | User interface to server | `--server`, `--token`, `--output` |

**Shared flags (ALL binaries):** `--help`, `--version`, `--shell`, `--debug`

**Binary naming rules (ALL binaries: server, agent, client):**

| Binary | Default Name | User-Agent |
|--------|--------------|------------|
| Server | `weather` | `weather/{version}` |
| Agent | `weather-agent` | `weather-agent/{version}` |
| Client | `weather-cli` | `weather-cli/{version}` |

**ALL binaries can be renamed by users. Must show ACTUAL binary name in:**
- `--help` and `--version` output
- Error messages showing "run X --help"
- Any user-facing documentation/instructions

**Hardcode `weather` for internal identifiers (never changes):**
- User-Agent header (identifies binary type to server)
- Default paths (`/etc/apimgr/weather/`)
- Config keys, database tables, API identifiers

**Get actual binary name:**
```go
binaryName := filepath.Base(os.Args[0])  // Use for display
// User-Agent uses hardcoded project name, not binaryName
```

**Example (user renames `jokes` to `myapp`):**
```
$ myapp --help
Usage: myapp [options]              # Shows actual name

$ myapp --version
myapp 1.0.0 (abc123)                # Shows actual name

# But internally:
User-Agent: jokes/1.0.0             # Hardcoded project name
Default config: /etc/apimgr/jokes/  # Hardcoded project name
```

**For CLI client and agent flags, see PART 36.**

**THESE SERVER COMMANDS CANNOT BE CHANGED. This is the complete command set.**

## Server Binary Commands

```bash
--help                       # Show help (can be run by anyone)
--version                    # Show version (can be run by anyone)
--shell completions [SHELL]  # Print shell completions (auto-detect if SHELL omitted)
--shell init [SHELL]         # Print shell init for eval (auto-detect if SHELL omitted)
--mode {production|development}  # Set application mode
--config {config_dir}         # Set config directory
--data {data_dir}             # Set data directory
--cache {cache_dir}           # Set cache directory
--log {log_dir}               # Set log directory
--backup {backup_dir}         # Set backup directory
--pid {pid_file}              # Set PID file path
--address {listen}           # Set listen address
--port {port}                # Set the port
--status                     # Show status and health (exit 0=healthy, 1=unhealthy)
--service {start,restart,stop,reload,--install,--uninstall,--disable,--help}
--daemon                     # Daemonize (detach from terminal)
--debug                      # Enable debug mode (verbose logging, debug endpoints)
--maintenance {backup,restore,update,mode,setup} [optional-file-or-setting]
--update [check|yes|branch {stable|beta|daily}]  # Check/perform updates
```

### Server --help Output

```bash
$ weather --help
weather {projectversion} - {project description}

Usage:
  weather [flags]

Flags:
  -h, --help                        Show help
  -v, --version                     Show version
      --shell completions [SHELL]   Print shell completions (auto-detect if SHELL omitted)
      --shell init [SHELL]          Print shell init command (auto-detect if SHELL omitted)

      --mode {production|development}  Application mode (default: production)
      --config DIR                  Config directory
      --data DIR                    Data directory
      --cache DIR                   Cache directory
      --log DIR                     Log directory
      --backup DIR                  Backup directory
      --pid FILE                    PID file path
      --address ADDR                Listen address (default: 0.0.0.0)
      --port PORT                   Listen port (default: 8080)

      --status                      Show server status and health
      --daemon                      Run as daemon (detach from terminal)
      --debug                       Enable debug mode

      --service CMD                 Service management (start|stop|restart|reload|install|uninstall)
      --maintenance CMD             Maintenance (backup|restore|update|mode|setup)
      --update [CMD]                Check/perform updates

Shells: bash, zsh, fish, sh, dash, ksh, powershell, pwsh
```

## Directory Flags (NON-NEGOTIABLE)

**All directory flags MUST create directories if they don't exist.**

| Flag | Type | Default (Linux root) | Default (Linux user) |
|------|------|----------------------|----------------------|
| `--config` | Directory | `/etc/apimgr/weather/` | `~/.config/apimgr/weather/` |
| `--data` | Directory | `/var/lib/apimgr/weather/` | `~/.local/share/apimgr/weather/` |
| `--cache` | Directory | `/var/cache/apimgr/weather/` | `~/.cache/apimgr/weather/` |
| `--log` | Directory | `/var/log/apimgr/weather/` | `~/.local/log/apimgr/weather/` |
| `--backup` | Directory | `/mnt/Backups/apimgr/weather/` (if writable) | `~/.local/share/Backups/apimgr/weather/` |
| `--pid` | File | `/var/run/apimgr/weather.pid` | `~/.local/share/apimgr/weather/weather.pid` |

**Note:** `--backup` prefers system backup dir if writable, falls back to user dir. See `GetBackupDir()` in PART 5.

### Directory Validation Rules

| Rule | Description |
|------|-------------|
| **Create if missing** | All directories are created with proper permissions if they don't exist |
| **Permissions (root)** | Directories: `0755`, Files: `0644`, PID: `0644` |
| **Permissions (user)** | Directories: `0700`, Files: `0600`, PID: `0600` |
| **Parent dirs** | Create parent directories as needed (`mkdir -p` equivalent) |
| **Validate writable** | Fail fast if directory is not writable |
| **Log on create** | Log directory creation at INFO level |

### Implementation

```go
// EnsureDir creates directory with proper permissions if it doesn't exist
func EnsureDir(path string, isRoot bool) error {
    perm := os.FileMode(0700)
    if isRoot {
        perm = 0755
    }

    if err := os.MkdirAll(path, perm); err != nil {
        return fmt.Errorf("failed to create directory %s: %w", path, err)
    }

    // Verify writable
    testFile := filepath.Join(path, ".write-test")
    if err := os.WriteFile(testFile, []byte{}, 0600); err != nil {
        return fmt.Errorf("directory %s is not writable: %w", path, err)
    }
    os.Remove(testFile)

    return nil
}

// EnsurePIDFile creates PID file directory and validates path
func EnsurePIDFile(path string, isRoot bool) error {
    dir := filepath.Dir(path)
    return EnsureDir(dir, isRoot)
}
```

### PID File Handling (NON-NEGOTIABLE)

**Stale PID detection is REQUIRED.** A crash or kill -9 leaves stale PID files.

```go
// CheckPIDFile checks if PID file exists and if the process is still running
// Returns: (isRunning bool, pid int, err error)
func CheckPIDFile(pidPath string) (bool, int, error) {
    data, err := os.ReadFile(pidPath)
    if os.IsNotExist(err) {
        // No PID file, not running
        return false, 0, nil
    }
    if err != nil {
        return false, 0, fmt.Errorf("reading pid file: %w", err)
    }

    pid, err := strconv.Atoi(strings.TrimSpace(string(data)))
    if err != nil {
        // Corrupt PID file - remove it
        os.Remove(pidPath)
        return false, 0, nil
    }

    // Check if process is running
    if !isProcessRunning(pid) {
        // Stale PID file - remove it
        os.Remove(pidPath)
        return false, 0, nil
    }

    // Process exists - verify it's actually our process (not PID reuse)
    if !isOurProcess(pid) {
        // PID was reused by another process - remove stale file
        os.Remove(pidPath)
        return false, 0, nil
    }

    return true, pid, nil
}

// Process checking is platform-dependent - see pid_unix.go and pid_windows.go

// --- pid_unix.go ---
//go:build !windows
// +build !windows

// isProcessRunning checks if a process with given PID exists (Unix)
func isProcessRunning(pid int) bool {
    process, err := os.FindProcess(pid)
    if err != nil {
        return false
    }
    // On Unix, FindProcess always succeeds - need to send signal 0
    err = process.Signal(syscall.Signal(0))
    return err == nil
}

// isOurProcess verifies the process is actually our binary (Unix)
func isOurProcess(pid int) bool {
    // Read /proc/{pid}/exe symlink (Linux)
    exePath, err := os.Readlink(fmt.Sprintf("/proc/%d/exe", pid))
    if err != nil {
        // On macOS/BSD, use ps command
        return isOurProcessDarwin(pid)
    }
    return strings.Contains(filepath.Base(exePath), "weather")
}

// isOurProcessDarwin checks process on macOS/BSD
func isOurProcessDarwin(pid int) bool {
    cmd := exec.Command("ps", "-p", strconv.Itoa(pid), "-o", "comm=")
    output, err := cmd.Output()
    if err != nil {
        return false
    }
    return strings.Contains(string(output), "weather")
}

// --- pid_windows.go ---
//go:build windows
// +build windows

// isProcessRunning checks if a process with given PID exists (Windows)
func isProcessRunning(pid int) bool {
    // On Windows, FindProcess succeeds for any valid PID
    // Use OpenProcess with PROCESS_QUERY_LIMITED_INFORMATION to check
    process, err := os.FindProcess(pid)
    if err != nil {
        return false
    }
    // Try to get exit code - fails if process doesn't exist or no permission
    // But for our own processes, this should work
    var exitCode uint32
    handle := windows.Handle(uintptr(process.Pid))
    err = windows.GetExitCodeProcess(handle, &exitCode)
    return err == nil && exitCode == windows.STILL_ACTIVE
}

// isOurProcess verifies the process is actually our binary (Windows)
func isOurProcess(pid int) bool {
    // Use Windows API to get process image name
    handle, err := windows.OpenProcess(windows.PROCESS_QUERY_LIMITED_INFORMATION, false, uint32(pid))
    if err != nil {
        return false
    }
    defer windows.CloseHandle(handle)

    var buf [windows.MAX_PATH]uint16
    var size uint32 = windows.MAX_PATH
    err = windows.QueryFullProcessImageName(handle, 0, &buf[0], &size)
    if err != nil {
        return false
    }
    exePath := windows.UTF16ToString(buf[:size])
    return strings.Contains(strings.ToLower(filepath.Base(exePath)), "weather")
}

// WritePIDFile writes current process PID to file
func WritePIDFile(pidPath string) error {
    // Check for existing running instance first
    running, existingPID, err := CheckPIDFile(pidPath)
    if err != nil {
        return err
    }
    if running {
        return fmt.Errorf("already running (pid %d)", existingPID)
    }

    // Write our PID
    pid := os.Getpid()
    return os.WriteFile(pidPath, []byte(strconv.Itoa(pid)), 0644)
}

// RemovePIDFile removes PID file on shutdown
func RemovePIDFile(pidPath string) error {
    return os.Remove(pidPath)
}
```

**Startup Flow:**

```
1. Check if PID file exists
   ├─► No  → Create PID file, start server
   └─► Yes → Read PID from file
             ├─► Process running AND is our binary → Exit "already running"
             ├─► Process running BUT different binary → Remove stale, start
             └─► Process not running → Remove stale, start
```

**Shutdown Flow:**

```
1. Receive SIGTERM/SIGINT
2. Graceful shutdown (close connections, flush logs)
3. Remove PID file
4. Exit
```

**Important:**
- Always remove PID file in signal handlers
- Use defer + signal handler for cleanup
- Check for stale PIDs on EVERY startup
- Verify process identity to handle PID reuse

### Server Startup Sequence (NON-NEGOTIABLE)

**The server binary handles ALL initialization. No external scripts needed.**

```
1. Parse CLI flags and environment variables
2. Determine run context (root vs user, container vs host)
3. Setup directories:
   ├─ Create {config_dir}
   ├─ Create {config_dir}/security
   ├─ Create {config_dir}/tor
   ├─ Create {data_dir}
   ├─ Create {data_dir}/db
   ├─ Create {data_dir}/tor
   ├─ Create {cache_dir}
   ├─ Create {log_dir}
   ├─ Create {backup_dir} (prefer system if writable, else user)
   ├─ Set permissions based on context (root: 0755, user: 0700)
   └─ Set ownership to current user/group
4. Check for stale PID file, exit if already running
5. Write PID file
6. Load configuration (server.yml)
7. Initialize logging (to {log_dir}/server.log)
8. Initialize databases (create if needed)
9. Start Tor (if tor binary found):
   ├─ Log INFO if tor not found (not an error)
   ├─ Call ensureTorDirs() - create tor dirs with 0700, enforce ownership
   ├─ Call ensureTorFile() for torrc - write with 0600, enforce ownership
   ├─ Start dedicated tor process (owned by app user)
   ├─ Log WARN on startup errors (non-fatal)
   └─ Continue without Tor if any issues
10. Start HTTP server
11. Register signal handlers
12. Enter main loop
```

| Step | Owner | Notes |
|------|-------|-------|
| Directory creation | **Server binary** | Creates all dirs with proper permissions |
| Permissions | **Server binary** | Sets based on root vs user context |
| Ownership | **Server binary** | Sets to current user/group (chown) |
| Cache dir | **Server binary** | `{cache_dir}` for temporary/cached data |
| Backup dir | **Server binary** | `{backup_dir}` - prefers system path if writable |
| Tor dirs | **Server binary** | `{config_dir}/tor/`, `{data_dir}/tor/`, `{data_dir}/tor/site/` with 0700 |
| Tor files | **Server binary** | torrc, keys, hostname with 0600, owned by app user |
| Tor process | **Server binary** | Starts/manages tor process, app user owns everything |
| Config files | **Server binary** | Creates defaults if missing |
| Databases | **Server binary** | Creates and migrates schemas |

**Key principle:** Drop the binary anywhere, run it, everything works. No setup scripts, no manual directory creation, no permission fixing.

### Daemonization (--daemon flag)

**By default, the server runs in foreground.** Modern service managers (systemd, launchd) prefer this.

**`--service start` ignores `daemonize` setting** - it auto-detects the service manager and does the right thing.

| Start Method | Daemonize Behavior |
|--------------|-------------------|
| `--service start` (systemd) | Always foreground (ignores config) |
| `--service start` (launchd) | Always foreground (ignores config) |
| `--service start` (runit/s6) | Always foreground (ignores config) |
| `--service start` (container) | Always foreground (ignores config) |
| `--service start` (SysV init) | Always daemonize (ignores config) |
| `--service start` (rc.d/BSD) | Always daemonize (ignores config) |
| Manual start (no --service) | Respects `--daemon` flag and config |

**Container Detection (always foreground):**
- `/.dockerenv` exists
- `container` env var set
- Parent process is: `tini`, `dumb-init`, `s6-svscan`, `runsv`, `runsvdir`
- Parent process is `weather` (self - entrypoint wrapper)

**Manual Start Priority Order:**
1. `--daemon` CLI flag (highest)
2. `server.daemonize` config setting
3. Default: `false` (foreground)

| Flag/Config | Behavior |
|-------------|----------|
| (default) | Run in foreground |
| `--daemon` or `daemonize: true` | Fork, detach from terminal, run in background |

**Service Manager Detection:**

```go
// detectServiceManager returns the active service manager
func detectServiceManager() string {
    // Check for container environment first
    if _, err := os.Stat("/.dockerenv"); err == nil {
        return "container"
    }
    if os.Getenv("container") != "" {
        return "container"
    }

    // Check parent process name for container init systems
    parentName := getParentProcessName()
    switch parentName {
    case "tini", "dumb-init", "s6-svscan", "runsv", "runsvdir":
        return "container"
    case "weather":
        // Parent is our own binary - likely container entrypoint
        return "container"
    }

    // Check parent process / init system
    ppid := os.Getppid()

    // systemd: parent is systemd or PPID=1 with systemd running
    if ppid == 1 {
        if _, err := os.Stat("/run/systemd/system"); err == nil {
            return "systemd"
        }
    }
    // Also check INVOCATION_ID (set by systemd)
    if os.Getenv("INVOCATION_ID") != "" {
        return "systemd"
    }

    // launchd: macOS with PPID=1
    if runtime.GOOS == "darwin" && ppid == 1 {
        return "launchd"
    }

    // runit: check for SVDIR
    if os.Getenv("SVDIR") != "" {
        return "runit"
    }

    // s6: check for S6_* vars
    if os.Getenv("S6_LOGGING") != "" {
        return "s6"
    }

    // SysV init: /etc/init.d script, no systemd
    if ppid == 1 {
        if _, err := os.Stat("/etc/init.d"); err == nil {
            if _, err := os.Stat("/run/systemd/system"); os.IsNotExist(err) {
                return "sysv"
            }
        }
    }

    // rc.d (BSD): check for rc.subr
    if _, err := os.Stat("/etc/rc.subr"); err == nil {
        return "rcd"
    }

    return "manual"
}

// getParentProcessName returns the name of the parent process
func getParentProcessName() string {
    ppid := os.Getppid()

    // Linux: read /proc/{ppid}/comm
    if data, err := os.ReadFile(fmt.Sprintf("/proc/%d/comm", ppid)); err == nil {
        return strings.TrimSpace(string(data))
    }

    // macOS/BSD: use ps command
    cmd := exec.Command("ps", "-p", strconv.Itoa(ppid), "-o", "comm=")
    if output, err := cmd.Output(); err == nil {
        return strings.TrimSpace(string(output))
    }

    return ""
}

// shouldDaemonize determines if we should daemonize based on context
func shouldDaemonize(isServiceStart bool, daemonFlag bool, configDaemonize bool) bool {
    if isServiceStart {
        // Service start - detect manager and ignore config
        switch detectServiceManager() {
        case "systemd", "launchd", "runit", "s6", "docker", "container":
            // Always foreground
            return false
        case "sysv", "rcd":
            // Always daemonize
            return true
        default:
            // Unknown, default to foreground
            return false
        }
    }

    // Manual start - respect flag and config
    if daemonFlag {
        return true
    }
    return configDaemonize
}
```

**When to use `--daemon` (manual start only):**
- Starting from terminal without service manager
- Running from cron/at
- Quick testing without terminal lock

**When NOT to use `--daemon`:**
- Any `--service start` scenario (auto-detected)
- Docker/containers (use entrypoint)
- systemd/launchd/runit/s6 (they manage it)

**Daemonization Process (Unix):**

```go
// Daemonize forks the process and detaches from terminal
func Daemonize() error {
    // Already daemonized? Check if parent is init (PID 1)
    if os.Getppid() == 1 {
        return nil
    }

    // Fork by re-executing ourselves with a marker env var
    if os.Getenv("_DAEMON_CHILD") != "" {
        // We are the child - continue execution
        return nil
    }

    // Prepare to re-exec as daemon
    execPath, err := os.Executable()
    if err != nil {
        return fmt.Errorf("getting executable path: %w", err)
    }

    // Build command with same args (minus --daemon to prevent loop)
    args := filterDaemonFlag(os.Args[1:])

    cmd := exec.Command(execPath, args...)
    cmd.Env = append(os.Environ(), "_DAEMON_CHILD=1")

    // Detach from terminal
    cmd.Stdin = nil
    cmd.Stdout = nil
    cmd.Stderr = nil
    cmd.SysProcAttr = &syscall.SysProcAttr{
        // Create new session (detach from controlling terminal)
        Setsid: true,
    }

    if err := cmd.Start(); err != nil {
        return fmt.Errorf("starting daemon: %w", err)
    }

    // Parent exits, child continues
    fmt.Printf("Daemon started with PID %d\n", cmd.Process.Pid)
    os.Exit(0)
    return nil
}

// filterDaemonFlag removes --daemon from args to prevent infinite loop
func filterDaemonFlag(args []string) []string {
    filtered := make([]string, 0, len(args))
    for _, arg := range args {
        if arg != "--daemon" && arg != "-d" {
            filtered = append(filtered, arg)
        }
    }
    return filtered
}
```

**Daemonization (Windows):**

```go
//go:build windows
// +build windows

// Windows does NOT support traditional Unix daemonization
// Instead, use Windows Services (golang.org/x/sys/windows/svc)

func Daemonize() error {
    // On Windows, --daemon flag is ignored with a warning
    // Use Windows Service (--service install/start) instead
    fmt.Fprintln(os.Stderr, "Warning: --daemon is not supported on Windows")
    fmt.Fprintln(os.Stderr, "Use --service install && --service start for Windows Service")
    // Continue in foreground
    return nil
}
```

**Platform Support Summary:**

| Feature | Unix (Linux/macOS/BSD) | Windows |
|---------|------------------------|---------|
| `--daemon` flag | Forks and detaches | Ignored (use --service) |
| setsid() | Creates new session | Not supported |
| Config reload | File watcher (auto) | File watcher (auto) |
| SIGTERM/SIGINT | Full support | os.Interrupt only |
| SIGUSR1/SIGUSR2 | Supported | Not supported |
| PID file | /var/run or XDG | AppData or program dir |
| Service manager | systemd/launchd/runit | Windows SCM |

**Startup with --daemon (Unix only):**

```
1. Parse --daemon flag
2. If --daemon:
   ├─► Fork child process with _DAEMON_CHILD=1
   ├─► Child: setsid() to create new session
   ├─► Child: Close stdin/stdout/stderr
   ├─► Parent: Print "Daemon started with PID {pid}"
   └─► Parent: Exit 0
3. Child continues normal startup (PID file, server, etc.)
```

**Console Output (Unix):**

```bash
$ ./myapp --daemon
Daemon started with PID 12345

$ ./myapp --status
myapp is running (PID 12345)
```

**--status Exit Codes (NON-NEGOTIABLE):**

| Exit Code | Meaning | When |
|-----------|---------|------|
| `0` | Healthy | Server running and responding |
| `1` | Unhealthy | Server not running, not responding, or error |

**Used for Docker/compose healthcheck:**
```yaml
healthcheck:
  test: /usr/local/bin/weather --status
  interval: 10s
  timeout: 5s
  retries: 3
  start_period: 90s
```

**Console Output (Windows):**

```cmd
C:\> myapp.exe --daemon
Warning: --daemon is not supported on Windows
Use --service install && --service start for Windows Service
[Server starts in foreground]
```

### Signal Handling & Graceful Shutdown (NON-NEGOTIABLE)

**All signals MUST be handled properly for graceful shutdown. Implementation MUST be platform-dependent.**

**Unix (Linux, macOS, FreeBSD):**

| Signal | Number | Action | Description |
|--------|--------|--------|-------------|
| `SIGTERM` | 15 | Graceful shutdown | Default kill signal, clean exit |
| `SIGINT` | 2 | Graceful shutdown | Ctrl+C, clean exit |
| `SIGQUIT` | 3 | Graceful shutdown | Ctrl+\, clean exit |
| `SIGHUP` | 1 | Ignored | Config auto-reloads via file watcher |
| `SIGUSR1` | 10 | Reopen logs | Log rotation |
| `SIGUSR2` | 12 | Status dump | Dump status to log |
| `SIGRTMIN+3` | 37 | Graceful shutdown | Docker STOPSIGNAL |

**Windows:**

| Signal | Action | Description |
|--------|--------|-------------|
| `os.Interrupt` | Graceful shutdown | Ctrl+C, Ctrl+Break |
| `os.Kill` | Immediate exit | Cannot be caught (for reference) |
| Windows Service Control | Graceful shutdown | SERVICE_CONTROL_STOP from SCM |

**IMPORTANT:** Windows does NOT support SIGHUP, SIGUSR1, SIGUSR2, SIGQUIT. Use build tags to separate platform code.

**Graceful Shutdown Sequence:**

```
1. Signal received (SIGTERM/SIGINT/SIGQUIT/SIGRTMIN+3)
2. Stop accepting new connections
3. Set shutdown flag (health checks return 503)
4. Wait for in-flight requests (with timeout)
5. Close database connections
6. Flush logs and metrics
7. Stop child processes (Tor, etc.) with SIGTERM
8. Wait for children (with timeout)
9. Remove PID file
10. Exit 0
```

**Shutdown Timeouts:**

| Phase | Timeout | Action if exceeded |
|-------|---------|-------------------|
| In-flight requests | 30s | Force close connections |
| Child processes | 10s | SIGKILL children |
| Database flush | 5s | Log warning, continue |
| Log flush | 2s | Skip, exit anyway |

**Implementation (Platform-Dependent with Build Tags):**

**File: `src/signal/signal_unix.go`**

```go
//go:build !windows
// +build !windows

package signal

import (
    "log"
    "net/http"
    "os"
    "os/signal"
    "syscall"
)

// setupSignalHandler configures graceful shutdown (Unix)
func setupSignalHandler(server *http.Server, pidFile string) {
    sigChan := make(chan os.Signal, 1)
    // SIGTERM: kill (default)
    // SIGINT: Ctrl+C
    // SIGQUIT: Ctrl+\
    // SIGUSR1: Reopen logs
    // SIGUSR2: Status dump
    signal.Notify(sigChan,
        syscall.SIGTERM,
        syscall.SIGINT,
        syscall.SIGQUIT,
        syscall.SIGUSR1,
        syscall.SIGUSR2,
    )

    // Handle SIGRTMIN+3 (Docker STOPSIGNAL) - signal 37
    signal.Notify(sigChan, syscall.Signal(37))

    // Ignore SIGHUP - config reloads automatically via file watcher
    signal.Ignore(syscall.SIGHUP)

    go func() {
        for sig := range sigChan {
            switch sig {
            case syscall.SIGUSR1:
                log.Println("Received SIGUSR1, reopening logs...")
                reopenLogs()

            case syscall.SIGUSR2:
                log.Println("Received SIGUSR2, dumping status...")
                dumpStatus()

            default:
                // Graceful shutdown (SIGTERM, SIGINT, SIGQUIT, SIGRTMIN+3)
                log.Printf("Received %v, starting graceful shutdown...", sig)
                gracefulShutdown(server, pidFile)
            }
        }
    }()
}

// killProcess sends signal to process (Unix)
func killProcess(pid int, graceful bool) error {
    process, err := os.FindProcess(pid)
    if err != nil {
        return err
    }
    if graceful {
        return process.Signal(syscall.SIGTERM)
    }
    return process.Signal(syscall.SIGKILL)
}
```

**File: `src/signal/signal_windows.go`**

```go
//go:build windows
// +build windows

package signal

import (
    "log"
    "net/http"
    "os"
    "os/signal"
)

// setupSignalHandler configures graceful shutdown (Windows)
// Windows only supports os.Interrupt (Ctrl+C, Ctrl+Break)
func setupSignalHandler(server *http.Server, pidFile string) {
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan, os.Interrupt)

    go func() {
        for sig := range sigChan {
            log.Printf("Received %v, starting graceful shutdown...", sig)
            gracefulShutdown(server, pidFile)
        }
    }()
}

// killProcess terminates process (Windows)
// Windows doesn't have graceful signals - uses TerminateProcess
func killProcess(pid int, graceful bool) error {
    process, err := os.FindProcess(pid)
    if err != nil {
        return err
    }
    // Windows: Kill() calls TerminateProcess - no graceful option
    return process.Kill()
}

// NOTE: For Windows Services, use golang.org/x/sys/windows/svc
// to handle SERVICE_CONTROL_STOP properly
```

**File: `src/signal/signal.go`** (shared, platform-independent)

```go
package signal

import (
    "context"
    "log"
    "net/http"
    "os"
    "time"
)

// gracefulShutdown performs orderly shutdown (cross-platform)
func gracefulShutdown(server *http.Server, pidFile string) {
    // Set shutdown flag for health checks
    setShuttingDown(true)

    // Create context with timeout
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()

    // Stop accepting new connections, wait for in-flight
    if err := server.Shutdown(ctx); err != nil {
        log.Printf("HTTP server shutdown error: %v", err)
    }

    // Stop child processes (Tor, etc.) - platform-specific
    stopChildProcesses(10 * time.Second)

    // Close database connections
    closeDatabase(5 * time.Second)

    // Flush logs
    flushLogs(2 * time.Second)

    // Remove PID file
    if pidFile != "" {
        os.Remove(pidFile)
    }

    log.Println("Graceful shutdown complete")
    os.Exit(0)
}
```

**Child Process Handling (Unix) - in `signal_unix.go`:**

```go
// stopChildProcesses sends SIGTERM to children, SIGKILL after timeout (Unix)
func stopChildProcesses(timeout time.Duration) {
    for _, pid := range getChildPIDs() {
        process, err := os.FindProcess(pid)
        if err != nil {
            continue
        }

        // Send SIGTERM (graceful)
        process.Signal(syscall.SIGTERM)
    }

    // Wait with timeout, then SIGKILL
    deadline := time.Now().Add(timeout)
    for _, pid := range getChildPIDs() {
        process, _ := os.FindProcess(pid)
        for time.Now().Before(deadline) {
            if err := process.Signal(syscall.Signal(0)); err != nil {
                // Process exited
                break
            }
            time.Sleep(100 * time.Millisecond)
        }
        // Force kill if still running
        process.Signal(syscall.SIGKILL)
    }
}
```

**Child Process Handling (Windows) - in `signal_windows.go`:**

```go
// stopChildProcesses terminates children (Windows)
// Windows cannot send graceful signals - immediate termination only
func stopChildProcesses(timeout time.Duration) {
    for _, pid := range getChildPIDs() {
        process, err := os.FindProcess(pid)
        if err != nil {
            continue
        }
        // Windows: Kill() is immediate termination (TerminateProcess)
        process.Kill()
    }
}
```

**Smart Config Reload (NON-NEGOTIABLE):**

The app automatically watches config files and hot-reloads what it can. Settings that require restart trigger admin UI notification.

**Hot-Reloadable (auto-applied on file change):**

| Setting Category | Examples |
|------------------|----------|
| Rate limits | `ratelimit.*` |
| CORS settings | `cors.*` |
| Branding/SEO | `branding.*`, `seo.*` |
| Logging level | `logging.level` |
| Notification settings | `notifications.*`, `smtp.*` |
| Security headers | `security.headers.*` |
| Allowed origins | `cors.allowed_origins` |

**Requires Graceful Reload (no downtime):**

| Setting | Why |
|---------|-----|
| `server.admin_path` | Routes must be re-registered |

**Requires Restart (admin UI shows notification):**

| Setting | Why |
|---------|-----|
| `server.port` | Bound socket cannot change |
| `server.address` | Bound socket cannot change |
| `ssl.*` | TLS listener must be recreated |
| `server.daemonize` | Process mode cannot change |
| `database.*` | Connection pool must be recreated |
| `tor.*` | Child process must be restarted |

**Implementation:**

```go
// ConfigManager manages config from both file AND database (admin WebUI)
// Changes from either source trigger hot-reload or restart notification
type ConfigManager struct {
    configPath      string
    db              *sql.DB
    lastFileModTime time.Time
    // Config version in database
    lastDBVersion   int64
    // True if restart-required settings changed
    pendingRestart  bool
    // Which settings need restart
    restartSettings []string
    mu              sync.RWMutex
}

func (m *ConfigManager) Start() {
    go func() {
        ticker := time.NewTicker(5 * time.Second)
        for range ticker.C {
            m.checkFileChanges()
            m.checkDBChanges()
        }
    }()
}

// checkFileChanges watches config file for external edits
func (m *ConfigManager) checkFileChanges() {
    info, err := os.Stat(m.configPath)
    if err != nil || info.ModTime() == m.lastFileModTime {
        return
    }
    m.lastFileModTime = info.ModTime()

    newConfig, err := loadConfigFromFile(m.configPath)
    if err != nil {
        log.Printf("Config file parse error: %v", err)
        return
    }

    m.applyConfigChanges(newConfig, "file")

    // Sync file changes to database so admin UI sees them
    m.syncToDatabase(newConfig)
}

// checkDBChanges watches database for admin WebUI changes
func (m *ConfigManager) checkDBChanges() {
    var version int64
    err := m.db.QueryRow("SELECT version FROM config_meta WHERE id = 1").Scan(&version)
    if err != nil || version == m.lastDBVersion {
        return
    }
    m.lastDBVersion = version

    newConfig, err := loadConfigFromDB(m.db)
    if err != nil {
        log.Printf("Config DB load error: %v", err)
        return
    }

    m.applyConfigChanges(newConfig, "database")

    // Sync database changes to file so file reflects current state
    m.syncToFile(newConfig)
}

// applyConfigChanges handles both file and database config changes
func (m *ConfigManager) applyConfigChanges(newConfig *Config, source string) {
    changes := compareConfigs(currentConfig, newConfig)
    if len(changes) == 0 {
        return
    }

    hotReloadable, needsRestart := categorizeChanges(changes)

    // Apply hot-reloadable settings immediately
    if len(hotReloadable) > 0 {
        applyHotReloadSettings(newConfig, hotReloadable)
        log.Printf("Hot-reloaded from %s: %v", source, hotReloadable)
    }

    // Flag restart-required settings
    if len(needsRestart) > 0 {
        m.mu.Lock()
        m.pendingRestart = true
        m.restartSettings = needsRestart
        m.mu.Unlock()
        log.Printf("Restart required for: %v (changed via %s)", needsRestart, source)
    }
}

// syncToDatabase writes file config to database
func (m *ConfigManager) syncToDatabase(cfg *Config) {
    // Update config table, bump version
    _, err := m.db.Exec(`
        UPDATE config SET value = ? WHERE key = ?
        -- ... for each setting
    `)
    if err == nil {
        m.db.Exec("UPDATE config_meta SET version = version + 1 WHERE id = 1")
    }
}

// syncToFile writes database config to file
func (m *ConfigManager) syncToFile(cfg *Config) {
    data, _ := yaml.Marshal(cfg)
    os.WriteFile(m.configPath, data, 0644)
    // Update lastFileModTime to prevent re-reading our own write
    info, _ := os.Stat(m.configPath)
    m.lastFileModTime = info.ModTime()
}
```

**Database Schema (NON-NEGOTIABLE):**

All projects use SQLite with two database files:
- `server.db` - Server state (config, sessions, rate limits, audit, scheduler)
- `users.db` - User data (admins, users, API keys) - separate for easy backup/restore

| Database | Table | Purpose |
|----------|-------|---------|
| `server.db` | `config` | Key-value config storage |
| `server.db` | `config_meta` | Config version tracking |
| `server.db` | `sessions` | Admin WebUI login sessions |
| `server.db` | `rate_limits` | Sliding window rate limit counters |
| `server.db` | `audit_log` | Admin actions, config changes, security events |
| `server.db` | `scheduler_tasks` | Background task definitions |
| `server.db` | `scheduler_history` | Task run history |
| `server.db` | `backups` | Backup metadata and history |
| `users.db` | `admins` | Server admin accounts (WebUI access) |
| `users.db` | `users` | Regular app users (if project has users) |
| `users.db` | `api_keys` | API authentication keys |
| `users.db` | `password_resets` | Password reset tokens |
| `users.db` | `email_verifications` | Email verification tokens |
| `users.db` | `totp_secrets` | 2FA TOTP secrets and backup codes |

**Why two databases?**
- `users.db` can be backed up/restored independently
- User data is more sensitive, may have different retention policies
- Easier to migrate users between instances
- `server.db` can be recreated from config file if needed

**Database Modes:**

| Mode | Database | Cache | Use Case |
|------|----------|-------|----------|
| Single Instance | SQLite (default) | memory (default) | Development, small deployments |
| Cluster | 1+ remote databases | 1× Valkey/Redis | Multiple instances, shared state, HA |

**Cluster minimum requirements:**
- 1× remote database (PostgreSQL, MySQL, MariaDB, or MSSQL)
- 1× Valkey/Redis instance (does NOT need to be a cluster)

**Supported Databases:**

| Database | Notes |
|----------|-------|
| **PostgreSQL** | Recommended for production. Read replicas supported. SSL/TLS recommended. |
| **MySQL/MariaDB** | Full support. Read replicas supported. UTF8MB4 required. |
| **MSSQL** | Full support. Windows environments. |
| **SQLite** | Embedded, zero config. Default. See below. |
| **MongoDB** | Project-specific only. See below. |

**MongoDB (Project-Specific Use):**

MongoDB is available but NOT used for standard schema (config, sessions, admins, api_keys, etc.). Use for project-specific application data only.

**Good for:**
- Document/JSON-heavy data (logs, events, analytics)
- Flexible schemas that change frequently
- Geospatial data and queries
- Time-series data
- Projects migrating from existing MongoDB

**Example use cases:**
- `quotes` - storing quote collections with varying metadata
- `jokes` - joke database with categories, tags, nested data
- `analytics` - event tracking, user behavior logs
- `search` - document indexing alongside Elasticsearch

**Configuration (when needed):**

```yaml
# Project-specific MongoDB connection (NOT for standard schema)
mongodb:
  url: ${MONGODB_URL}  # mongodb://user:pass@host:27017/dbname
  database: myapp
  # Replica set for HA
  replica_set: rs0
  # Connection pool
  max_pool_size: 100
  min_pool_size: 10
```

**Standard schema still uses relational DB (SQLite/PostgreSQL/MySQL/MSSQL).**

**SQLite Details:**

| Feature | Description |
|---------|-------------|
| **Zero configuration** | No server, no setup, just works |
| **Embedded** | Database is a file, ships with app |
| **Automatic backups** | Scheduled backups to `{backup_dir}` |
| **Local cache mode** | Can cache remote DB data for offline/fast access |

**Good for:**
- Development and testing
- Single server deployments
- Small to medium traffic (< 100 concurrent users)
- Appliances and embedded systems
- Edge deployments with intermittent connectivity
- Desktop applications

**NOT good for:**
- Multiple app instances (no shared state)
- High write concurrency (SQLite locks on write)
- Large datasets (> 10GB, consider PostgreSQL)

**SQLite as Local Cache (with remote DB):**

```yaml
database:
  # Primary: remote database
  primary:
    driver: postgres
    url: ${DATABASE_URL}

  # Local SQLite cache for fast reads and offline resilience
  cache:
    enabled: true
    path: ${DATA_DIR}/db/cache.db
    sync_interval: 30s     # Sync from remote
    offline_mode: true     # Continue working if remote unavailable
    max_age: 1h            # Max cache age before forcing remote
```

When enabled:
- Reads check local cache first
- Writes go to remote, then update local cache
- If remote unavailable, serve from cache (read-only mode)
- Background sync keeps cache fresh

**Multiple Connections & Mixed Mode:**

Supports multiple database connections of different types with automatic sync:

```yaml
database:
  # Primary database (required)
  primary:
    driver: postgres
    url: ${DATABASE_URL}

  # Additional databases (optional, for redundancy/failover)
  replicas:
    - name: mariadb-1
      driver: mysql
      url: mysql://user:pass@mariadb1.example.com:3306/myapp
      priority: 1        # Failover priority (lower = higher priority)
      read_only: true    # Read replica

    - name: mariadb-2
      driver: mysql
      url: mysql://user:pass@mariadb2.example.com:3306/myapp
      priority: 2
      read_only: true

    - name: postgres-backup
      driver: postgres
      url: postgres://user:pass@pg-backup.example.com:5432/myapp
      priority: 3
      read_only: false   # Can be promoted to primary

    - name: mssql-legacy
      driver: mssql
      url: sqlserver://user:pass@mssql.example.com:1433?database=myapp
      priority: 10
      sync: true         # Sync data to this DB

  # Sync settings
  sync:
    enabled: true        # Auto-sync between all databases
    interval: 5s         # Sync check interval

  # Failover settings
  failover:
    enabled: true
    health_check: 10s    # Health check interval
    threshold: 3         # Failed checks before failover
```

**Failover Priority:**
- Lower number = higher priority
- Primary always tried first
- On primary failure, try replicas in priority order
- Auto-promote read-write replica if primary down

**Automatic Sync:**
- Changes written to primary, synced to all replicas
- Conflict resolution: primary wins
- Sync uses Valkey/Redis pub/sub for real-time updates

See **PART 12: SERVER CONFIGURATION** for Valkey/Redis setup.
See **PART 10: DATABASE & CLUSTER** for full cluster configuration.

**SQLite vs Remote - Key Differences:**

| Feature | SQLite | PostgreSQL/MySQL |
|---------|--------|------------------|
| Files | `server.db`, `users.db` | Single DB, prefixed tables (`srv_*`, `usr_*`) |
| Timestamps | `strftime('%s','now')` | `EXTRACT(EPOCH FROM NOW())` / `UNIX_TIMESTAMP()` |
| Auto-increment | `AUTOINCREMENT` | `SERIAL` / `AUTO_INCREMENT` |
| Upsert | `ON CONFLICT DO UPDATE` | `ON CONFLICT DO UPDATE` / `ON DUPLICATE KEY` |
| Boolean | `INTEGER (0/1)` | `BOOLEAN` / `TINYINT(1)` |

**Automatic Detection:**

```go
// If database.url provided → remote, otherwise SQLite
func OpenDatabase(cfg *Config) (*Database, error) {
    if cfg.Database.URL != "" {
        return openRemoteDB(cfg.Database.Driver, cfg.Database.URL)
    }
    // Default to SQLite
    return openSQLite(cfg.DataDir)
}
```

```sql
-- ============================================================================
-- SERVER.DB - Server state and operations
-- ============================================================================

-- Config key-value storage (mirrors YAML structure as flat keys)
CREATE TABLE IF NOT EXISTS config (
    key         TEXT PRIMARY KEY,              -- Dot notation: "server.port", "ssl.enabled"
    value       TEXT NOT NULL,                 -- JSON-encoded value (string, number, bool, array)
    type        TEXT NOT NULL DEFAULT 'string', -- string, number, bool, array, object
    updated_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

-- Config metadata for change detection
CREATE TABLE IF NOT EXISTS config_meta (
    id          INTEGER PRIMARY KEY CHECK (id = 1),  -- Single row
    version     INTEGER NOT NULL DEFAULT 1,          -- Incremented on any change
    updated_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

-- Initialize metadata row
INSERT OR IGNORE INTO config_meta (id, version) VALUES (1, 1);

-- Trigger to auto-increment version on config change
CREATE TRIGGER IF NOT EXISTS config_version_bump
AFTER INSERT OR UPDATE OR DELETE ON config
BEGIN
    UPDATE config_meta SET
        version = version + 1,
        updated_at = strftime('%s', 'now')
    WHERE id = 1;
END;

-- Index for fast lookups by prefix (e.g., all "ssl.*" settings)
CREATE INDEX IF NOT EXISTS idx_config_key_prefix ON config(key);

-- ----------------------------------------------------------------------------
-- Admin Sessions (admin WebUI login sessions)
-- NOTE: admin_id is a logical FK to users.db admins table (cross-DB, not enforced)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS admin_sessions (
    id          TEXT PRIMARY KEY,              -- Session token (secure random)
    admin_id    INTEGER NOT NULL,              -- Logical FK to admins.id in users.db
    ip_address  TEXT NOT NULL,
    user_agent  TEXT,
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    expires_at  INTEGER NOT NULL,              -- Unix timestamp (default: 30 days)
    last_active INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

CREATE INDEX IF NOT EXISTS idx_admin_sessions_admin ON admin_sessions(admin_id);
CREATE INDEX IF NOT EXISTS idx_admin_sessions_expires ON admin_sessions(expires_at);

-- Cleanup expired sessions (run via scheduler)
-- DELETE FROM admin_sessions WHERE expires_at < strftime('%s', 'now');

-- ----------------------------------------------------------------------------
-- Rate Limiting (sliding window counters)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS rate_limits (
    key         TEXT PRIMARY KEY,              -- "ip:1.2.3.4:login" or "key:abc12345:global" (prefix, not hash)
    count       INTEGER NOT NULL DEFAULT 1,
    window_start INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    updated_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

CREATE INDEX IF NOT EXISTS idx_rate_limits_window ON rate_limits(window_start);

-- Cleanup old rate limit entries (run periodically)
-- DELETE FROM rate_limits WHERE window_start < strftime('%s', 'now') - 3600;

-- ----------------------------------------------------------------------------
-- Audit Log (admin actions, config changes, security events)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS audit_log (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp   INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    level       TEXT NOT NULL DEFAULT 'info',  -- info, warning, error, security
    category    TEXT NOT NULL,                 -- auth, config, admin, api, system
    action      TEXT NOT NULL,                 -- login, logout, config_change, user_create, etc.
    actor_type  TEXT,                          -- admin, api_key, system, anonymous
    actor_id    TEXT,                          -- admin ID, API key ID, or null
    actor_ip    TEXT,
    target_type TEXT,                          -- user, config, api_key, etc.
    target_id   TEXT,
    details     TEXT,                          -- JSON with additional context
    success     INTEGER NOT NULL DEFAULT 1     -- 1=success, 0=failure
);

CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_log(timestamp);
CREATE INDEX IF NOT EXISTS idx_audit_category ON audit_log(category);
CREATE INDEX IF NOT EXISTS idx_audit_actor ON audit_log(actor_type, actor_id);

-- ----------------------------------------------------------------------------
-- Scheduler (background task tracking)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS scheduler_tasks (
    id          TEXT PRIMARY KEY,              -- Task name: "backup_daily", "backup_hourly", "geoip_update", "cleanup"
    name        TEXT NOT NULL,                 -- Human-readable: "Daily Backup", "Hourly Incremental"
    task_type   TEXT NOT NULL DEFAULT 'global', -- global (one node) or local (all nodes)
    enabled     INTEGER NOT NULL DEFAULT 1,
    schedule    TEXT NOT NULL,                 -- Cron expression: "0 2 * * *"
    last_run    INTEGER,                       -- Unix timestamp
    next_run    INTEGER,                       -- Unix timestamp
    last_status TEXT,                          -- success, failed, running, skipped
    last_error  TEXT,                          -- Error message if failed
    run_count   INTEGER NOT NULL DEFAULT 0,
    fail_count  INTEGER NOT NULL DEFAULT 0,
    locked_by   TEXT,                          -- Node ID holding lock (cluster mode)
    locked_at   INTEGER                        -- When lock was acquired (cluster mode)
);

CREATE TABLE IF NOT EXISTS scheduler_history (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    task_id     TEXT NOT NULL,
    started_at  INTEGER NOT NULL,
    finished_at INTEGER,
    status      TEXT NOT NULL,                 -- running, success, failed
    error       TEXT,
    duration_ms INTEGER
);

CREATE INDEX IF NOT EXISTS idx_scheduler_history_task ON scheduler_history(task_id);
CREATE INDEX IF NOT EXISTS idx_scheduler_history_started ON scheduler_history(started_at);

-- Keep only last 100 runs per task (run periodically via scheduler)
-- DELETE FROM scheduler_history WHERE id NOT IN (
--     SELECT id FROM (
--         SELECT id, ROW_NUMBER() OVER (PARTITION BY task_id ORDER BY started_at DESC) as rn
--         FROM scheduler_history
--     ) WHERE rn <= 100
-- );

-- ----------------------------------------------------------------------------
-- Backups (backup history and metadata)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS backups (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    filename    TEXT NOT NULL UNIQUE,          -- "backup-2025-01-15-103045.tar.gz"
    filepath    TEXT NOT NULL,                 -- Full path
    size_bytes  INTEGER NOT NULL,
    type        TEXT NOT NULL DEFAULT 'auto',  -- auto, manual, pre_update
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    checksum    TEXT,                          -- SHA256
    notes       TEXT
);

CREATE INDEX IF NOT EXISTS idx_backups_created ON backups(created_at);

-- ============================================================================
-- USERS.DB - User accounts and authentication
-- ============================================================================

-- ----------------------------------------------------------------------------
-- Server Admins (admin WebUI access)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS admins (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    username    TEXT NOT NULL UNIQUE,
    password    TEXT NOT NULL,                 -- Argon2id hash
    email       TEXT,
    role        TEXT NOT NULL DEFAULT 'admin', -- superadmin, admin, readonly
    enabled     INTEGER NOT NULL DEFAULT 1,
    api_token_hash TEXT,                       -- SHA-256 hash of API token (prefix: adm_)
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    updated_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    last_login  INTEGER,
    failed_attempts INTEGER NOT NULL DEFAULT 0,
    locked_until INTEGER,                      -- Account lockout timestamp
    -- OIDC/LDAP sync fields (null for local accounts)
    source      TEXT NOT NULL DEFAULT 'local', -- local, oidc:{provider}, ldap
    external_id TEXT,                          -- Provider's user ID
    groups      TEXT,                          -- JSON array of group memberships
    last_sync   INTEGER                        -- Last OIDC/LDAP sync timestamp
);

CREATE UNIQUE INDEX IF NOT EXISTS idx_admins_username ON admins(username);

-- ----------------------------------------------------------------------------
-- Admin Preferences (settings storage for server admins)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS admin_preferences (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    admin_id    INTEGER NOT NULL UNIQUE,          -- FK to admins.id (one row per admin)

    -- Appearance Settings
    theme           TEXT NOT NULL DEFAULT 'dark', -- dark (default), light, auto
    font_size       TEXT NOT NULL DEFAULT 'medium', -- small, medium, large
    reduce_motion   INTEGER NOT NULL DEFAULT 0,   -- Minimize animations

    -- Display Settings
    date_format     TEXT NOT NULL DEFAULT 'YYYY-MM-DD', -- YYYY-MM-DD, MM/DD/YYYY, DD/MM/YYYY
    time_format     TEXT NOT NULL DEFAULT '24h',  -- 12h, 24h

    -- Notification Settings (Email)
    email_security  INTEGER NOT NULL DEFAULT 1,   -- Security alerts (CANNOT be disabled)
    email_server    INTEGER NOT NULL DEFAULT 1,   -- Server alerts (SSL, updates, disk space)
    email_backups   INTEGER NOT NULL DEFAULT 1,   -- Backup notifications
    email_users     INTEGER NOT NULL DEFAULT 1,   -- User activity (if multi-user)

    -- Timestamps
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    updated_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

CREATE UNIQUE INDEX IF NOT EXISTS idx_admin_preferences_admin ON admin_preferences(admin_id);

-- Trigger to create preferences row when admin is created
-- (Or handle in application code - create on first access)

-- ----------------------------------------------------------------------------
-- Regular Users (app users - ONLY if project has user accounts)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS users (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    username    TEXT NOT NULL UNIQUE,
    email       TEXT UNIQUE,
    password    TEXT NOT NULL,                 -- Argon2id hash
    display_name TEXT,
    bio         TEXT,                          -- Short biography (max 500 chars)
    location    TEXT,                          -- Location (free text)
    website     TEXT,                          -- Personal website URL
    avatar_type TEXT NOT NULL DEFAULT 'gravatar', -- gravatar, upload, url
    avatar_url  TEXT,                          -- URL for upload/url types, null for gravatar
    visibility  TEXT NOT NULL DEFAULT 'public', -- public, private
    org_visibility INTEGER NOT NULL DEFAULT 1, -- 1=show basic info in orgs, 0=username only
    timezone    TEXT,                          -- IANA timezone (e.g., America/New_York)
    language    TEXT NOT NULL DEFAULT 'en',    -- Preferred language
    role        TEXT NOT NULL DEFAULT 'user',  -- user, moderator, premium, etc.
    enabled     INTEGER NOT NULL DEFAULT 1,
    verified    INTEGER NOT NULL DEFAULT 0,    -- Email verified
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    updated_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    last_login  INTEGER,
    failed_attempts INTEGER NOT NULL DEFAULT 0,
    locked_until INTEGER,                      -- Account lockout timestamp
    metadata    TEXT                           -- JSON for app-specific data
);

CREATE UNIQUE INDEX IF NOT EXISTS idx_users_username ON users(username);
CREATE UNIQUE INDEX IF NOT EXISTS idx_users_email ON users(email);

-- ----------------------------------------------------------------------------
-- User Preferences (settings storage for users)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS user_preferences (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id     INTEGER NOT NULL UNIQUE,          -- FK to users.id (one row per user)

    -- Privacy Settings
    show_email      INTEGER NOT NULL DEFAULT 0,   -- Show email on public profile
    show_activity   INTEGER NOT NULL DEFAULT 1,   -- Show activity on public profile
    show_orgs       INTEGER NOT NULL DEFAULT 1,   -- Show org memberships on profile
    searchable      INTEGER NOT NULL DEFAULT 1,   -- Appear in user search results

    -- Notification Settings (Email)
    email_security  INTEGER NOT NULL DEFAULT 1,   -- Security alerts (CANNOT be disabled)
    email_mentions  INTEGER NOT NULL DEFAULT 1,   -- Email when mentioned
    email_updates   INTEGER NOT NULL DEFAULT 1,   -- Product updates and news
    email_digest    TEXT NOT NULL DEFAULT 'weekly', -- never, daily, weekly

    -- Notification Settings (Push)
    push_enabled    INTEGER NOT NULL DEFAULT 0,   -- Browser push notifications
    push_mentions   INTEGER NOT NULL DEFAULT 1,   -- Push when mentioned

    -- Appearance Settings
    theme           TEXT NOT NULL DEFAULT 'dark', -- dark (default), light, auto
    font_size       TEXT NOT NULL DEFAULT 'medium', -- small, medium, large
    reduce_motion   INTEGER NOT NULL DEFAULT 0,   -- Minimize animations

    -- Display Settings
    date_format     TEXT NOT NULL DEFAULT 'YYYY-MM-DD', -- YYYY-MM-DD, MM/DD/YYYY, DD/MM/YYYY
    time_format     TEXT NOT NULL DEFAULT '24h',  -- 12h, 24h

    -- Timestamps
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    updated_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

CREATE UNIQUE INDEX IF NOT EXISTS idx_user_preferences_user ON user_preferences(user_id);

-- Trigger to create preferences row when user is created
-- (Or handle in application code - create on first access)

-- ----------------------------------------------------------------------------
-- Organizations (for multi-user collaboration - ONLY if project has orgs)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS orgs (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    slug        TEXT NOT NULL UNIQUE,             -- URL-safe identifier
    name        TEXT NOT NULL,                    -- Display name
    description TEXT,
    avatar_type TEXT NOT NULL DEFAULT 'gravatar', -- gravatar, upload, url
    avatar_url  TEXT,                             -- URL for upload/url types
    visibility  TEXT NOT NULL DEFAULT 'public',  -- public, private
    owner_id    INTEGER NOT NULL,                 -- FK to users.id (creator)
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    updated_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    metadata    TEXT                              -- JSON for app-specific data
);

CREATE UNIQUE INDEX IF NOT EXISTS idx_orgs_slug ON orgs(slug);
CREATE INDEX IF NOT EXISTS idx_orgs_owner ON orgs(owner_id);

-- Organization Members
CREATE TABLE IF NOT EXISTS org_members (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    org_id      INTEGER NOT NULL,                 -- FK to orgs.id
    user_id     INTEGER NOT NULL,                 -- FK to users.id
    role        TEXT NOT NULL DEFAULT 'member',   -- owner, admin, member
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    UNIQUE(org_id, user_id)
);

CREATE INDEX IF NOT EXISTS idx_org_members_org ON org_members(org_id);
CREATE INDEX IF NOT EXISTS idx_org_members_user ON org_members(user_id);

-- ----------------------------------------------------------------------------
-- Organization Preferences (settings storage for orgs)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS org_preferences (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    org_id      INTEGER NOT NULL UNIQUE,          -- FK to orgs.id (one row per org)

    -- Member Settings
    default_member_role TEXT NOT NULL DEFAULT 'member', -- Role for new members
    require_2fa     INTEGER NOT NULL DEFAULT 0,   -- Require 2FA for all members
    allow_invites   INTEGER NOT NULL DEFAULT 1,   -- Allow admins to invite members

    -- Visibility Settings
    show_members    INTEGER NOT NULL DEFAULT 1,   -- Show member list publicly
    show_activity   INTEGER NOT NULL DEFAULT 1,   -- Show org activity publicly

    -- Notification Settings
    notify_new_member   INTEGER NOT NULL DEFAULT 1, -- Notify admins of new members
    notify_member_leave INTEGER NOT NULL DEFAULT 1, -- Notify admins when members leave

    -- Timestamps
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    updated_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

CREATE UNIQUE INDEX IF NOT EXISTS idx_org_preferences_org ON org_preferences(org_id);

-- ----------------------------------------------------------------------------
-- NOTE: API tokens are stored in the unified `tokens` table (see PART 10)
-- The `tokens` table handles all token types: adm_, usr_, org_, and agent tokens
-- Each token has: name, scope (global/read-write/read), expiration options
-- ----------------------------------------------------------------------------

-- ----------------------------------------------------------------------------
-- Password Reset Tokens
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS password_resets (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    token_hash  TEXT NOT NULL UNIQUE,          -- SHA256 of token
    user_type   TEXT NOT NULL,                 -- admin, user
    user_id     INTEGER NOT NULL,
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    expires_at  INTEGER NOT NULL,
    used_at     INTEGER
);

CREATE INDEX IF NOT EXISTS idx_password_resets_expires ON password_resets(expires_at);

-- Cleanup expired/used tokens (run periodically via scheduler)
-- DELETE FROM password_resets WHERE expires_at < strftime('%s', 'now') OR used_at IS NOT NULL;

-- ----------------------------------------------------------------------------
-- Email Verification Tokens (for user email verification)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS email_verifications (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    token_hash  TEXT NOT NULL UNIQUE,          -- SHA256 of token
    user_type   TEXT NOT NULL,                 -- admin, user
    user_id     INTEGER NOT NULL,
    email       TEXT NOT NULL,                 -- Email being verified
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    expires_at  INTEGER NOT NULL,
    verified_at INTEGER
);

CREATE INDEX IF NOT EXISTS idx_email_verifications_expires ON email_verifications(expires_at);

-- Cleanup expired/used tokens (run periodically via scheduler)
-- DELETE FROM email_verifications WHERE expires_at < strftime('%s', 'now') OR verified_at IS NOT NULL;

-- ----------------------------------------------------------------------------
-- TOTP Secrets (for 2FA - admin only by default)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS totp_secrets (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    user_type   TEXT NOT NULL,                 -- admin (users can be added per-project)
    user_id     INTEGER NOT NULL UNIQUE,       -- One TOTP per user
    secret      TEXT NOT NULL,                 -- Encrypted TOTP secret
    enabled     INTEGER NOT NULL DEFAULT 0,    -- 0=setup pending, 1=active
    backup_codes TEXT,                         -- JSON array of hashed backup codes
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    last_used   INTEGER
);

CREATE UNIQUE INDEX IF NOT EXISTS idx_totp_user ON totp_secrets(user_type, user_id);

-- ----------------------------------------------------------------------------
-- User Sessions (app user login sessions - ONLY if project has user accounts)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS user_sessions (
    id          TEXT PRIMARY KEY,              -- Session token (secure random)
    user_id     INTEGER NOT NULL,              -- FK to users.id
    ip_address  TEXT NOT NULL,
    user_agent  TEXT,
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    expires_at  INTEGER NOT NULL,              -- Unix timestamp (default: 7 days)
    last_active INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

CREATE INDEX IF NOT EXISTS idx_user_sessions_user ON user_sessions(user_id);
CREATE INDEX IF NOT EXISTS idx_user_sessions_expires ON user_sessions(expires_at);

-- Cleanup expired sessions (run via scheduler)
-- DELETE FROM user_sessions WHERE expires_at < strftime('%s', 'now');

-- ----------------------------------------------------------------------------
-- Passkeys (WebAuthn/FIDO2 credentials)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS passkeys (
    id              TEXT PRIMARY KEY,              -- WebAuthn credential ID (base64url)
    user_type       TEXT NOT NULL,                 -- admin, user
    user_id         INTEGER NOT NULL,              -- FK to admins or users
    name            TEXT NOT NULL,                 -- User-friendly name: "MacBook Pro Touch ID"
    public_key      TEXT NOT NULL,                 -- WebAuthn public key (base64)
    sign_count      INTEGER NOT NULL DEFAULT 0,    -- Signature counter (replay protection)
    transports      TEXT,                          -- JSON array: ["usb", "nfc", "ble", "internal"]
    aaguid          TEXT,                          -- Authenticator AAGUID
    created_at      INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    last_used       INTEGER
);

CREATE INDEX IF NOT EXISTS idx_passkeys_user ON passkeys(user_type, user_id);

-- ----------------------------------------------------------------------------
-- Trusted Devices (skip 2FA for remembered devices)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS trusted_devices (
    id          TEXT PRIMARY KEY,              -- Device token (secure random)
    user_type   TEXT NOT NULL,                 -- admin, user
    user_id     INTEGER NOT NULL,              -- FK to admins or users
    device_hash TEXT NOT NULL,                 -- SHA256(user_agent + ip partial)
    name        TEXT,                          -- "Chrome on Windows" (auto-detected)
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    expires_at  INTEGER NOT NULL,              -- 30 days from creation
    last_used   INTEGER
);

CREATE INDEX IF NOT EXISTS idx_trusted_devices_user ON trusted_devices(user_type, user_id);
CREATE INDEX IF NOT EXISTS idx_trusted_devices_expires ON trusted_devices(expires_at);

-- Cleanup expired trusted devices (run via scheduler)
-- DELETE FROM trusted_devices WHERE expires_at < strftime('%s', 'now');
```

**Example Config Data:**

```sql
-- Flat key-value pairs (dot notation matches YAML structure)
INSERT INTO config (key, value, type) VALUES
    ('server.port', '8080', 'number'),
    ('server.address', '"0.0.0.0"', 'string'),
    ('ssl.enabled', 'true', 'bool'),
    ('ssl.cert', '""', 'string'),                    -- Empty = auto-detect
    ('ssl.key', '""', 'string'),                     -- Empty = auto-detect
    ('ssl.min_version', '"TLS1.2"', 'string'),
    ('cors.allowed_origins', '["https://example.com","https://api.example.com"]', 'array'),
    ('ratelimit.requests_per_minute', '60', 'number'),
    ('branding.site_name', '"My App"', 'string');
```

**Config Load/Save Helpers:**

```go
// loadConfigFromDB loads config from database into struct
func loadConfigFromDB(db *sql.DB) (*Config, error) {
    rows, err := db.Query("SELECT key, value, type FROM config")
    if err != nil {
        return nil, err
    }
    defer rows.Close()

    cfg := &Config{}
    for rows.Next() {
        var key, value, typ string
        rows.Scan(&key, &value, &typ)

        // Parse JSON value and set on config struct
        if err := setConfigValue(cfg, key, value, typ); err != nil {
            log.Printf("Config key %s parse error: %v", key, err)
        }
    }
    return cfg, nil
}

// saveConfigToDB saves config struct to database
func saveConfigToDB(db *sql.DB, cfg *Config) error {
    tx, _ := db.Begin()
    defer tx.Rollback()

    // Flatten config struct to key-value pairs
    pairs := flattenConfig(cfg)

    stmt, _ := tx.Prepare(`
        INSERT INTO config (key, value, type, updated_at)
        VALUES (?, ?, ?, strftime('%s', 'now'))
        ON CONFLICT(key) DO UPDATE SET
            value = excluded.value,
            type = excluded.type,
            updated_at = strftime('%s', 'now')
    `)
    defer stmt.Close()

    for _, p := range pairs {
        stmt.Exec(p.Key, p.Value, p.Type)
    }

    return tx.Commit()
}

// flattenConfig converts nested struct to flat key-value pairs
func flattenConfig(cfg *Config) []ConfigPair {
    // Uses reflection to walk struct and build dot-notation keys
    // server.port, ssl.enabled, cors.allowed_origins, etc.
    return flattenStruct(reflect.ValueOf(cfg), "")
}
```

**Config Priority (NON-NEGOTIABLE):**

```
1. CLI flags (highest priority)
2. Environment variables
3. Database (admin WebUI changes)
4. Config file (config.yml)
5. Defaults (lowest priority)
```

On startup, merge all sources. Database and file stay in sync via ConfigManager.

```go
// Settings that require restart
var restartRequiredSettings = []string{
    "server.port",
    "server.address",
    "ssl.enabled",
    "ssl.cert",
    "ssl.key",
    "ssl.min_version",
    "server.daemonize",
    "database.path",
    "tor.enabled",
}

func categorizeChanges(changes []string) (hotReload, needsRestart []string) {
    for _, setting := range changes {
        requiresRestart := false
        for _, rs := range restartRequiredSettings {
            if strings.HasPrefix(setting, rs) {
                requiresRestart = true
                break
            }
        }
        if requiresRestart {
            needsRestart = append(needsRestart, setting)
        } else {
            hotReload = append(hotReload, setting)
        }
    }
    return
}
```

**Admin UI Restart Notification:**

```go
// GET /{adminpath}/api/status returns pending restart info
func adminStatusHandler(w http.ResponseWriter, r *http.Request) {
    status := map[string]interface{}{
        "running":         true,
        "pending_restart": configManager.PendingRestart(),
        "restart_reason":  configManager.RestartSettings(),
    }
    json.NewEncoder(w).Encode(status)
}
```

**Admin UI displays:**
```
┌─────────────────────────────────────────────────────────┐
│ ⚠️  Restart Required                                    │
│                                                         │
│ The following settings require a restart to take effect:│
│ • server.port                                           │
│ • ssl.enabled                                           │
│                                                         │
│ [Restart Now]  [Dismiss]                                │
└─────────────────────────────────────────────────────────┘
```

**Health Check Endpoint (`/healthz`):**

```go
// GET /healthz - used by load balancers, orchestrators, monitoring
func healthHandler(w http.ResponseWriter, r *http.Request) {
    w.Header().Set("Content-Type", "application/json")

    status := struct {
        Status         string   `json:"status"`
        PendingRestart bool     `json:"pending_restart,omitempty"`
        RestartReason  []string `json:"restart_reason,omitempty"`
    }{
        Status: "ok",
    }

    // Check shutdown state
    if isShuttingDown() {
        status.Status = "shutting_down"
        w.WriteHeader(http.StatusServiceUnavailable)
        json.NewEncoder(w).Encode(status)
        return
    }

    // Check pending restart (config changed, needs restart)
    if configManager.PendingRestart() {
        status.Status = "restart_required"
        status.PendingRestart = true
        status.RestartReason = configManager.RestartSettings()
        // Still return 200 - service is running, just needs restart
        // Orchestrators can watch pending_restart field
    }

    w.WriteHeader(http.StatusOK)
    json.NewEncoder(w).Encode(status)
}

// ConfigManager helper methods
func (m *ConfigManager) PendingRestart() bool {
    m.mu.RLock()
    defer m.mu.RUnlock()
    return m.pendingRestart
}

func (m *ConfigManager) RestartSettings() []string {
    m.mu.RLock()
    defer m.mu.RUnlock()
    return m.restartSettings
}

func (m *ConfigManager) ClearPendingRestart() {
    m.mu.Lock()
    defer m.mu.Unlock()
    m.pendingRestart = false
    m.restartSettings = nil
}
```

**Health Check Responses:**

```json
// Normal operation
{"status": "ok"}

// Restart required (service running but config changed)
{"status": "restart_required", "pending_restart": true, "restart_reason": ["ssl.enabled", "server.port"]}

// Shutting down
{"status": "shutting_down"}
```

**Orchestrator Integration:**

```yaml
# Kubernetes - check pending_restart for rolling updates
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  # Don't fail on restart_required - service is still live

# Custom controller can watch for pending_restart and trigger rollout
```

**Console Output:**

```
$ kill -TERM $(cat /var/run/myapp.pid)

[INFO] 2025-01-15 10:30:45 Received SIGTERM, starting graceful shutdown...
[INFO] 2025-01-15 10:30:45 Stopping HTTP server...
[INFO] 2025-01-15 10:30:46 Waiting for 3 in-flight requests...
[INFO] 2025-01-15 10:30:47 HTTP server stopped
[INFO] 2025-01-15 10:30:47 Stopping Tor process (PID 12346)...
[INFO] 2025-01-15 10:30:48 Tor stopped
[INFO] 2025-01-15 10:30:48 Closing database connections...
[INFO] 2025-01-15 10:30:48 Flushing logs...
[INFO] 2025-01-15 10:30:48 Removing PID file...
[INFO] 2025-01-15 10:30:48 Graceful shutdown complete
```

### Environment Variable Fallbacks (NON-NEGOTIABLE)

**Server binary directory flags accept corresponding environment variables as fallbacks.**

**Priority order:** Server binary CLI flag > Environment variable > Default

| CLI Flag | Env Variable | Description |
|----------|--------------|-------------|
| `--config` | `CONFIG_DIR` | Configuration directory |
| `--data` | `DATA_DIR` | Data directory |
| `--log` | `LOG_DIR` | Log directory |
| `--pid` | `PID_FILE` | PID file path |
| `--port` | `PORT` | Listen port |
| `--address` | `LISTEN` | Listen address |
| `--mode` | `MODE` | Application mode (production/development) |
| (none) | `DATABASE_DIR` | SQLite database directory (defaults to `{data_dir}/db/`, changeable) |
| (none) | `BACKUP_DIR` | Backup directory (defaults to `{data_dir}/backup/`, changeable) |

**External backup mounts:** In production, `BACKUP_DIR` should typically point to external storage (NAS, separate disk, etc.) rather than staying under `{data_dir}`. Example: `BACKUP_DIR=/mnt/Backups/apimgr/weather`. The default `{data_dir}/backup/` is for development/testing only.

**Implementation:**

```go
// GetConfigDir returns config directory from flag, env, or default
func GetConfigDir(flagValue string) string {
    if flagValue != "" {
        return flagValue
    }
    if envValue := os.Getenv("CONFIG_DIR"); envValue != "" {
        return envValue
    }
    // OS-specific default
    return defaultConfigDir()
}

// GetDatabaseDir returns database directory (always under data dir)
// This ensures SQLite is NEVER in {data_dir} root, always in {data_dir}/db/
func GetDatabaseDir(dataDir string) string {
    if envValue := os.Getenv("DATABASE_DIR"); envValue != "" {
        return envValue
    }
    return filepath.Join(dataDir, "db")
}

// GetCacheDir returns cache directory from env or default
func GetCacheDir(flagValue string) string {
    if flagValue != "" {
        return flagValue
    }
    if envValue := os.Getenv("CACHE_DIR"); envValue != "" {
        return envValue
    }
    // OS-specific default
    return defaultCacheDir()
}

// GetBackupDir returns backup directory from env or default
// Prefers system backup dir if writable, falls back to user dir
func GetBackupDir(flagValue string) string {
    if flagValue != "" {
        return flagValue
    }
    if envValue := os.Getenv("BACKUP_DIR"); envValue != "" {
        return envValue
    }
    // Prefer system backup dir if writable
    sysBackup := systemBackupDir()
    if isWritable(sysBackup) {
        return sysBackup
    }
    // Fall back to user backup dir
    return userBackupDir()
}

// isWritable checks if a directory is writable (or can be created)
func isWritable(path string) bool {
    // Check if parent exists and is writable
    parent := filepath.Dir(path)
    info, err := os.Stat(parent)
    if err != nil {
        return false
    }
    if !info.IsDir() {
        return false
    }
    // Try to create a temp file to test write access
    testFile := filepath.Join(parent, ".write_test_"+strconv.FormatInt(time.Now().UnixNano(), 36))
    f, err := os.Create(testFile)
    if err != nil {
        return false
    }
    f.Close()
    os.Remove(testFile)
    return true
}

// systemBackupDir returns the system-level backup directory
// Linux: /mnt/Backups/apimgr/weather
// macOS: /Library/Backups/apimgr/weather
// BSD:   /var/backups/apimgr/weather
// Windows: %ProgramData%\Backups\apimgr\weather
func systemBackupDir() string {
    switch runtime.GOOS {
    case "darwin":
        return filepath.Join("/Library/Backups", projectOrg, projectName)
    case "windows":
        return filepath.Join(os.Getenv("ProgramData"), "Backups", projectOrg, projectName)
    case "freebsd", "openbsd", "netbsd":
        return filepath.Join("/var/backups", projectOrg, projectName)
    default: // linux
        return filepath.Join("/mnt/Backups", projectOrg, projectName)
    }
}

// userBackupDir returns the user-level backup directory
// Linux/BSD: ~/.local/share/Backups/apimgr/weather
// macOS: ~/Library/Backups/apimgr/weather
// Windows: %LocalAppData%\Backups\apimgr\weather
func userBackupDir() string {
    home, _ := os.UserHomeDir()
    switch runtime.GOOS {
    case "darwin":
        return filepath.Join(home, "Library/Backups", projectOrg, projectName)
    case "windows":
        return filepath.Join(os.Getenv("LOCALAPPDATA"), "Backups", projectOrg, projectName)
    default: // linux, bsd
        return filepath.Join(home, ".local/share/Backups", projectOrg, projectName)
    }
}
```

**Container defaults (set by entrypoint.sh):**

```bash
# Configurable paths - organized by component
# APP_NAME is set to weather
export CONFIG_DIR="/config/${APP_NAME}"
export DATA_DIR="/data/${APP_NAME}"
export CACHE_DIR="/data/${APP_NAME}/cache"
export LOG_DIR="/data/log/${APP_NAME}"
export DATABASE_DIR="/data/db"
export BACKUP_DIR="/data/backups/${APP_NAME}"

# Tor directories under binary's dirs (binary owns Tor)
# ${CONFIG_DIR}/tor/ = /config/weather/tor/
# ${DATA_DIR}/tor/   = /data/weather/tor/
```

### Docker Compose Mapping

**Directory flags enable clean volume mounts:**

```yaml
services:
  weather:
    image: {PLATFORM_CONTAINER_REGISTRY}/apimgr/weather:latest
    command:
      - --config=/config
      - --data=/data
      - --log=/logs
      - --pid=/run/weather.pid
      - --port=8080
    volumes:
      - config:/config:ro          # Config (read-only)
      - data:/data                 # Data (read-write)
      - logs:/logs                 # Logs (read-write)
      - /var/run:/run                # PID file
    ports:
      - "8080:8080"
```

**Minimal compose (uses container defaults):**

```yaml
services:
  weather:
    image: {PLATFORM_CONTAINER_REGISTRY}/apimgr/weather:latest
    volumes:
      - weather-data:/data
    ports:
      - "8080:8080"

volumes:
  weather-data:
```

### Commands Anyone Can Run (No Privileges)

- `--help`
- `--version`
- `--status`
- `--update check`

## Display Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| Never show | `0.0.0.0`, `127.0.0.1`, `localhost` |
| Always show | Valid FQDN, host, or IP |
| Show only | One address, the most relevant |

## URL & FQDN Detection (NON-NEGOTIABLE)

**CRITICAL: Never hardcode host, IP, or port in project code. Always detect dynamically.**

### URL Display Rules

| Rule | Description |
|------|-------------|
| **NEVER hardcode** | `localhost`, `127.0.0.1`, `0.0.0.0`, `[::1]`, any static host/IP |
| **NEVER display** | `GET /api/`, `POST /api/` without full URL |
| **ALWAYS use** | `{proto}://{fqdn}:{port}/path` format |
| **ALWAYS detect** | `{proto}`, `{fqdn}`, `{port}` from request context |
| **ALWAYS strip** | `:80` for HTTP, `:443` for HTTPS |
| **Default proto** | `http` if not detected |

### URL Format Examples

| WRONG | RIGHT |
|-------|-------|
| `GET /api/v1/resource/random` | `https://api.example.com/api/v1/resource/random` |
| `POST /api/v1/admin/server/settings` | `https://api.example.com/api/v1/admin/server/settings` |
| `http://localhost:8080/api` | `http://192.168.1.100:64580/api` |
| `http://0.0.0.0:80/healthz` | `https://myserver.example.com/healthz` |

### URL Variables (NON-NEGOTIABLE)

**Three variables for building URLs: `{proto}`, `{fqdn}`, `{port}`**

All templates, Swagger/OpenAPI, GraphQL, email links, etc. MUST use these resolved variables.

| Variable | Description | Example |
|----------|-------------|---------|
| `{proto}` | Protocol (http/https) | `https` |
| `{fqdn}` | Fully qualified domain name | `api.example.com` |
| `{port}` | Port number (ALWAYS stripped if 80/443) | `8080` or empty |

**URL Format:** `{proto}://{fqdn}/path` or `{proto}://{fqdn}:{port}/path`

**Port Stripping (NON-NEGOTIABLE):**
- `:80` and `:443` are NEVER included in URLs
- `{port}` returns empty string for 80/443
- Only non-standard ports appear in URLs

### Resolution Order (Reverse Proxy Preferred)

**We prefer to run behind a reverse proxy. Reverse proxy headers take priority.**

**`{fqdn}` Resolution:**

| Priority | Source | Description |
|----------|--------|-------------|
| 1 | **Reverse Proxy Headers** | `X-Forwarded-Host`, `X-Real-Host`, `X-Original-Host` |
| 2 | **DOMAIN env var** | Comma-separated list (first is primary) |
| 3 | **os.Hostname()** | Go's hostname function |
| 4 | **$HOSTNAME env var** | Shell fallback |
| 5 | **Public IPv6** | First public IPv6 (excludes private/link-local) |
| 6 | **Public IPv4** | First public IPv4 (excludes 10/8, 172.16/12, 192.168/16) |
| 7 | **localhost** | Last resort |

**Public IP Detection (Go 1.17+):**
- Uses `ip.IsGlobalUnicast() && !ip.IsPrivate()`
- IPv4 excludes: `10.0.0.0/8`, `172.16.0.0/12`, `192.168.0.0/16`, `169.254.0.0/16`, `127.0.0.0/8`
- IPv6 excludes: `::1`, `fe80::/10` (link-local), `fc00::/7` (unique local)

**DOMAIN Environment Variable (Comma-Separated List):**

```bash
# Single domain
DOMAIN=myapp.com

# Multiple domains (first is primary)
DOMAIN=myapp.com,www.myapp.com,api.myapp.com
```

| Behavior | Description |
|----------|-------------|
| First domain is primary | Used as `{fqdn}` and `GetBaseDomain()` |
| Auto-infer wildcard | Same base domain → `*.myapp.com` |
| Skip learning | If DOMAIN set, no need to learn from requests |
| CORS auto-configured | All listed domains added to allowed origins |
| Validate on startup | Invalid domains cause startup warning |

**Examples:**

```bash
# Explicit list - skips learning
DOMAIN=myapp.com,www.myapp.com,api.myapp.com
# Result: fqdn=myapp.com, wildcard=*.myapp.com

# Single domain - still learns subdomains from requests
DOMAIN=myapp.com
# Result: fqdn=myapp.com, wildcard learned if www/api seen

# Not set - full auto-detection
# Result: learned from reverse proxy headers
```

**`{proto}` Resolution:**

| Priority | Source | Description |
|----------|--------|-------------|
| 1 | `X-Forwarded-Proto` | `https` or `http` |
| 2 | `X-Forwarded-Ssl` | `on` → https |
| 3 | `X-Url-Scheme` | `https` or `http` |
| 4 | **TLS on connection** | If TLS → https |
| 5 | **Default** | `http` |

**`{port}` Resolution:**

| Priority | Source | Description |
|----------|--------|-------------|
| 1 | `X-Forwarded-Port` | Port from proxy |
| 2 | **Host header port** | `example.com:8080` → 8080 |
| 3 | **Server listen port** | Actual port server is on |
| 4 | **Proto default** | https → 443, http → 80 |

**Reverse Proxy Headers (All Checked):**

| Header | Provides |
|--------|----------|
| `X-Forwarded-Host` | `{fqdn}` |
| `X-Forwarded-Proto` | `{proto}` |
| `X-Forwarded-Port` | `{port}` |
| `X-Forwarded-Ssl` | `{proto}` (on=https) |
| `X-Real-Host` | `{fqdn}` (fallback) |
| `X-Original-Host` | `{fqdn}` (fallback) |
| `X-Url-Scheme` | `{proto}` (fallback) |
| `X-Forwarded-For` | Request IP (for logging) |
| `X-Real-IP` | Request IP (fallback) |

### Smart FQDN Detection (Live Reload)

**App automatically detects and learns domain patterns from reverse proxy headers:**

When reverse proxy headers are detected, the app:
1. **Live reloads** URL variables immediately (no restart required)
2. **Infers wildcard domains** from observed patterns
3. **Updates cached values** for Swagger/GraphQL/templates

**Domain Learning Algorithm:**

```
Observation History:
  Request 1: myapp.com
  Request 2: www.myapp.com
  Request 3: api.myapp.com
  Request 4: myapp.com

Inference:
  Base domain: myapp.com
  Pattern: *.myapp.com (wildcard detected)
  Primary FQDN: myapp.com (most frequent non-www)
```

**Detection Rules:**

| Scenario | Detection | Result |
|----------|-----------|--------|
| Same domain repeated | Stable | Use as `{fqdn}` |
| www + apex seen | Wildcard | Infer `*.domain.com`, use apex as primary |
| Multiple subdomains | Wildcard | Infer `*.domain.com`, use most common |
| Conflicting domains | Warning | Log warning, use most recent |
| IP then domain | Upgrade | Switch to domain, log detection |

**Live Reload Triggers:**

| Trigger | Action |
|---------|--------|
| First reverse proxy header detected | Reload all URL vars |
| Domain change detected | Reload, log change |
| Proto change (http→https) | Reload, log upgrade |
| Conflicting headers | Log warning, use priority order |

**Configuration:**

```yaml
server:
  url_detection:
    # Enable smart domain learning
    learning: true
    # Minimum requests before inferring wildcard
    min_samples: 3
    # Time window for pattern analysis (duration)
    sample_window: 5m
    # Log domain changes to application log
    log_changes: true
    # Allow live reload without restart
    live_reload: true
```

**Sane Defaults:**
- Learning enabled
- 3 samples minimum for wildcard inference
- 5 minute sample window
- Log all domain changes
- Live reload enabled

**Usage in Code:**

```go
// GetURLVars returns resolved URL variables from request
// Checks reverse proxy headers first, triggers live reload on detection
// Port is empty string for 80/443 (always stripped)
func GetURLVars(r *http.Request) (proto, fqdn, port string)

// BuildURL constructs full URL with automatic port stripping
// :80 and :443 are NEVER included
func BuildURL(r *http.Request, path string) string {
    proto, fqdn, port := GetURLVars(r)
    if port == "" {
        return fmt.Sprintf("%s://%s%s", proto, fqdn, path)
    }
    return fmt.Sprintf("%s://%s:%s%s", proto, fqdn, port, path)
}

// GetBaseDomain returns inferred base domain from learning
// Returns: "myapp.com" even if accessed via "www.myapp.com"
func GetBaseDomain() string

// GetWildcardDomain returns inferred wildcard if detected
// Returns: "*.myapp.com" or empty if no wildcard pattern
func GetWildcardDomain() string
```

**Usage in Templates/Swagger/GraphQL:**

| Component | Base URL Source |
|-----------|-----------------|
| HTML templates | `BuildURL(r, "/path")` |
| Swagger/OpenAPI | `servers[0].url` = `BuildURL(r, "")` |
| GraphQL | `BuildURL(r, "/graphql")` |
| Email links | `BuildURL(r, "/verify")` |
| CORS origins | Auto-include `GetWildcardDomain()` if detected |
| OAuth callbacks | `BuildURL(r, "/auth/callback")` |

### FQDN/Host Validation Rules

**Uses `golang.org/x/net/publicsuffix` for proper TLD validation.**

**go.mod:**
```
require golang.org/x/net v0.33.0
```

This properly handles complex suffixes like `.co.uk`, `.com.au`, `.org.uk`, etc.

**Production Mode (Strict):**

| Valid | Invalid |
|-------|---------|
| `api.example.com` | `localhost` |
| `my.server.domain.co.uk` | `dev.local` |
| `app.company.com.au` | `app.test` |
| `server.company.io` | `192.168.1.1` (IP address) |
| | `myhost` (single-label) |

**Development Mode (Relaxed):**

| Valid | Invalid |
|-------|---------|
| `api.example.com` | `192.168.1.1` (IP address) |
| `localhost` | `myhost` (single-label, not localhost) |
| `dev.local` | `devbox` (single-label) |
| `app.test` | |
| `staging.internal` | |

**Validation Requirements:**

| Mode | Rules |
|------|-------|
| **Production** | Must have valid public suffix (ICANN TLD), no IPs, no dev TLDs |
| **Development** | Must have dot OR be localhost, no IPs, dev TLDs allowed |

**Internal/Dev-Only TLDs (blocked in production):**
- `localhost` (literal)
- `.localhost`, `.test`, `.example`, `.invalid` (RFC 6761)
- `.local`, `.lan`, `.internal`, `.home`, `.localdomain`
- `.home.arpa`, `.intranet`, `.corp`, `.private`
- `weather` - dynamic (e.g., `app.jokes`, `dev.quotes`, `my.api`)

**Overlay Network TLDs (App-Managed, not set in DOMAIN):**
- `.onion` - Tor hidden services (RFC 7686) - app generates/manages
- `.i2p` - I2P eepsites - app generates/manages
- `.exit` - Tor exit notation - app generates/manages

These are NOT set via `DOMAIN` env var. App handles registration and displays them in console.

**Go Implementation:**
```go
import (
    "net"
    "strings"

    "golang.org/x/net/publicsuffix"
)

var devOnlyTLDs = map[string]bool{
    "localhost": true, "test": true, "example": true, "invalid": true,
    "local": true, "lan": true, "internal": true, "home": true,
    "localdomain": true, "home.arpa": true, "intranet": true,
    "corp": true, "private": true,
}

func IsValidHost(host string, devMode bool, projectName string) bool {
    lower := strings.ToLower(strings.TrimSpace(host))

    // Reject empty
    if lower == "" {
        return false
    }

    // Reject IP addresses always
    if net.ParseIP(lower) != nil {
        return false
    }

    // Handle localhost
    if lower == "localhost" {
        return devMode
    }

    // Must contain at least one dot
    if !strings.Contains(lower, ".") {
        return false
    }

    // Overlay network TLDs - valid but app-managed (not set via DOMAIN)
    // These are checked here for internal validation, not for DOMAIN env var
    if strings.HasSuffix(lower, ".onion") ||
       strings.HasSuffix(lower, ".i2p") ||
       strings.HasSuffix(lower, ".exit") {
        return true
    }

    // Check dynamic project-specific TLD (e.g., app.jokes, dev.quotes, quotes, jokes, weather)
    if projectName != "" && strings.HasSuffix(lower, "."+strings.ToLower(projectName)) {
        // Project TLDs only valid in dev mode
        return devMode
    }

    // Get the public suffix (TLD or eTLD like co.uk)
    suffix, icann := publicsuffix.PublicSuffix(lower)

    // Check if it's a dev-only TLD
    if devOnlyTLDs[suffix] {
        // Dev TLDs only valid in dev mode
        return devMode
    }

    // In production, require valid ICANN TLD
    if !devMode && !icann {
        return false
    }

    // Verify we have at least eTLD+1 (not just the suffix itself)
    etldPlusOne, err := publicsuffix.EffectiveTLDPlusOne(lower)
    if err != nil {
        return false
    }

    // Host must be at least eTLD+1 (e.g., "domain.co.uk" not just "co.uk")
    return len(etldPlusOne) > 0
}
```

**Example Results (projectName = "jokes"):**

| Host | Production | Development | Reason |
|------|------------|-------------|--------|
| `my.server.domain.co.uk` | ✓ | ✓ | Valid eTLD+1: `domain.co.uk` |
| `api.example.com` | ✓ | ✓ | Valid eTLD+1: `example.com` |
| `app.company.com.au` | ✓ | ✓ | Valid eTLD+1: `company.com.au` |
| `dev.local` | ✗ | ✓ | Dev TLD `.local` |
| `app.test` | ✗ | ✓ | Dev TLD `.test` |
| `app.jokes` | ✗ | ✓ | Dynamic dev TLD `jokes` |
| `my.app.jokes` | ✗ | ✓ | Dynamic dev TLD `jokes` |
| `localhost` | ✗ | ✓ | Dev only |
| `co.uk` | ✗ | ✗ | No eTLD+1 (suffix only) |
| `192.168.1.1` | ✗ | ✗ | IP address |
| `myhost` | ✗ | ✗ | No dot (single-label) |

**Note:** DOMAIN and HOSTNAME environment variables MUST pass host validation for the current mode. Invalid values are skipped silently and detection continues to next source.

### SSL/Let's Encrypt FQDN Requirements

When requesting SSL certificates (Let's Encrypt), the FQDN must be **publicly resolvable**. This uses the same validation as production mode - no internal/dev-only TLDs allowed.

**Go Implementation for SSL validation:**
```go
func IsValidSSLHost(host string) bool {
    lower := strings.ToLower(host)

    // .onion addresses cannot use Let's Encrypt (not publicly resolvable)
    // Tor provides end-to-end encryption, so SSL is optional for .onion
    if strings.HasSuffix(lower, ".onion") {
        return false
    }

    // SSL always requires production-valid host (devMode=false)
    return IsValidHost(host, false)
}
```

**Behavior:**
- SSL with Let's Encrypt: Must pass production-mode validation (no dev TLDs)
- .onion addresses: Cannot use Let's Encrypt (Tor provides encryption)
- If Let's Encrypt requested with invalid host: Log warning, skip cert request, continue without SSL
- Self-signed certs: Can use any valid host for current mode

### Reverse Proxy Header Support (All Headers Supported)

**Protocol Detection (`{proto}`):**
- `X-Forwarded-Proto` - Standard: "https" or "http"
- `X-Forwarded-Ssl` - "on" = https, "off" = http
- `X-Url-Scheme` - Alternative: "https" or "http"
- `Front-End-Https` - Microsoft: "on" = https

**Host Detection (`{fqdn}`):**
- `X-Forwarded-Host` - Standard: "example.com" or "example.com:8080"
- `X-Real-Host` - nginx: "example.com"
- `X-Original-Host` - Alternative

**Port Detection (`{port}`):**
- `X-Forwarded-Port` - Standard: "443" or "8080"
- `X-Real-Port` - nginx alternative

**Client IP Detection (for logging, rate limiting, GeoIP):**
- `X-Forwarded-For` - Standard: may contain chain "client, proxy1, proxy2"
- `X-Real-IP` - nginx: single IP
- `CF-Connecting-IP` - Cloudflare
- `True-Client-IP` - Akamai/Cloudflare Enterprise
- `X-Client-IP` - Alternative

**Request ID (for tracing):**
- `X-Request-ID` - Standard
- `X-Correlation-ID` - Alternative
- `X-Trace-ID` - Distributed tracing

### Request ID Handling (NON-NEGOTIABLE)

**Every request MUST have a Request ID for tracing and debugging.**

| Scenario | Behavior |
|----------|----------|
| Client sends `X-Request-ID` | Use client's ID (validate format) |
| No Request ID header | Generate new UUID |
| Invalid format | Generate new UUID, log warning |

**Request ID Rules:**

| Rule | Description |
|------|-------------|
| **Format** | UUID v4 (e.g., `550e8400-e29b-41d4-a716-446655440000`) |
| **Generation** | Use secure random UUID generator |
| **Propagation** | Include in all outgoing requests to downstream services |
| **Response** | Return `X-Request-ID` in response headers |
| **Logging** | Include `{request_id}` in all log entries for the request |

**Go Implementation:**
```go
func RequestIDMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // Check for existing request ID from client or upstream proxy
        requestID := r.Header.Get("X-Request-ID")
        if requestID == "" {
            requestID = r.Header.Get("X-Correlation-ID")
        }
        if requestID == "" {
            requestID = r.Header.Get("X-Trace-ID")
        }

        // Generate new ID if none provided or invalid
        if requestID == "" || !isValidUUID(requestID) {
            requestID = uuid.New().String()
        }

        // Add to response headers
        w.Header().Set("X-Request-ID", requestID)

        // Add to request context for logging and downstream calls
        ctx := context.WithValue(r.Context(), "request_id", requestID)
        next.ServeHTTP(w, r.WithContext(ctx))
    })
}
```

### Auth Token Headers (All Headers Supported)

**Standard Authorization:**
- `Authorization` - Standard: `Bearer {token}`, `Basic {base64}`, `Digest {credentials}`

**API Key Headers:**
- `X-API-Key` - Common API key header
- `X-Api-Key` - Case variant (treat as same)
- `API-Key` - Alternative without X- prefix
- `ApiKey` - No hyphen variant

**Custom Token Headers:**
- `X-Auth-Token` - Custom auth token
- `X-Access-Token` - Access token header
- `X-Token` - Short form
- `Token` - Minimal form

**Session/CSRF Headers:**
- `X-CSRF-Token` - CSRF protection token
- `X-XSRF-Token` - Angular variant
- `X-Session-ID` - Session identifier

**Service-to-Service:**
- `X-Service-Token` - Internal service auth
- `X-Internal-Token` - Internal API calls

**Priority Order (first found wins):**
1. `Authorization` header (standard, preferred)
2. `X-API-Key` / `API-Key`
3. `X-Auth-Token` / `X-Access-Token`
4. `X-Token` / `Token`
5. Query parameter `?token=` (least preferred, avoid in production)

### Implementation Requirements

1. **Request Context Helper**: Create a helper function that extracts `{proto}`, `{fqdn}`, `{port}` from each request
2. **URL Builder**: Create a helper that builds full URLs: `{proto}://{fqdn}:{port}/path` (strip :80/:443)
3. **Never Import** hardcoded URLs into templates - always pass detected values
4. **API Response URLs**: All URLs in API responses must be absolute, using detected values
5. **Swagger/OpenAPI**: Server URL must be detected, not hardcoded

---


# PART 9: ERROR HANDLING & CACHING (NON-NEGOTIABLE)

## Error Handling

### Core Principles

| Principle | Description |
|-----------|-------------|
| **Clear messages** | User-facing errors must be actionable and understandable |
| **No stack traces** | Never expose stack traces in production responses |
| **Consistent format** | All errors use the same JSON structure |
| **Appropriate codes** | HTTP status codes match error semantics |
| **Log everything** | All errors logged with context for debugging |

### Response Format

**See "Unified Response Format (NON-NEGOTIABLE)" in PART 16 for the complete specification.**

**All responses use simple, consistent format:**

Success:
```json
{
  "ok": true,
  "data": {}
}
```

Error:
```json
{
  "ok": false,
  "error": "ERROR_CODE",
  "message": "Human readable message"
}
```

### Error Codes

**Standard error codes (see PART 16 for full list):**

| Code | HTTP | Message |
|------|------|---------|
| `BAD_REQUEST` | 400 | "Invalid request format" |
| `VALIDATION_FAILED` | 400 | "Validation failed: {details}" |
| `UNAUTHORIZED` | 401 | "Authentication required" |
| `TOKEN_EXPIRED` | 401 | "Token has expired" |
| `TOKEN_INVALID` | 401 | "Invalid token" |
| `2FA_REQUIRED` | 401 | "Two-factor authentication required" |
| `2FA_INVALID` | 401 | "Invalid 2FA code" |
| `FORBIDDEN` | 403 | "Permission denied" |
| `ACCOUNT_LOCKED` | 403 | "Account locked" |
| `NOT_FOUND` | 404 | "Resource not found" |
| `METHOD_NOT_ALLOWED` | 405 | "Method not allowed" |
| `CONFLICT` | 409 | "Resource already exists" |
| `RATE_LIMITED` | 429 | "Too many requests" |
| `SERVER_ERROR` | 500 | "Internal server error" |
| `MAINTENANCE` | 503 | "Service unavailable" |

### Error Implementation

```go
// Unified response structure
type Response struct {
    OK      bool            `json:"ok"`
    Data    any             `json:"data,omitempty"`
    Error   string          `json:"error,omitempty"`
    Message string          `json:"message,omitempty"`
}

// Send success response
func SendOK(w http.ResponseWriter, data any) {
    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(Response{OK: true, Data: data})
}

// Send error response
func SendError(w http.ResponseWriter, code string, message string) {
    status := errorCodeToHTTP(code)
    w.Header().Set("Content-Type", "application/json")
    w.WriteHeader(status)
    json.NewEncoder(w).Encode(Response{OK: false, Error: code, Message: message})
}

// Map error code to HTTP status
func errorCodeToHTTP(code string) int {
    switch code {
    case "BAD_REQUEST", "VALIDATION_FAILED":
        return 400
    case "UNAUTHORIZED", "TOKEN_EXPIRED", "TOKEN_INVALID", "2FA_REQUIRED", "2FA_INVALID":
        return 401
    case "FORBIDDEN", "ACCOUNT_LOCKED":
        return 403
    case "NOT_FOUND":
        return 404
    case "METHOD_NOT_ALLOWED":
        return 405
    case "CONFLICT":
        return 409
    case "RATE_LIMITED":
        return 429
    case "MAINTENANCE":
        return 503
    default:
        return 500
    }
}
```

### Error Logging

**All errors MUST be logged with context:**

```go
func logError(ctx context.Context, err *AppError) {
    logger := log.FromContext(ctx)

    fields := []slog.Attr{
        slog.String("error_code", err.Code),
        slog.String("request_id", err.RequestID),
        slog.Int("http_status", err.HTTPStatus),
    }

    // Include internal error for debugging (never in response)
    if err.Internal != nil {
        fields = append(fields, slog.String("internal", err.Internal.Error()))
    }

    // Log level based on HTTP status
    if err.HTTPStatus >= 500 {
        logger.Error(err.Message, fields...)
    } else if err.HTTPStatus >= 400 {
        logger.Warn(err.Message, fields...)
    }
}
```

**Log format:**
```json
{
  "time": "2024-12-31T10:15:30Z",
  "level": "ERROR",
  "msg": "Database connection failed",
  "error": "SERVER_ERROR",
  "request_id": "req_abc123",
  "http_status": 500,
  "internal": "pq: connection refused",
  "path": "/api/v1/users",
  "method": "GET",
  "ip": "192.168.1.100"
}
```

### Retry and Backoff

**For transient errors, implement exponential backoff:**

| Attempt | Wait Time | Total Elapsed |
|---------|-----------|---------------|
| 1 | 0s | 0s |
| 2 | 1s | 1s |
| 3 | 2s | 3s |
| 4 | 4s | 7s |
| 5 | 8s | 15s |
| Max | 30s | - |

```go
func withRetry(ctx context.Context, fn func() error) error {
    backoff := []time.Duration{0, 1*time.Second, 2*time.Second, 4*time.Second, 8*time.Second}
    maxBackoff := 30 * time.Second

    var lastErr error
    for attempt := 0; attempt < len(backoff); attempt++ {
        if attempt > 0 {
            wait := backoff[attempt]
            if wait > maxBackoff {
                wait = maxBackoff
            }
            select {
            case <-ctx.Done():
                return ctx.Err()
            case <-time.After(wait):
            }
        }

        if err := fn(); err != nil {
            if !isRetryable(err) {
                return err
            }
            lastErr = err
            continue
        }
        return nil
    }
    return lastErr
}

func isRetryable(err error) bool {
    // Network errors, timeouts, 503s are retryable
    // 4xx errors are NOT retryable
    return errors.Is(err, context.DeadlineExceeded) ||
           errors.Is(err, syscall.ECONNREFUSED) ||
           isHTTPStatus(err, 503)
}
```

---

## Caching

See **PART 12: SERVER CONFIGURATION** for full Valkey/Redis setup.

### Cache Drivers

| Driver | Mode | Use Case | Notes |
|--------|------|----------|-------|
| `memory` | Single instance | Development, small deployments | Default, in-process, lost on restart |
| `valkey` | Single/Cluster | Production | Preferred, open-source Redis fork |
| `redis` | Single/Cluster | Production | Full compatibility |

### Cache Key Naming

**Use hierarchical, descriptive keys:**

| Pattern | Example | Description |
|---------|---------|-------------|
| `{type}:{id}` | `user:123` | Single resource |
| `{type}:{id}:{field}` | `user:123:sessions` | Resource sub-field |
| `{type}:list:{filter}` | `jokes:list:category=puns` | Filtered list |
| `{scope}:{type}:{id}` | `org:42:settings` | Scoped resource |
| `rate:{type}:{key}` | `rate:api:192.168.1.1` | Rate limiting |
| `lock:{resource}` | `lock:backup` | Distributed locks |

**Key naming rules:**
- Use colons (`:`) as separators
- Lowercase only
- No spaces or special characters
- Include version for cache-busting: `v1:user:123`

### Cache TTL Defaults

| Content Type | TTL | Reason |
|--------------|-----|--------|
| Session tokens | 7 days | User convenience vs security |
| API tokens | No expiry | Explicit revocation only |
| Rate limit counters | 1 minute | Rolling window |
| User profile | 5 minutes | Balance freshness and load |
| Configuration | 1 minute | Quick propagation of changes |
| Static content hash | 24 hours | Immutable content |
| GeoIP data | 7 days | Infrequent updates |
| Blocklist | 1 hour | Security updates |
| Page cache | 5 minutes | Dynamic content |
| API response cache | 30 seconds | Frequently changing data |

### Cache Invalidation

**Patterns for cache invalidation:**

| Strategy | When to Use | Implementation |
|----------|-------------|----------------|
| **Time-based (TTL)** | Data has known freshness | Set TTL on write |
| **Event-based** | Data changes on specific events | Delete on update/delete |
| **Version-based** | Need immediate invalidation | Include version in key |
| **Tag-based** | Related data needs invalidation | Tag keys, invalidate by tag |

```go
// Event-based invalidation
func UpdateUser(ctx context.Context, user *User) error {
    if err := db.Save(user); err != nil {
        return err
    }

    // Invalidate all related cache entries
    cache.Delete(ctx, fmt.Sprintf("user:%d", user.ID))
    cache.Delete(ctx, fmt.Sprintf("user:%d:profile", user.ID))
    cache.Delete(ctx, fmt.Sprintf("user:%d:sessions", user.ID))

    return nil
}

// Version-based invalidation
func GetUserWithVersion(ctx context.Context, userID int, version int) (*User, error) {
    key := fmt.Sprintf("v%d:user:%d", version, userID)
    // Old version keys naturally expire via TTL
    return cache.GetOrSet(ctx, key, 5*time.Minute, func() (*User, error) {
        return db.GetUser(userID)
    })
}
```

### HTTP Cache Headers

| Content Type | Cache-Control Header | Description |
|--------------|---------------------|-------------|
| Static assets (JS/CSS/images) | `public, max-age=31536000, immutable` | 1 year, fingerprinted files |
| HTML pages | `no-store` | Always fetch fresh |
| API responses (public) | `public, max-age=60` | Short cache for CDN |
| API responses (private) | `private, no-store` | User-specific data |
| Authenticated pages | `private, no-store` | Never cache |
| Error pages | `no-store` | Don't cache errors |

```go
func setCacheHeaders(w http.ResponseWriter, contentType string, isAuthenticated bool) {
    if isAuthenticated {
        w.Header().Set("Cache-Control", "private, no-store")
        return
    }

    switch contentType {
    case "static":
        w.Header().Set("Cache-Control", "public, max-age=31536000, immutable")
    case "api":
        w.Header().Set("Cache-Control", "public, max-age=60")
    case "html":
        w.Header().Set("Cache-Control", "no-store")
    }
}
```

### Cache Warming

**Pre-populate cache for frequently accessed data:**

```go
func warmCache(ctx context.Context) error {
    // Warm on startup and periodically

    // Configuration
    config, _ := db.GetServerConfig()
    cache.Set(ctx, "config:server", config, 1*time.Minute)

    // Blocklists
    blocklist, _ := db.GetBlocklist()
    cache.Set(ctx, "security:blocklist", blocklist, 1*time.Hour)

    // GeoIP databases (just metadata, not the actual DB)
    geoInfo, _ := geoip.GetDatabaseInfo()
    cache.Set(ctx, "geoip:info", geoInfo, 7*24*time.Hour)

    return nil
}
```

### Distributed Locks

**Use for operations that must run on only one node:**

```go
func acquireLock(ctx context.Context, key string, ttl time.Duration) (bool, error) {
    // SET key value NX EX ttl
    return cache.SetNX(ctx, "lock:"+key, nodeID, ttl)
}

func releaseLock(ctx context.Context, key string) error {
    // Only release if we own the lock
    val, _ := cache.Get(ctx, "lock:"+key)
    if val == nodeID {
        return cache.Delete(ctx, "lock:"+key)
    }
    return nil
}

// Usage
func runScheduledBackup(ctx context.Context) error {
    acquired, err := acquireLock(ctx, "backup", 30*time.Minute)
    if err != nil || !acquired {
        return nil // Another node is handling it
    }
    defer releaseLock(ctx, "backup")

    return performBackup(ctx)
}
```

---


# PART 10: DATABASE & CLUSTER (NON-NEGOTIABLE)

## Database Schema

**ALL apps use `CREATE TABLE IF NOT EXISTS` for self-creating schema.**

| Feature | Description |
|---------|-------------|
| Self-creating | Tables created on startup if missing |
| Idempotent | Safe to run multiple times |
| Schema changes | Use `ALTER TABLE` inline when needed |
| No migrations table | Keep it simple |

See **Database Schema for Configuration** section in PART 5 for full table definitions.

## Cluster Support (NON-NEGOTIABLE)

**ALL apps MUST support cluster mode with config sync.**

### What Clustering Provides (Standard for ALL Apps)

| Feature | Description |
|---------|-------------|
| **Config Sync** | Change setting on one node → syncs to all nodes |
| **Session Sharing** | User sessions shared across nodes |
| **Distributed Locks** | Prevent duplicate task execution |
| **Primary Election** | One node handles cluster-wide tasks |
| **Health Monitoring** | Nodes monitor each other |

**This is the BASE functionality. Every project gets this.**

### Single Instance (Auto-detected)

- No external cache/database configured
- Uses local file/SQLite for state
- Fully functional, just not clustered

### Cluster Mode (Auto-detected)

- Auto-enabled when external cache or shared database detected
- Requires: PostgreSQL/MySQL + Valkey/Redis
- All nodes share same database and cache
- Config changes propagate automatically

### Cluster Heartbeat & Failure Handling

**Every cluster node sends heartbeats to detect failures.**

| Setting | Value | Description |
|---------|-------|-------------|
| Heartbeat interval | 30 seconds | How often nodes send heartbeats |
| Heartbeat timeout | 90 seconds | 3 missed heartbeats = node considered unresponsive |
| Degraded threshold | 90 seconds | Node marked as `degraded` |
| Offline threshold | 5 minutes | Node marked as `offline` |
| Removal threshold | Manual | Offline nodes require manual removal |

**Node States:**

| State | Meaning | Action |
|-------|---------|--------|
| `healthy` | Heartbeat received within 30 seconds | Normal operation |
| `degraded` | Heartbeat missed (30-90 seconds) | Logged, monitoring continues |
| `offline` | No heartbeat for 5+ minutes | Node excluded from load balancing |
| `removed` | Manually removed by admin | Node record deleted |

**Failure Detection Flow:**

```
Node A sends heartbeat every 30 seconds
         │
         ▼
Other nodes track "last_seen" timestamp
         │
         ▼
If now - last_seen > 90 seconds:
   Mark as "degraded", log warning
         │
         ▼
If now - last_seen > 5 minutes:
   Mark as "offline", exclude from cluster operations
         │
         ▼
Admin manually removes dead nodes via:
   /{adminpath}/server/cluster → Remove Node
```

**Primary Election:**

| Event | Action |
|-------|--------|
| Cluster starts | Node with lowest ID becomes primary |
| Primary goes offline | Next healthy node (by ID) becomes primary |
| Primary comes back | Remains secondary (no preemption) |
| Split-brain | Database is source of truth (latest write wins) |

**What Primary Node Handles:**

- Scheduled tasks (only primary runs cron jobs)
- Cluster-wide maintenance
- GeoIP/blocklist updates (once, shared via DB)

### Extended Node Functions (PER-PROJECT)

**Beyond config sync, what nodes DO varies by project.**

| App Type | Base (Config Sync) | Extended Node Function |
|----------|:------------------:|------------------------|
| Jokes API | ✓ | None - sync only |
| Quotes API | ✓ | None - sync only |
| Watchtower-type | ✓ | + Manage Docker hosts |
| DNS Server | ✓ | + HA failover |
| Monitoring App | ✓ | + Monitor remote servers |
| Proxmox-type | ✓ | + Manage VMs + HA failover |

**Extended functions are defined in the project's AI.md under "Node Functions".**

### High Availability (Specialized Apps Only)

**HA is NOT standard - only for apps that specifically require failover.**

| HA Requirement | Examples |
|----------------|----------|
| DNS failover | DNS servers, domain controllers |
| Service continuity | Proxmox, cPanel, critical infrastructure |
| Data redundancy | Database clusters, storage systems |

**If your app needs HA, define it in AI.md under "High Availability Requirements".**

Most apps (Jokes, Quotes, Airports, etc.) do NOT need HA - clustering with config sync is sufficient.

---

## Connection Pooling

**All database connections MUST use connection pooling.**

### Pool Configuration

```yaml
server:
  database:
    driver: postgres
    host: localhost
    port: 5432
    name: myapp
    username: myapp
    password: ${DB_PASSWORD}

    # Connection pool settings
    pool:
      max_open: 25        # Max open connections
      max_idle: 5         # Max idle connections
      max_lifetime: 5m    # Max connection lifetime
      max_idle_time: 1m   # Max idle time before close
```

### Pool Sizing Guidelines

| Deployment | max_open | max_idle | Reason |
|------------|----------|----------|--------|
| Development | 5 | 2 | Minimal resources |
| Small (1-2 nodes) | 25 | 5 | Default, works for most |
| Medium (3-5 nodes) | 50 | 10 | More concurrent requests |
| Large (6+ nodes) | 100 | 20 | High concurrency |

**Formula:** `max_open = (available_connections / num_nodes) * 0.8`

### Implementation

```go
func NewDB(cfg *config.Database) (*sql.DB, error) {
    db, err := sql.Open(cfg.Driver, cfg.DSN())
    if err != nil {
        return nil, err
    }

    // Configure pool
    db.SetMaxOpenConns(cfg.Pool.MaxOpen)
    db.SetMaxIdleConns(cfg.Pool.MaxIdle)
    db.SetConnMaxLifetime(cfg.Pool.MaxLifetime)
    db.SetConnMaxIdleTime(cfg.Pool.MaxIdleTime)

    // Verify connection
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()
    if err := db.PingContext(ctx); err != nil {
        return nil, fmt.Errorf("database ping failed: %w", err)
    }

    return db, nil
}
```

---

## Query Timeouts

**All database queries MUST have timeouts.**

### Timeout Configuration

| Query Type | Default Timeout | Reason |
|------------|-----------------|--------|
| Simple SELECT | 5 seconds | Fast reads |
| Complex SELECT (JOIN) | 15 seconds | More processing |
| INSERT/UPDATE/DELETE | 10 seconds | Write operations |
| Bulk operations | 60 seconds | Large data sets |
| Migrations | 5 minutes | Schema changes |
| Reports | 2 minutes | Aggregations |

### Implementation

```go
// Always use context with timeout
func GetUser(ctx context.Context, db *sql.DB, id int) (*User, error) {
    // Query timeout (use parent context or create new)
    ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
    defer cancel()

    var user User
    err := db.QueryRowContext(ctx,
        "SELECT id, email, name FROM users WHERE id = $1", id,
    ).Scan(&user.ID, &user.Email, &user.Name)

    if err == context.DeadlineExceeded {
        return nil, fmt.Errorf("query timeout: %w", err)
    }
    return &user, err
}

// For transactions
func WithTransaction(ctx context.Context, db *sql.DB, fn func(*sql.Tx) error) error {
    // Transaction timeout
    ctx, cancel := context.WithTimeout(ctx, 30*time.Second)
    defer cancel()

    tx, err := db.BeginTx(ctx, nil)
    if err != nil {
        return err
    }

    if err := fn(tx); err != nil {
        tx.Rollback()
        return err
    }

    return tx.Commit()
}
```

### Handling Timeouts

```go
func handleQueryError(err error) error {
    switch {
    case errors.Is(err, context.DeadlineExceeded):
        return errors.New("TIMEOUT: Request timed out")
    case errors.Is(err, sql.ErrNoRows):
        return errors.New("NOT_FOUND: Resource not found")
    case errors.Is(err, context.Canceled):
        return errors.New("CANCELED: Request was canceled")
    default:
        return fmt.Errorf("SERVER_ERROR: Database error: %w", err)
    }
}
```

---

## Transaction Patterns

### Basic Transaction

```go
func TransferFunds(ctx context.Context, db *sql.DB, from, to int, amount float64) error {
    return WithTransaction(ctx, db, func(tx *sql.Tx) error {
        // Debit source account
        result, err := tx.ExecContext(ctx,
            "UPDATE accounts SET balance = balance - $1 WHERE id = $2 AND balance >= $1",
            amount, from)
        if err != nil {
            return err
        }
        if rows, _ := result.RowsAffected(); rows == 0 {
            return errors.New("insufficient funds")
        }

        // Credit destination account
        _, err = tx.ExecContext(ctx,
            "UPDATE accounts SET balance = balance + $1 WHERE id = $2",
            amount, to)
        return err
    })
}
```

### Optimistic Locking

```go
type User struct {
    ID        int
    Name      string
    Version   int  // Optimistic lock version
}

func UpdateUser(ctx context.Context, db *sql.DB, user *User) error {
    result, err := db.ExecContext(ctx,
        `UPDATE users SET name = $1, version = version + 1
         WHERE id = $2 AND version = $3`,
        user.Name, user.ID, user.Version)
    if err != nil {
        return err
    }

    rows, _ := result.RowsAffected()
    if rows == 0 {
        return errors.New("CONFLICT: Resource was modified by another request")
    }

    user.Version++
    return nil
}
```

### Serializable Isolation (When Needed)

```go
func ReserveTicket(ctx context.Context, db *sql.DB, eventID, userID int) error {
    ctx, cancel := context.WithTimeout(ctx, 10*time.Second)
    defer cancel()

    tx, err := db.BeginTx(ctx, &sql.TxOptions{
        Isolation: sql.LevelSerializable,
    })
    if err != nil {
        return err
    }
    defer tx.Rollback()

    // Check availability
    var available int
    err = tx.QueryRowContext(ctx,
        "SELECT available FROM events WHERE id = $1", eventID,
    ).Scan(&available)
    if err != nil {
        return err
    }
    if available <= 0 {
        return errors.New("CONFLICT: No tickets available")
    }

    // Reserve
    _, err = tx.ExecContext(ctx,
        "UPDATE events SET available = available - 1 WHERE id = $1", eventID)
    if err != nil {
        return err
    }

    // Create reservation
    _, err = tx.ExecContext(ctx,
        "INSERT INTO reservations (event_id, user_id) VALUES ($1, $2)",
        eventID, userID)
    if err != nil {
        return err
    }

    return tx.Commit()
}
```

### Retry on Serialization Failure

```go
func WithSerializableRetry(ctx context.Context, db *sql.DB, maxRetries int, fn func(*sql.Tx) error) error {
    for attempt := 0; attempt < maxRetries; attempt++ {
        tx, err := db.BeginTx(ctx, &sql.TxOptions{
            Isolation: sql.LevelSerializable,
        })
        if err != nil {
            return err
        }

        err = fn(tx)
        if err != nil {
            tx.Rollback()
            // Check if serialization failure (retry)
            if isSerializationError(err) && attempt < maxRetries-1 {
                time.Sleep(time.Duration(attempt*10) * time.Millisecond)
                continue
            }
            return err
        }

        if err := tx.Commit(); err != nil {
            if isSerializationError(err) && attempt < maxRetries-1 {
                continue
            }
            return err
        }
        return nil
    }
    return errors.New("max retries exceeded")
}

func isSerializationError(err error) bool {
    // PostgreSQL: 40001 serialization_failure
    // MySQL: 1213 Deadlock found
    return strings.Contains(err.Error(), "40001") ||
           strings.Contains(err.Error(), "1213")
}
```

---


# PART 11: SECURITY & LOGGING (NON-NEGOTIABLE)

## Security Headers

**All responses MUST include:**

```
X-Content-Type-Options: nosniff
X-Frame-Options: SAMEORIGIN
X-XSS-Protection: 1; mode=block
Referrer-Policy: strict-origin-when-cross-origin
Content-Security-Policy: default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'
Permissions-Policy: geolocation=(), microphone=(), camera=()
```

**When SSL is enabled, also include:**

```
Strict-Transport-Security: max-age=31536000; includeSubDomains
```

**Notes:**
- `X-XSS-Protection` is deprecated in modern browsers but kept for older browser compatibility
- `'unsafe-inline'` in CSP is required for many frameworks; tighten if your app allows
- HSTS `max-age` is configurable (default 1 year = 31536000 seconds)

**In development mode, these may be relaxed.**

## API Token Security (NON-NEGOTIABLE)

**ALL projects have API tokens for server admins. Multi-user projects also have user tokens.**

### Token Format

```
{prefix}_{random_32_alphanumeric}

Examples:
  adm_a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6        (admin token)
  usr_x9y8z7w6v5u4t3s2r1q0p9o8n7m6l5k4        (user token - if multi-user)
  org_q1w2e3r4t5y6u7i8o9p0a1s2d3f4g5h6        (org token - if orgs)

Agent tokens (scoped to owner):
  adm_agt_z1x2c3v4b5n6m7l8k9j0h1g2f3d4s5a6   (admin agent - server infrastructure)
  usr_agt_a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6   (user agent - user's personal agent)
  org_agt_q1w2e3r4t5y6u7i8o9p0a1s2d3f4g5h6   (org agent - organization agent)
```

### Token Prefixes (NON-NEGOTIABLE)

| Prefix | Type | Required | Description |
|--------|------|----------|-------------|
| `adm_` | Admin token | **YES - all projects** | Server admin API access |
| `usr_` | User token | If multi-user (PART 33) | Regular user API access |
| `org_` | Organization token | If orgs (PART 34) | Organization-level API access |

### Token Properties (NON-NEGOTIABLE)

**All tokens (adm_, usr_, org_) support these properties:**

| Property | Options | Default |
|----------|---------|---------|
| **Name** | User-defined string | "default" |
| **Scope** | `global`, `read-write`, `read` | `global` |
| **Expiration** | Never, 7 days, 1 month, 6 months, 1 year, custom | Never |

**Scope definitions:**
- `global` - All permissions the owner has access to (auto-detected)
- `read-write` - Read and write operations (no delete, no admin actions)
- `read` - Read-only operations

**Token actions:**
- **Create** - Generate new token with name, scope, expiration
- **Rotate** - Generate new token value, keep settings
- **Delete** - Revoke token immediately

**Users can have multiple tokens:**
```
adm_abc123...  "default"      global     never
adm_def456...  "ci-cd"        read-write 6 months
adm_ghi789...  "monitoring"   read       1 year
```

### Agent Token Prefixes (If PART 36 Implemented)

| Prefix | Scope | Route | Description |
|--------|-------|-------|-------------|
| `adm_agt_` | Admin | `/api/v1/admin/server/agents/*` | Server infrastructure agents |
| `usr_agt_` | User | `/api/v1/users/agents/*` | User's personal agents (SaaS) |
| `org_agt_` | Org | `/api/v1/orgs/{slug}/agents/*` | Organization agents |

**Same setup procedure across all scopes** - one-line config, same registration flow.

### Token Storage (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **Never store plaintext** | Store SHA-256 hash only (tokens are already random) |
| **Show once** | Display full token only on creation |
| **Store prefix** | Keep first 8 chars for display: `adm_a1b2...` |
| **Secure generation** | Use cryptographically secure random (32 alphanumeric chars) |

### Token Database Schema

**Tokens table (supports multiple tokens per owner):**
```sql
CREATE TABLE tokens (
    id            INTEGER PRIMARY KEY,
    owner_type    TEXT NOT NULL,       -- 'admin', 'user', 'org'
    owner_id      INTEGER NOT NULL,    -- admin.id, user.id, or org.id

    -- Token identification
    name          TEXT NOT NULL,       -- User-provided label: "default", "ci-cd"
    token_hash    TEXT NOT NULL,       -- SHA-256 hash of full token
    token_prefix  TEXT NOT NULL,       -- First 8 chars: "adm_a1b2"

    -- Token properties
    scope         TEXT NOT NULL DEFAULT 'global',  -- 'global', 'read-write', 'read'
    expires_at    TIMESTAMP,           -- NULL = never expires

    -- Tracking
    last_used_at  TIMESTAMP,
    created_at    TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,

    UNIQUE(owner_type, owner_id, name)  -- One token per name per owner
);

CREATE INDEX idx_tokens_hash ON tokens(token_hash);
CREATE INDEX idx_tokens_owner ON tokens(owner_type, owner_id);
```

**Expiration options:**
```go
var ExpirationOptions = map[string]time.Duration{
    "never":    0,              // NULL in database
    "7days":    7 * 24 * time.Hour,
    "1month":   30 * 24 * time.Hour,
    "6months":  180 * 24 * time.Hour,
    "1year":    365 * 24 * time.Hour,
    // "custom" - user picks date from calendar
}
```

### Token Validation

```go
func ValidateToken(token string) (*TokenInfo, error) {
    // Check for compound agent prefixes first (adm_agt_, usr_agt_, org_agt_)
    if strings.HasPrefix(token, "adm_agt_") {
        return validateAgentToken(token, ScopeAdmin)
    }
    if strings.HasPrefix(token, "usr_agt_") {
        return validateAgentToken(token, ScopeUser)
    }
    if strings.HasPrefix(token, "org_agt_") {
        return validateAgentToken(token, ScopeOrg)
    }

    // Standard single-prefix tokens: {prefix}_{32_chars}
    parts := strings.SplitN(token, "_", 2)
    if len(parts) != 2 || len(parts[1]) != 32 {
        return nil, ErrInvalidTokenFormat
    }

    prefix := parts[0] + "_"

    switch prefix {
    case "adm_":
        return validateAdminToken(token)
    case "usr_":
        return validateUserToken(token)  // Only if multi-user
    case "org_":
        return validateOrgToken(token)   // Only if orgs
    default:
        return nil, ErrUnknownTokenType
    }
}

// Agent token validation with scope
func validateAgentToken(token string, scope TokenScope) (*TokenInfo, error) {
    // Extract the random part after compound prefix
    var prefix string
    switch scope {
    case ScopeAdmin:
        prefix = "adm_agt_"
    case ScopeUser:
        prefix = "usr_agt_"
    case ScopeOrg:
        prefix = "org_agt_"
    }

    random := strings.TrimPrefix(token, prefix)
    if len(random) != 32 {
        return nil, ErrInvalidTokenFormat
    }

    // Validate against appropriate agents table based on scope
    return lookupAgentByScope(token, scope)
}
```

### Server-Side Context Detection (NON-NEGOTIABLE)

**Server MUST auto-detect context from token scope. `--user` / `X-Target-Context` only needed when ambiguous.**

**Token scope determines available contexts:**

| Token Type | Possible Scopes | Default Context |
|------------|-----------------|-----------------|
| `adm_` | Server admin only | Admin (no user/org) |
| `usr_` (user only) | User's personal | User |
| `usr_` (user + 1 org) | User + that org | User |
| `usr_` (user + N orgs) | User + all orgs | User (require `--user` for org) |
| `org_` (org-specific) | Single org only | That org |
| `adm_agt_` | Admin agent | Admin infrastructure |
| `usr_agt_` | User agent | User's personal agent |
| `org_agt_` | Org agent | Organization agent |

**Server request handling:**

```go
// ContextMiddleware extracts and validates context from request
func ContextMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        token := getTokenFromRequest(r)
        if token == nil {
            // No token - anonymous access (if allowed)
            next.ServeHTTP(w, r)
            return
        }

        // Get token's available scopes
        scopes := token.GetScopes()

        // Get requested context from header (optional)
        requestedContext := r.Header.Get("X-Target-Context")
        requestedType := r.Header.Get("X-Target-Type")  // "user" or "org" hint

        // Resolve context
        ctx, err := resolveContext(token, scopes, requestedContext, requestedType)
        if err != nil {
            http.Error(w, err.Error(), http.StatusForbidden)
            return
        }

        // Add to request context
        r = r.WithContext(context.WithValue(r.Context(), "target_context", ctx))
        next.ServeHTTP(w, r)
    })
}

// resolveContext determines the effective context for a request
func resolveContext(token *Token, scopes []TokenScope, requested, typeHint string) (*Context, error) {
    // No context requested - auto-detect from scopes
    if requested == "" {
        return autoDetectContext(scopes)
    }

    // Context requested - validate access
    cleanName := strings.TrimLeft(requested, "@+")

    // Determine type from prefix or hint
    var targetType TargetType
    switch {
    case strings.HasPrefix(requested, "@"):
        targetType = TargetUser
    case strings.HasPrefix(requested, "+"):
        targetType = TargetOrg
    case typeHint == "user":
        targetType = TargetUser
    case typeHint == "org":
        targetType = TargetOrg
    default:
        // Auto-detect: check if name is user or org
        targetType = detectTargetType(cleanName)
    }

    // Validate token has access to this context
    if !hasScope(scopes, cleanName, targetType) {
        return nil, ErrForbidden
    }

    return &Context{Name: cleanName, Type: targetType}, nil
}

// autoDetectContext picks default context from scopes
func autoDetectContext(scopes []TokenScope) (*Context, error) {
    if len(scopes) == 0 {
        return nil, ErrNoScopes
    }

    // Single scope - use it (no ambiguity)
    if len(scopes) == 1 {
        return &Context{Name: scopes[0].Name, Type: scopes[0].Type}, nil
    }

    // Multiple scopes - prefer user scope as default
    for _, scope := range scopes {
        if scope.Type == TargetUser {
            return &Context{Name: scope.Name, Type: TargetUser}, nil
        }
    }

    // Multiple org scopes, no user - require explicit selection
    return nil, ErrAmbiguousContext
}
```

**Error responses:**

| Scenario | HTTP Status | Error |
|----------|-------------|-------|
| No scopes on token | 403 | `{"error": "token has no valid scopes"}` |
| Requested context not in scopes | 403 | `{"error": "no access to context: acme-corp"}` |
| Multiple orgs, no `--user` | 400 | `{"error": "ambiguous context, specify --user"}` |
| Invalid context name | 404 | `{"error": "user or org not found: xyz"}` |

**API response includes context:**

```json
{
  "data": [...],
  "meta": {
    "context": {
      "name": "acme-corp",
      "type": "org"
    }
  }
}
```

### Auth Routes (NON-NEGOTIABLE)

**ALL projects require auth routes. The same routes handle both server admins and regular users (if multi-user enabled).**

**Required Routes (all projects):**

| Route | Method | Purpose |
|-------|--------|---------|
| `/auth/login` | GET | Login form (handles both admin and user) |
| `/auth/login` | POST | Process login, redirect based on account type |
| `/auth/logout` | GET/POST | End session |
| `/auth/password/reset` | GET/POST | Password reset (if SMTP) |
| `/auth/invite/server/{code}` | GET | Admin invite acceptance |

**Additional routes if multi-user (PART 33):**

| Route | Method | Purpose |
|-------|--------|---------|
| `/auth/register` | GET/POST | User registration |
| `/auth/verify/{code}` | GET | Email verification |
| `/auth/invite/user/{code}` | GET | User invite acceptance |

### Scoped Login Redirect (NON-NEGOTIABLE)

**Single login form, scoped redirect based on account type.**

| Account Type | Stored In | After Login Redirect |
|--------------|-----------|---------------------|
| **Server Admin** | `admins` table | `/{admin_path}` (default: `/admin`) |
| **Regular User** | `users` table | `/users` or `?redirect=` param |

**Login Flow:**

```
User submits /auth/login form
         ↓
Check credentials against `admins` table
         ↓
    ┌─── Match found? ───┐
    │                    │
   YES                   NO
    │                    │
    ↓                    ↓
Set admin_session    Check `users` table (if multi-user)
    │                    │
    ↓               ┌─── Match found? ───┐
Redirect to         │                    │
/{admin_path}      YES                   NO
                    │                    │
                    ↓                    ↓
               Set user_session    Return error:
                    │              "Invalid credentials"
                    ↓
               Redirect to
               /users (or ?redirect=)
```

**Login Form Behavior:**

| Feature | Description |
|---------|-------------|
| **Single form** | Same form for admin and user login |
| **Username or email** | Accept either (detect format) |
| **No account type selector** | Server determines account type from credentials |
| **Redirect param** | `?redirect=/path` honored for users, ignored for admins |
| **Remember me** | Extends session (both admin and user) |

**Security Notes:**
- Admin login NEVER redirects to user routes
- User login NEVER redirects to admin routes
- Failed login does NOT reveal if username exists
- Rate limiting applies to all login attempts

## Well-Known Files (NON-NEGOTIABLE)

**Standard files served at well-known paths. Generated automatically if no file exists.**

### Required Files

| File | Path | Purpose |
|------|------|---------|
| `robots.txt` | `/robots.txt` | Search engine crawling rules |
| `security.txt` | `/.well-known/security.txt` | Security vulnerability reporting (RFC 9116) |

### Additional Well-Known Paths

| Path | Purpose |
|------|---------|
| `/.well-known/acme-challenge/` | Let's Encrypt HTTP-01 challenge |
| `/.well-known/change-password` | Password change URL (redirects to `/users/security/password` if logged in, `/auth/password/forgot` if not) |

### Well-Known Directory Support

Files can be served from:
1. Files in `{data_dir}/web/.well-known/` (checked first)
2. Embedded files in binary
3. Dynamically generated (e.g., ACME challenges, config-based security.txt)

### robots.txt

```
# Served at /robots.txt - generated if no file exists

User-agent: *
Allow: /
Allow: /api
Disallow: /admin
Sitemap: {app_url}/sitemap.xml
```

**Configuration:**
```yaml
web:
  robots:
    allow:
      - /
      - /api
    deny:
      - /admin
```

### security.txt (RFC 9116)

**ALL projects MUST serve a valid security.txt file.**

```
# Served at /.well-known/security.txt

Contact: mailto:{security_contact}
Expires: {expiry_date}
```

**Configuration:**
```yaml
web:
  security:
    contact: "security@{fqdn}"    # Security contact email
    expires: "{1year}"            # Auto-calculated 1 year from generation
```

**Fields:**
| Field | Required | Description |
|-------|----------|-------------|
| `Contact` | YES | Email for reporting vulnerabilities (mailto: prefix added automatically) |
| `Expires` | YES | Expiration date (auto-renewed yearly by default) |

### Admin Panel (/admin/web)

**robots.txt Settings:**

| Element | Type | Description |
|---------|------|-------------|
| Allow paths | Tag input / List | Paths to allow crawling (e.g., `/`, `/api`) |
| Deny paths | Tag input / List | Paths to deny crawling (e.g., `/admin`) |
| Preview | Read-only textarea | Shows generated robots.txt content |

**security.txt Settings:**

| Element | Type | Description |
|---------|------|-------------|
| Security contact | Text input | Email for vulnerability reports |
| Expires | Date picker | Expiration date (default: 1 year from now, auto-renews) |
| Preview | Read-only textarea | Shows generated security.txt content |

## Logging

### Log Files

| Log | Purpose | Default Format | Available Formats |
|-----|---------|----------------|-------------------|
| `access.log` | HTTP requests | `apache` | `apache`, `nginx`, `json` |
| `server.log` | Application events | `text` | `text`, `json` |
| `error.log` | Error messages | `text` | `text`, `json` |
| `audit.log` | Security events | `json` | `json` only (must be machine-parseable) |
| `security.log` | Security/auth events | `fail2ban` | `fail2ban`, `syslog`, `cef`, `json`, `text` |
| `debug.log` | Debug (dev mode) | `text` | `text`, `json` |

### Log Format Details

**Access Log Formats:**
| Format | Description | Example |
|--------|-------------|---------|
| `apache` | Apache Combined Log Format (default) | `127.0.0.1 - - [10/Oct/2024:13:55:36 -0700] "GET /api/v1/healthz HTTP/1.1" 200 2326 "-" "curl/7.64.1"` |
| `nginx` | Nginx Common Log Format | `127.0.0.1 - - [10/Oct/2024:13:55:36 -0700] "GET /api/v1/healthz HTTP/1.1" 200 2326` |
| `json` | Structured JSON | `{"ip":"127.0.0.1","time":"2024-10-10T13:55:36Z","method":"GET","path":"/api/v1/healthz","status":200,"size":2326,"ua":"curl/7.64.1"}` |

**Security Log Formats:**
| Format | Description | Use Case |
|--------|-------------|----------|
| `fail2ban` | Fail2ban compatible (default) | Intrusion prevention integration |
| `syslog` | RFC 5424 syslog format | SIEM integration, centralized logging |
| `cef` | Common Event Format | SIEM/security tools (ArcSight, Splunk) |
| `json` | Structured JSON | Custom parsing, ELK stack |
| `text` | Plain text | Human readable |

**Text Log Format:**
```
2024-10-10 13:55:36 [INFO] Server started on :8080
2024-10-10 13:55:40 [ERROR] Database connection failed: timeout
```

**JSON Log Format:**
```json
{"time":"2024-10-10T13:55:36Z","level":"INFO","msg":"Server started on :8080"}
{"time":"2024-10-10T13:55:40Z","level":"ERROR","msg":"Database connection failed","error":"timeout"}
```

**Fail2ban Format:**
```
2024-10-10 13:55:36 [security] Failed login attempt from 192.168.1.100 for user admin
2024-10-10 13:55:40 [security] Rate limit exceeded from 192.168.1.100
```

### Custom Format Variables

When using `format: custom`, these variables are available:

| Variable | Description |
|----------|-------------|
| `{time}` | Time only |
| `{date}` | Date only |
| `{datetime}` | Date and time |
| `{remote_ip}` | Client IP address |
| `{method}` | HTTP method |
| `{path}` | Request path |
| `{query}` | Query string |
| `{status}` | HTTP status code |
| `{bytes}` | Response size |
| `{latency}` | Request latency (human readable) |
| `{latency_ms}` | Request latency (milliseconds) |
| `{user_agent}` | User agent string |
| `{referer}` | Referer header |
| `{request_id}` | Request ID |
| `{fqdn}` | Request host |
| `{protocol}` | HTTP protocol version |
| `{tls_version}` | TLS version (if HTTPS) |
| `{country}` | GeoIP country code |
| `{asn}` | GeoIP ASN |

### Rotation Options

| Option | Description |
|--------|-------------|
| `never` | Never rotate |
| `daily` | Rotate daily |
| `weekly` | Rotate weekly |
| `monthly` | Rotate monthly |
| `yearly` | Rotate yearly |
| `NMB` | Rotate at N megabytes (e.g., `50MB`) |
| `NGB` | Rotate at N gigabytes (e.g., `1GB`) |
| Combined | Time + size, whichever first (e.g., `weekly,50MB`) |

### Retention Options

| Option | Description |
|--------|-------------|
| `none` | Do not keep old logs (delete after rotation) |
| `N` | Keep N old log files |
| `Nd` | Keep logs for N days |
| `Nw` | Keep logs for N weeks |
| `Nm` | Keep logs for N months |
| `forever` | Keep forever (no automatic deletion) |

### Configuration

```yaml
server:
  logs:
    # Global log level: debug, info, warn, error
    level: warn

    # All log types share these options:
    #   filename: name of log file
    #   format: output format (varies by log type)
    #   custom: custom format string (when format=custom)
    #   rotate: rotation policy
    #   keep: retention policy

    access:
      filename: access.log
      # Format: apache, nginx, json, custom
      format: apache
      custom: ""
      rotate: monthly
      keep: none

    server:
      filename: server.log
      # Format: text, json
      format: text
      custom: ""
      rotate: weekly,50MB
      keep: none

    error:
      filename: error.log
      # Format: text, json
      format: text
      custom: ""
      rotate: weekly,50MB
      keep: none

    audit:
      enabled: true
      filename: audit.log
      # Format: json only (text not supported for audit - must be machine-parseable)
      format: json
      rotate: daily
      keep: none
      # Compress rotated logs (only useful if keep > 0)
      compress: false

    security:
      filename: security.log
      # Format: fail2ban, syslog, cef, json, text
      format: fail2ban
      custom: ""
      rotate: weekly,50MB
      keep: none

    debug:
      # Debug log has an enabled flag since it's for troubleshooting only
      enabled: false
      filename: debug.log
      # Format: text, json
      format: text
      custom: ""
      rotate: weekly,50MB
      keep: none
```

### Log Output Rules (NON-NEGOTIABLE)

**All log FILES MUST use raw text only:**
- NO emojis
- NO ANSI color codes
- NO special characters or formatting
- Plain ASCII text only
- Machine-parseable format

**Console output (stdout/stderr) CAN be pretty:**
- Emojis allowed (e.g., `✅ Server started`, `❌ Error`, `⚠️ Warning`)
- ANSI colors allowed
- Pretty formatting allowed
- Used for start/stop/restart/status messages
- User-facing CLI output can be visually appealing

**Rule:** Log files = raw/plain text. Console = pretty is OK.

### Log Rotation

**Defaults:**
| Log Type | Rotation | Keep |
|----------|----------|------|
| access.log | monthly | none |
| audit.log | daily | none |
| All others | weekly,50MB | none |

**Rules:**
- `weekly,50MB` = rotate on weekly OR 50MB, whichever comes first
- `keep: none` = do not retain old logs (default)
- Built-in rotation support (no external logrotate needed)
- Old logs deleted immediately after rotation (default)
- Optional: compress before delete, retain with `keep: weekly:N` or `monthly:N`

### Audit Log (NON-NEGOTIABLE)

**The audit log records ALL security-relevant events and administrative actions. It is the authoritative record of who did what and when.**

## Audit Log Purpose

| Purpose | Description |
|---------|-------------|
| **Accountability** | Track all admin and user actions |
| **Security** | Detect unauthorized access attempts |
| **Compliance** | Meet regulatory requirements (GDPR, SOC2, etc.) |
| **Debugging** | Investigate issues and incidents |
| **Forensics** | Post-incident analysis |

## Audit Log Events

### Server Admin Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `admin.login` | Admin logged in | IP, user agent, MFA used, admin username |
| `admin.logout` | Admin logged out | Admin username, session duration |
| `admin.login_failed` | Failed login attempt | IP, user agent, reason, attempted username |
| `admin.created` | New admin account created | New admin username, created by (admin username) |
| `admin.deleted` | Admin account removed | Deleted admin username, deleted by (admin username) |
| `admin.password_changed` | Admin changed password | Admin username, IP (NEVER log password) |
| `admin.mfa_enabled` | Admin enabled 2FA | Admin username, method (TOTP, WebAuthn) |
| `admin.mfa_disabled` | Admin disabled 2FA | Admin username, method |
| `admin.token_regenerated` | Admin API token regenerated | Admin username, IP |
| `admin.session_expired` | Admin session timed out | Admin username, session ID |
| `admin.session_revoked` | Admin session manually ended | Admin username, revoked by |

### User Events (Multi-User Mode)

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `user.registered` | New user registered | User ID, IP, registration method (form, OIDC, invite) |
| `user.login` | User logged in | User ID, IP, user agent, auth method |
| `user.logout` | User logged out | User ID, session duration |
| `user.login_failed` | Failed login attempt | IP, user agent, reason (NOT username/email) |
| `user.created` | Admin created user | User ID, created by (admin username) |
| `user.deleted` | User account deleted | User ID, deleted by (admin/self), reason |
| `user.suspended` | User account suspended | User ID, suspended by, reason |
| `user.unsuspended` | User account reactivated | User ID, unsuspended by |
| `user.role_changed` | User role modified | User ID, old role, new role, changed by |
| `user.password_changed` | User changed password | User ID, IP, method (direct, reset link) |
| `user.password_reset_requested` | Password reset requested | IP (NOT email/username) |
| `user.password_reset_completed` | Password reset completed | User ID, IP |
| `user.email_verified` | Email address verified | User ID, email (masked) |
| `user.mfa_enabled` | User enabled 2FA | User ID, method |
| `user.mfa_disabled` | User disabled 2FA | User ID, method, disabled by (self/admin) |
| `user.recovery_key_used` | Recovery key consumed | User ID, keys remaining |

### Organization Events (Multi-User Mode)

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `org.created` | Organization created | Org ID, org slug, created by (user ID) |
| `org.deleted` | Organization deleted | Org ID, org slug, deleted by, member count at deletion |
| `org.settings_updated` | Org settings changed | Org ID, changed keys, changed by |
| `org.member_invited` | Member invitation sent | Org ID, invited email (masked), role, invited by |
| `org.member_joined` | Member joined org | Org ID, user ID, role, join method (invite, direct) |
| `org.member_removed` | Member removed from org | Org ID, user ID, removed by, reason |
| `org.member_left` | Member left org voluntarily | Org ID, user ID |
| `org.role_changed` | Member role changed | Org ID, user ID, old role, new role, changed by |
| `org.role_created` | Custom role created | Org ID, role name, permissions, created by |
| `org.role_updated` | Custom role modified | Org ID, role name, changed permissions, updated by |
| `org.role_deleted` | Custom role deleted | Org ID, role name, deleted by |
| `org.token_created` | Org API token created | Org ID, token ID (partial), permissions, created by |
| `org.token_revoked` | Org API token revoked | Org ID, token ID (partial), revoked by |
| `org.ownership_transferred` | Org ownership transferred | Org ID, old owner, new owner |
| `org.billing_updated` | Billing settings changed | Org ID, changed by (NOT payment details) |

### Organization Audit Compliance

**Org audit logs are stored separately per organization for compliance isolation.**

| Requirement | Implementation |
|-------------|----------------|
| **Isolation** | Each org's audit log stored in separate table/partition |
| **Retention** | Configurable per-org (default: 2 years, min: 90 days) |
| **Immutability** | Append-only, no modification or deletion by org admins |
| **Export** | JSON, CSV, or PDF export for auditors (`/orgs/{slug}/security/audit/export`) |
| **Filtering** | Filter by date range, event type, actor, target |
| **Search** | Full-text search on audit entries |
| **Access control** | Only org admins with `audit:read` permission |
| **Server admin access** | Server admins can view for moderation (logged as `admin.org_audit_viewed`) |

**Compliance Export Format:**
```json
{
  "export_info": {
    "org_id": "org_abc123",
    "org_slug": "acme-corp",
    "exported_at": "2025-01-15T10:00:00Z",
    "exported_by": "user_xyz",
    "date_range": { "from": "2024-01-01", "to": "2024-12-31" },
    "total_events": 15420,
    "hash": "sha256:abc123..."
  },
  "events": [...]
}
```

**Org Audit API Endpoints:**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/orgs/{slug}/security/audit` | GET | List audit events (paginated) |
| `/api/v1/orgs/{slug}/security/audit/export` | POST | Request audit export |
| `/api/v1/orgs/{slug}/security/audit/export/{id}` | GET | Download audit export |
| `/api/v1/orgs/{slug}/security/audit/retention` | GET | Get retention settings |
| `/api/v1/orgs/{slug}/security/audit/retention` | PATCH | Update retention (org owner only) |

### OIDC/LDAP Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `oidc.login` | User logged in via OIDC | User ID, provider name, IP |
| `oidc.login_failed` | OIDC login failed | Provider name, IP, reason |
| `oidc.user_created` | Auto-provisioned user via OIDC | User ID, provider name |
| `oidc.admin_granted` | Admin access via group mapping | User ID, provider name, group name |
| `oidc.admin_revoked` | Admin access removed (group change) | User ID, provider name |
| `ldap.login` | User logged in via LDAP | User ID, IP |
| `ldap.login_failed` | LDAP login failed | IP, reason |
| `ldap.admin_granted` | Admin access via group mapping | User ID, group DN |
| `ldap.admin_revoked` | Admin access removed (group change) | User ID |

### Configuration Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `config.updated` | Configuration changed | Changed keys (NOT sensitive values), changed by |
| `config.smtp_updated` | SMTP settings changed | Changed by (NOT credentials) |
| `config.ssl_updated` | SSL certificate changed | Subject, expiry, changed by |
| `config.ssl_expired` | SSL certificate expired | Domain |
| `config.tor_address_regenerated` | Onion address regenerated | Changed by |
| `config.branding_updated` | Branding settings changed | Changed by |
| `config.oidc_provider_added` | OIDC provider configured | Provider name, added by |
| `config.oidc_provider_removed` | OIDC provider removed | Provider name, removed by |
| `config.ldap_updated` | LDAP settings changed | Changed by |
| `config.admin_groups_updated` | Admin group mapping changed | Old groups, new groups, changed by |

### Security Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `security.rate_limit_exceeded` | Rate limit hit | IP, endpoint, limit |
| `security.ip_blocked` | IP address blocked | IP, reason, duration |
| `security.ip_unblocked` | IP address unblocked | IP, unblocked by |
| `security.country_blocked` | Request blocked by GeoIP | IP, country code |
| `security.csrf_failure` | CSRF token validation failed | IP, endpoint |
| `security.invalid_token` | Invalid API token used | Token type, IP |
| `security.brute_force_detected` | Brute force attempt detected | IP, target (masked), attempt count |
| `security.suspicious_activity` | Unusual activity detected | IP, activity type, details |

### Token Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `token.created` | API token created | Token ID (partial), permissions, expiry, created by |
| `token.revoked` | API token revoked | Token ID (partial), revoked by |
| `token.expired` | API token expired | Token ID (partial) |
| `token.used` | API token used (optional, high volume) | Token ID (partial), endpoint, IP |

### Backup & System Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `backup.created` | Backup created | Filename, size, created by |
| `backup.restored` | Backup restored | Filename, restored by |
| `backup.deleted` | Backup deleted | Filename, deleted by |
| `backup.failed` | Backup failed | Error message |
| `server.started` | Application started | Version, mode, node ID |
| `server.stopped` | Application stopped | Reason, uptime |
| `server.maintenance_entered` | Maintenance mode enabled | Reason, enabled by |
| `server.maintenance_exited` | Maintenance mode disabled | Duration, disabled by |
| `server.updated` | Application updated | Old version, new version |
| `scheduler.task_failed` | Scheduled task failed | Task name, error |
| `scheduler.task_manual_run` | Task manually triggered | Task name, triggered by |

### Cluster Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `cluster.node_joined` | Node joined cluster | Node ID, IP |
| `cluster.node_removed` | Node removed from cluster | Node ID, removed by |
| `cluster.node_failed` | Node became unreachable | Node ID, last seen |
| `cluster.token_generated` | Join token generated | Token ID (partial), generated by |
| `cluster.mode_changed` | Cluster mode changed | Old mode, new mode, changed by |

## Audit Log Format

**All audit logs are JSON format, one entry per line (JSON Lines).**

```json
{
  "id": "audit_01HQXYZ123ABC",
  "time": "2025-01-15T10:30:00.123Z",
  "event": "admin.login",
  "category": "authentication",
  "severity": "info",
  "actor": {
    "type": "admin",
    "id": "administrator",
    "ip": "192.168.1.100",
    "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)..."
  },
  "target": {
    "type": "session",
    "id": "sess_abc123"
  },
  "details": {
    "mfa_used": true,
    "mfa_method": "totp"
  },
  "result": "success",
  "node_id": "node-1"
}
```

**Required Fields:**

| Field | Type | Description |
|-------|------|-------------|
| `id` | String | Unique audit entry ID (ULID format) |
| `time` | String | ISO 8601 timestamp with milliseconds, UTC |
| `event` | String | Event type (e.g., `admin.login`) |
| `category` | String | Event category (e.g., `authentication`) |
| `severity` | String | `info`, `warn`, `error`, `critical` |
| `actor` | Object | Who performed the action |
| `result` | String | `success` or `failure` |

**Optional Fields:**

| Field | Type | Description |
|-------|------|-------------|
| `target` | Object | What was acted upon |
| `details` | Object | Event-specific details |
| `node_id` | String | Node ID (cluster mode) |
| `reason` | String | Reason for action (if provided) |

## Severity Levels

| Severity | Use For | Examples |
|----------|---------|----------|
| `info` | Successful normal operations | Login, config save, backup complete |
| `warn` | Failed attempts, recoverable issues | Failed login, rate limit hit |
| `error` | Failures requiring attention | Backup failed, scheduler error |
| `critical` | Security incidents, server failures | Brute force detected, maintenance mode |

## Audit Log Configuration

**Extended audit options (in addition to basic log options):**

```yaml
server:
  logs:
    audit:
      # Basic options (same as other logs)
      enabled: true
      filename: audit.log
      format: json           # json only - must be machine-parseable
      rotate: daily          # daily, weekly, monthly, NMB, or combined
      keep: none             # none, N, Nd, Nw, Nm
      compress: false

      # What to log (event categories)
      events:
        authentication: true  # Login/logout events
        configuration: true   # Config changes
        security: true        # Security events
        tokens: true          # Token create/revoke
        users: true           # User management
        backup: true          # Backup/restore
        server: true          # Server events (start, stop, maintenance)
        cluster: true         # Cluster events
        token_usage: false    # Individual token uses (high volume - disabled by default)

      # Sensitive data handling
      mask_emails: true       # Show j***n@e***.com instead of full
      mask_usernames: false   # Show full usernames in logs
      include_user_agent: true
```

## Sane Defaults

| Setting | Default | Description |
|---------|---------|-------------|
| `enabled` | `true` | Audit logging enabled |
| `format` | `json` | JSON format (required) |
| `rotate` | `daily` | Rotate daily |
| `keep` | `none` | Delete on rotation (no old logs kept) |
| `compress` | `false` | No compression (deleted immediately) |
| `mask_emails` | `true` | Mask email addresses |
| All event categories | `true` | Log all events |
| `token_usage` | `false` | Don't log every token use |

**Why `keep: none` by default?**
- Reduces disk usage
- Minimizes data retention liability
- Users who need log history can configure retention
- Current log always available until rotation

## Audit Log Rules (NON-NEGOTIABLE)

**NEVER Log:**
- ❌ Passwords (plain, hashed, or encrypted)
- ❌ API tokens or secrets (full value)
- ❌ Session tokens (full value)
- ❌ Recovery keys
- ❌ TOTP secrets
- ❌ Private keys
- ❌ Credit card numbers
- ❌ Full email addresses (mask them)

**ALWAYS Log:**
- ✓ Timestamp in UTC with milliseconds
- ✓ IP address for all events
- ✓ Actor identity (who did it)
- ✓ Event result (success/failure)
- ✓ Unique event ID

**Token/ID Masking:**
- Show only first 8 characters: `token_abc12345...`
- Or use separate ID field that doesn't expose token value

## Admin Panel (`/admin/server/logs/audit`)

| Element | Type | Description |
|---------|------|-------------|
| Log viewer | Table | Paginated audit log entries |
| Filters | Dropdowns | Filter by category, severity, date range |
| Search | Text input | Search by actor, IP, event type |
| Export | Button | Download filtered results as JSON/CSV |
| Retention | Display | Show current retention policy |
| Stats | Cards | Event counts by category/severity |

**Log Viewer Columns:**
| Column | Description |
|--------|-------------|
| Time | Timestamp (local timezone) |
| Event | Event type with icon |
| Actor | Who performed action |
| Target | What was affected |
| IP | Source IP address |
| Result | Success/failure badge |
| Details | Expandable row |

**Filters:**
- Category: All, Authentication, Configuration, Security, etc.
- Severity: All, Info, Warn, Error, Critical
- Result: All, Success, Failure
- Date range: Today, Last 7 days, Last 30 days, Custom
- Actor: Text search
- IP: Text search

**Export Options:**
- Format: JSON (default), CSV
- Range: Current view, All matching filters, Full log
- Note: Export respects same masking rules as display

## Audit Log Integrity

**The audit log is append-only and tamper-evident.**

| Protection | Description |
|------------|-------------|
| Append-only | Application can only append, never modify or delete entries |
| No truncate | Application cannot truncate the log file |
| Rotation only | Only log rotation can remove old entries |
| Checksum | Optional: Include running checksum for tamper detection |

**File Permissions:**
```
audit.log: 0640 (rw-r-----)
Owner: application user
Group: audit group (if configured)
```

## Audit Log Retention

| Retention | Description |
|-----------|-------------|
| `keep: none` | Delete on rotation (default) - no old logs kept |
| `keep: 30d` | Keep 30 days |
| `keep: 90d` | Keep 90 days |
| `keep: 12m` | Keep 1 year (365d also works) |
| `keep: forever` | Keep forever (no automatic deletion) |

**Rotation Schedule:**
- Daily rotation at midnight UTC
- If `keep: none`: Old log deleted immediately after rotation
- If `keep: Nd`: Rotated files named `audit.log.2025-01-15.gz`, deleted after N days
- Current day's log always available until next rotation

## Compliance Standards

**All compliance standards are DISABLED by default. Enable individually as needed.**

### Available Standards

| Standard | Description | Region/Industry |
|----------|-------------|-----------------|
| `gdpr` | General Data Protection Regulation | EU/EEA |
| `ccpa` | California Consumer Privacy Act | California, USA |
| `hipaa` | Health Insurance Portability and Accountability Act | USA Healthcare |
| `soc2` | Service Organization Control 2 | USA (Trust Services) |
| `pci_dss` | Payment Card Industry Data Security Standard | Global (Payments) |
| `iso27001` | Information Security Management | Global |
| `fedramp` | Federal Risk and Authorization Management | USA Government |
| `lgpd` | Lei Geral de Proteção de Dados | Brazil |
| `pipeda` | Personal Information Protection and Electronic Documents Act | Canada |
| `appi` | Act on Protection of Personal Information | Japan |
| `pdpa` | Personal Data Protection Act | Singapore |

### Configuration

```yaml
server:
  compliance:
    # All disabled by default - enable individually
    gdpr: false
    ccpa: false
    hipaa: false
    soc2: false
    pci_dss: false
    iso27001: false
    fedramp: false
    lgpd: false
    pipeda: false
    appi: false
    pdpa: false
```

### Compliance Requirements Matrix

| Requirement | GDPR | CCPA | HIPAA | SOC2 | PCI-DSS | ISO27001 |
|-------------|------|------|-------|------|---------|----------|
| Data encryption at rest | ✓ | - | ✓ | ✓ | ✓ | ✓ |
| Data encryption in transit | ✓ | - | ✓ | ✓ | ✓ | ✓ |
| Audit log retention (min) | 1yr | 1yr | 6yr | 1yr | 1yr | 3yr |
| Right to erasure | ✓ | ✓ | - | - | - | - |
| Data portability | ✓ | ✓ | - | - | - | - |
| Consent tracking | ✓ | ✓ | ✓ | - | - | - |
| Access logging | ✓ | - | ✓ | ✓ | ✓ | ✓ |
| Breach notification | 72hr | - | 60days | ✓ | ✓ | ✓ |
| Data residency | ✓ | - | - | - | - | - |
| MFA requirement | - | - | ✓ | ✓ | ✓ | - |
| Password policy | ✓ | - | ✓ | ✓ | ✓ | ✓ |
| Session timeout | - | - | ✓ | ✓ | ✓ | - |
| Vulnerability scanning | - | - | - | ✓ | ✓ | ✓ |

### Overlap Resolution (NON-NEGOTIABLE)

**When multiple compliance standards are enabled and conflict, the STRICTEST requirement wins.**

| Conflict Type | Resolution | Example |
|---------------|------------|---------|
| **Retention period** | Use longest | HIPAA (6yr) beats GDPR (1yr) |
| **Encryption strength** | Use strongest | AES-256 over AES-128 |
| **Breach notification** | Use shortest | GDPR (72hr) beats HIPAA (60days) |
| **Password requirements** | Use strictest | Longest min length, most complexity |
| **Session timeout** | Use shortest | 15min beats 30min |
| **MFA requirement** | Required if ANY standard requires it | |
| **Right to erasure vs retention** | See below | |

**Special Case: Right to Erasure vs Retention Requirements**

When GDPR/CCPA (right to erasure) conflicts with HIPAA/SOC2 (retention requirements):
1. User data is **anonymized** (not deleted) to preserve audit trail
2. All PII is removed, replaced with `[REDACTED]` or anonymized IDs
3. Audit log entries reference anonymized user ID
4. Original user ID mapping is deleted
5. This satisfies both erasure (PII gone) and retention (audit preserved)

### Compliance-Specific Behaviors

#### GDPR (gdpr: true)

| Feature | Behavior |
|---------|----------|
| Cookie consent | Required popup before any tracking |
| Data export | `/users/data/export` endpoint enabled |
| Data deletion | `/users/data/delete` endpoint enabled |
| Consent tracking | All consents logged with timestamp |
| Data residency | Configurable allowed regions |
| Privacy policy | Required, must specify data processing |
| DPO contact | Displayed in privacy policy |
| Breach notification | 72-hour automated alert system |

#### HIPAA (hipaa: true)

| Feature | Behavior |
|---------|----------|
| PHI encryption | All health data encrypted with per-record keys |
| Audit trail | 6-year minimum retention, tamper-evident |
| Access controls | Role-based with minimum necessary access |
| Session timeout | 15 minutes maximum idle |
| MFA | Required for all users |
| BAA tracking | Business Associate Agreements logged |
| Breach notification | 60-day notification system |

#### SOC2 (soc2: true)

| Feature | Behavior |
|---------|----------|
| Change management | All config changes require approval workflow |
| Access reviews | Quarterly access review reminders |
| Vulnerability management | Integration with security scanners |
| Incident response | Defined escalation paths |
| Vendor management | Third-party risk tracking |
| Availability monitoring | Uptime SLA tracking |

#### PCI-DSS (pci_dss: true)

| Feature | Behavior |
|---------|----------|
| Cardholder data | Never stored (use tokenization) |
| Network segmentation | Cardholder environment isolated |
| Password policy | 12+ chars, complexity, 90-day rotation |
| Session timeout | 15 minutes maximum |
| Audit logging | All access to cardholder data logged |
| Vulnerability scanning | Quarterly scans required |
| Penetration testing | Annual requirement tracking |

#### CCPA (ccpa: true)

| Feature | Behavior |
|---------|----------|
| Data disclosure | `/users/data/export` - what data is collected and sold |
| Opt-out of sale | `/users/privacy/do-not-sell` toggle |
| Right to delete | `/users/data/delete` endpoint enabled |
| Non-discrimination | Cannot deny service for exercising rights |
| Privacy notice | "Do Not Sell My Personal Information" link required |
| Verification | Identity verification before data requests |
| Response time | 45 days to fulfill requests (90 with extension) |

#### ISO27001 (iso27001: true)

| Feature | Behavior |
|---------|----------|
| Risk assessment | Documented risk register required |
| Asset inventory | All data assets tracked |
| Access control | Role-based, principle of least privilege |
| Cryptography | Encryption policy enforced |
| Physical security | N/A (cloud-native, document controls) |
| Operations security | Change management, capacity planning |
| Incident management | Defined response procedures |
| Business continuity | Backup and recovery procedures |
| Audit logging | 3-year minimum retention |

#### FedRAMP (fedramp: true)

| Feature | Behavior |
|---------|----------|
| Authorization level | Low/Moderate/High impact configurable |
| Continuous monitoring | Automated security scanning |
| FIPS 140-2 | Cryptographic module compliance |
| Data residency | US-only data centers required |
| Personnel security | Background check tracking |
| Incident response | US-CERT notification procedures |
| Vulnerability scanning | Monthly automated scans |
| Penetration testing | Annual third-party testing |
| POA&M tracking | Plan of Action & Milestones dashboard |

#### LGPD (lgpd: true)

| Feature | Behavior |
|---------|----------|
| Legal basis | Consent or legitimate interest tracking |
| Data subject rights | Access, correction, deletion, portability |
| DPO requirement | Data Protection Officer contact displayed |
| International transfer | Adequacy or safeguards required |
| Breach notification | ANPD notification within reasonable time |
| Privacy notice | Clear, accessible privacy policy in Portuguese |
| Consent | Granular, specific, freely given |
| Children's data | Parental consent for under 18 |

#### PIPEDA (pipeda: true)

| Feature | Behavior |
|---------|----------|
| Consent | Meaningful consent for collection/use/disclosure |
| Purpose limitation | Data used only for stated purposes |
| Access rights | Users can access their personal information |
| Accuracy | Users can challenge and correct data |
| Retention limits | Data kept only as long as necessary |
| Safeguards | Appropriate security for sensitivity level |
| Openness | Privacy policies publicly available |
| Accountability | Designated privacy officer |
| Breach notification | OPC notification for significant breaches |

#### APPI (appi: true)

| Feature | Behavior |
|---------|----------|
| Purpose specification | Clear purpose before collection |
| Use limitation | No use beyond specified purpose |
| Proper acquisition | No deceptive collection practices |
| Accuracy | Keep data accurate and up-to-date |
| Security control | Appropriate safeguards required |
| Third-party oversight | Supervise data handling by processors |
| Disclosure restrictions | User consent for third-party sharing |
| Cross-border transfer | Consent or equivalent protection required |
| Breach notification | PPC and affected individuals notified |

#### PDPA (pdpa: true)

| Feature | Behavior |
|---------|----------|
| Consent | Consent required before collection |
| Purpose limitation | Data used only for notified purposes |
| Notification | Inform users of purposes at collection |
| Access and correction | Users can access and correct data |
| Accuracy | Reasonable efforts to ensure accuracy |
| Protection | Reasonable security arrangements |
| Retention limitation | Delete when no longer needed |
| Transfer limitation | Adequate protection for overseas transfers |
| DPO requirement | Data Protection Officer for certain orgs |
| Breach notification | PDPC notification within 3 days |

### Compliance Routes

| Route | Method | Description |
|-------|--------|-------------|
| `/users/data/export` | GET | Request personal data export (GDPR/CCPA) |
| `/users/data/export/{id}` | GET | Download data export |
| `/users/data/delete` | POST | Request account deletion (GDPR/CCPA) |
| `/users/consents` | GET | View consent history |
| `/users/consents` | PATCH | Update consent preferences |
| `/server/privacy` | GET | Privacy policy |
| `/server/dpo` | GET | Data Protection Officer contact (GDPR) |
| `/admin/server/compliance` | GET | Compliance dashboard |
| `/admin/server/compliance/report` | POST | Generate compliance report |
| `/admin/server/compliance/breach` | POST | Report data breach |

### Compliance API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/users/data/export` | POST | Request data export |
| `/api/v1/users/data/export/{export_id}` | GET | Download export |
| `/api/v1/users/data/delete` | POST | Request deletion |
| `/api/v1/users/consents` | GET | Get consents |
| `/api/v1/users/consents` | PATCH | Update consents |
| `/api/v1/admin/server/compliance` | GET | Compliance status |
| `/api/v1/admin/server/compliance/standards` | GET | Enabled standards |
| `/api/v1/admin/server/compliance/report` | POST | Generate report |
| `/api/v1/admin/server/compliance/breach` | POST | Report breach |
| `/api/v1/admin/server/compliance/audit` | GET | Compliance audit log |

### Admin UI: Compliance Dashboard

**Location:** `/admin/server/compliance`

| Section | Description |
|---------|-------------|
| Enabled Standards | Toggle switches for each standard |
| Compliance Score | Per-standard compliance percentage |
| Issues | Outstanding compliance issues |
| Data Requests | Pending export/deletion requests |
| Breach Log | Data breach history |
| Reports | Generate/download compliance reports |
| Upcoming | Scheduled audits, certificate renewals |

### Compliance Audit Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `compliance.standard_enabled` | Standard enabled | Standard name, enabled by |
| `compliance.standard_disabled` | Standard disabled | Standard name, disabled by |
| `compliance.data_export_requested` | User requested data export | User ID, request ID |
| `compliance.data_export_completed` | Data export ready | User ID, request ID, file size |
| `compliance.data_deletion_requested` | User requested deletion | User ID, request ID |
| `compliance.data_deletion_completed` | Deletion completed | User ID (anonymized after) |
| `compliance.consent_updated` | User updated consents | User ID, consent type, new value |
| `compliance.breach_reported` | Data breach reported | Breach ID, severity, reporter |
| `compliance.breach_notified` | Breach notification sent | Breach ID, notification type |
| `compliance.breach_investigation_started` | Investigation began | Breach ID, investigator |
| `compliance.breach_investigation_completed` | Investigation closed | Breach ID, outcome |
| `compliance.breach_escalated` | Breach escalated to authorities | Breach ID, authority |
| `compliance.report_generated` | Compliance report generated | Report type, generated by |

### Data Protection

**Encryption Strategy:**

| Data Type | Protection | Method |
|-----------|------------|--------|
| Passwords | Always hashed | Argon2id |
| API tokens | Always hashed | SHA-256 |
| 2FA secrets | Always encrypted | AES-256-GCM (server key) |
| Recovery keys | Always hashed | SHA-256 |
| Backups | Encrypted if password set | AES-256-GCM (user password) |
| Database at rest | OS responsibility | Use encrypted filesystem |
| Data in transit | Always TLS | TLS 1.2+ required |

**Database Encryption:**

The application does **not** implement database-level encryption. This is intentional:

| Reason | Explanation |
|--------|-------------|
| Complexity | Key management adds significant complexity |
| Performance | Encryption/decryption overhead on every query |
| OS-level better | LUKS, FileVault, BitLocker handle this transparently |
| SQLite limitation | SQLite doesn't support transparent encryption natively |

**Recommendation:** Use OS-level disk encryption (LUKS on Linux, FileVault on macOS, BitLocker on Windows) for encryption at rest. This protects all data including databases, logs, and config files.

**What IS Protected by the Application:**

| Protected | How |
|-----------|-----|
| Passwords | Argon2id hash (never stored in plain text) |
| API tokens | SHA-256 hash (never stored in plain text) |
| 2FA secrets | AES-256-GCM encrypted with server-generated key |
| Backup files | AES-256-GCM encrypted with admin password (if configured) |
| Session tokens | Cryptographically random, short-lived |

**Server Encryption Key:**

For 2FA secrets and other server-encrypted data:

```yaml
# Auto-generated on first run, stored in server.yml
server:
  security:
    encryption_key: "base64-encoded-32-byte-random-key"
```

- Generated automatically on first run (32 bytes from crypto/rand)
- Stored in config file (protected by file permissions)
- Used to encrypt 2FA secrets and similar sensitive data
- If lost, users must re-enroll 2FA

### Breach Detection

**Automated Detection Mechanisms:**

| Detection Type | Trigger | Severity | Auto-Action |
|----------------|---------|----------|-------------|
| **Brute Force** | 10+ failed logins in 5min from same IP | Medium | Block IP, alert admin |
| **Credential Stuffing** | 50+ failed logins in 10min across accounts | High | Rate limit, alert admin |
| **Unusual Access Pattern** | Access from new country + sensitive action | Medium | Require 2FA, alert user |
| **Mass Data Export** | Export requests > threshold in timeframe | High | Queue for review, alert admin |
| **Privilege Escalation** | Unauthorized admin action attempt | Critical | Block session, alert admin |
| **API Abuse** | API rate exceeded 10x normal | Medium | Throttle, alert admin |
| **Session Anomaly** | Same session from multiple IPs/locations | High | Invalidate session, alert user |
| **Database Anomaly** | Unusual query patterns (injection attempts) | Critical | Block request, alert admin |
| **File Access Anomaly** | Access to backup/export files without request | Critical | Block, alert admin |
| **Config Tampering** | Unauthorized config file modification | Critical | Rollback, alert admin |

**Detection Configuration:**

Breach detection is **always enabled** with sane defaults. Thresholds are configurable but detection cannot be disabled.

```yaml
server:
  security:
    breach_detection:
      # Brute force: too many failed logins from same IP
      brute_force:
        attempts: 10
        window: 5m
        block_duration: 1h

      # Credential stuffing: failed logins across many accounts
      credential_stuffing:
        attempts: 50
        window: 10m

      # Unusual access patterns
      unusual_access:
        new_country_alert: true
        new_device_alert: true

      # Mass data export detection
      mass_export:
        threshold: 10
        window: 1h

      # API abuse (multiplier of normal rate)
      api_abuse:
        multiplier: 10

      # Auto-actions (all enabled by default)
      auto_block_ip: true
      auto_invalidate_sessions: true
      auto_alert_admin: true
      auto_alert_user: true
```

**Sane Defaults (NON-NEGOTIABLE):**

| Setting | Default | Rationale |
|---------|---------|-----------|
| Brute force threshold | 10 attempts / 5min | Catches attacks, allows typos |
| Credential stuffing | 50 attempts / 10min | Cross-account pattern detection |
| Block duration | 1 hour | Sufficient deterrent, not permanent |
| New country alert | Enabled | High-value security signal |
| New device alert | Enabled | Helps users spot compromises |
| Mass export threshold | 10 / hour | Prevents data scraping |
| API abuse multiplier | 10x | Catches abuse, allows bursts |
| Auto-block IP | Enabled | Immediate threat response |
| Auto-invalidate sessions | Enabled | Limits breach scope |
| Auto-alert admin | Enabled | Ensures visibility |
| Auto-alert user | Enabled | User can take action |

**Detection Events (Audit Log):**

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `security.breach_detected` | Automated breach detection triggered | Detection type, severity, details |
| `security.breach_auto_action` | Auto-action taken | Action type, target, reason |
| `security.threat_blocked` | Threat automatically blocked | Threat type, source IP, target |
| `security.anomaly_detected` | Anomalous pattern detected | Anomaly type, score, details |

### IP Block Management

**Block Types:**

| Type | Duration | Release | Description |
|------|----------|---------|-------------|
| **Temporary** | Configurable (default 1h) | Auto-release after expiry | Brute force, rate limiting |
| **Extended** | 24 hours | Auto-release after expiry | Credential stuffing, repeated offenses |
| **Permanent** | Indefinite | Manual only | Admin-added, severe threats |

**Auto-Release:**

Temporary blocks are automatically released when:
1. Block duration expires (checked every minute by scheduler)
2. Admin manually unblocks
3. IP is added to allowlist

**Escalation (Repeat Offenders):**

| Offense | Block Duration |
|---------|----------------|
| 1st | 1 hour (configurable) |
| 2nd within 24h | 4 hours |
| 3rd within 24h | 24 hours |
| 4th+ within 7 days | 7 days + admin alert |

### Account Lockout (User-Level)

**Separate from IP blocking.** When a specific user account has too many failed login attempts:

| Failed Attempts | Action | Duration |
|-----------------|--------|----------|
| 5 in 15 minutes | Soft lock | 15 minutes |
| 10 in 1 hour | Hard lock | 1 hour |
| 15 in 24 hours | Account lock | Until admin unlock OR password reset |

**Sane Defaults:**
```yaml
server:
  security:
    account_lockout:
      # Soft lock: brief lockout after few failures
      soft_lock_attempts: 5
      soft_lock_window: 15m
      soft_lock_duration: 15m
      # Hard lock: longer lockout after more failures
      hard_lock_attempts: 10
      hard_lock_window: 1h
      hard_lock_duration: 1h
      # Permanent lock: requires admin unlock or password reset
      permanent_lock_attempts: 15
      permanent_lock_window: 24h
```

**Lockout Behavior:**
- **Soft lock**: User sees "Too many attempts, try again in X minutes"
- **Hard lock**: Same message, longer wait
- **Permanent lock**: User must reset password via email OR admin unlocks

**Unlock Methods:**
| Method | Who Can Do | When |
|--------|------------|------|
| Wait | System | Soft/hard lock expiry |
| Password reset | User | Any lockout |
| Admin unlock | Server admin | Any lockout |
| Allowlisted IP | System | Never locked from trusted IPs |

**Why Both IP Block AND Account Lockout?**
- IP block stops distributed attacks from one source
- Account lockout stops attacks targeting one account from multiple IPs
- Together they cover credential stuffing (many accounts, one IP) AND targeted attacks (one account, many IPs)

**IP Block Data Model:**

```go
type IPBlock struct {
    IP          string    `json:"ip"`
    // Optional range block
    CIDR        string    `json:"cidr,omitempty"`
    // temporary, extended, permanent
    Type        BlockType `json:"type"`
    Reason      string    `json:"reason"`
    BlockedAt   time.Time `json:"blocked_at"`
    // nil = permanent
    ExpiresAt   *time.Time `json:"expires_at,omitempty"`
    OffenseCount int      `json:"offense_count"`
    // true = system, false = admin
    AutoBlocked bool      `json:"auto_blocked"`
    // admin ID if manual
    BlockedBy   string    `json:"blocked_by,omitempty"`
}
```

**IP Management API:**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/security/blocked-ips` | GET | List blocked IPs |
| `/api/v1/admin/server/security/blocked-ips` | POST | Manually block IP/CIDR |
| `/api/v1/admin/server/security/blocked-ips/{ip}` | GET | Get block details |
| `/api/v1/admin/server/security/blocked-ips/{ip}` | DELETE | Unblock IP |
| `/api/v1/admin/server/security/blocked-ips/expired` | DELETE | Purge expired blocks from log |
| `/api/v1/admin/server/security/allowlist` | GET | List allowed IPs |
| `/api/v1/admin/server/security/allowlist` | POST | Add IP/CIDR to allowlist |
| `/api/v1/admin/server/security/allowlist/{ip}` | DELETE | Remove from allowlist |

**Account Lockout API:**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/security/locked-accounts` | GET | List locked accounts |
| `/api/v1/admin/server/security/locked-accounts/{id}` | DELETE | Unlock account |

**Security Settings API:**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/security/settings` | GET | Get all security settings |
| `/api/v1/admin/server/security/settings` | PATCH | Update security settings |
| `/api/v1/admin/server/security/auth` | GET | Get auth settings (password policy, etc.) |
| `/api/v1/admin/server/security/auth` | PATCH | Update auth settings |
| `/api/v1/admin/server/security/ratelimit` | GET | Get rate limit settings |
| `/api/v1/admin/server/security/ratelimit` | PATCH | Update rate limit settings |

**Password Policy (Sane Defaults):**

```yaml
server:
  security:
    password:
      # Minimum 8 chars (auto-upgrades to 12 if HIPAA/SOC2 enabled)
      min_length: 8
      # Complexity requirements (auto-enabled if compliance standards active)
      require_uppercase: false
      require_lowercase: false
      require_number: false
      require_special: false
      # Password expiry (0 = never, auto-sets to 90 if compliance)
      max_age_days: 0
      # Password history (0 = none, auto-sets to 12 if compliance)
      history_count: 0
```

**Password Policy Auto-Upgrade (Compliance):**

When compliance standards are enabled, password policy automatically upgrades:

| Setting | Default | HIPAA/SOC2/PCI-DSS |
|---------|---------|---------------------|
| min_length | 8 | 12 |
| require_uppercase | false | true |
| require_number | false | true |
| require_special | false | true |
| max_age_days | 0 | 90 |
| history_count | 0 | 12 |

**Note:** These are minimums. Admin can set stricter policies but not weaker when compliance is enabled.

**API Token Management:**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/security/tokens` | GET | List all API tokens (admin view) |
| `/api/v1/admin/server/security/tokens/{id}` | DELETE | Revoke token |
| `/api/v1/admin/server/security/tokens/{id}/rotate` | POST | Force token rotation |

**Token Expiry (Sane Defaults):**

```yaml
server:
  security:
    tokens:
      # 0 = tokens never expire
      default_expiry: 0
      # Maximum allowed expiry (365 days)
      max_expiry: 365d
      # Remind admin to rotate after 90 days
      rotation_reminder: 90d
```

**Allowlist:**

IPs on the allowlist are **never auto-blocked**. Use for:
- Office IPs
- CI/CD servers
- Monitoring services
- Load balancers / reverse proxies

```yaml
server:
  security:
    allowlist:
      - 10.0.0.0/8        # Internal network
      - 192.168.1.0/24    # Office
      # Add trusted IPs/CIDRs
```

**Admin UI: IP Blocks**

**Location:** `/admin/server/security/blocked-ips`

| Section | Description |
|---------|-------------|
| Active Blocks | Currently blocked IPs with expiry countdown |
| Block History | Past blocks (configurable retention) |
| Allowlist | Trusted IPs that bypass blocking |
| Add Block | Manually block IP/CIDR |
| Bulk Actions | Unblock selected, export list |

**Block Details View:**

| Field | Description |
|-------|-------------|
| IP/CIDR | Blocked address or range |
| Type | Temporary / Extended / Permanent |
| Reason | Why blocked (brute_force, credential_stuffing, manual, etc.) |
| Blocked At | Timestamp |
| Expires At | Countdown or "Never" |
| Offense Count | Number of times this IP triggered blocks |
| Related Events | Link to audit log entries |
| Actions | Unblock, Extend, Make Permanent |

**Audit Events:**

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `security.ip_blocked` | IP was blocked | IP, reason, duration, auto/manual |
| `security.ip_unblocked` | IP was unblocked | IP, unblocked_by (system/admin), reason |
| `security.ip_block_extended` | Block duration extended | IP, new_expiry, reason |
| `security.ip_allowlisted` | IP added to allowlist | IP/CIDR, added_by |
| `security.ip_allowlist_removed` | IP removed from allowlist | IP/CIDR, removed_by |
| `security.account_soft_locked` | Account soft locked | User ID (masked), attempts, duration |
| `security.account_hard_locked` | Account hard locked | User ID (masked), attempts, duration |
| `security.account_locked` | Account permanently locked | User ID (masked), attempts |
| `security.account_unlocked` | Account unlocked | User ID, unlocked_by (system/admin/password_reset) |
| `security.password_policy_changed` | Password policy updated | Changed fields, changed_by |
| `security.token_revoked` | API token revoked | Token ID (masked), revoked_by |
| `security.token_rotated` | API token rotated | Token ID (masked), rotated_by |

### Breach Management

**Breach Lifecycle:**

```
┌─────────────┐     ┌──────────────┐     ┌───────────────┐     ┌─────────────┐
│  Detected   │────▶│ Investigating│────▶│   Contained   │────▶│  Notifying  │
└─────────────┘     └──────────────┘     └───────────────┘     └─────────────┘
                                                                      │
                    ┌──────────────┐     ┌───────────────┐           │
                    │   Resolved   │◀────│  Remediated   │◀──────────┘
                    └──────────────┘     └───────────────┘
```

**Breach Severity Levels:**

| Level | Description | Notification Timeline | Auto-Escalate |
|-------|-------------|----------------------|---------------|
| **Critical** | Active data exfiltration, full system compromise | Immediate | Yes |
| **High** | Unauthorized access to sensitive data | 24 hours | Yes (72hr) |
| **Medium** | Potential data exposure, failed attacks | 72 hours | No |
| **Low** | Minor security events, policy violations | 7 days | No |

**Breach Management API:**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/breaches` | GET | List all breaches |
| `/api/v1/admin/server/breaches` | POST | Report new breach |
| `/api/v1/admin/server/breaches/{id}` | GET | Get breach details |
| `/api/v1/admin/server/breaches/{id}` | PATCH | Update breach status |
| `/api/v1/admin/server/breaches/{id}/investigate` | POST | Start investigation |
| `/api/v1/admin/server/breaches/{id}/contain` | POST | Mark as contained |
| `/api/v1/admin/server/breaches/{id}/notify` | POST | Send notifications |
| `/api/v1/admin/server/breaches/{id}/resolve` | POST | Mark as resolved |
| `/api/v1/admin/server/breaches/{id}/affected` | GET | List affected users |
| `/api/v1/admin/server/breaches/{id}/timeline` | GET | Breach timeline/events |
| `/api/v1/admin/server/breaches/{id}/report` | GET | Generate breach report |

**Breach Data Model:**

```go
type Breach struct {
    ID              string        `json:"id"`
    Status          BreachStatus  `json:"status"`
    Severity        Severity      `json:"severity"`
    Type            string        `json:"type"`
    Summary         string        `json:"summary"`
    Description     string        `json:"description"`
    DetectedAt      time.Time     `json:"detected_at"`
    // "system" or admin ID
    DetectedBy      string        `json:"detected_by"`
    // automated/manual/external
    DetectionMethod string        `json:"detection_method"`
    // data categories
    AffectedData    []string      `json:"affected_data"`
    AffectedUsers   int           `json:"affected_users"`
    ContainedAt     *time.Time    `json:"contained_at,omitempty"`
    NotifiedAt      *time.Time    `json:"notified_at,omitempty"`
    ResolvedAt      *time.Time    `json:"resolved_at,omitempty"`
    RootCause       string        `json:"root_cause,omitempty"`
    Remediation     string        `json:"remediation,omitempty"`
    Timeline        []BreachEvent `json:"timeline"`
    // applicable standards
    Compliance      []string      `json:"compliance"`
    // based on strictest standard
    NotifyDeadline  time.Time     `json:"notify_deadline"`
}

type BreachStatus string
const (
    BreachDetected     BreachStatus = "detected"
    BreachInvestigating BreachStatus = "investigating"
    BreachContained    BreachStatus = "contained"
    BreachNotifying    BreachStatus = "notifying"
    BreachRemediated   BreachStatus = "remediated"
    BreachResolved     BreachStatus = "resolved"
)
```

**Admin UI: Breach Management**

**Location:** `/admin/server/compliance/breaches`

| Section | Description |
|---------|-------------|
| Active Breaches | Current breaches requiring attention |
| Breach Timeline | Visual timeline of all breach events |
| Affected Users | List users impacted, notification status |
| Notification Queue | Pending notifications, send/preview |
| Authority Reporting | Generate reports for regulatory authorities |
| Breach History | All past breaches with outcomes |

**Report New Breach Form:**

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| Severity | Select | Yes | Critical/High/Medium/Low |
| Type | Select | Yes | Unauthorized access, Data exposure, etc. |
| Summary | Text | Yes | Brief description (shown in notifications) |
| Description | Textarea | Yes | Full details for internal use |
| Affected Data | Multi-select | Yes | Categories: credentials, email, profile, etc. |
| Detection Method | Select | Yes | Automated/Manual/External report |
| Estimated Affected Users | Number | No | Initial estimate |

---


# PART 12: SERVER CONFIGURATION (NON-NEGOTIABLE)

## Config Validation Rule (NON-NEGOTIABLE)

**If config setting is invalid, warn and replace with default. Never fail startup.**

```go
// validateConfig validates all config values, replacing invalid with defaults
func validateConfig(cfg *Config) {
    // Example: port must be 1-65535
    if cfg.Server.Port < 1 || cfg.Server.Port > 65535 {
        log.Warnf("invalid port %d, using default 8080", cfg.Server.Port)
        cfg.Server.Port = 8080
    }

    // Example: timeout must be positive
    if cfg.Server.Timeout <= 0 {
        log.Warnf("invalid timeout %d, using default 30s", cfg.Server.Timeout)
        cfg.Server.Timeout = 30
    }
}
```

| Principle | Rule |
|-----------|------|
| **Validate everything** | Check all config values on load |
| **Invalid → default** | Replace invalid values with defaults |
| **Warn, don't error** | Log warning, don't fail startup |
| **Never crash on config** | Server must start with sane defaults |

## Request Limits

```yaml
server:
  limits:
    max_body_size: 10MB
    read_timeout: 30s
    write_timeout: 30s
    idle_timeout: 120s
```

| Setting | Description | Default |
|---------|-------------|---------|
| `max_body_size` | Maximum request body size | 10MB |
| `read_timeout` | Read timeout | 30s |
| `write_timeout` | Write timeout | 30s |
| `idle_timeout` | Idle connection timeout | 120s |

## Response Compression

```yaml
server:
  compression:
    enabled: true
    # Compression level 1-9
    level: 5
    # MIME types to compress
    types:
      - text/html
      - text/css
      - text/javascript
      - application/json
      - application/xml
```

## Trusted Proxies

```yaml
server:
  trusted_proxies:
    # Additional IPs/CIDRs to trust (private ranges always trusted)
    additional: []
```

## Session Configuration

```yaml
server:
  session:
    # Admin sessions (server.db admin_sessions table)
    admin:
      cookie_name: admin_session
      # Cookie max age: 30 days (absolute session lifetime)
      max_age: 2592000
      # Idle timeout: 24 hours (session expires after inactivity)
      idle_timeout: 86400
    # User sessions (users.db user_sessions table) - only if app has users
    user:
      cookie_name: user_session
      # Cookie max age: 7 days
      max_age: 604800
      # Idle timeout: 24 hours
      idle_timeout: 86400
    # Common settings (apply to both)
    extend_on_activity: true     # Reset idle timeout on each request
    # auto, true, false
    secure: auto
    http_only: true
    # strict, lax, none
    same_site: lax
```

**Session Lifetime vs Idle Timeout:**

| Setting | Admin Default | User Default | Description |
|---------|---------------|--------------|-------------|
| `max_age` | 30 days | 7 days | Absolute session lifetime (cookie expiry) |
| `idle_timeout` | 24 hours | 24 hours | Expires after inactivity (reset on each request if `extend_on_activity` is true) |

## Rate Limiting

```yaml
server:
  rate_limit:
    enabled: true
    # Requests allowed per window
    requests: 120
    # Window size in seconds
    window: 60
```

## Internationalization (i18n)

```yaml
server:
  i18n:
    default_language: en
    supported: [en]
```

## Cache Configuration (NON-NEGOTIABLE)

**EVERY application MUST support Valkey/Redis.** This is REQUIRED for:
- Clustering (session sharing, state sync)
- Mixed Mode (cross-database synchronization)
- Horizontal scaling
- Rate limiting in distributed deployments

| Mode | Cache Requirement |
|------|-------------------|
| **Single Instance** | `memory` (default) - works standalone |
| **Cluster** | `valkey` or `redis` - REQUIRED for state sync |
| **Mixed Mode** | `valkey` or `redis` - REQUIRED for cross-DB sync |

```yaml
server:
  cache:
    # Type: none (disabled), memory (default), valkey, redis
    # IMPORTANT: Use valkey/redis for cluster or mixed mode deployments
    type: memory

    # Connection: Use EITHER url OR host/port/password (not both)
    # url takes precedence if both are specified
    # Format: redis://user:password@host:port/db or valkey://...
    url: ""

    # Individual connection settings (alternative to url)
    host: localhost
    port: 6379
    # ACL username (Redis 6+)
    username: ""
    password: ""
    db: 0

    # TLS settings (for secure connections)
    tls: false
    tls_skip_verify: false

    # Connection pool
    pool_size: 10
    min_idle: 2
    timeout: 5s

    # Key prefix to avoid collisions (use unique prefix per app)
    prefix: "weather:"

    # Default TTL in seconds
    ttl: 3600

    # Cluster settings (when using Valkey/Redis Cluster)
    cluster: false
    # e.g., ["node1:6379", "node2:6379", "node3:6379"]
    cluster_nodes: []
```

### Connection Methods

**Two ways to configure connection (pick one):**

| Method | When to Use |
|--------|-------------|
| `url` | Simple, single connection string, environment-friendly |
| `host`/`port`/etc | More explicit, when fields come from different sources |

**URL Format:**
```
redis://[[username:]password@]host[:port][/database]
valkey://[[username:]password@]host[:port][/database]
rediss://...  # Redis with TLS
```

### Valkey/Redis Configuration Examples

**Using connection URL:**
```yaml
server:
  cache:
    type: valkey
    url: ${CACHE_URL}  # valkey://user:pass@valkey.example.com:6379/0
    prefix: "weather:"
```

**Using individual fields:**
```yaml
server:
  cache:
    type: valkey
    host: valkey.example.com
    port: 6379
    password: ${VALKEY_PASSWORD}
    db: 0
    prefix: "weather:"
```

**Valkey/Redis Cluster:**
```yaml
server:
  cache:
    type: valkey
    cluster: true
    cluster_nodes:
      - valkey1.example.com:6379
      - valkey2.example.com:6379
      - valkey3.example.com:6379
    password: ${VALKEY_PASSWORD}
    prefix: "weather:"
```

### Cache Usage in Application

| Feature | Uses Cache | Purpose |
|---------|------------|---------|
| Sessions | Yes | Session data storage |
| Rate limiting | Yes | Request counters per IP/user |
| API responses | Optional | Response caching |
| Cluster heartbeat | Yes | Node liveness detection |
| Pub/Sub events | Yes | Real-time state sync |
| Distributed locks | Yes | Prevent duplicate task execution |

## Admin Panel (/admin/server/settings)

All settings above MUST be configurable via admin panel:

| Section | Settings |
|---------|----------|
| Request Limits | Body size, timeouts |
| Compression | Enable, level, MIME types |
| Trusted Proxies | Additional IPs/CIDRs |
| Session | Cookie name, max age, secure, http_only, same_site |
| Rate Limiting | Enable, requests, window |
| i18n | Default language, supported languages |
| Cache | Type, connection settings, prefix, TTL |

---



# PART 13: HEALTH & VERSIONING (NON-NEGOTIABLE)

## Health Checks

**Endpoints:**
- `/healthz` - Frontend route (follows PART 14 content negotiation rules)
- `/api/v1/healthz` - API route (always JSON)

**Content negotiation:** Follows standard frontend rules (see PART 14). No special /healthz rules.

**NO sub-routes** - just `/healthz`, not `/healthz/db` or `/healthz/**`

### Security: Public Info Only (NON-NEGOTIABLE)

**Healthz is PUBLIC. NEVER expose sensitive data.**

| ALLOWED (public) | FORBIDDEN (sensitive) |
|------------------|----------------------|
| Status: "healthy"/"unhealthy" | Database connection strings |
| Version: "1.0.0" | API keys or tokens |
| Uptime: "2d 5h" | Passwords or secrets |
| Mode: "production" | Internal IP addresses |
| Checks: "ok"/"error" | File paths on server |
| Node ID (opaque) | Environment variables |
| Cluster node count | Config file contents |

**Database/cache checks MUST be vague:**
- ✅ `"database": "ok"` or `"database": "error"`
- ❌ `"database": "postgresql://user:pass@host:5432/db"`
- ❌ `"database": {"host": "10.0.0.5", "port": 5432}`

### /healthz Response Formats

**Follows standard content negotiation (PART 14). Browser gets HTML, CLI gets text, API gets JSON.**

#### HTML (browsers)

**Full HTML page following frontend rules (PART 16).**

**Required Elements:**
- Full HTML document with `<head>` and `<body>`
- Proper page title: "weather - Health Status"
- Uses site theme (light/dark mode support)
- Responsive layout
- Header with navigation (if logged in) or minimal header (if public)
- Footer with standard links

**Health Information Display:**

**Frontend MUST display ALL data returned by backend, formatted properly.**

| Section | Content | Backend Field |
|---------|---------|---------------|
| **Status Banner** | Large status indicator (Healthy ✓ / Unhealthy ✗) with color | `status` |
| **Version Info** | Version, Go version, build commit, build date | `version`, `go_version`, `build.*` |
| **Uptime** | Server uptime in human-readable format | `uptime` |
| **Mode** | Production/Development | `mode` |
| **Cluster** | Status, primary, nodes list, role | `cluster.*` |
| **Features** | Enabled features with icons | `features.*` |
| **Component Checks** | Database, cache, disk, scheduler, cluster - each with status indicator | `checks.*` |
| **Statistics** | Total requests, 24h requests, active connections | `stats.*` |
| **Last Updated** | Timestamp of health check | `timestamp` |

**HTML Structure:**
```html
<!DOCTYPE html>
<html lang="en">
<head>
  <title>weather - Health Status</title>
  <!-- Standard meta, CSS, theme support -->
</head>
<body>
  <header><!-- Standard header --></header>
  <main class="health-status">
    <h1>System Health</h1>

    <!-- Status Banner -->
    <div class="status-banner status-healthy">
      <span class="status-icon">✓</span>
      <span class="status-text">All Systems Operational</span>
    </div>

    <!-- Version & Build Info -->
    <section class="health-section">
      <h2>Version</h2>
      <dl class="info-grid">
        <dt>Version</dt><dd>1.0.0</dd>
        <dt>Go Version</dt><dd>1.23.0</dd>
        <dt>Build</dt><dd>abc1234 (2024-01-10)</dd>
        <dt>Uptime</dt><dd>2d 5h 30m</dd>
        <dt>Mode</dt><dd><span class="badge badge-production">Production</span></dd>
      </dl>
    </section>

    <!-- Cluster Info (if enabled) -->
    <section class="health-section">
      <h2>Cluster</h2>
      <dl class="info-grid">
        <dt>Status</dt><dd><span class="status-ok">Connected</span></dd>
        <dt>Primary</dt><dd><code>https://node1.example.com</code></dd>
        <dt>Role</dt><dd>Member</dd>
      </dl>
      <h3>Nodes</h3>
      <ul class="node-list">
        <li><code>https://node1.example.com</code> <span class="badge badge-primary">Primary</span></li>
        <li><code>https://node2.example.com</code></li>
        <li><code>https://node3.example.com</code></li>
      </ul>
    </section>

    <!-- Features -->
    <section class="health-section">
      <h2>Features</h2>
      <ul class="feature-list">
        <li class="feature-enabled">✓ Multi-User</li>
        <li class="feature-enabled">✓ Organizations</li>
        <li class="feature-enabled">✓ Tor: <span class="status-ok">healthy</span> <code>abc123xyz456.onion</code></li>
        <li class="feature-enabled">✓ GeoIP</li>
        <li class="feature-enabled">✓ Metrics</li>
      </ul>
    </section>

    <!-- Component Checks -->
    <section class="health-section">
      <h2>Component Status</h2>
      <table class="checks-table">
        <thead><tr><th>Component</th><th>Status</th></tr></thead>
        <tbody>
          <tr><td>Database</td><td class="status-ok">OK</td></tr>
          <tr><td>Cache</td><td class="status-ok">OK</td></tr>
          <tr><td>Disk</td><td class="status-ok">OK</td></tr>
          <tr><td>Scheduler</td><td class="status-ok">OK</td></tr>
          <tr><td>Cluster</td><td class="status-ok">OK</td></tr>
        </tbody>
      </table>
    </section>

    <!-- Statistics -->
    <section class="health-section">
      <h2>Statistics</h2>
      <dl class="info-grid stats-grid">
        <dt>Total Requests</dt><dd>1,234,567</dd>
        <dt>Requests (24h)</dt><dd>45,678</dd>
        <dt>Active Connections</dt><dd>42</dd>
      </dl>
    </section>

    <!-- Footer -->
    <footer class="health-footer">
      <p>Last checked: <time datetime="2024-01-15T10:30:00Z">Jan 15, 2024 10:30 AM</time></p>
      <p class="auto-refresh">Auto-refreshing in <span id="countdown">30</span>s</p>
    </footer>
  </main>
  <footer><!-- Standard footer --></footer>
</body>
</html>
```

**Status Styling:**
```css
/* Status Banner */
.status-banner {
  padding: 1.5rem;
  border-radius: 8px;
  text-align: center;
  font-size: 1.5rem;
  margin-bottom: 2rem;
}
.status-healthy { background: var(--color-success-bg); color: var(--color-success); }
.status-unhealthy { background: var(--color-error-bg); color: var(--color-error); }
.status-degraded { background: var(--color-warning-bg); color: var(--color-warning); }

/* Status Indicators */
.status-ok { color: var(--color-success); }
.status-error { color: var(--color-error); }
.status-warning { color: var(--color-warning); }

/* Sections */
.health-section {
  margin-bottom: 2rem;
  padding: 1rem;
  border: 1px solid var(--color-border);
  border-radius: 8px;
}
.health-section h2 {
  margin-top: 0;
  border-bottom: 1px solid var(--color-border);
  padding-bottom: 0.5rem;
}

/* Info Grid (dl/dt/dd) */
.info-grid {
  display: grid;
  grid-template-columns: auto 1fr;
  gap: 0.5rem 1rem;
}
.info-grid dt { font-weight: 600; }
.info-grid dd { margin: 0; }

/* Feature List */
.feature-list {
  list-style: none;
  padding: 0;
  display: flex;
  flex-wrap: wrap;
  gap: 0.5rem;
}
.feature-enabled { color: var(--color-success); }
.feature-disabled { color: var(--color-muted); }

/* Node List */
.node-list {
  list-style: none;
  padding: 0;
}
.node-list li {
  padding: 0.25rem 0;
  font-family: monospace;
}

/* Checks Table */
.checks-table {
  width: 100%;
  border-collapse: collapse;
}
.checks-table th, .checks-table td {
  padding: 0.5rem;
  border-bottom: 1px solid var(--color-border);
  text-align: left;
}

/* Badges */
.badge {
  padding: 0.125rem 0.5rem;
  border-radius: 4px;
  font-size: 0.875rem;
}
.badge-production { background: var(--color-success-bg); color: var(--color-success); }
.badge-development { background: var(--color-warning-bg); color: var(--color-warning); }
.badge-primary { background: var(--color-primary-bg); color: var(--color-primary); }

/* Stats */
.stats-grid dd {
  font-size: 1.25rem;
  font-weight: 600;
}

/* Auto-refresh */
.auto-refresh {
  color: var(--color-muted);
  font-size: 0.875rem;
}
```

**Auto-refresh (optional):**
- Page may auto-refresh every 30-60 seconds
- Use `<meta http-equiv="refresh" content="30">` or JavaScript
- Show countdown or "Auto-refreshing in Xs" indicator

#### JSON (Accept: application/json)

```json
{
  "status": "healthy",
  "version": "1.0.0",
  "mode": "production",
  "uptime": "2d 5h 30m",
  "timestamp": "2024-01-15T10:30:00Z",
  "go_version": "1.23.0",
  "build": {
    "commit": "abc1234",
    "date": "2024-01-10T10:00:00Z"
  },
  "cluster": {
    "enabled": true,
    "status": "connected",
    "primary": "https://node1.example.com",
    "nodes": [
      "https://node1.example.com",
      "https://node2.example.com",
      "https://node3.example.com"
    ],
    "role": "member"
  },
  "features": {
    "multi_user": true,
    "organizations": true,
    "tor": {
      "enabled": true,
      "running": true,
      "status": "healthy",
      "hostname": "abc123xyz456.onion"
    },
    "geoip": true,
    "metrics": true
  },
  "checks": {
    "database": "ok",
    "cache": "ok",
    "disk": "ok",
    "scheduler": "ok",
    "cluster": "ok"
  },
  "stats": {
    "requests_total": 1234567,
    "requests_24h": 45678,
    "active_connections": 42
  }
}
```

### /api/v1/healthz Security Rules (NON-NEGOTIABLE)

**NEVER expose in /healthz response:**

| Category | NEVER Include | Why |
|----------|---------------|-----|
| **Credentials** | Tokens, API keys, passwords | Direct security breach |
| **Database** | Connection strings, host, port, user | Attack vector |
| **Internal IPs** | Private IPs, internal hostnames | Network reconnaissance |
| **Paths** | Config paths, data paths, file locations | File system info |
| **Usernames** | Admin names, user counts with names | User enumeration |
| **Email** | SMTP host, admin emails | Phishing/spam target |
| **Secrets** | Encryption keys, session secrets | Cryptographic breach |
| **Debug** | Stack traces, detailed errors | Exploitation info |

**Safe to include:**

| Category | OK to Include | Example |
|----------|---------------|---------|
| **Version** | App version, Go version, build info | `1.0.0`, `go1.23.0` |
| **Status** | Health status, uptime | `healthy`, `2d 5h` |
| **Features** | Enabled features (bool only) | `multi_user: true` |
| **Checks** | Service status (ok/error only) | `database: ok` |
| **Cluster** | Public node URLs | `https://node1.example.com` |
| **Stats** | Aggregate counts only | `requests_total: 12345` |
| **Mode** | Production/development | `production` |

**Rule: If in doubt, don't include it. Health checks need status, not details.**

#### Plain Text (Accept: text/plain)

```
status: healthy
version: 1.0.0
mode: production
uptime: 2d 5h 30m
go_version: 1.23.0
build.commit: abc1234
database: ok
cache: ok
disk: ok
scheduler: ok
cluster: ok
cluster.primary: https://node1.example.com
cluster.nodes: https://node1.example.com, https://node2.example.com, https://node3.example.com
features: multi_user, organizations, tor, geoip, metrics
features.tor.enabled: true
features.tor.running: true
features.tor.status: healthy
features.tor.hostname: abc123xyz456.onion
```

### /api/v1/healthz (JSON only)

Same JSON response as `/healthz` with `Accept: application/json`. Always returns JSON regardless of Accept header.

### Single Instance Response

When not in cluster mode:

```json
{
  "status": "healthy",
  "version": "1.0.0",
  "mode": "production",
  "uptime": "2d 5h 30m",
  "timestamp": "2024-01-15T10:30:00Z",
  "go_version": "1.23.0",
  "build": {
    "commit": "abc1234",
    "date": "2024-01-10T10:00:00Z"
  },
  "cluster": {
    "enabled": false,
    "primary": "",
    "nodes": []
  },
  "features": {
    "multi_user": false,
    "organizations": false,
    "tor": {
      "enabled": false,
      "running": false,
      "status": "",
      "hostname": ""
    },
    "geoip": true,
    "metrics": true
  },
  "checks": {
    "database": "ok",
    "cache": "ok",
    "disk": "ok",
    "scheduler": "ok"
  },
  "stats": {
    "requests_total": 12345,
    "requests_24h": 678,
    "active_connections": 5
  }
}
```

### Health Response Fields

| Field | Description |
|-------|-------------|
| `status` | healthy, degraded, unhealthy |
| `version` | Application version (SemVer) |
| `mode` | production, development |
| `uptime` | Human-readable uptime |
| `timestamp` | ISO 8601 timestamp |
| `go_version` | Go runtime version |
| `build.commit` | Git commit hash (short) |
| `build.date` | Build timestamp |
| `cluster.enabled` | Whether cluster mode is active |
| `cluster.status` | connected, degraded, disconnected |
| `cluster.primary` | Primary node URL (for failover) |
| `cluster.nodes` | Array of all node URLs (for failover) |
| `cluster.role` | member (all nodes are equal) |
| `features.*` | Enabled features (bool or object) |
| `features.tor.enabled` | Tor hidden service enabled (config) |
| `features.tor.running` | Tor process currently running |
| `features.tor.status` | healthy, error:{short message} |
| `features.tor.hostname` | Onion address (if running) |
| `checks.*` | Service health (ok, degraded, error) |
| `stats.requests_total` | Total requests served |
| `stats.requests_24h` | Requests in last 24 hours |
| `stats.active_connections` | Current active connections |

**Cluster fields for agent/CLI failover:**
- `cluster.primary` - The primary server URL
- `cluster.nodes` - All available nodes (agents/CLI use for automatic failover)

## Versioning

### Semantic Versioning (SemVer) Rules

**ALL stable releases MUST follow semantic versioning:**

| Component | When to Increment | Example |
|-----------|-------------------|---------|
| **MAJOR** | Breaking API changes, incompatible config changes, database schema changes requiring migration | `1.0.0` → `2.0.0` |
| **MINOR** | New features (backward compatible), new config options, new API endpoints | `1.0.0` → `1.1.0` |
| **PATCH** | Bug fixes, security patches, documentation updates (no new features) | `1.0.0` → `1.0.1` |

**Version Rules:**
- Start at `1.0.0` for first stable release (NOT `0.x.x`)
- Never reuse version numbers
- Pre-release versions use suffix: `1.0.0-rc1`, `1.0.0-alpha`
- No leading zeros: `1.0.1` (NOT `1.0.01`)
- No `v` prefix in version string: `1.0.0` (NOT `v1.0.0`)
- Git tags add `v` prefix: `v1.0.0`

### Format

- Stable: Semantic versioning `MAJOR.MINOR.PATCH` (e.g., `1.0.0`)
- Beta: `YYYYMMDDHHMMSS-beta` (e.g., `20251205143022-beta`)
- Daily: `YYYYMMDDHHMMSS` (e.g., `20251218060432`)

### Sources (Priority Order)

1. `release.txt` in project root
2. Git tag (if available)
3. Fallback: `dev`

### --version Output

```
weather {projectversion}
Built: {BUILD_DATE}
Go: {GO_VERSION}
OS/Arch: {GOOS}/{GOARCH}
```

---


# PART 14: API STRUCTURE (NON-NEGOTIABLE)

**Note:** This section covers API structure and requirements. For specific route listings, see:
- Admin Web Routes: PART 17 (Admin Panel)
- Admin API Routes: PART 17 (Admin Panel → API Routes)
- Project-specific Routes: PART 37 (Project-Specific Sections)

## Legacy vs Compatibility Endpoints (NON-NEGOTIABLE)

| Type | Definition | Action |
|------|------------|--------|
| **Compatibility** | External service endpoints (pastebin.com, microbin, etc.) | Implement per "External API Compatibility" section below |
| **Legacy** | Old, changed, or removed endpoints from YOUR project | **NEVER KEEP - DELETE THEM** |

**Legacy endpoints are technical debt.** When an endpoint changes or is removed:
- DELETE the old endpoint completely
- Update documentation
- Update clients to use new endpoint
- NO backwards compatibility shims, redirects, or deprecation periods

## API Versioning

**Use versioned API: `/api/v1`**

## Route Compliance (NON-NEGOTIABLE)

**IF A ROUTE EXISTS, IT MUST FOLLOW THESE RULES. NO EXCEPTIONS.**

### Mandatory Route Rules

| Rule | Requirement | Wrong | Correct |
|------|-------------|-------|---------|
| **Versioning** | All API routes MUST be versioned | `/api/users` | `/api/v1/users` |
| **Plural nouns** | All resource names MUST be plural | `/api/v1/user` | `/api/v1/users` |
| **Lowercase** | All routes MUST be lowercase | `/api/v1/Users` | `/api/v1/users` |
| **Hyphens** | Multi-word routes use hyphens | `/api/v1/api_keys` | `/api/v1/api-keys` |
| **No trailing slash** | Routes MUST NOT end with `/` | `/api/v1/users/` | `/api/v1/users` |
| **No verbs** | Routes are nouns, not actions | `/api/v1/getUsers` | `GET /api/v1/users` |

### Frontend-Backend Integration (NON-NEGOTIABLE)

**API is the source of truth. Frontend consumes the API. Not every API needs a frontend route.**

| API Type | Frontend Required | Example |
|----------|-------------------|---------|
| **User-facing features** | Yes | `/api/v1/users` → `/users` page |
| **Admin features** | Yes | `/api/v1/admin/*` → `/{adminpath}/*` pages |
| **Health/status** | No | `/api/v1/healthz` - API only |
| **Webhooks** | No | `/api/v1/webhooks/*` - backend only |
| **Agent endpoints** | No | `/api/v1/*/agents/*` - CLI/agent only |
| **System/internal** | No | Metrics, cluster sync, etc. |

| Requirement | Description |
|-------------|-------------|
| **API first** | API is complete and works standalone |
| **Frontend consumes API** | Frontend makes requests to API, displays responses |
| **Full functionality** | User-facing features work completely in browser |
| **CRUD parity** | If user can do it in API, they can do it in frontend |

**Example - User Features:**

| Backend API | Frontend | Purpose |
|-------------|----------|---------|
| `GET /api/v1/users` | `GET /users` | View user profile |
| `PATCH /api/v1/users` | `POST /users` (form) | Update user profile |
| `GET /api/v1/users/tokens` | `GET /users/tokens` | List tokens |
| `POST /api/v1/users/tokens` | `POST /users/tokens` (form) | Create token |
| `DELETE /api/v1/users/tokens/{id}` | `POST /users/tokens/{id}/delete` | Delete token |

**API-only (no frontend needed):**

| API Endpoint | Why No Frontend |
|--------------|-----------------|
| `/api/v1/healthz` | Machine monitoring |
| `/api/v1/admin/server/agents/*` | Agent binary uses directly |
| `/api/v1/cluster/*` | Node-to-node communication |
| `/api/v1/webhooks/*` | External service callbacks |

### Frontend Functionality Requirements (NON-NEGOTIABLE)

**Frontend is NOT just a display layer. It MUST be fully functional:**

| Requirement | Description |
|-------------|-------------|
| **Forms work** | All frontend forms submit to backend and process responses |
| **CRUD complete** | Create, Read, Update, Delete all work from frontend |
| **Error handling** | Frontend displays backend errors appropriately |
| **Validation** | Client-side validation matches server-side rules |
| **State sync** | Frontend state reflects backend state after operations |
| **No dead ends** | Every action has a result (success message, error, redirect) |

**Frontend MUST work without JavaScript for core functionality (progressive enhancement).**

### Route Audit Checklist

Before adding ANY route, verify:

- [ ] Is it versioned? (`/api/v1/...`)
- [ ] Is the resource name plural? (`users`, not `user`)
- [ ] Is it lowercase with hyphens? (`api-keys`, not `API_Keys`)
- [ ] Does the route follow scope rules? (`/auth/`, `/users/`, `/orgs/`, `/admin/`)
- [ ] If user-facing: does frontend route exist and work?
- [ ] If system/agent: documented as API-only?

## Route Naming Convention (NON-NEGOTIABLE)

### Always Plural

**All resource routes use plural form. No singular forms. No exceptions.**

| ✓ Correct | ✗ Wrong |
|-----------|---------|
| `/api/v1/users` | `/api/v1/user` |
| `/api/v1/orgs` | `/api/v1/org` |
| `/api/v1/orgs/{slug}/members` | `/api/v1/org/{slug}/members` |

### Route Scopes

| Scope | Web Route | API Route | ID Required | Description |
|-------|-----------|-----------|-------------|-------------|
| **Server** | `/server/*` | `/api/v1/server/*` | No | About, privacy, contact, help, terms |
| **Auth** | `/auth/*` | `/api/v1/auth/*` | No | Login, register, logout, OAuth |
| **Users** | `/users/*` | `/api/v1/users/*` | **No** | Current user's resources (from session) |
| **Orgs** | `/orgs/*` | `/api/v1/orgs/*` | **Yes** (`{slug}`) | User can own multiple orgs |
| **Admin** | `/{admin_path}/*` | `/api/v1/{admin_path}/*` | No | Server administration |
| **Project** | `/*` | `/api/v1/*` | Varies | Project-specific (jokes, pastes, etc.) |

### User Routes - No ID Required (NON-NEGOTIABLE)

**Users can only manage themselves. The app knows who from the session.**

| Route | Description |
|-------|-------------|
| `GET /api/v1/users` | Current user's profile |
| `PATCH /api/v1/users` | Update current user's profile |
| `GET /api/v1/users/tokens` | Current user's API tokens |
| `GET /api/v1/users/security` | Current user's security settings |
| `GET /api/v1/users/settings` | Current user's preferences |

**Admin routes for managing OTHER users use `/admin/users/{id}`:**

| Route | Description |
|-------|-------------|
| `GET /api/v1/{admin_path}/users` | List all users (admin) |
| `GET /api/v1/{admin_path}/users/{id}` | View specific user (admin) |
| `PATCH /api/v1/{admin_path}/users/{id}` | Edit specific user (admin) |

### Org Routes - Slug Required (NON-NEGOTIABLE)

**Users can own multiple orgs. Slug identifies which org.**

| Route | Description |
|-------|-------------|
| `GET /api/v1/orgs` | List user's organizations |
| `POST /api/v1/orgs` | Create new organization |
| `GET /api/v1/orgs/{slug}` | Get specific org |
| `GET /api/v1/orgs/{slug}/members` | Get org members |
| `GET /api/v1/orgs/{slug}/settings` | Get org settings |

### Frontend Must Match Backend

**Every API route has a corresponding frontend route. They MUST match.**

| API Route | Frontend Route | Notes |
|-----------|----------------|-------|
| `/api/v1/users` | `/users` | Current user profile |
| `/api/v1/users/tokens` | `/users/tokens` | Current user's tokens |
| `/api/v1/users/settings` | `/users/settings` | Current user's settings |
| `/api/v1/orgs` | `/orgs` | User's org list |
| `/api/v1/orgs/{slug}` | `/orgs/{slug}` | Specific org |
| `/api/v1/orgs/{slug}/members` | `/orgs/{slug}/members` | Org members |
| `/api/v1/server/about` | `/server/about` | About page |

**Frontend uses same routes, different response format:**
- Browser request → HTML page
- API request → JSON
- `.txt` extension → Plain text

### ID/Slug Consistency

**Use descriptive parameter names in nested routes:**

| Route | Parameter | Notes |
|-------|-----------|-------|
| `/users/tokens/{token_id}` | `token_id` | User's token |
| `/users/sessions/{session_id}` | `session_id` | User's session |
| `/orgs/{slug}` | `slug` | Org identifier |
| `/orgs/{slug}/members/{member_id}` | `member_id` | Org member |
| `/orgs/{slug}/tokens/{token_id}` | `token_id` | Org's token |

## URL Parameters (NON-NEGOTIABLE)

**Prefer path parameters over query parameters.**

| Parameter Type | Use When | Example |
|----------------|----------|---------|
| **Path params** | Identifying a resource | `/api/v1/users/{id}`, `/api/v1/jokes/{category}` |
| **Query params** | Filtering, sorting, pagination | `?page=2&limit=10&sort=date` |

**Path Parameters (Preferred):**
```
GET /api/v1/users/123              ✓ Good - resource ID in path
GET /api/v1/jokes/programming      ✓ Good - category in path
GET /api/v1/search/golang          ✓ Good - search term in path

GET /api/v1/users?id=123           ✗ Bad - should be path param
GET /api/v1/jokes?category=prog    ✗ Bad - should be path param
```

**Query Parameters (When Needed):**
```
GET /api/v1/users?page=2&limit=10          ✓ Pagination
GET /api/v1/jokes?sort=rating&order=desc   ✓ Sorting
GET /api/v1/search/golang?safe=true        ✓ Filtering/options
GET /api/v1/users?status=active&role=admin ✓ Multiple filters
```

**Rules:**
| Rule | Description |
|------|-------------|
| **Resource identity → path** | IDs, slugs, categories in URL path |
| **Modifiers → query** | Pagination, sorting, filtering as query params |
| **No redundancy** | Don't duplicate path params as query params |
| **Clean URLs** | Prefer `/jokes/random` over `/jokes?type=random` |

## Response Formatting (NON-NEGOTIABLE)

**ALL responses and ALL code MUST be properly formatted.**

### Universal Formatting Rules

**These rules apply to EVERYTHING: responses, code files, templates, configs.**

| Rule | Applies To | Requirement |
|------|-----------|-------------|
| **Single trailing newline** | JSON, TXT, HTML, XML, YAML, Go, all files | End with exactly one `\n` |
| **2-space indentation** | HTML, JSON, YAML, JavaScript, CSS | Use 2 spaces per level |
| **Tab indentation** | Go code, Makefiles | Use tabs where required by language |
| **Proper nesting** | All structured formats | Each level indented correctly |
| **No trailing whitespace** | All files | No spaces/tabs at end of lines |

### JSON Formatting (API Responses)

```go
// ALL JSON responses MUST be indented and end with newline
// Use 2-space indent
data, _ := json.MarshalIndent(response, "", "  ")
w.Header().Set("Content-Type", "application/json")
w.Write(data)
// Single trailing newline
w.Write([]byte("\n"))
```

**Output:**
```json
{
  "id": "123",
  "name": "Test User",
  "items": [
    {
      "id": "1"
    }
  ]
}
⏎
```

### Text Formatting (TXT Responses)

```go
// ALL text responses MUST end with single newline
w.Header().Set("Content-Type", "text/plain; charset=utf-8")
// Single trailing newline included in format string
fmt.Fprintf(w, "%s\n", text)
```

**Output:**
```
This is the response text.
⏎
```

### HTML Formatting (Frontend Responses)

```go
// ALL HTML MUST be indented with 2 spaces and end with newline
```

**Output:**
```html
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Page Title</title>
  </head>
  <body>
    <div class="container">
      <h1>Heading</h1>
      <p>Paragraph text here.</p>
      <ul>
        <li>Item 1</li>
        <li>Item 2</li>
      </ul>
    </div>
  </body>
</html>
⏎
```

### YAML Formatting (Config Files)

```yaml
# 2-space indentation, single trailing newline
server:
  address: 0.0.0.0
  port: 80

  users:
    enabled: false
    registration:
      mode: disabled
⏎
```

### Go Code Formatting

```go
// Use tabs for indentation (gofmt standard)
func Handler(w http.ResponseWriter, r *http.Request) {
	// Tab indent
	if err := validate(r); err != nil {
		// Tab indent
		http.Error(w, "Invalid", 400)
		return
	}

	// Response
	fmt.Fprintf(w, "OK\n")
}
⏎
```

### CSS Formatting

```css
/* 2-space indentation */
.container {
  width: 90%;
  max-width: 1400px;
  margin: 0 auto;
}

@media (min-width: 720px) {
  .container {
    width: 98%;
  }
}
⏎
```

### JavaScript Formatting

```javascript
// 2-space indentation
function handleClick(event) {
  event.preventDefault();

  const data = {
    id: 123,
    name: "test"
  };

  fetch('/api/v1/users', {
    method: 'POST',
    body: JSON.stringify(data)
  });
}
⏎
```

### Formatting Rules Summary

**Indentation:**
- **2 spaces**: HTML, JSON, YAML, CSS, JavaScript
- **Tabs**: Go code, Makefiles
- **NEVER mix**: Use consistent indentation throughout file

**Newlines:**
- **Every file**: Ends with exactly one newline
- **Every response**: Ends with exactly one newline
- **No extra blank lines**: At end of files/responses

**Validation:**
```bash
# Check file ends with single newline
tail -c 2 file.txt | od -An -tx1
# Should show: '0a' (one newline) or 'XX 0a' (char + newline)
# Should NOT show: '0a 0a' (two newlines) or no '0a' (no newline)
```

## Content Negotiation (NON-NEGOTIABLE)

**All endpoints respond based on how they are accessed.**

### Accept Header Detection

| Accept Header | Response Format |
|---------------|-----------------|
| `text/html` | HTML (full page or fragment) |
| `application/json` | JSON |
| `text/plain` | Plain text |
| `*/*` or missing | Default for endpoint type |

### Response by Endpoint Type

| Endpoint | Default | Browser | curl/CLI | API Client |
|----------|---------|---------|----------|------------|
| `/` (public pages) | HTML | HTML | Text | HTML |
| `/admin/*` | HTML | HTML | HTML | HTML |
| `/api/v1/*` | JSON | JSON | Text | JSON |
| `/healthz` | HTML | HTML | Text | JSON (Accept: application/json) |
| `*.txt` extension | Text | Text | Text | Text |

### Smart Content Negotiation (NON-NEGOTIABLE)

**Frontend routes (`/**`) have BUILT-IN smart detection:**
- Browser request → HTML
- CLI/curl → text (via User-Agent or lack of browser headers)
- Accept: text/plain → text
- Accept: text/html → HTML

**Frontend routes do NOT need `.txt` extension - smart detection handles it.**

### Backend API Content Negotiation (NON-NEGOTIABLE)

**Backend routes (`/api/**`) default to JSON, but support text output:**

| Condition | Response Format |
|-----------|-----------------|
| Default (browser, API client) | JSON |
| CLI tool detected (User-Agent) | Plain text |
| `.txt` extension (e.g., `/api/v1/joke.txt`) | Plain text |
| `Accept: text/plain` header | Plain text |

**API routes ALWAYS return JSON unless one of the above conditions triggers text output.**

**CLI Tool Detection (User-Agent patterns):**

```go
// isCliTool detects CLI tools that prefer plain text
func isCliTool(r *http.Request) bool {
    ua := r.Header.Get("User-Agent")

    // Our own CLI client
    if strings.HasPrefix(ua, projectName+"-cli/") {
        return true
    }

    // Common CLI tools
    cliTools := []string{
        "curl/", "wget/", "httpie/", "HTTPie/",
        "Wget/", "libcurl/", "python-requests/",
        "Go-http-client/", "axios/", "node-fetch/",
    }
    for _, tool := range cliTools {
        if strings.Contains(ua, tool) {
            return true
        }
    }

    // No User-Agent or empty = likely CLI
    if ua == "" {
        return true
    }

    return false
}

// getAPIResponseFormat determines format for /api/** routes
func getAPIResponseFormat(r *http.Request) string {
    // 1. Check .txt extension
    if strings.HasSuffix(r.URL.Path, ".txt") {
        return "text"
    }

    // 2. Check Accept header
    accept := r.Header.Get("Accept")
    if strings.Contains(accept, "text/plain") {
        return "text"
    }

    // 3. Check if CLI tool
    if isCliTool(r) {
        return "text"
    }

    // 4. Default to JSON
    return "json"
}
```

**`.txt` extension support for API routes:**
- ✓ ALL `/api/v1/*` endpoints
- ✓ Health API endpoints (`/api/v1/healthz`)
- ✓ Project-specific API endpoints
- ✓ Admin API endpoints (`/api/v1/admin/*`)

**API Routes (JSON default, text via CLI/.txt/Accept header):**

| Endpoint | Default | CLI Tool | With `.txt` | Accept: text/plain |
|----------|---------|----------|-------------|-------------------|
| `/api/v1/jokes/random` | JSON | Text | Text | Text |
| `/api/v1/healthz` | JSON | Text | Text | Text |
| `/api/v1/status` | JSON | Text | Text | Text |
| `/api/v1/users/123` | JSON | Text | Text | Text |

**Frontend Routes (smart detection):**

| Endpoint | Browser | CLI/curl | Accept: text/plain | Accept: text/html |
|----------|---------|----------|-------------------|-------------------|
| `/jokes/random` | HTML | Text | Text | HTML |
| `/users/123` | HTML | Text | Text | HTML |
| `/healthz` | HTML | Text | Text | HTML |
| `/` | HTML | Text | Text | HTML |

**Use cases:**

**API with `.txt` extension:**
- `curl https://api.example.com/api/v1/joke/random.txt` → Just the joke text
- `curl https://api.example.com/api/v1/healthz.txt` → "OK" or "ERROR: ..."
- Scripts that need plain output without JSON parsing

**Frontend with smart detection:**
- `curl https://example.com/joke/random` → Auto-detects CLI, returns text (no .txt needed)
- `curl -H "Accept: text/plain" https://example.com/users/123` → Plain text
- Browser visit to `/joke/random` → HTML page
- Command-line tools get text automatically

**Testing:** Test scripts MUST verify:
- API `.txt` extension works
- Frontend smart detection works (browser → HTML, CLI → text)
- Accept headers work on both API and frontend (see PART 29: TESTING & DEVELOPMENT)

### Content Negotiation Priority (NON-NEGOTIABLE)

**For API routes (`/api/v1/*`), response format is determined in this order:**

| Priority | Method | Example | Returns |
|----------|--------|---------|---------|
| **1** | `.txt` extension | `/api/v1/joke.txt` | Plain text (ALWAYS) |
| **2** | `Accept: application/json` header | `Accept: application/json` | JSON |
| **3** | `Accept: text/plain` header | `Accept: text/plain` | Plain text |
| **4** | Default | `/api/v1/joke` | JSON |

**For frontend routes (`/**`), response format is determined in this order:**

| Priority | Method | Example | Returns |
|----------|--------|---------|---------|
| **1** | `Accept: text/html` header | `Accept: text/html` | HTML |
| **2** | `Accept: text/plain` header | `Accept: text/plain` | Plain text |
| **3** | User-Agent (browser detection) | Browser visit | HTML |
| **4** | CLI/curl (no browser UA) | `curl /joke` | Plain text |
| **5** | Default | Any request | HTML |

**Summary:**
- API routes: Support .txt extension + Accept headers + smart defaults
- Frontend routes: Smart detection only (User-Agent + Accept headers)
- No .txt extension needed on frontend - smart detection handles it

### Content Negotiation Implementation

```go
func detectResponseFormat(r *http.Request) string {
    // 1. Check for .txt extension
    if strings.HasSuffix(r.URL.Path, ".txt") {
        return "text/plain"
    }

    // 2. Check Accept header
    accept := r.Header.Get("Accept")

    switch {
    case strings.Contains(accept, "application/json"):
        return "application/json"
    case strings.Contains(accept, "text/plain"):
        return "text/plain"
    case strings.Contains(accept, "text/html"):
        return "text/html"
    default:
        // 3. Default based on endpoint
        if strings.HasPrefix(r.URL.Path, "/api/") {
            return "application/json"
        }
        return "text/html"
    }
}
```

### Response Examples

**JSON (default for `/api/*`):**
```json
{
  "joke": "Why do programmers prefer dark mode? Because light attracts bugs.",
  "category": "programming",
  "id": "joke_123"
}
```

**Text (`.txt` extension or `Accept: text/plain`):**
```
Why do programmers prefer dark mode? Because light attracts bugs.
```

**HTML (browser request):**
```html
<!DOCTYPE html>
<html>
<head><title>Random Joke</title></head>
<body>
  <p>Why do programmers prefer dark mode? Because light attracts bugs.</p>
</body>
</html>
```

## API Types

**ALL PROJECTS GET ALL THREE:**

| Type | Required |
|------|----------|
| REST API | YES (primary) |
| Swagger/OpenAPI | YES |
| GraphQL | YES |

### Swagger & GraphQL Sync (NON-NEGOTIABLE)

**Swagger and GraphQL MUST always be in sync with each other AND with the project's API.**

| Rule | Description |
|------|-------------|
| **Sync with project** | Both MUST reflect current project API at all times |
| **Sync with each other** | Both Swagger and GraphQL expose identical functionality |
| **Auto-generated** | Both specs generated from code (annotations, comments, or schema) |
| **Never manual** | NEVER manually edit OpenAPI JSON or GraphQL schema |
| **Build-time generation** | Specs regenerated on every build |
| **JSON only** | OpenAPI spec uses JSON format only (NO YAML) |
| **Single source of truth** | Code is the source, specs are generated output |
| **Match site theme** | Both UIs styled to match site theme (light/dark/auto) |
| **Standardized locations** | ALWAYS `src/swagger/` and `src/graphql/` (NEVER in root `.`) |

**Standardized File Locations (NON-NEGOTIABLE):**

| Component | Location | Never Use |
|-----------|----------|-----------|
| Swagger handler | `src/swagger/swagger.go` | `./swagger.go`, `swagger/swagger.go` |
| Swagger theming | `src/swagger/theme.go` | `./theme.go`, `public/swagger-theme.css` |
| Swagger annotations | `src/swagger/annotations.go` | `./docs/`, anywhere else |
| GraphQL handler | `src/graphql/graphql.go` | `./graphql.go`, `graphql/graphql.go` |
| GraphQL schema | `src/graphql/schema.go` | `./schema.graphql`, `graph/schema.graphqls` |
| GraphQL resolvers | `src/graphql/resolvers.go` | `./resolvers.go`, anywhere else |
| GraphQL theming | `src/graphql/theme.go` | `./theme.go`, `public/graphql-theme.css` |

**All paths MUST be relative to `src/` directory. Files in project root (`.`) are FORBIDDEN.**

**Sync Flow:**
```
Code Changes (handlers, routes, types)
         │
         ▼
Build Process
         │
         ├──► src/swagger/swagger.go → Generate OpenAPI JSON from code annotations
         │
         └──► src/graphql/schema.go → Generate GraphQL schema from code annotations
         │
         ▼
Both specs automatically in sync with project
```

**Implementation:**
- Use Go struct tags and comments for documentation
- Generate OpenAPI spec at build time (e.g., swaggo/swag)
- Generate GraphQL schema from same structs
- Embed generated specs in binary
- Serve at runtime from embedded files
- All implementation files in `src/swagger/` and `src/graphql/`

**Why both?**
- Swagger: Industry standard, tooling support, code generation
- GraphQL: Flexible queries, reduced over-fetching, modern clients

**NEVER:**
- Manually edit `openapi.json`
- Manually edit GraphQL schema files
- Let specs drift from actual API
- Have endpoints not documented in both
- Put swagger/graphql files in project root (`.`)
- Use relative paths from project root

### Swagger & GraphQL Theming (NON-NEGOTIABLE)

**Both Swagger UI and GraphiQL MUST match the PROJECT-WIDE theme system.**

See the **"Themes (NON-NEGOTIABLE - PROJECT-WIDE)"** section for the complete theme system that applies to the entire project, including Swagger and GraphQL.

**Key Points:**
- Swagger/GraphQL UIs automatically use the same theme as the rest of the application
- Theme switching is synchronized across all components (no page reload)
- BOTH light AND dark themes MUST be easy to read with no color conflicts
- File locations: `src/swagger/theme.go` and `src/graphql/theme.go`

---

**Dark Theme - DEFAULT:**

**Color Palette:**
```css
/* Dark Theme Colors */
--dark-bg: #282a36;           /* Background */
--dark-bg-alt: #1e1f29;       /* Alternate background (topbar, etc.) */
--dark-bg-elevated: #44475a;  /* Elevated elements (inputs, buttons) */
--dark-text: #f8f8f2;         /* Primary text */
--dark-text-muted: #6272a4;   /* Muted text, borders */
--dark-accent-cyan: #8be9fd;  /* Links, GET methods */
--dark-accent-green: #50fa7b; /* Success, POST methods */
--dark-accent-orange: #ffb86c; /* Warning, PUT methods */
--dark-accent-red: #ff5555;   /* Error, DELETE methods */
--dark-accent-purple: #bd93f9; /* Primary accent */
--dark-accent-pink: #ff79c6;  /* Secondary accent */
--dark-accent-yellow: #f1fa8c; /* Highlights */
```

| Element | Style |
|---------|-------|
| Background | `#282a36` (--dark-bg) |
| Text | `#f8f8f2` (--dark-text) |
| Links/Accents | Cyan `#8be9fd`, Green `#50fa7b`, Purple `#bd93f9` |
| Code blocks | Syntax highlighted with dark theme colors |
| Inputs | Dark background `#44475a`, light text `#f8f8f2`, visible borders `#6272a4` |
| Buttons | Accent colors from dark palette |

**Swagger UI - Dark Theme:**

```css
/* Swagger UI - Dark Theme */
.swagger-ui.theme-dark {
  background: #282a36;
  color: #f8f8f2;
}

.swagger-ui.theme-dark .topbar {
  background: #1e1f29;
}

.swagger-ui.theme-dark .info .title,
.swagger-ui.theme-dark .opblock-tag {
  color: #f8f8f2;
}

.swagger-ui.theme-dark .opblock.opblock-get {
  background: rgba(139, 233, 253, 0.1);
  border-color: #8be9fd;
}

.swagger-ui.theme-dark .opblock.opblock-post {
  background: rgba(80, 250, 123, 0.1);
  border-color: #50fa7b;
}

.swagger-ui.theme-dark .opblock.opblock-put {
  background: rgba(255, 184, 108, 0.1);
  border-color: #ffb86c;
}

.swagger-ui.theme-dark .opblock.opblock-delete {
  background: rgba(255, 85, 85, 0.1);
  border-color: #ff5555;
}

.swagger-ui.theme-dark input,
.swagger-ui.theme-dark textarea,
.swagger-ui.theme-dark select {
  background: #44475a;
  color: #f8f8f2;
  border: 1px solid #6272a4;
}

.swagger-ui.theme-dark .btn {
  background: #6272a4;
  color: #f8f8f2;
}
```

**GraphiQL - Dark Theme:**

```css
/* GraphiQL - Dark Theme */
.graphiql-container.theme-dark {
  background: #282a36;
  color: #f8f8f2;
}

.graphiql-container.theme-dark .CodeMirror {
  background: #282a36;
  color: #f8f8f2;
}

.graphiql-container.theme-dark .CodeMirror-gutters {
  background: #1e1f29;
  border-right: 1px solid #44475a;
}

.graphiql-container.theme-dark .result-window {
  background: #282a36;
}

.graphiql-container.theme-dark .execute-button {
  background: #50fa7b;
  color: #282a36;
}

.graphiql-container.theme-dark .toolbar-button {
  background: #44475a;
  color: #f8f8f2;
}
```

---

**Light Theme:**

**Color Palette:**
```css
/* Light Theme Colors */
--light-bg: #ffffff;           /* Background */
--light-bg-alt: #f5f5f5;       /* Alternate background (topbar, etc.) */
--light-bg-elevated: #e0e0e0;  /* Elevated elements, borders */
--light-text: #1a1a1a;         /* Primary text */
--light-text-muted: #666666;   /* Muted text */
--light-accent-blue: #0066cc;  /* Links, GET methods */
--light-accent-green: #008000; /* Success, POST methods */
--light-accent-orange: #ff8c00; /* Warning, PUT methods */
--light-accent-red: #cc0000;   /* Error, DELETE methods */
--light-accent-purple: #6600cc; /* Primary accent */
--light-accent-teal: #008080;  /* Secondary accent */
```

| Element | Style |
|---------|-------|
| Background | `#ffffff` (--light-bg) |
| Text | `#1a1a1a` (--light-text) |
| Links/Accents | Blue `#0066cc`, Green `#008000`, Purple `#6600cc` |
| Code blocks | Syntax highlighted with light theme colors |
| Inputs | White background, dark text, visible borders `#cccccc` |
| Buttons | Accent colors with sufficient contrast (4.5:1 minimum) |

**Swagger UI - Light Theme:**

```css
/* Swagger UI - Light Theme */
.swagger-ui.theme-light {
  background: #ffffff;
  color: #1a1a1a;
}

.swagger-ui.theme-light .topbar {
  background: #f5f5f5;
  border-bottom: 1px solid #e0e0e0;
}

.swagger-ui.theme-light .info .title,
.swagger-ui.theme-light .opblock-tag {
  color: #1a1a1a;
}

.swagger-ui.theme-light .opblock.opblock-get {
  background: rgba(0, 102, 204, 0.05);
  border-color: #0066cc;
}

.swagger-ui.theme-light .opblock.opblock-post {
  background: rgba(0, 128, 0, 0.05);
  border-color: #008000;
}

.swagger-ui.theme-light .opblock.opblock-put {
  background: rgba(255, 140, 0, 0.05);
  border-color: #ff8c00;
}

.swagger-ui.theme-light .opblock.opblock-delete {
  background: rgba(204, 0, 0, 0.05);
  border-color: #cc0000;
}

.swagger-ui.theme-light input,
.swagger-ui.theme-light textarea,
.swagger-ui.theme-light select {
  background: #ffffff;
  color: #1a1a1a;
  border: 1px solid #cccccc;
}

.swagger-ui.theme-light .btn {
  background: #0066cc;
  color: #ffffff;
}
```

**GraphiQL - Light Theme:**

```css
/* GraphiQL - Light Theme */
.graphiql-container.theme-light {
  background: #ffffff;
  color: #1a1a1a;
}

.graphiql-container.theme-light .CodeMirror {
  background: #ffffff;
  color: #1a1a1a;
}

.graphiql-container.theme-light .CodeMirror-gutters {
  background: #f5f5f5;
  border-right: 1px solid #e0e0e0;
}

.graphiql-container.theme-light .result-window {
  background: #ffffff;
}

.graphiql-container.theme-light .execute-button {
  background: #008000;
  color: #ffffff;
}

.graphiql-container.theme-light .toolbar-button {
  background: #f5f5f5;
  color: #1a1a1a;
  border: 1px solid #cccccc;
}
```

---

**Theme Implementation Requirements:**

1. **Theme Detection:**
   - Check `localStorage` or cookie for user preference
   - Fall back to `prefers-color-scheme` media query if auto mode
   - Default to dark if no preference set

2. **Theme Switching:**
   - Provide theme toggle in UI (light/dark/auto)
   - Store preference in `localStorage` or cookie
   - Apply theme class to root element (`theme-light`, `theme-dark`)
   - NO page reload required

3. **Accessibility:**
   - Both themes MUST pass WCAG AA contrast requirements
   - Focus indicators MUST be visible in both themes
   - Keyboard navigation MUST work identically in both themes

## External API Compatibility (NON-NEGOTIABLE)

**Focus on create/init endpoint compatibility and response format matching - NOT replicating entire APIs.**

When the user requests compatibility with external services (e.g., "compatible with pastebin.com", "support microbin clients", "work with opengist"), you MUST focus on **creation endpoints and response formats** - not hundreds of redundant routes.

### Why Limited Compatibility?

**Problem:** Replicating entire external APIs creates hundreds of routes that do mostly the same thing, adding massive complexity for minimal benefit.

**Solution:** Implement ONLY the create/init endpoints and match response formats. This allows existing clients to work while keeping our codebase clean.

### Compatibility Implementation (NON-NEGOTIABLE)

**1. Research the target service:**
   - Look up official API documentation
   - Identify the **create/init endpoint** (how resources are created)
   - Document the **response format** (fields, structure, content-type: JSON/XML/text)
   - Note required request parameters and authentication (if any)

**2. Implement create/init compatibility:**
   - Match the exact URL path for creating resources
   - Support same request method (POST, PUT, etc.)
   - Accept same parameters (query params, form fields, JSON body)
   - Return response in same format with matching field names
   - Preserve response content-type (JSON, XML, plain text, etc.)

**3. Use our standard routes for everything else:**
   - View: Use our standard `/api/v1/{resource}/{id}` pattern
   - List: Use our standard `/api/v1/{resource}` pattern
   - Search: Use our standard `/api/v1/{resource}/search` pattern
   - DO NOT replicate their entire API surface

**Example - Pastebin Compatibility:**

```
User: "Make it compatible with pastebin.com"

AI Research:
- Create endpoint: POST /api/api_post.php
- Parameters: api_paste_code, api_paste_format, api_paste_expire_date
- Response: Plain text paste ID or URL

AI Implementation:
✓ POST /api/api_post.php → Create paste (compatible)
✓ Response format matches (plain text ID)
✗ Skip their /api/list, /api/trends, /api/raw/{id} (use our routes instead)

Result:
- pastebin.com clients can CREATE pastes using familiar endpoint
- Viewing/listing uses OUR standard API routes
- Clean codebase without route duplication
```

**Rules:**
| Rule | Description |
|------|-------------|
| **Research first** | NEVER guess - look up actual API documentation |
| **Create/init only** | Implement creation endpoints, skip view/list/search/delete duplicates |
| **Match response format** | Field names, structure, content-type must match target exactly |
| **Standard routes for rest** | Use our `/api/v1/*` patterns for all other operations |
| **Avoid complexity** | Do NOT add hundreds of redundant routes |
| **Document compatibility** | List what IS and ISN'T compatible in AI.md |

**What to implement:**
- ✓ Create/init endpoints
- ✓ Response format matching
- ✓ Required authentication if applicable

**What NOT to implement:**
- ✗ View/retrieve endpoints (use our routes)
- ✗ List/search endpoints (use our routes)
- ✗ Delete endpoints (use our routes)
- ✗ Pagination variants (use our standard pagination)
- ✗ Any route that duplicates our functionality

### RFC-Based Applications (CRITICAL - NON-NEGOTIABLE)

**IF THE APPLICATION ITSELF IMPLEMENTS AN RFC-DEFINED PROTOCOL, YOU MUST FOLLOW ALL RELEVANT RFCs COMPLETELY.**

This is NOT optional. This is NOT about "adding compatibility." If you're building a protocol implementation, you MUST be RFC-compliant or the application is fundamentally broken.

| Application Type | Required RFCs | Compliance Level |
|------------------|---------------|------------------|
| **DNS Server** | RFC 1034, 1035, 2181, 6891 (EDNS), etc. | FULL - ALL DNS RFCs |
| **DHCP Server** | RFC 2131, 2132, 3046, etc. | FULL - ALL DHCP RFCs |
| **SMTP Server** | RFC 5321, 5322, 6531, etc. | FULL - ALL SMTP RFCs |
| **HTTP Server** | RFC 7230-7235, 9110-9114, etc. | FULL - ALL HTTP RFCs |
| **FTP Server** | RFC 959, 2428, 4217, etc. | FULL - ALL FTP RFCs |
| **NTP Server** | RFC 5905, 5906, etc. | FULL - ALL NTP RFCs |
| **LDAP Server** | RFC 4510-4519, etc. | FULL - ALL LDAP RFCs |
| **WebDAV Server** | RFC 4918, etc. | FULL - ALL WebDAV RFCs |

**Why this is critical:**
- DNS server that violates DNS RFCs = broken DNS, network failures
- SMTP server that violates SMTP RFCs = rejected by mail servers
- DHCP server that violates DHCP RFCs = clients can't get IP addresses
- HTTP server that violates HTTP RFCs = browsers/clients break

**Implementation requirements:**
1. **Research ALL relevant RFCs** for the protocol being implemented
2. **Implement ALL required behavior** per specifications
3. **Follow exact message formats, response codes, headers, etc.**
4. **Handle edge cases and error conditions** as specified
5. **Document which RFCs are implemented** in AI.md

**Example:**
```
User: "Build a DNS server"

AI Response:
"A DNS server MUST comply with DNS RFCs. I'll implement:
- RFC 1034: Domain Names - Concepts and Facilities
- RFC 1035: Domain Names - Implementation and Specification
- RFC 2181: Clarifications to the DNS Specification
- RFC 6891: Extension Mechanisms for DNS (EDNS)
- Additional RFCs for DNSSEC, dynamic updates, etc.

This is mandatory - DNS clients expect RFC-compliant behavior."
```

**This is different from optional compatibility** (see next section).

### Exceptions: Full Compatibility Required

**Some cases require complete API/protocol implementation:**

| Case | Action | Example |
|------|--------|---------|
| **Protocol compliance** | Implement ALL required endpoints | Matrix, ActivityPub, XMPP |
| **Adding RFC feature to existing app** | Follow RFC specification exactly | Adding WebDAV to file server |
| **Explicit user request** | User specifies which endpoints needed | "Also need delete and list endpoints" |

**How to determine:**

**1. Full protocol/standard (Matrix, ActivityPub, WebDAV, etc.):**
```
User: "Build a Matrix homeserver"

AI Response:
"Matrix is a complete protocol requiring full specification compliance.
I'll implement ALL Matrix Client-Server API endpoints per the spec:
- Account registration and login
- Room creation and management
- Event sending and syncing
- Media uploads
- Presence and typing indicators
This is NOT optional - Matrix clients expect the full protocol."
```

**2. RFC compliance:**
```
User: "Add WebDAV support"

AI Response:
"WebDAV is defined by RFC 4918 which requires specific HTTP methods
and behavior. I'll implement:
- PROPFIND, PROPPATCH (property management)
- MKCOL (collection creation)
- COPY, MOVE (resource operations)
- LOCK, UNLOCK (locking mechanism)
All endpoints required for RFC compliance."
```

**3. Simple service compatibility (pastebin, URL shortener, etc.):**
```
User: "Compatible with pastebin.com"

AI Response:
"Pastebin.com is a simple service, not a protocol.
I'll implement:
✓ POST /api/api_post.php (create endpoint)
✗ Skip view/list/delete (use our /api/v1/* routes)

Need additional compatible endpoints?"
```

**Smart determination rules:**

| If compatibility target is... | Then... |
|-------------------------------|---------|
| Full protocol (Matrix, XMPP, ActivityPub) | Implement complete spec |
| RFC-defined standard (WebDAV, CalDAV, CardDAV) | Follow RFC exactly |
| Simple web service (pastebin, URL shortener) | Create/init endpoint only |
| Unclear/ambiguous | Ask user: "Do you need full protocol compliance or just create endpoint compatibility?" |

**When in doubt, ASK the user:**
- "This appears to be a full protocol. Do you need complete specification compliance?"
- "I found 25 endpoints in their API. Do you need all of them, or just create/init compatibility?"
- "RFC 4918 defines 9 required methods. Should I implement the full RFC?"

## Root-Level Endpoints (NON-NEGOTIABLE)

| Endpoint | Method | Auth | Description |
|----------|--------|------|-------------|
| `/` | GET | None | Web interface (HTML) |
| `/healthz` | GET | None | Health check (HTML/JSON/text via content negotiation) |
| `/openapi` | GET | None | Swagger UI |
| `/openapi.json` | GET | None | OpenAPI spec (JSON only) |
| `/graphql` | GET | None | GraphiQL interface |
| `/graphql` | POST | None | GraphQL queries |
| `/metrics` | GET | Optional | Prometheus metrics |
| `/admin` | GET | Session | Admin panel login |
| `/admin/*` | ALL | Session | Admin panel pages |
| `/api/v1/healthz` | GET | None | Health check (JSON) |
| `/api/v1/admin/*` | ALL | Bearer | Admin API |

**NOTE: No `/openapi.yaml` endpoint. JSON only.**

## Response Standards

| Route Type | Response Format |
|------------|-----------------|
| `/` routes | HTML |
| `/api` routes | JSON (default) or text |
| `/api/**/*.txt` | Text |

### Standard Response Formats

**All API responses MUST follow these formats for consistency:**

#### Single Item Response

```json
{
  "id": "item_123",
  "name": "Example",
  "created_at": "2024-01-15T10:30:00Z"
}
```

*Returns the item directly without wrapper.*

#### Action Response (Create, Update, Delete)

```json
{
  "ok": true,
  "data": {
    "id": "item_123",
    "message": "Item created successfully"
  }
}
```

| Field | Required | Description |
|-------|----------|-------------|
| `ok` | Yes | Always `true` for success |
| `data` | Yes | Response payload |
| `data.id` | If created | ID of created/affected resource |
| `data.message` | No | Human-readable status message |

#### Error Response

```json
{
  "ok": false,
  "error": "ERROR_CODE",
  "message": "Human readable message"
}
```

| Field | Required | Description |
|-------|----------|-------------|
| `error` | Yes | Human-readable error message |
| `code` | Yes | Machine-readable error code (e.g., `INVALID_INPUT`, `NOT_FOUND`) |
| `status` | Yes | HTTP status code |
| `details` | No | Additional error context (validation errors, field names) |

#### Pagination (default: 250 items)

```json
{
  "data": [],
  "pagination": {
    "page": 1,
    "limit": 250,
    "total": 1000,
    "pages": 4
  }
}
```

---

# CHECKPOINT 6: FRONTEND & API VERIFICATION

Before proceeding, confirm you understand:
- [ ] Frontend is required for ALL projects
- [ ] NO inline CSS, NO JS alerts
- [ ] Project-wide theme system: light/dark/auto (dark is default)
- [ ] Themes apply to entire project: web UI, admin, Swagger, GraphQL
- [ ] All 3 API types required: REST, Swagger, GraphQL (Swagger & GraphQL in sync)
- [ ] Standard endpoints must exist (/healthz, /openapi, /openapi.json, /graphql, /admin)
- [ ] OpenAPI uses JSON only (no YAML)

---

# PART 15: SSL/TLS & LET'S ENCRYPT (NON-NEGOTIABLE)

## Built-in Let's Encrypt Support

**ALL projects MUST have built-in Let's Encrypt support.**

### Supported Challenge Types

| Type | Description |
|------|-------------|
| HTTP-01 | HTTP-based challenge (default, requires port 80) |
| TLS-ALPN-01 | TLS-based challenge (requires port 443) |
| DNS-01 | DNS TXT record challenge (wildcard certs, no port requirements) |

### DNS-01 Provider Configuration

**ALL DNS providers are supported.** The admin WebUI provides a dropdown that dynamically shows the appropriate credential fields based on the selected provider.

**Admin WebUI Flow (`/admin/server/ssl`):**

1. Select DNS provider from dropdown (all lego-supported providers available)
2. Form dynamically shows required credential fields for that provider
3. Submit credentials → app validates by attempting DNS API connection
4. On success, credentials are **encrypted** and stored for reuse
5. Certificate requests use stored encrypted credentials

**Provider Credential Storage:**

| Field | Description |
|-------|-------------|
| `provider` | Provider identifier (e.g., `cloudflare`, `route53`) |
| `credentials_encrypted` | AES-256-GCM encrypted JSON of provider credentials |
| `validated_at` | Timestamp of last successful validation |

**Common Providers (examples):**

| Provider | Required Fields |
|----------|-----------------|
| `cloudflare` | `api_token` OR (`api_key` + `email`) |
| `route53` | `access_key_id`, `secret_access_key`, `region` |
| `digitalocean` | `auth_token` |
| `godaddy` | `api_key`, `api_secret` |
| `namecheap` | `api_user`, `api_key`, `client_ip` |
| `rfc2136` | `nameserver`, `tsig_key`, `tsig_secret`, `tsig_algorithm` |

**Note:** Full provider list from [lego DNS providers](https://go-acme.github.io/lego/dns/). Fields are determined dynamically at runtime.

**See PART 35: CUSTOM DOMAINS for user/org custom domain support (optional per-project feature).**

### FQDN Resolution (NON-NEGOTIABLE)

**See PART 8: SERVER BINARY CLI → "URL Variables" section for complete `{proto}`, `{fqdn}`, `{port}` resolution.**

**Summary - `{fqdn}` resolution order:**

| Priority | Source |
|----------|--------|
| 1 | Reverse Proxy Headers (`X-Forwarded-Host`, etc.) |
| 2 | `DOMAIN` env var |
| 3 | `os.Hostname()` |
| 4 | `$HOSTNAME` env var |
| 5 | Public IPv6 (excludes private/link-local) |
| 6 | Public IPv4 (excludes 10/8, 172.16/12, 192.168/16) |
| 7 | `localhost` |

**We prefer to run behind a reverse proxy. Reverse proxy headers take priority.**

**DOMAIN Usage:**

| Environment | DOMAIN Value | Example |
|-------------|--------------|---------|
| **Development** | `weather` | `DOMAIN=jokes` |
| **Production** | Valid FQDN | `DOMAIN=api.example.com` |

**Valid Production DOMAIN formats (comma-separated list supported):**
```
# Single domain
DOMAIN=example.com
DOMAIN=api.example.com

# Multiple domains (first is primary, auto-infers wildcard)
DOMAIN=myapp.com,www.myapp.com,api.myapp.com
# Result: fqdn=myapp.com, wildcard=*.myapp.com, CORS includes all

# Complex TLDs work too
DOMAIN=google.co.uk,www.google.co.uk
```

**Do NOT set DOMAIN to overlay network addresses:**
- `.onion`, `.i2p`, `.exit` - these are app-generated and managed
- App handles overlay network registration/generation automatically
- Overlay addresses shown separately in console (see below)

**Go Implementation:**
```go
// GetHostFromRequest - use this for request-time host resolution (preferred)
func GetHostFromRequest(r *http.Request, projectName string) string {
    // 1. Reverse proxy headers (highest priority - we prefer to be behind a proxy)
    for _, header := range []string{"X-Forwarded-Host", "X-Real-Host", "X-Original-Host"} {
        if host := r.Header.Get(header); host != "" {
            // Strip port if present (we handle port separately)
            if h, _, err := net.SplitHostPort(host); err == nil {
                return h
            }
            return host
        }
    }

    // 2. Fall back to static resolution
    return GetFQDN(projectName)
}

// GetFQDN - use this when no request context available (startup, background tasks)
// Returns first domain from DOMAIN env var (comma-separated list supported)
func GetFQDN(projectName string) string {
    // 1. DOMAIN env var (explicit user override, comma-separated)
    if domain := os.Getenv("DOMAIN"); domain != "" {
        // Return first domain as primary
        if idx := strings.Index(domain, ","); idx > 0 {
            return strings.TrimSpace(domain[:idx])
        }
        return domain
    }

    // 2. os.Hostname() - cross-platform (Linux, macOS, Windows, BSD)
    if hostname, err := os.Hostname(); err == nil && hostname != "" {
        if !isLoopback(hostname) {
            return hostname
        }
    }

    // 3. $HOSTNAME env var (skip loopback)
    if hostname := os.Getenv("HOSTNAME"); hostname != "" {
        if !isLoopback(hostname) {
            return hostname
        }
    }

    // 4. Global IPv6 (preferred for modern networks)
    if ipv6 := getGlobalIPv6(); ipv6 != "" {
        return ipv6
    }

    // 5. Global IPv4
    if ipv4 := getGlobalIPv4(); ipv4 != "" {
        return ipv4
    }

    // Last resort (not recommended)
    return "localhost"
}

func isLoopback(host string) bool {
    lower := strings.ToLower(host)
    if lower == "localhost" {
        return true
    }
    if ip := net.ParseIP(host); ip != nil {
        return ip.IsLoopback()
    }
    return false
}

// getGlobalIPv6 returns first public IPv6 address
// Excludes: loopback (::1), link-local (fe80::/10), unique local (fc00::/7)
func getGlobalIPv6() string {
    addrs, err := net.InterfaceAddrs()
    if err != nil {
        return ""
    }
    for _, addr := range addrs {
        if ipnet, ok := addr.(*net.IPNet); ok {
            ip := ipnet.IP
            // Must be IPv6 (not IPv4), globally routable, and not private
            if ip.To4() == nil && ip.IsGlobalUnicast() && !ip.IsPrivate() {
                return ip.String()
            }
        }
    }
    return ""
}

// getGlobalIPv4 returns first public IPv4 address
// Excludes: loopback (127.0.0.0/8), private (10/8, 172.16/12, 192.168/16), link-local (169.254/16)
func getGlobalIPv4() string {
    addrs, err := net.InterfaceAddrs()
    if err != nil {
        return ""
    }
    for _, addr := range addrs {
        if ipnet, ok := addr.(*net.IPNet); ok {
            ip := ipnet.IP
            // Must be IPv4, globally routable, and not private
            // Note: IsGlobalUnicast() alone is NOT enough for IPv4 (returns true for private)
            if ip4 := ip.To4(); ip4 != nil && ip.IsGlobalUnicast() && !ip.IsPrivate() {
                return ip4.String()
            }
        }
    }
    return ""
}

// isPublicIP checks if an IP is publicly routable (not private, loopback, or link-local)
func isPublicIP(ip net.IP) bool {
    return ip.IsGlobalUnicast() && !ip.IsPrivate() && !ip.IsLoopback() && !ip.IsLinkLocalUnicast()
}

// GetAllDomains returns all domains from DOMAIN env var
// Used for CORS configuration and SSL certificates
func GetAllDomains() []string {
    domain := os.Getenv("DOMAIN")
    if domain == "" {
        return nil
    }
    parts := strings.Split(domain, ",")
    domains := make([]string, 0, len(parts))
    for _, p := range parts {
        if d := strings.TrimSpace(p); d != "" {
            domains = append(domains, d)
        }
    }
    return domains
}

// GetWildcardDomain infers wildcard from DOMAIN list or learned patterns
// Returns "*.example.com" if multiple subdomains share same base, else ""
func GetWildcardDomain() string {
    domains := GetAllDomains()
    if len(domains) < 2 {
        // Need multiple to infer wildcard
        return ""
    }

    // Extract base domain from first (primary)
    base := extractBaseDomain(domains[0])

    // Check if all share same base
    for _, d := range domains[1:] {
        if extractBaseDomain(d) != base {
            // Different base domains, no wildcard
            return ""
        }
    }

    return "*." + base
}

// extractBaseDomain gets eTLD+1 using publicsuffix
func extractBaseDomain(domain string) string {
    // Uses golang.org/x/net/publicsuffix
    base, err := publicsuffix.EffectiveTLDPlusOne(domain)
    if err != nil {
        return domain
    }
    return base
}
```

**Note:** For production SSL/Let's Encrypt, always set `DOMAIN` explicitly:
```bash
# Single domain
export DOMAIN=api.example.com

# Multiple domains (first is primary, all get SSL certs)
export DOMAIN=myapp.com,www.myapp.com,api.myapp.com
```

**The resolved FQDN is used for:**
- SSL certificate lookup and generation
- Let's Encrypt certificate requests
- `server.host` default value (if not configured)

### Dev TLD Handling (NON-NEGOTIABLE)

**Dev TLDs are allowed in development mode but require global IP fallback for remote access.**

**Dynamic Dev TLDs (project name as TLD):**
- `weather` - e.g., `app.jokes`, `my.quotes`, `dev.api`
- `weather.local` - e.g., `app.jokes.local`
- `weather.test` - e.g., `app.jokes.test`

**Static Dev TLDs:**
- `.local`, `.test`, `.example`, `.invalid` (RFC 6761)
- `.localhost`, `.lan`, `.internal`, `.home`, `.localdomain`
- `.home.arpa`, `.intranet`, `.corp`, `.private`

**Get display URL (returns ONE URL):**

```go
// GetDisplayURL returns the best URL for display/access
// Prefers valid FQDN, falls back to global IP if dev TLD
// isHTTPS: true if this is the HTTPS port (second port in dual mode)
func GetDisplayURL(projectName string, port int, isHTTPS bool) string {
    fqdn := GetFQDN(projectName)

    // If valid production FQDN, use it
    if !isDevTLD(fqdn, projectName) && fqdn != "localhost" {
        return formatURL(fqdn, port, isHTTPS)
    }

    // Dev TLD or localhost - use global IP instead
    if ipv6 := getGlobalIPv6(); ipv6 != "" {
        return formatURL("["+ipv6+"]", port, isHTTPS)
    }
    if ipv4 := getGlobalIPv4(); ipv4 != "" {
        return formatURL(ipv4, port, isHTTPS)
    }

    // Last resort
    return formatURL(fqdn, port, isHTTPS)
}

func isDevTLD(host, projectName string) bool {
    lower := strings.ToLower(host)

    // Check dynamic project-specific TLD (e.g., app.jokes, dev.quotes, quotes, jokes, weather)
    if projectName != "" && strings.HasSuffix(lower, "."+strings.ToLower(projectName)) {
        return true
    }

    // Check static dev TLDs
    for tld := range devOnlyTLDs {
        if strings.HasSuffix(lower, "."+tld) || lower == tld {
            return true
        }
    }

    return false
}
```

**Startup Banner - Pretty Console with Icons:**

**IMPORTANT: Logs are ALWAYS raw text. No icons, ASCII art, or special characters in log output.**

| Element | Icon | Usage |
|---------|------|-------|
| App name | 🚀 | Header |
| Version | 📦 | Version info |
| Production mode | 🔒 | Mode indicator |
| Development mode | 🔧 | Mode indicator |
| Debugging | 🐛 | Debug flag active |
| Tor/Onion | 🧅 | Overlay network |
| I2P | 🔗 | Overlay network |
| SSL/HTTPS | 🔐 | Secure connection |
| HTTP | 🌐 | Non-secure connection |
| IPv6 | 🌍 | Network address |
| IPv4 | 🌐 | Network address |
| Success | ✅ | Status |
| Warning | ⚠️ | Status |
| Error | ❌ | Status |
| Info | ℹ️ | Status |

### Responsive Startup Banner (NON-NEGOTIABLE)

**Banner MUST adapt to terminal size. Phone SSH users are common.**

| Terminal Size | Banner Style | Example |
|---------------|--------------|---------|
| **≥80 cols** | Full ASCII art + icons + URLs | Full branded banner |
| **60-79 cols** | Icons + text only, no ASCII art | `🚀 AppName v1.0.0` |
| **40-59 cols** | Minimal text, abbreviated | `AppName 1.0.0 :8080` |
| **<40 cols** | Single line only | `AppName :8080` |

```go
// src/server/banner/banner.go
package banner

import (
    "fmt"
    "os"
    "golang.org/x/term"
)

func Print(appName, version, mode string, urls []string) {
    width, _, _ := term.GetSize(int(os.Stdout.Fd()))
    if width == 0 {
        width = 80 // Default
    }

    switch {
    case width >= 80:
        printFullBanner(appName, version, mode, urls)
    case width >= 60:
        printCompactBanner(appName, version, mode, urls)
    case width >= 40:
        printMinimalBanner(appName, version, urls)
    default:
        printMicroBanner(appName, urls)
    }
}

func printFullBanner(appName, version, mode string, urls []string) {
    // Full ASCII art logo
    fmt.Println(getASCIIArt(appName))
    fmt.Println()
    fmt.Printf("🚀 %s v%s\n", appName, version)
    printModeLine(mode, true)
    fmt.Println()
    for _, url := range urls {
        fmt.Printf("  🌐 %s\n", url)
    }
    fmt.Println()
}

func printCompactBanner(appName, version, mode string, urls []string) {
    // No ASCII art, just icons and text
    fmt.Printf("🚀 %s v%s\n", appName, version)
    printModeLine(mode, true)
    for _, url := range urls {
        fmt.Printf("🌐 %s\n", url)
    }
}

func printMinimalBanner(appName, version string, urls []string) {
    // Abbreviated, no icons
    fmt.Printf("%s %s\n", appName, version)
    for _, url := range urls {
        // Extract just host:port
        fmt.Println(extractHostPort(url))
    }
}

func printMicroBanner(appName string, urls []string) {
    // Single line for very narrow terminals
    if len(urls) > 0 {
        fmt.Printf("%s %s\n", appName, extractHostPort(urls[0]))
    } else {
        fmt.Println(appName)
    }
}

func printModeLine(mode string, useIcons bool) {
    if useIcons {
        icon := "🔒"
        if mode == "development" {
            icon = "🔧"
        }
        fmt.Printf("%s Running in mode: %s\n", icon, mode)
    } else {
        fmt.Printf("Mode: %s\n", mode)
    }
}
```

**Terminal Size Detection on Startup:**
```go
// In main.go or server init
func init() {
    width, height, _ := term.GetSize(int(os.Stdout.Fd()))

    // Store for use throughout application
    runtime.TerminalWidth = width
    runtime.TerminalHeight = height

    // Log terminal size in debug mode
    if config.Debug {
        log.Printf("Terminal size: %dx%d", width, height)
    }
}
```

**Resize Handling (for long-running servers):**
```go
// Handle SIGWINCH for terminal resize
func watchTerminalSize(ctx context.Context) {
    sigCh := make(chan os.Signal, 1)
    signal.Notify(sigCh, syscall.SIGWINCH)

    for {
        select {
        case <-ctx.Done():
            return
        case <-sigCh:
            width, height, _ := term.GetSize(int(os.Stdout.Fd()))
            runtime.TerminalWidth = width
            runtime.TerminalHeight = height
        }
    }
}
```

**Mode Line (NON-NEGOTIABLE):**

Displayed immediately after the header line, before URLs. Shows current mode and debug status.

| Mode | Debug | Output |
|------|-------|--------|
| production | false | `🔒 Running in mode: production` |
| production | true | `🔒 Running in mode: production [debugging]` |
| development | false | `🔧 Running in mode: development` |
| development | true | `🔧 Running in mode: development [debugging]` |

**Note:** Development mode always has debug features enabled internally, but `[debugging]` only shows when `--debug` flag or `DEBUG=true` is explicitly set.

**Port Configuration (Project-Wide, NON-NEGOTIABLE):**

| Mode | Config | HTTP Port | HTTPS Port |
|------|--------|-----------|------------|
| Single HTTP | `--port 8080` | 8080 | None |
| Single HTTPS | `--port 443` | None | 443 |
| Dual | `--port 80,443` | 80 | 443 |
| Dual | `--port 8080,8443` | 8080 | 8443 |

**Rules:**
- Single port: HTTP by default
- **Exception: If single port is 443 → HTTPS-only mode**
- Dual ports: First = HTTP, Second = HTTPS
- **Override: `CONFIG(ssl.enabled)` can override HTTP → HTTPS on any port**

**URL Format Rule:**

**ALWAYS strip :80 and :443.**

| Port | Protocol | URL |
|------|----------|-----|
| 80 | HTTP | `http://host` |
| 443 | HTTPS | `https://host` |
| Other | Depends on config | `{proto}://host:{port}` |

```go
func formatURL(host string, port int, isHTTPS bool) string {
    proto := "http"
    if isHTTPS || port == 443 {
        proto = "https"
    }

    // Always strip :80 and :443
    if port == 80 || port == 443 {
        return proto + "://" + host
    }

    return fmt.Sprintf("%s://%s:%d", proto, host, port)
}
```

**Usage:**
```go
// Single HTTP port
// Returns: http://host:8080
formatURL(host, 8080, false)

// Single HTTPS port (443 = HTTPS-only mode)
// Returns: https://host (443 forces HTTPS)
formatURL(host, 443, false)

// Dual port mode
// Returns: http://host
formatURL(host, 80, false)
// Returns: https://host
formatURL(host, 443, true)
// Returns: http://host:8080
formatURL(host, 8080, false)
// Returns: https://host:8443
formatURL(host, 8443, true)
```

**Overlay Network Protocol Rules (Tor, I2P, etc.):**

| Network | Default | HTTPS-Only Mode | Certificate |
|---------|---------|-----------------|-------------|
| Clearnet | HTTP/HTTPS | Port 443 | Let's Encrypt or local |
| Tor (.onion) | HTTP | When clearnet is HTTPS-only | Self-signed (LE doesn't support .onion) |
| I2P (.i2p) | HTTP | When clearnet is HTTPS-only | Self-signed (LE doesn't support .i2p) |

**Rules:**
- Overlay networks inherit HTTPS-only mode from clearnet configuration
- If clearnet port is 443 (HTTPS-only) → overlay also uses HTTPS
- If clearnet is dual port (80,443) → overlay uses HTTP (encryption provided by overlay)
- Overlay HTTPS requires self-signed certificates (Let's Encrypt doesn't support .onion/.i2p)

**Banner Examples:**

| Clearnet Config | Tor URL | I2P URL |
|-----------------|---------|---------|
| `--port 8080` | `http://{onion}.onion` | `http://{i2p}.b32.i2p` |
| `--port 443` | `https://{onion}.onion` | `https://{i2p}.b32.i2p` |
| `--port 80,443` | `http://{onion}.onion` | `http://{i2p}.b32.i2p` |
| `--port 8080,8443` | `http://{onion}.onion` | `http://{i2p}.b32.i2p` |

**Why HTTP for overlays in dual mode?**
- Tor/I2P provide end-to-end encryption at the network layer
- HTTPS adds overhead without additional security benefit
- Only use HTTPS on overlays when HTTPS-only mode is required (port 443)

**Footer timestamp format:** `%B %d, %Y at %H:%M:%S %Z` → `June 27, 2026 at 16:15:12 EST`

**"Last update" MUST use build date, NOT hardcoded.** Use `BUILD_DATE` from build process.

**Example (Production with SSL + Tor on 443):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 WEATHER · 📦 {projectversion}                      │
├─────────────────────────────────────────────────────────────┤
│  🔒 Running in mode: production                             │
├─────────────────────────────────────────────────────────────┤
│  🧅 Tor    http://abc123def456ghi789jklmnop.onion           │
│  🔐 HTTPS  https://api.example.com                          │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on https://203.0.113.50                       │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯
```

**Example (Production with Tor + I2P on 443):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 WEATHER · 📦 {projectversion}                      │
├─────────────────────────────────────────────────────────────┤
│  🔒 Running in mode: production                             │
├─────────────────────────────────────────────────────────────┤
│  🧅 Tor    http://abc123def456ghi789jklmnop.onion           │
│  🔗 I2P    http://xyz789abc123def456uvwxyz.b32.i2p          │
│  🔐 HTTPS  https://api.example.com                          │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on https://203.0.113.50                       │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯
```

**Example (Production on port 8080):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 WEATHER · 📦 {projectversion}                      │
├─────────────────────────────────────────────────────────────┤
│  🔒 Running in mode: production                             │
├─────────────────────────────────────────────────────────────┤
│  🌐 HTTP   http://api.example.com:8080                      │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on http://203.0.113.50:8080                   │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯
```

**Example (Development on port 8080):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 WEATHER · 📦 {projectversion}                      │
├─────────────────────────────────────────────────────────────┤
│  🔧 Running in mode: development                            │
├─────────────────────────────────────────────────────────────┤
│  🌐 HTTP   http://192.168.1.100:8080                        │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on http://192.168.1.100:8080                  │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯
```

**Example (Development IPv6 on port 8080):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 WEATHER · 📦 {projectversion}                      │
├─────────────────────────────────────────────────────────────┤
│  🔧 Running in mode: development                            │
├─────────────────────────────────────────────────────────────┤
│  🌍 IPv6   http://[2001:db8::1]:8080                        │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on http://[2001:db8::1]:8080                  │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯
```

**Example (Production on port 80):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 WEATHER · 📦 {projectversion}                      │
├─────────────────────────────────────────────────────────────┤
│  🔒 Running in mode: production                             │
├─────────────────────────────────────────────────────────────┤
│  🌐 HTTP   http://api.example.com                           │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on http://203.0.113.50                        │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯
```

**Example (Production with debugging enabled):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 WEATHER · 📦 {projectversion}                      │
├─────────────────────────────────────────────────────────────┤
│  🔒 Running in mode: production [debugging]                 │
├─────────────────────────────────────────────────────────────┤
│  🌐 HTTP   http://api.example.com                           │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on http://203.0.113.50                        │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯
```

**Example (First Run - Setup Required):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 WEATHER · 📦 {projectversion}                      │
├─────────────────────────────────────────────────────────────┤
│  🔧 Running in mode: development                            │
├─────────────────────────────────────────────────────────────┤
│  🌐 HTTP   http://192.168.1.100:8080                        │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on http://192.168.1.100:8080                  │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯

┌─────────────────────────────────────────────────────────────┐
│  🔑 SETUP REQUIRED                                          │
├─────────────────────────────────────────────────────────────┤
│  Setup Token: a1b2c3d4e5f67890abcdef1234567890              │
│                                                             │
│  Go to /admin and enter this token to complete setup.       │
│  This token will only be shown ONCE.                        │
└─────────────────────────────────────────────────────────────┘
```

**Note:** Setup token is displayed ONCE on first run. After setup wizard is completed, this section never appears again.

### Console vs Logs (NON-NEGOTIABLE)

| Output | Icons | ASCII Art | Colors | Format |
|--------|-------|-----------|--------|--------|
| **Startup banner** | ✅ Responsive | ✅ If ≥80 cols | ✅ Yes | Pretty, adapts to terminal |
| **Interactive console** | ✅ Yes | ✅ Yes | ✅ Yes | Pretty |
| **Log files** | ❌ Never | ❌ Never | ❌ Never | Raw text |
| **Log output (stdout)** | ❌ Never | ❌ Never | ❌ Never | Raw text |

**Note:** Startup banner adapts to terminal width. ASCII art only shown at ≥80 columns. Icons reduced at <60 columns. See "Responsive Startup Banner" section.

**Log format is ALWAYS plain text:**
```
2025-01-15 09:00:00 INFO  Server started on :8080
2025-01-15 09:00:01 INFO  Database connected
2025-01-15 09:00:05 WARN  High memory usage: 85%
2025-01-15 09:00:10 ERROR Connection timeout to upstream
```

**Never this in logs:**
```
✅ Server started    <- NO icons in logs
🔧 Development mode  <- NO icons in logs
```

### Certificate Lookup Order (NON-NEGOTIABLE)

**On startup, check for existing certificates in this order:**

| Priority | Path | Description |
|----------|------|-------------|
| 1 | `/etc/letsencrypt/live/domain/` | Literal "domain" directory (common shared setup) |
| 2 | `/etc/letsencrypt/live/{fqdn}/` | FQDN-named directory (e.g., `/etc/letsencrypt/live/api.example.com/`) |
| 3 | `{config_dir}/ssl/letsencrypt/{fqdn}/` | App-managed Let's Encrypt certificates |
| 4 | `{config_dir}/ssl/local/{fqdn}/` | Self-signed or user-provided certificates |

**Certificate Validation:**
- Certificate CN or SAN must match configured FQDN (`server.host`)
- Certificate must not be expired
- Both cert and key files must be readable

### Certificate Directory Structure

```
{config_dir}/ssl/
├── letsencrypt/
│   └── {fqdn}/                # e.g., api.example.com/
│       ├── fullchain.pem
│       └── privkey.pem
└── local/
    └── {fqdn}/                # e.g., api.example.com/
        ├── cert.pem
        └── key.pem
```

**Mirrors certbot structure** (`/etc/letsencrypt/live/{fqdn}/`) for consistency.

### Certificate Management Ownership

| Location | Manager | Renewal |
|----------|---------|---------|
| `/etc/letsencrypt/live/**` | **System** (certbot) | App does NOT renew |
| `{config_dir}/ssl/letsencrypt/{fqdn}/` | **App** | Auto-renew 7 days before expiry |
| `{config_dir}/ssl/local/{fqdn}/` | **User** | No auto-renewal (manual) |

**Rule: If cert is in `{config_dir}/ssl/**`, app manages. Subdirectory determines HOW.**

### Renewal Rules

| Directory | Check Frequency | Renewal Trigger |
|-----------|-----------------|-----------------|
| `{config_dir}/ssl/letsencrypt/{fqdn}/` | Daily (03:00) | 7 days before expiry |
| `{config_dir}/ssl/local/{fqdn}/` | Never | Manual only |
| `/etc/letsencrypt/live/**` | Never | System (certbot) manages |

**Logic Flow:**
```
Startup (for configured FQDN)
   │
   ├─► Check /etc/letsencrypt/live/domain/
   │   └─► Found + cert matches FQDN? → Use it (system manages)
   │
   ├─► Check /etc/letsencrypt/live/{fqdn}/
   │   └─► Found? → Use it (system manages)
   │
   ├─► Check {config_dir}/ssl/letsencrypt/{fqdn}/
   │   └─► Found? → Use it (app auto-renews)
   │
   ├─► Check {config_dir}/ssl/local/{fqdn}/
   │   └─► Found? → Use it (no auto-renewal)
   │
   └─► Not found anywhere
       └─► Request new cert via Let's Encrypt
           └─► Save to {config_dir}/ssl/letsencrypt/{fqdn}/ (app auto-renews)
```

**Important:**
- `/etc/letsencrypt/` → app uses but does NOT manage renewal
- `{config_dir}/ssl/letsencrypt/{fqdn}/` → app manages, auto-renews 7 days before expiry
- `{config_dir}/ssl/local/{fqdn}/` → app uses but does NOT auto-renew (user manages)

---


# PART 16: WEB FRONTEND (NON-NEGOTIABLE)

## Requirements

**ALL PROJECTS MUST HAVE A PROFESSIONAL, WELL-DESIGNED, FULLY FUNCTIONAL FRONTEND.**

| Requirement | Description |
|-------------|-------------|
| **Fully Functional** | ALL features work in browser - not just API |
| **Professional UI/UX** | Clean, modern, polished design |
| **Mobile Support** | Full responsive design with touch-friendly targets |
| **HTML5** | Full web standards compliance |
| **Accessibility** | WCAG 2.1 AA compliant, screen reader friendly |
| **UX** | Readable, navigable, intuitive, user-friendly, self-explanatory |
| **PWA Support** | Progressive Web App - installable, offline-capable |
| **CORS** | `Access-Control-Allow-Origin: *` for API endpoints |

## Frontend Consumes Backend (NON-NEGOTIABLE)

**API is the source of truth. Frontend fully integrates with relevant API endpoints.**

| Rule | Description |
|------|-------------|
| **API first** | Backend API works standalone, frontend consumes it |
| **User features in browser** | All user-facing API features accessible via frontend |
| **Same validation** | Frontend validates same rules as backend |
| **Real-time feedback** | Frontend shows success/error from backend responses |

**User-facing features work in browser. System/agent endpoints are API-only (see PART 14).**

### Frontend Route Structure

| API Route | Frontend Route | Page Type |
|-----------|----------------|-----------|
| `GET /api/v1/users` | `GET /users` | Current user profile |
| `PATCH /api/v1/users` | `POST /users` | Profile update form |
| `GET /api/v1/users/tokens` | `GET /users/tokens` | Token list page |
| `GET /api/v1/users/settings` | `GET /users/settings` | User settings page |
| `GET /api/v1/users/security` | `GET /users/security` | Security settings page |
| `GET /api/v1/orgs` | `GET /orgs` | User's org list |
| `GET /api/v1/orgs/{slug}` | `GET /orgs/{slug}` | Org detail page |
| `GET /api/v1/server/about` | `GET /server/about` | About page |

### Vanity URLs (OPTIONAL - Requires PART 33/34)

**For apps with public user/org profiles, support short vanity URLs at root level.**

This is OPTIONAL and only applies to apps where user/org profiles are a core feature (social platforms, code hosting, link aggregators, etc.).

| Vanity URL | Maps To | API Equivalent | Example Apps |
|------------|---------|----------------|--------------|
| `/{username}` | `/users/{username}` | `/api/v1/users/{username}` | GitHub, Linktree, Twitter |
| `/{orgname}` | `/orgs/{orgname}` | `/api/v1/orgs/{orgname}` | GitHub, GitLab, Gitea |
| `/{username}/{project}` | `/users/{username}/{project}` | `/api/v1/users/{username}/projects/{project}` | GitHub repos |
| `/{orgname}/{project}` | `/orgs/{orgname}/{project}` | `/api/v1/orgs/{orgname}/projects/{project}` | GitHub org repos |

**Route Priority (NON-NEGOTIABLE when implemented):**

```
1. /api/v1/*          → API routes (highest priority)
2. /{adminpath}/*     → Admin panel (configurable path)
3. /healthz           → Health check
4. /static/*          → Static assets
5. /users/*           → Explicit user routes
6. /orgs/*            → Explicit org routes
7. /{reserved}        → Reserved names (see below)
8. /{username}        → User vanity URL (lowest priority)
9. /{orgname}         → Org vanity URL (if no user match)
```

**Reserved Names (MUST block from registration):**

```go
var reservedNames = []string{
    // System routes
    "api", "admin", "static", "assets", "healthz", "metrics",
    "login", "logout", "register", "signup", "signin", "auth",
    "oauth", "callback", "webhook", "webhooks",

    // Common paths
    "users", "orgs", "organizations", "teams", "groups",
    "settings", "profile", "account", "dashboard",
    "search", "explore", "discover", "trending",
    "help", "support", "docs", "documentation",
    "about", "contact", "terms", "privacy", "legal",

    // Technical
    "graphql", "rest", "rpc", "ws", "websocket",
    "cdn", "media", "uploads", "files", "images",
    ".well-known", "robots.txt", "sitemap.xml", "favicon.ico",

    // Project-specific (add yours in PART 37)
}
```

**Resolution Logic:**

A single `/{slug}` route handles both users and orgs:

```go
// Route: GET /{slug}
// Route: GET /{slug}/{sub}
// Route: GET /{slug}/{sub}/{item}

func vanityHandler(w http.ResponseWriter, r *http.Request) {
    slug := chi.URLParam(r, "slug")
    sub := chi.URLParam(r, "sub")      // optional: repo, project, etc.
    item := chi.URLParam(r, "item")    // optional: file, issue, etc.

    routeType, id := resolveVanityURL(slug)

    switch routeType {
    case "user":
        // /{username} → proxy to /api/v1/users/{username}
        // /{username}/{repo} → proxy to /api/v1/users/{username}/repos/{repo}
        proxyToUserAPI(w, r, id, sub, item)
    case "org":
        // /{orgname} → proxy to /api/v1/orgs/{orgname}
        // /{orgname}/{repo} → proxy to /api/v1/orgs/{orgname}/repos/{repo}
        proxyToOrgAPI(w, r, id, sub, item)
    case "reserved":
        http.Redirect(w, r, "/"+slug, http.StatusFound) // let normal router handle
    default:
        renderNotFound(w, r, slug) // "user/org not found" page
    }
}

func resolveVanityURL(slug string) (routeType string, id string) {
    // 1. Check reserved names first
    if isReserved(slug) {
        return "reserved", ""
    }

    // 2. Check if user exists
    if user, err := db.GetUserByUsername(slug); err == nil {
        return "user", user.ID
    }

    // 3. Check if org exists (if orgs enabled)
    if org, err := db.GetOrgBySlug(slug); err == nil {
        return "org", org.ID
    }

    // 4. Not found
    return "notfound", ""
}
```

**Route Registration:**

```go
// Vanity routes (lowest priority - registered last)
r.Get("/{slug}", vanityHandler)
r.Get("/{slug}/{sub}", vanityHandler)
r.Get("/{slug}/{sub}/{item}", vanityHandler)
```

**Custom Domain + Vanity URL (PART 35):**

When custom domains are enabled, the vanity URL becomes the root:

| Setup | URL | Shows |
|-------|-----|-------|
| Default | `example.com/johndoe` | John's profile |
| Custom domain | `johndoe.example.com` | John's profile (at root `/`) |
| Custom domain | `johndoe.example.com/links` | John's links page |
| User's own domain | `john.me` | John's profile (PART 35) |

**Examples by App Type:**

| App Type | `/{slug}` Shows | Sub-routes |
|----------|-----------------|------------|
| **Linktree clone** | User's link page | `/{user}/analytics` |
| **GitHub/Gitea clone** | User/org profile + repos | `/{user}/{repo}`, `/{org}/{repo}` |
| **Twitter clone** | User's profile + posts | `/{user}/status/{id}` |
| **Pastebin clone** | Paste by ID | `/{paste_id}` |
| **URL shortener** | Redirect to target | `/{short_code}` |

**Implementation Notes:**

1. **Username/org validation**: Must match `^[a-z0-9]([a-z0-9-]*[a-z0-9])?$` (lowercase, alphanumeric, hyphens, 2-39 chars)
2. **Case insensitive**: `/JohnDoe` → `/johndoe` (redirect or serve)
3. **Trailing slash**: Normalize (pick one, redirect other)
4. **404 handling**: Unknown slugs show "user not found" page, not generic 404

### No JavaScript-Disabled Broken State

**Frontend MUST work without JavaScript for core functionality:**

| Feature | Without JS | With JS |
|---------|------------|---------|
| **Navigation** | Works (links) | Works (maybe enhanced) |
| **Forms** | Work (submit) | Enhanced validation |
| **Content** | Visible | Maybe enhanced |
| **CRUD** | Works via forms | AJAX enhanced |

**JavaScript enhances, it does not enable.**

## Smart Content Detection (NON-NEGOTIABLE)

**Frontend routes (`/**`) MUST automatically detect request type and respond appropriately.**

### Detection Logic (MUST Support Full CRUD)

**ALL frontend routes with CRUD operations MUST work in BOTH modes:**

```go
func detectClientType(r *http.Request) string {
    // 1. Check Accept header first (explicit preference)
    accept := r.Header.Get("Accept")

    if strings.Contains(accept, "text/html") {
        return "html"
    }
    if strings.Contains(accept, "text/plain") {
        return "text"
    }
    if strings.Contains(accept, "application/json") {
        // Rare for frontend, but support it
        return "json"
    }

    // 2. Check User-Agent for browser detection
    ua := r.Header.Get("User-Agent")

    // Browser User-Agents (common patterns)
    browsers := []string{
        "Mozilla/", "Chrome/", "Safari/", "Edge/", "Firefox/",
        "Opera/", "MSIE", "Trident/",
    }

    for _, browser := range browsers {
        if strings.Contains(ua, browser) {
            return "html"
        }
    }

    // 3. CLI tools (curl, wget, httpie, etc.)
    cliTools := []string{
        "curl/", "Wget/", "HTTPie/", "python-requests/",
        "Go-http-client/", "node-fetch/",
    }

    for _, tool := range cliTools {
        if strings.Contains(ua, tool) {
            return "text"
        }
    }

    // 4. Empty or unknown User-Agent
    if ua == "" {
        // Default to text for programmatic access
        return "text"
    }

    // 5. Default: HTML (safest fallback)
    return "html"
}
```

### Response by Client Type

**Frontend routes MUST respond differently based on client:**

| Route | Browser | curl/CLI | Accept: text/plain | Accept: text/html | Accept: application/json |
|-------|---------|----------|-------------------|-------------------|--------------------------|
| `/` | HTML page | Text | Text | HTML | JSON |
| `/users` | HTML list | Text list | Text list | HTML list | JSON array |
| `/users/123` | HTML profile | Text (username) | Text | HTML profile | JSON object |
| `/jokes/random` | HTML joke page | Just the joke | Just the joke | HTML page | JSON object |

### CRUD Operations MUST Work in All Modes

**ALL CRUD operations must be accessible via:**

1. **HTML Forms** (browser users):
   ```html
   <form action="/users" method="POST">...</form>
   <form action="/users/123" method="POST">
     <input type="hidden" name="_method" value="PUT">
   </form>
   ```

2. **API Endpoints** (programmatic):
   ```bash
   curl -X POST /api/v1/users -d '{"username":"test"}'
   curl -X PUT /api/v1/users/123 -d '{"email":"new@test.com"}'
   curl -X DELETE /api/v1/users/123
   ```

3. **Frontend Direct** (CLI/scripting):
   ```bash
   curl -X POST /users -d 'username=test'  # Form-encoded
   curl /users/123  # Returns text (auto-detected)
   ```

**Rule:** CRUD must work for browsers (HTML forms), APIs (JSON), and CLI (text/form-encoded).

### Frontend Testing Best Practice

**For automated testing, use text responses (much simpler than HTML parsing):**

```bash
# Easy: Test text output (no HTML parsing needed)
curl /users/123                           # Auto-detects CLI, returns text
curl -H "Accept: text/plain" /users/123  # Explicitly request text

# Hard: Testing HTML requires parsing
curl -H "Accept: text/html" /users/123 | grep "<title>"  # Fragile
```

**Recommended testing approach:**
- ✓ Use Accept: text/plain for frontend route testing
- ✓ Or rely on CLI auto-detection (curl returns text automatically)
- ✓ Verify text output contains expected data
- ✗ Avoid parsing HTML in test scripts (complex and fragile)

**Test scripts should:**
```bash
# Test frontend returns text for CLI
RESULT=$(curl -s http://localhost:80/users/123)
if echo "$RESULT" | grep -q "testuser"; then
    echo "✓ Frontend returns user data"
else
    echo "✗ FAILED: User data not returned"
fi

# Test frontend returns HTML for browser (optional, just check Content-Type)
CONTENT_TYPE=$(curl -s -H "Accept: text/html" -I http://localhost:80/users/123 | grep -i "content-type")
if echo "$CONTENT_TYPE" | grep -q "text/html"; then
    echo "✓ Frontend serves HTML to browsers"
fi
```

## Responsive Layout (NON-NEGOTIABLE)

**Content width adapts based on screen size:**

| Screen Width | Content Width | Margins | Device Category |
|--------------|---------------|---------|-----------------|
| ≥720px | 90% | 5% left, 5% right | Desktop/Tablet |
| <720px | 98% | 1% left, 1% right | Mobile |

```css
/* Responsive container */
.container {
  width: 98%;
  margin: 0 auto;
  max-width: 1400px;
}

@media (min-width: 720px) {
  .container {
    width: 90%;
  }
}
```

**Responsive Behavior by Element:**

| Element | <720px (Mobile) | ≥720px (Desktop) |
|---------|-----------------|------------------|
| **Admin Sidebar** | Hidden, hamburger menu toggle | Visible, collapsible |
| **Public Nav** | Hamburger menu | Horizontal links |
| **Tables** | Horizontal scroll or card layout | Full table |
| **Modals** | Full-width (98%) | Centered, max-width 600px |
| **Forms** | Single column, full-width inputs | Multi-column where appropriate |
| **Touch Targets** | Minimum 44x44px | Standard sizing |
| **Font Size** | Base 16px minimum | Base 16px |

**Footer Behavior:**
- Footer is ALWAYS at the bottom of the page content
- Footer scrolls with content (NOT fixed/sticky)
- Uses flexbox or grid to push footer down on short pages
- ALWAYS horizontally centered

```css
/* Footer always at bottom */
body {
  display: flex;
  flex-direction: column;
  min-height: 100vh;
}

main {
  flex: 1;
}

footer {
  text-align: center;
}
```

## Technology Stack (NON-NEGOTIABLE)

| Rule | Description | Details |
|------|-------------|---------|
| **Go Templates** | ALL HTML uses Go `html/template` | See Template Rules below |
| **Pure Vanilla JS** | NO frameworks | See JavaScript Rules below |
| **CSS-First** | Prefer CSS over JS | See CSS Rules below |
| **NO JS Alerts** | Use custom modals/toasts | See UI Components below |
| **NO Inline CSS/JS** | External files only | See CSS/JS Rules below |

## UI Components (NON-NEGOTIABLE)

### Buttons

| Type | Use For | Style |
|------|---------|-------|
| Primary | Main actions (Save, Submit, Create) | Filled, brand color |
| Secondary | Alternative actions (Cancel, Back) | Outlined or muted |
| Danger | Destructive actions (Delete, Remove) | Red, requires confirmation |
| Icon | Compact actions (Edit, Copy, Refresh) | Icon only with tooltip |

**Button States:** Normal, Hover, Active, Disabled, Loading

**Submit Button Behavior (NON-NEGOTIABLE):**

| Rule | Implementation |
|------|----------------|
| **Single submit only** | Disable button immediately on click (prevent double-submit) |
| **Show action state** | Change text to indicate action (Saving..., Searching..., Loading...) |
| **Re-enable on complete** | Re-enable button after success OR error response |
| **Preserve width** | Button width should not change when text changes |

**Loading Text Examples:**

| Original | Loading State |
|----------|---------------|
| Save | Saving... |
| Search | Searching... |
| Submit | Submitting... |
| Create | Creating... |
| Delete | Deleting... |
| Send | Sending... |
| Login | Logging in... |
| Register | Registering... |
| Upload | Uploading... |
| Download | Downloading... |

```html
<!-- Submit button with loading state -->
<button type="submit" id="save-btn" onclick="this.disabled=true; this.textContent='Saving...';">
  Save
</button>
```

```javascript
// Re-enable after response
fetch('/api/save', { method: 'POST', body: data })
  .then(response => { /* handle success */ })
  .catch(error => { /* handle error */ })
  .finally(() => {
    btn.disabled = false;
    btn.textContent = 'Save';
  });
```

### Toggle Switches

**CSS-only toggle using hidden checkbox:**

```html
<label class="toggle">
  <input type="checkbox" name="setting">
  <span class="slider"></span>
  Enable Feature
</label>
```

### Modals

**Modal Behavior (NON-NEGOTIABLE):**

| Action | Modal Behavior |
|--------|----------------|
| Success (Save, Submit, Create) | Close automatically after success |
| Error | Stay open, display error message |
| Cancel button clicked | Close immediately |
| Escape key pressed | Close immediately |
| Backdrop clicked | Close immediately |
| Form with unsaved changes | Warn before closing |

**Modal Features:**
- Focus trap (Tab stays within modal)
- Escape key closes modal
- Backdrop click closes modal
- Body scroll locked while open
- Centered vertically and horizontally
- Responsive (full-width on mobile)

**Accessibility (NON-NEGOTIABLE):**

| Requirement | Implementation |
|-------------|----------------|
| **Focus trap** | Tab/Shift+Tab cycles through modal elements only |
| **Initial focus** | First focusable element OR primary action button |
| **Return focus** | Restore focus to trigger element on close |
| **ARIA attributes** | `role="dialog"`, `aria-modal="true"`, `aria-labelledby` |
| **Escape key** | Close modal (unless confirmation required) |
| **Screen reader** | Announce modal title on open |

```html
<!-- Modal structure using native <dialog> -->
<dialog id="confirm-modal" aria-labelledby="modal-title">
  <header>
    <h2 id="modal-title">Modal Title</h2>
    <button type="button" aria-label="Close" onclick="this.closest('dialog').close()">✕</button>
  </header>
  <main>Modal content here</main>
  <footer>
    <button type="button" onclick="this.closest('dialog').close()">Cancel</button>
    <button type="submit" autofocus>Confirm</button>
  </footer>
</dialog>
```

**Note:** Native `<dialog>` element handles focus trap and backdrop automatically. Use `showModal()` to open with backdrop, `close()` to close.

### Toast vs Modal: When to Use Which (NON-NEGOTIABLE)

**Toasts and modals serve DIFFERENT purposes. Do NOT use them interchangeably.**

**Quick Reference:**

| Scenario | Use | Reason |
|----------|-----|--------|
| "Settings saved" | **Toast** | Non-blocking confirmation |
| "Are you sure you want to delete?" | **Modal** | Requires user decision |
| "File uploaded successfully" | **Toast** | Non-blocking confirmation |
| "Enter new password" | **Modal** | Requires user input |
| "Network error, try again" | **Toast** | Informational, user can retry |
| "Session expired, please login" | **Modal** | Blocking, requires action |
| "Item added to cart" | **Toast** | Non-blocking confirmation |
| "Select shipping address" | **Modal** | Requires user selection |
| "Email sent" | **Toast** | Non-blocking confirmation |
| "Confirm your email address" | **Modal** | Requires user input/action |

**Use TOAST When:**

| Criteria | Examples |
|----------|----------|
| **Confirmation of action** | "Saved", "Deleted", "Copied", "Sent" |
| **Non-blocking information** | "New update available", "You have 3 notifications" |
| **Transient feedback** | "Loading...", "Processing..." |
| **Errors that don't need input** | "Network error", "Rate limited, try again" |
| **User can continue working** | Any message that doesn't require immediate attention |

**Use MODAL When:**

| Criteria | Examples |
|----------|----------|
| **Requires user decision** | "Delete this item?", "Discard unsaved changes?" |
| **Requires user input** | Forms, password entry, settings that need confirmation |
| **Destructive action confirmation** | Delete, remove, revoke, disconnect |
| **Blocking workflow** | Must complete before continuing (login, terms acceptance) |
| **Complex information** | Details that need space (error details, help text) |
| **Multi-step process** | Wizards, setup flows, guided processes |

**NEVER Do This:**

| Wrong | Right |
|-------|-------|
| Toast: "Are you sure?" | Modal: "Are you sure?" (needs decision) |
| Modal: "Settings saved" | Toast: "Settings saved" (just confirmation) |
| Toast with buttons | Modal with buttons (toasts should auto-dismiss) |
| Modal for every error | Toast for simple errors (modal for blocking errors) |
| Stacking modals | One modal at a time (queue if needed) |
| Toast requiring action | Modal if action required |

**Decision Flowchart:**
```
Does user need to make a decision or provide input?
├── YES → Use MODAL
└── NO → Does user need to acknowledge before continuing?
         ├── YES → Use MODAL
         └── NO → Is it destructive action confirmation?
                  ├── YES → Use MODAL
                  └── NO → Use TOAST
```

**Code Pattern:**
```javascript
// TOAST - Non-blocking feedback
async function saveSettings(data) {
    const result = await api.post('/users/settings', data);
    if (result.ok) {
        showToast('Settings saved', 'success');  // Non-blocking, auto-dismiss
    } else {
        showToast('Failed to save settings', 'error');  // Non-blocking error
    }
}

// MODAL - Blocking decision required
function deleteItem(itemId) {
    showModal({
        title: 'Delete Item',
        message: 'Are you sure you want to delete this item? This cannot be undone.',
        confirmText: 'Delete',
        confirmStyle: 'danger',
        onConfirm: async () => {
            await api.delete(`/items/${itemId}`);
            showToast('Item deleted', 'success');  // Confirmation after action
        }
    });
}

// MODAL - User input required
function changePassword() {
    showModal({
        title: 'Change Password',
        form: true,
        fields: ['current_password', 'new_password', 'confirm_password'],
        onSubmit: async (data) => {
            await api.post('/users/security/password', data);
            showToast('Password changed', 'success');  // Confirmation after action
        }
    });
}
```

### Toast Notifications (NON-NEGOTIABLE)

**In-app notifications for immediate feedback. Follows common patterns (GitHub, GitLab, Slack).**

**Toast Behavior Rules:**

| Rule | Value | Description |
|------|-------|-------------|
| **Position** | Top-right corner | Fixed position, doesn't scroll with page |
| **Stacking** | Vertical, newest on top | Multiple toasts stack without overlapping |
| **Max visible** | 5 toasts | Older toasts queue until space available |
| **Auto-dismiss** | 3 seconds (default) | Countdown visible, can be paused on hover |
| **Click to dismiss** | Always | User can click X or entire toast to dismiss |
| **Keyboard dismiss** | Escape key | Dismisses topmost toast |
| **Animation** | Slide in from right | Fade out on dismiss |
| **Pause on hover** | Yes | Hovering pauses auto-dismiss countdown |

**Toast Types:**

| Type | Icon | Auto-dismiss | Use For |
|------|------|--------------|---------|
| **Success** | ✓ (checkmark) | 3 seconds | Action completed successfully |
| **Error** | ✗ (X) | No auto-dismiss | Action failed, needs attention |
| **Warning** | ⚠ (triangle) | 5 seconds | Caution needed, action may have issues |
| **Info** | ℹ (info) | 3 seconds | General information, tips |

**Toast Structure:**
```html
<div class="toast toast-success" role="alert" aria-live="polite">
  <span class="toast-icon">✓</span>
  <span class="toast-message">Settings saved successfully</span>
  <button class="toast-close" aria-label="Dismiss">&times;</button>
  <div class="toast-progress"></div>
</div>
```

**Toast Container (for stacking):**
```html
<div id="toast-container" aria-label="Notifications">
  <!-- Toasts inserted here, newest first -->
</div>
```

**CSS for Stacking:**
```css
#toast-container {
  position: fixed;
  top: 1rem;
  right: 1rem;
  z-index: 9999;
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
  max-height: calc(100vh - 2rem);
  overflow: hidden;
}

.toast {
  display: flex;
  align-items: center;
  gap: 0.75rem;
  padding: 0.75rem 1rem;
  border-radius: 4px;
  box-shadow: 0 2px 8px rgba(0,0,0,0.15);
  animation: slideIn 0.3s ease-out;
  position: relative;
  min-width: 300px;
  max-width: 400px;
}

.toast-progress {
  position: absolute;
  bottom: 0;
  left: 0;
  height: 3px;
  background: rgba(255,255,255,0.5);
  animation: countdown linear forwards;
}

@keyframes slideIn { from { transform: translateX(100%); opacity: 0; } }
@keyframes countdown { from { width: 100%; } to { width: 0%; } }
```

**JavaScript Toast API:**
```javascript
// Show toast - returns toast ID for programmatic control
const toastId = showToast("Settings saved", "success");        // 3s auto-dismiss
const toastId = showToast("Save failed", "error");             // No auto-dismiss
const toastId = showToast("Check your input", "warning", 5000); // 5s auto-dismiss
const toastId = showToast("Tip: Use shortcuts", "info");       // 3s auto-dismiss

// Dismiss programmatically
dismissToast(toastId);

// Dismiss all
dismissAllToasts();
```

### Notification Bell (NON-NEGOTIABLE)

**Built-in notification center accessible via bell icon in header. Follows GitHub/GitLab patterns.**

**Bell Icon Behavior:**

| Feature | Description |
|---------|-------------|
| **Position** | Header, right side, before profile icon |
| **Icon** | Bell outline (empty = no unread), filled (has unread) |
| **Badge** | Red dot or count (1-9, then "9+") for unread |
| **Click** | Opens dropdown panel below bell |
| **Keyboard** | Enter/Space opens dropdown, Escape closes |

**Dropdown Panel:**

| Feature | Description |
|---------|-------------|
| **Position** | Below bell icon, right-aligned |
| **Width** | 320-400px |
| **Max height** | 400px (scrollable) |
| **Empty state** | "No notifications" message |
| **Header** | "Notifications" title + "Mark all read" link |
| **Footer** | "View all notifications" link to `/users/notifications` |

**Notification Item:**

| Element | Description |
|---------|-------------|
| **Icon** | Type indicator (info, success, warning, error) |
| **Title** | Brief notification title |
| **Message** | Short description (truncated if long) |
| **Timestamp** | Relative time ("2m ago", "1h ago", "Yesterday") |
| **Unread indicator** | Blue dot on left side |
| **Click behavior** | Mark as read + navigate to related page |

**HTML Structure:**
```html
<div class="header-actions">
  <!-- Notification Bell -->
  <div class="notification-bell" aria-label="Notifications">
    <button class="bell-button" aria-haspopup="true" aria-expanded="false">
      <svg class="bell-icon"><!-- bell SVG --></svg>
      <span class="badge" aria-label="3 unread">3</span>
    </button>
    <div class="notification-dropdown" role="menu" hidden>
      <div class="dropdown-header">
        <span>Notifications</span>
        <button class="mark-all-read">Mark all read</button>
      </div>
      <div class="notification-list">
        <a href="/users/settings" class="notification-item unread">
          <span class="notification-dot"></span>
          <span class="notification-icon">ℹ</span>
          <div class="notification-content">
            <span class="notification-title">Settings updated</span>
            <span class="notification-message">Your preferences were saved</span>
            <span class="notification-time">2m ago</span>
          </div>
        </a>
        <!-- More items... -->
      </div>
      <a href="/users/notifications" class="dropdown-footer">View all</a>
    </div>
  </div>

  <!-- Profile Icon -->
  <div class="profile-menu"><!-- See below --></div>
</div>
```

### Profile Icon (NON-NEGOTIABLE)

**User profile dropdown accessible via avatar/icon in header. Follows GitHub/GitLab patterns.**

**Profile Icon Behavior:**

| Feature | Description |
|---------|-------------|
| **Position** | Header, right side, last item |
| **Icon** | User avatar (if uploaded) or default avatar |
| **Size** | 32x32px, circular |
| **Click** | Opens dropdown menu below icon |
| **Keyboard** | Enter/Space opens dropdown, Escape closes |

**Dropdown Menu Items:**

| Item | Link | Description |
|------|------|-------------|
| **Username** | - | Display current username (not clickable, header) |
| **Profile** | `/users` | View/edit profile |
| **Settings** | `/users/settings` | Account settings |
| **Security** | `/users/security` | Password, 2FA, sessions |
| **API Tokens** | `/users/tokens` | Manage API tokens |
| *(divider)* | - | - |
| **Theme** | - | Theme toggle (Dark/Light/Auto) |
| *(divider)* | - | - |
| **Help** | `/server/help` | Help documentation |
| **Sign out** | `/auth/logout` | Log out |

**HTML Structure:**
```html
<div class="profile-menu" aria-label="User menu">
  <button class="profile-button" aria-haspopup="true" aria-expanded="false">
    <img src="/users/avatar" alt="Username" class="avatar">
    <svg class="dropdown-arrow"><!-- chevron --></svg>
  </button>
  <div class="profile-dropdown" role="menu" hidden>
    <div class="dropdown-header">
      <span class="username">johndoe</span>
    </div>
    <a href="/users" class="dropdown-item" role="menuitem">Profile</a>
    <a href="/users/settings" class="dropdown-item" role="menuitem">Settings</a>
    <a href="/users/security" class="dropdown-item" role="menuitem">Security</a>
    <a href="/users/tokens" class="dropdown-item" role="menuitem">API Tokens</a>
    <div class="dropdown-divider" role="separator"></div>
    <div class="dropdown-item theme-toggle">
      Theme: <button>Dark</button> | <button>Light</button> | <button>Auto</button>
    </div>
    <div class="dropdown-divider" role="separator"></div>
    <a href="/server/help" class="dropdown-item" role="menuitem">Help</a>
    <form action="/auth/logout" method="POST">
      <button type="submit" class="dropdown-item logout" role="menuitem">Sign out</button>
    </form>
  </div>
</div>
```

**CSS for Header Actions:**
```css
.header-actions {
  display: flex;
  align-items: center;
  gap: 1rem;
}

.notification-bell, .profile-menu {
  position: relative;
}

.bell-button, .profile-button {
  background: none;
  border: none;
  cursor: pointer;
  display: flex;
  align-items: center;
  gap: 0.25rem;
}

.badge {
  position: absolute;
  top: -4px;
  right: -4px;
  background: var(--color-danger);
  color: white;
  font-size: 0.75rem;
  min-width: 18px;
  height: 18px;
  border-radius: 9px;
  display: flex;
  align-items: center;
  justify-content: center;
}

.avatar {
  width: 32px;
  height: 32px;
  border-radius: 50%;
  object-fit: cover;
}

.notification-dropdown, .profile-dropdown {
  position: absolute;
  top: 100%;
  right: 0;
  margin-top: 0.5rem;
  background: var(--color-bg);
  border: 1px solid var(--color-border);
  border-radius: 6px;
  box-shadow: 0 4px 12px rgba(0,0,0,0.15);
  z-index: 1000;
}

.dropdown-item {
  display: block;
  padding: 0.5rem 1rem;
  color: inherit;
  text-decoration: none;
}

.dropdown-item:hover {
  background: var(--color-hover);
}

.dropdown-divider {
  height: 1px;
  background: var(--color-border);
  margin: 0.5rem 0;
}
```

- See PART 18: EMAIL & NOTIFICATIONS for full notification specification

### Empty States (NON-NEGOTIABLE)

**Every list, table, and data view MUST have a proper empty state - NEVER show blank space.**

| Scenario | Display | Call to Action |
|----------|---------|----------------|
| No search results | "No results found for '{query}'" | Suggest clearing filters or different search |
| Empty list | "No {items} yet" | "Create your first {item}" button |
| Empty table | Friendly message in table body | Action button or instructions |
| No notifications | "No notifications" | - |
| Failed to load | Error message | "Retry" button |
| No permissions | "You don't have access to this" | Link to request access or go back |

**Empty State Structure:**
```html
<div class="empty-state">
  <svg class="empty-state-icon"><!-- relevant icon --></svg>
  <h3 class="empty-state-title">No items yet</h3>
  <p class="empty-state-message">Create your first item to get started.</p>
  <a href="/items/new" class="btn btn-primary">Create Item</a>
</div>
```

**Rules:**
- Always include an icon or illustration
- Title should be short and clear
- Message should explain what to do next
- Include action button when user can fix the state
- Center vertically and horizontally in the container

### Form Validation (NON-NEGOTIABLE)

**All forms MUST provide clear, inline validation feedback.**

| Rule | Implementation |
|------|----------------|
| **Validate on blur** | Show error when user leaves field (not while typing) |
| **Inline errors** | Error message directly below the field, not in alert/modal |
| **Highlight field** | Red border on invalid fields, green on valid (optional) |
| **Clear on fix** | Remove error immediately when user corrects input |
| **Submit validation** | Re-validate all fields on submit, focus first error |
| **Accessible errors** | Use `aria-describedby` to link error to field |

**Error Message Style:**
```html
<div class="form-group error">
  <label for="email">Email</label>
  <input type="email" id="email" name="email"
         aria-describedby="email-error" aria-invalid="true">
  <span id="email-error" class="field-error" role="alert">
    Please enter a valid email address
  </span>
</div>
```

**Validation Timing:**

| Event | Action |
|-------|--------|
| Field blur | Validate that field only |
| Field input (after error shown) | Clear error when valid |
| Form submit | Validate all fields, focus first error |
| Field focus | Do NOT validate (let user type) |

**Error Message Content:**

| Field Type | Error Message |
|------------|---------------|
| Required empty | "{Field name} is required" |
| Invalid email | "Please enter a valid email address" |
| Password too short | "Password must be at least 8 characters" |
| Passwords don't match | "Passwords do not match" |
| Invalid URL | "Please enter a valid URL" |
| Number out of range | "Value must be between {min} and {max}" |

**CSS for Validation States:**
```css
.form-group.error input,
.form-group.error select,
.form-group.error textarea {
  border-color: var(--color-error);
}

.field-error {
  color: var(--color-error);
  font-size: 0.875rem;
  margin-top: 0.25rem;
  display: block;
}

.form-group.success input {
  border-color: var(--color-success);
}
```

## Accessibility (NON-NEGOTIABLE)

**WCAG 2.1 AA Compliance Required:**

| Requirement | Implementation |
|-------------|----------------|
| **Keyboard Navigation** | All interactive elements focusable and operable via keyboard |
| **Focus Indicators** | Visible focus ring on all focusable elements |
| **ARIA Labels** | Proper `aria-label`, `aria-describedby`, `role` attributes |
| **Color Contrast** | Minimum 4.5:1 for normal text, 3:1 for large text |
| **Alt Text** | All images have descriptive `alt` attributes |
| **Form Labels** | All inputs have associated `<label>` elements |
| **Error Messages** | Announced to screen readers via `aria-live` |
| **Skip Links** | "Skip to content" link for keyboard users |
| **Semantic HTML** | Proper heading hierarchy (h1 → h2 → h3) |
| **Reduced Motion** | Respect `prefers-reduced-motion` preference |

```css
/* Respect reduced motion preference */
@media (prefers-reduced-motion: reduce) {
  *, *::before, *::after {
    animation-duration: 0.01ms !important;
    transition-duration: 0.01ms !important;
  }
}
```

## PWA Support (NON-NEGOTIABLE)

**Progressive Web App = Native-like web app (installable, offline, push notifications)**

| Feature | Implementation | Notes |
|---------|----------------|-------|
| **Manifest** | `/manifest.json` with app metadata | Required for install |
| **Icons** | Multiple sizes (192x192, 512x512 minimum) | For home screen |
| **Service Worker** | Cache static assets, handle push | Core of PWA |
| **Installable** | Meets PWA install criteria | Add to home screen |
| **HTTPS** | Required for service workers | Non-negotiable |
| **Push Notifications** | Web Push API via Service Worker | User opt-in required |
| **User Sessions** | Tokens in localStorage/IndexedDB | Persists across restarts |
| **Background Sync** | Queue actions when offline, sync when online | Seamless offline |

### Push Notifications (PWA)

**Push notifications work even when app is closed (like native apps).**

| Component | Purpose |
|-----------|---------|
| **Service Worker** | Receives push events, shows notifications |
| **Push API** | Subscribe to push service |
| **Notifications API** | Display system notifications |
| **VAPID Keys** | Server authentication for push |

**User must grant permission** - prompt on first relevant action, not page load.

```javascript
// Service Worker - handle push
self.addEventListener('push', event => {
  const data = event.data.json();
  self.registration.showNotification(data.title, {
    body: data.body,
    icon: '/static/icons/icon-192.png'
  });
});
```

**Admin Panel Settings (`/admin/server/notifications`):**
- Enable/disable push notifications
- VAPID key generation
- Test push functionality

### User Sessions in PWA

**PWA maintains user login across app restarts.**

| Storage | Use Case | Cleared |
|---------|----------|---------|
| **localStorage** | Session token, user preferences | Manual/logout |
| **IndexedDB** | Offline data, cached responses | Manual/logout |
| **Cookies** | Server-side session (fallback) | Expiry/logout |

**Session persists when:**
- App is closed and reopened
- Device is restarted
- Switching between browser and installed PWA

**Logout clears all:** localStorage, IndexedDB, service worker cache of user data.

**Offline Behavior:**

| Resource Type | Cache Strategy | Offline Behavior |
|---------------|----------------|------------------|
| **Static assets** (CSS, JS, images) | Cache-first | Served from cache |
| **HTML pages** | Network-first, cache fallback | Show cached version if offline |
| **API calls** | Network-only | Show offline indicator, queue for retry |
| **Fonts** | Cache-first | Served from cache |

**Service Worker Caching:**
- Cache static assets on install
- Update cache on service worker activation
- Maximum cache size: 50MB
- Cache expiration: 7 days for static assets
- Never cache: API responses, user-specific data

**Offline Indicator:**
- Show banner/toast when offline: "You are offline. Some features may be unavailable."
- Hide automatically when connection restored
- Do not block UI - allow browsing cached pages

**manifest.json:**
```json
{
  "name": "{App Name}",
  "short_name": "{AppName}",
  "description": "{App description}",
  "start_url": "/",
  "display": "standalone",
  "background_color": "#ffffff",
  "theme_color": "#000000",
  "icons": [
    { "src": "/static/icons/icon-192.png", "sizes": "192x192", "type": "image/png" },
    { "src": "/static/icons/icon-512.png", "sizes": "512x512", "type": "image/png" }
  ]
}
```

**HTML head:**
```html
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="#000000">
<link rel="apple-touch-icon" href="/static/icons/icon-192.png">
```

## HTTP Status Codes (NON-NEGOTIABLE)

**Use standard RFC 7231 HTTP status codes consistently:**

| Code | Meaning | Use For |
|------|---------|---------|
| 200 | OK | Successful GET, PUT, PATCH |
| 201 | Created | Successful POST creating resource |
| 204 | No Content | Successful DELETE |
| 301 | Moved Permanently | Permanent redirects |
| 302 | Found | Temporary redirects |
| 400 | Bad Request | Invalid input, validation errors |
| 401 | Unauthorized | Not authenticated |
| 403 | Forbidden | Authenticated but not authorized |
| 404 | Not Found | Resource doesn't exist |
| 405 | Method Not Allowed | Wrong HTTP method |
| 409 | Conflict | Duplicate resource, version conflict |
| 422 | Unprocessable Entity | Semantic validation errors |
| 429 | Too Many Requests | Rate limit exceeded |
| 500 | Internal Server Error | Server-side errors |
| 503 | Service Unavailable | Maintenance mode |

## Unified Response Format (NON-NEGOTIABLE)

**ALL responses (server → client/agent) use this exact format. Simple to parse everywhere.**

### Success Response

```json
{
  "ok": true,
  "data": {}
}
```

### Error Response

```json
{
  "ok": false,
  "error": "ERROR_CODE",
  "message": "Human readable message"
}
```

### Standard Error Codes (server sends, client/agent parses)

| Error Code | HTTP | Message | Client/Agent Display |
|------------|------|---------|---------------------|
| `BAD_REQUEST` | 400 | "Invalid request format" | Invalid request |
| `VALIDATION_FAILED` | 400 | "Validation failed: {field}" | Check input: {field} |
| `UNAUTHORIZED` | 401 | "Authentication required" | Please log in |
| `TOKEN_EXPIRED` | 401 | "Token has expired" | Session expired, log in again |
| `TOKEN_INVALID` | 401 | "Invalid token" | Invalid session |
| `2FA_REQUIRED` | 401 | "Two-factor authentication required" | Enter 2FA code |
| `2FA_INVALID` | 401 | "Invalid 2FA code" | Wrong code, try again |
| `FORBIDDEN` | 403 | "Permission denied" | Access denied |
| `ACCOUNT_LOCKED` | 403 | "Account locked" | Account locked, try later |
| `NOT_FOUND` | 404 | "Resource not found" | Not found |
| `METHOD_NOT_ALLOWED` | 405 | "Method not allowed" | Invalid operation |
| `CONFLICT` | 409 | "Resource already exists" | Already exists |
| `RATE_LIMITED` | 429 | "Too many requests" | Slow down, try later |
| `SERVER_ERROR` | 500 | "Internal server error" | Something went wrong |
| `MAINTENANCE` | 503 | "Service unavailable" | Maintenance, try later |

### Parsing Rules (NON-NEGOTIABLE)

**All consumers (client binary, agent binary, web UI, external tools) parse the same way:**

```go
// Universal response parser - works for server, client, agent
type Response struct {
    OK      bool            `json:"ok"`
    Data    json.RawMessage `json:"data,omitempty"`
    Error   string          `json:"error,omitempty"`
    Message string          `json:"message,omitempty"`
}

func ParseResponse(body []byte) (*Response, error) {
    var r Response
    if err := json.Unmarshal(body, &r); err != nil {
        return nil, err
    }
    return &r, nil
}

// Usage in client/agent
resp, _ := ParseResponse(body)
if !resp.OK {
    // Display: resp.Message (human) or handle by resp.Error (code)
    return fmt.Errorf("%s: %s", resp.Error, resp.Message)
}
// Success: use resp.Data
```

### Client/Agent Message Display

| Context | What to Show |
|---------|--------------|
| Terminal (CLI/TUI) | `resp.Message` directly |
| Web UI | `resp.Message` in toast/alert |
| Logging | `resp.Error: resp.Message` |
| Machine parsing | Check `resp.Error` code |

### Examples

**Success - List items:**
```json
{
  "ok": true,
  "data": {
    "items": [],
    "total": 42
  }
}
```

**Success - Create item:**
```json
{
  "ok": true,
  "data": {
    "id": 123,
    "name": "new-item"
  }
}
```

**Error - Not authenticated:**
```json
{
  "ok": false,
  "error": "UNAUTHORIZED",
  "message": "Authentication required"
}
```

**Error - Validation:**
```json
{
  "ok": false,
  "error": "VALIDATION_FAILED",
  "message": "Validation failed: email must be valid"
}
```

**Error - Rate limit:**
```json
{
  "ok": false,
  "error": "RATE_LIMITED",
  "message": "Too many requests, retry after 60 seconds"
}
```

### Why This Format

| Benefit | Explanation |
|---------|-------------|
| **Simple** | Just check `ok` field first |
| **Consistent** | Same structure everywhere |
| **Parseable** | One parser for all responses |
| **Human-friendly** | `message` always displayable |
| **Machine-friendly** | `error` code for programmatic handling |
| **Minimal** | No nested complexity for simple cases |

## Text Response Format (NON-NEGOTIABLE)

**CLI/agent text output uses standardized format. Easy to parse with grep/awk/cut.**

### Success Response (text/plain)

```
OK: {message}
{data lines...}
```

### Error Response (text/plain)

```
ERROR: {code}: {message}
```

### Text Response Examples

**Success - Single value:**
```
OK: Retrieved successfully
value: 42
```

**Success - List:**
```
OK: 3 items found
item-1
item-2
item-3
```

**Error:**
```
ERROR: NOT_FOUND: Resource not found
```

**Error with details:**
```
ERROR: VALIDATION_FAILED: email must be valid
```

## Server Response Rules (NON-NEGOTIABLE)

**These rules apply SERVER-WIDE to ALL responses (API, frontend AJAX, CLI, agent, webhooks).**

### Content-Type Detection

| Source | Content-Type | Format |
|--------|--------------|--------|
| API routes (`/api/v1/*`) | `application/json` | JSON |
| `.txt` suffix (API only) | `text/plain` | Text |
| `Accept: application/json` | `application/json` | JSON |
| `Accept: text/plain` | `text/plain` | Text |
| CLI/Agent (auto-detected) | `text/plain` | Text |
| Browser (no Accept header) | `text/html` | HTML |
| Frontend AJAX/fetch | Auto-detect from `Accept` | JSON/Text |

**Notes:**
- `.txt` suffix only works on API routes (`/api/v1/*.txt`)
- No `.json` suffix exists - JSON is the default for API
- Frontend uses `Accept` header for format negotiation (set by fetch/XMLHttpRequest)

### Newline Rules (NON-NEGOTIABLE)

**ALL non-HTML responses MUST end with a single newline (`\n`).**

| Format | Rule | Example |
|--------|------|---------|
| JSON | Single `\n` after closing `}` or `]` | `{"ok": true}\n` |
| Text | Single `\n` after last line | `OK: done\n` |
| HTML | No trailing newline requirement | `</html>` |

**Why:** Ensures consistent parsing, clean terminal output, proper file concatenation.

```go
// Server response helper
func WriteJSON(w http.ResponseWriter, data any) {
    w.Header().Set("Content-Type", "application/json")
    enc := json.NewEncoder(w)
    enc.SetIndent("", "  ")
    enc.Encode(data)  // Encode() adds trailing newline
}

func WriteText(w http.ResponseWriter, text string) {
    w.Header().Set("Content-Type", "text/plain")
    if !strings.HasSuffix(text, "\n") {
        text += "\n"
    }
    w.Write([]byte(text))
}
```

### JSON Rules (NON-NEGOTIABLE)

| Rule | Correct | Wrong |
|------|---------|-------|
| No comments | `{"key": "value"}` | `{"key": "value" // comment}` |
| No trailing commas | `{"a": 1, "b": 2}` | `{"a": 1, "b": 2,}` |
| Double quotes only | `{"key": "value"}` | `{'key': 'value'}` |
| No undefined | `{"key": null}` | `{"key": undefined}` |
| 2-space indentation | `  "key": "value"` | `    "key"` or `\t"key"` |
| Trailing newline | `}\n` | `}` (no newline) |

### Text Rules (NON-NEGOTIABLE)

| Rule | Correct | Wrong |
|------|---------|-------|
| Lines end with `\n` | `line1\nline2\n` | `line1\nline2` |
| No trailing spaces | `value\n` | `value  \n` |
| UTF-8 encoding | Always UTF-8 | Other encodings |
| Unix line endings | `\n` | `\r\n` (Windows) |

## CORS Configuration

**See "CORS (NON-NEGOTIABLE)" section below for complete configuration and behavior.**

Quick reference: Default allows all origins (`*`). Configure via `web.cors` in server.yml.

### HTML5 & CSS Over JavaScript (NON-NEGOTIABLE)

**Priority Order: HTML5 first → CSS second → JavaScript last resort.**

| Priority | Technology | Use For |
|----------|------------|---------|
| **1st** | HTML5 | Structure, forms, validation, semantic content, `<details>`, `<dialog>` |
| **2nd** | CSS | Styling, layout, themes, animations, hover states, responsive design |
| **3rd** | JavaScript | ONLY when HTML5/CSS cannot achieve the functionality |

**JavaScript is the exception, not the rule. Every JS line must be justified.**

| Use Case | Use HTML5/CSS | Use JavaScript Only When |
|----------|---------------|--------------------------|
| Form validation | HTML5 `required`, `pattern`, `min`, `max`, `type="email"` | Complex cross-field validation |
| Collapsible sections | `<details>/<summary>` | Need animation or programmatic control |
| Tabs | CSS `:target` or radio button hack | Need deep linking or state management |
| Tooltips | CSS `::after` with `data-tooltip` | Need dynamic positioning |
| Modals | CSS `:target` selector | Need focus trap, escape key, backdrop click |
| Hover effects | CSS `:hover`, `:focus`, `:active` | Never - always CSS |
| Animations | CSS `@keyframes`, `transition` | Complex sequenced animations |
| Responsive design | CSS media queries | Never - always CSS |
| Toggle switches | CSS with hidden checkbox | Need state persistence |
| Dropdowns/menus | CSS `:focus-within` | Complex multi-level menus |
| Progress bars | HTML5 `<progress>` | Need dynamic updates |
| Sliders | HTML5 `<input type="range">` | Complex custom styling |
| Date pickers | HTML5 `<input type="date">` | Need custom calendar UI |
| Color pickers | HTML5 `<input type="color">` | Need swatches or advanced features |
| Accordions | `<details>/<summary>` | Need single-open behavior |

**JavaScript Guidelines:**
- **Last resort** - only when HTML5/CSS cannot achieve the functionality
- **Progressive enhancement** - features must work without JS where possible
- **No JS for styling** - unless it cannot be done in HTML5 and CSS
- **No JS for simple interactions** - hover, focus, basic toggles are CSS-only

**HTML5 Required (NON-NEGOTIABLE):**
- ALL HTML MUST be valid HTML5
- Use `<!DOCTYPE html>` declaration
- Use semantic HTML5 elements: `<header>`, `<nav>`, `<main>`, `<footer>`, `<article>`, `<section>`, `<aside>`
- Use HTML5 form elements: `<input type="email">`, `<input type="date">`, `<input type="number">`, etc.
- Use HTML5 attributes: `required`, `pattern`, `placeholder`, `autofocus`, `autocomplete`
- NO deprecated elements: `<center>`, `<font>`, `<marquee>`, `<blink>`, etc.
- NO deprecated attributes: `align`, `bgcolor`, `border`, `cellpadding`, etc.
- **Required for**: API calls, dynamic content loading, complex state, WebSockets
- **Size matters** - keep JS minimal, no large libraries for simple tasks

**Inline JavaScript - Allowed for simple operations:**
```html
<!-- Navigation -->
<button onclick="history.back()">Go Back</button>
<button onclick="history.forward()">Go Forward</button>
<button onclick="location.reload()">Refresh</button>

<!-- Print -->
<button onclick="window.print()">Print</button>

<!-- Scroll -->
<button onclick="window.scrollTo(0,0)">Back to Top</button>

<!-- Form helpers -->
<button onclick="document.getElementById('myform').reset()">Reset Form</button>
<button onclick="document.getElementById('field').select()">Select All</button>
```

**Rule:** Inline JS is fine for one-liner operations that cannot be done with CSS/HTML5.
Move to `static/js/app.js` if logic needs feedback, reuse, or exceeds one statement.
See **JavaScript Rules** section below for `app.js` structure.

**CSS-First Patterns (use these instead of JS):**

```html
<!-- Collapsible section - use <details>/<summary> NOT JS -->
<details>
  <summary>Click to expand</summary>
  <p>Hidden content revealed when clicked.</p>
</details>

<!-- Toggle menu - use checkbox hack NOT JS -->
<label for="menu-toggle" class="menu-btn">☰ Menu</label>
<input type="checkbox" id="menu-toggle" hidden>
<nav class="menu">
  <a href="/">Home</a>
  <a href="/about">About</a>
</nav>

<style>
.menu { display: none; }
#menu-toggle:checked ~ .menu { display: block; }
</style>

<!-- Dropdown - use :focus-within NOT JS -->
<div class="dropdown">
  <button>Options</button>
  <div class="dropdown-content">
    <a href="#">Option 1</a>
    <a href="#">Option 2</a>
  </div>
</div>

<style>
.dropdown-content { display: none; }
.dropdown:focus-within .dropdown-content { display: block; }
</style>
```

### Go Templates (NON-NEGOTIABLE)

**ALL frontend HTML MUST use Go's `html/template` package.**

| Location | Purpose |
|----------|---------|
| `src/server/template/` | All `.tmpl` template files |
| `src/server/template/partial/` | Reusable template partials |
| `src/server/template/layout/` | Base layouts |
| `src/server/template/page/` | Page-specific templates |
| `src/server/static/` | Static assets (CSS, JS, images) |

**Template Structure (all files use `.tmpl` extension):**
```
src/server/template/
├── layout/
│   ├── public.tmpl         # Public-facing layout (/, /auth/*, /server/*)
│   └── admin.tmpl          # Admin panel layout (/admin/*)
├── partial/
│   ├── public/
│   │   ├── header.tmpl     # Public header (logo, nav, login)
│   │   ├── nav.tmpl        # Public navigation
│   │   └── footer.tmpl     # Public footer (about, privacy, etc.)
│   ├── admin/
│   │   ├── header.tmpl     # Admin header (logo, search, notifications, logout)
│   │   ├── sidebar.tmpl    # Admin sidebar navigation
│   │   └── footer.tmpl     # Admin footer (version, docs)
│   ├── head.tmpl           # <head> contents (meta, CSS)
│   └── scripts.tmpl        # JavaScript includes
├── page/
│   ├── index.tmpl          # Home page
│   ├── healthz.tmpl        # Health check page
│   └── error.tmpl          # Error pages (404, 500, etc.)
├── auth/
│   ├── login.tmpl          # Login page
│   ├── register.tmpl       # Registration page
│   └── forgot.tmpl         # Password reset
├── admin/
│   ├── dashboard.tmpl      # Admin dashboard
│   ├── settings.tmpl       # Settings page
│   └── ...
└── component/
    ├── modal.tmpl          # Reusable modal component
    ├── toast.tmpl          # Toast notifications
    └── ...
```

## Layout Separation (NON-NEGOTIABLE)

**Public and Admin routes use DIFFERENT layouts:**

| Layout | Routes | Design Philosophy |
|--------|--------|-------------------|
| `public.tmpl` | `/`, `/auth/*`, `/server/*`, `/users/*` | Clean, marketing-friendly, top navigation |
| `admin.tmpl` | `/admin/*` | Dashboard-style, sidebar navigation, data-dense |

### Public Layout (`public.tmpl`)

**For end-users and public-facing pages:**

```
┌─────────────────────────────────────────────────────────────────┐
│  [Logo]              Home  API  Docs                [Login]     │  ← Header + Top Nav
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│                                                                 │
│                         <main>                                  │  ← Page content
│                     (centered, clean)                           │
│                                                                 │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│        About · Privacy · Contact · GitHub · {projectversion}    │  ← Footer (centered)
└─────────────────────────────────────────────────────────────────┘
```

**Public Layout Characteristics:**
- Top horizontal navigation bar
- Clean, minimal design with whitespace
- Centered content area
- Marketing/product-focused styling
- Simple footer with links

**Public Navigation Rules (NON-NEGOTIABLE):**

| Rule | Description |
|------|-------------|
| **App-focused** | Navigation reflects the application's features and purpose |
| **NO admin links** | NEVER link to `/admin` from public pages |
| **NO admin hints** | Do not advertise that an admin panel exists |
| **Direct access only** | Admin panel accessed by navigating directly to `{fqdn}/admin` |

**Public nav contains (project-specific):**
- Home (`/`)
- App-specific feature pages (e.g., API docs, features, pricing)
- Login/Register (if multi-user) or just Login link
- User menu (if logged in): Profile, Settings, Logout

**Public nav NEVER contains:**
- ❌ Admin link
- ❌ Dashboard link (unless user dashboard)
- ❌ Settings link to admin settings
- ❌ Any hint of `/admin/*` routes

### Admin Layout (`admin.tmpl`)

**For server administrators:**

```
┌─────────────────────────────────────────────────────────────────┐
│  [Logo]        [Search...]              [🔔] [Admin ▼] [Logout] │  ← Header
├──────────────┬──────────────────────────────────────────────────┤
│              │                                                  │
│  Dashboard   │                                                  │
│              │                                                  │
│  📦 Server   │              <main>                              │
│  🔒 Security │          (content area)                          │
│  🌐 Network  │                                                  │
│  👥 Users    │                                                  │
│  🔗 Cluster  │                                                  │
│              │                                                  │
│  Sidebar     │                                                  │
├──────────────┴──────────────────────────────────────────────────┤
│                    {projectversion} · Docs · Status             │  ← Footer
└─────────────────────────────────────────────────────────────────┘
```

**Admin Layout Characteristics:**
- Collapsible sidebar navigation (left)
- Header with search, notifications bell, admin menu
- Data-dense, dashboard-style design
- Compact footer with version and links
- Breadcrumbs for navigation context

### Shared Theme Classes (NON-NEGOTIABLE)

**Both `public.tmpl` and `admin.tmpl` use the SAME theme CSS classes. No conflicts, no ambiguities.**

| Rule | Description |
|------|-------------|
| **Same theme classes** | Both layouts use `theme-dark`, `theme-light` on `<html>` |
| **Same CSS variables** | Theme colors defined once in `common.css`, used everywhere |
| **Same color schemes** | `dark.css` and `light.css` apply to both public and admin |
| **No layout-specific themes** | Do NOT create `admin-dark.css` or `public-light.css` |
| **No class conflicts** | Theme class names are global and consistent |
| **No ambiguity** | One set of theme rules for the entire project |

**Both layouts start with:**
```html
<!DOCTYPE html>
<html lang="en" class="theme-dark">  <!-- or theme-light -->
<head>
  {{ template "partial/head.tmpl" . }}
</head>
```

**Theme class on `<html>` element (NOT `<body>`):**
```html
<!-- CORRECT -->
<html class="theme-dark">

<!-- WRONG - do not put theme class on body -->
<body class="theme-dark">
```

**CSS variable inheritance:**
```css
/* common.css - theme variables */
html.theme-dark {
  --bg-color: #1a1a2e;
  --text-color: #eaeaea;
  --border-color: #333;
  /* ... all theme colors ... */
}

html.theme-light {
  --bg-color: #ffffff;
  --text-color: #212529;
  --border-color: #dee2e6;
  /* ... all theme colors ... */
}

/* public.css and admin.css use the SAME variables */
.sidebar { background: var(--bg-color); }
.header { color: var(--text-color); }
```

**Theme preference source:**
| Context | Preference Source | Fallback |
|---------|-------------------|----------|
| Public (guest) | `localStorage.theme` | `dark` |
| Public (user) | `user_preferences.theme` | `dark` |
| Admin | `admin_preferences.theme` | `dark` |

**JavaScript theme switching (shared):**

**Note:** Per "HTML5 & CSS Over JavaScript" rules - CSS does all theming via variables. JavaScript ONLY handles preference detection and class switching (cannot be done in pure CSS).

```javascript
// Same function works for both public and admin
// JS only sets the class - CSS does all the actual styling
function setTheme(theme) {
  if (theme === 'auto') {
    const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
    theme = prefersDark ? 'dark' : 'light';
  }
  document.documentElement.className = `theme-${theme}`;
  localStorage.setItem('theme', theme);
}
```

### Layout Partials

| Partial | Public | Admin | Purpose |
|---------|:------:|:-----:|---------|
| `partial/public/header.tmpl` | ✓ | | Logo + top nav + login/user menu |
| `partial/public/nav.tmpl` | ✓ | | Horizontal navigation links |
| `partial/public/footer.tmpl` | ✓ | | About, Privacy, Contact links |
| `partial/admin/header.tmpl` | | ✓ | Logo + search + bell + admin menu |
| `partial/admin/sidebar.tmpl` | | ✓ | Collapsible sidebar navigation |
| `partial/admin/footer.tmpl` | | ✓ | Version, docs, status |
| `partial/head.tmpl` | ✓ | ✓ | Shared `<head>` contents |
| `partial/scripts.tmpl` | ✓ | ✓ | Shared JavaScript includes |

### Static Assets Organization (NON-NEGOTIABLE)

```
src/server/static/
├── css/
│   ├── common.css      # Reset, variables, utilities (loaded first)
│   ├── public.css      # Public layout styles
│   ├── admin.css       # Admin layout styles
│   └── components.css  # Shared components (modals, buttons, toasts)
├── js/
│   └── app.js          # ALL JavaScript in ONE file (minimal)
├── images/
│   ├── logo.svg        # App logo (SVG preferred)
│   ├── favicon.ico     # Favicon
│   └── icons/          # UI icons (SVG preferred)
└── fonts/              # Self-hosted fonts (if any)
```

### CSS Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **One file per context** | `common.css`, `public.css`, `admin.css`, `components.css` |
| **Load order matters** | common → components → public/admin |
| **CSS variables** | Define in `common.css` `:root {}` for theming |
| **NO inline styles** | All styles in CSS files, never in HTML |
| **NO `!important`** | Exception: print styles only |
| **BEM-like naming** | `.component`, `.component-element`, `.component--modifier` |
| **Mobile-first** | Base styles for mobile, `@media (min-width)` for larger |

**CSS Variables (common.css):**
```css
:root {
  /* Colors */
  --primary-color: #007bff;
  --success-color: #28a745;
  --warning-color: #ffc107;
  --danger-color: #dc3545;
  --bg-color: #ffffff;
  --text-color: #212529;

  /* Typography */
  --font-family: system-ui, -apple-system, sans-serif;
  --font-size-base: 1rem;

  /* Spacing */
  --spacing-xs: 0.25rem;
  --spacing-sm: 0.5rem;
  --spacing-md: 1rem;
  --spacing-lg: 2rem;

  /* Borders */
  --border-radius: 0.25rem;
  --border-color: #dee2e6;
}
```

### JavaScript Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **ONE file only** | All JS in `static/js/app.js` - no multiple files |
| **Minimal JS** | CSS-first, JS only when absolutely necessary |
| **No frameworks** | No React, Vue, Alpine, jQuery, etc. |
| **No bundlers** | No webpack, vite, rollup - plain JS only |
| **No transpilers** | No TypeScript, Babel - browser-native JS only |
| **No npm/node** | No package.json for frontend |

**app.js Structure:**
```js
// static/js/app.js - Keep this file SMALL

// ============================================================================
// Clipboard (with feedback)
// ============================================================================
function copyToClipboard(text, btn) {
  navigator.clipboard.writeText(text).then(() => {
    const original = btn.textContent;
    btn.textContent = 'Copied!';
    btn.classList.add('copied');
    setTimeout(() => {
      btn.textContent = original;
      btn.classList.remove('copied');
    }, 2000);
  });
}

// ============================================================================
// Toast notifications
// ============================================================================
function showToast(message, type = 'info', duration = 3000) {
  const toast = document.createElement('div');
  toast.className = `toast toast-${type}`;
  toast.textContent = message;
  document.body.appendChild(toast);

  setTimeout(() => toast.remove(), duration);
}

// ============================================================================
// Modal helpers (for native <dialog>)
// ============================================================================
function openModal(id) {
  document.getElementById(id).showModal();
}

function closeModal(id) {
  document.getElementById(id).close();
}

// ============================================================================
// Form helpers
// ============================================================================
function confirmDelete(form, message = 'Are you sure?') {
  if (confirm(message)) {
    form.submit();
  }
}
```

**What goes in app.js:**
- Clipboard with feedback
- Toast notifications
- Modal helpers
- Form validation (complex only)
- Dynamic content loading (AJAX)
- WebSocket connections

**What stays inline (simple one-liners):**
- `onclick="history.back()"`
- `onclick="window.print()"`
- `onclick="this.closest('dialog').close()"`

### Template Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **Go templates only** | `html/template` package, `.tmpl` extension |
| **Layouts for structure** | `layout/public.tmpl`, `layout/admin.tmpl` |
| **Partials for reuse** | Header, nav, footer, components |
| **Pages for content** | One `.tmpl` per page/route |
| **No logic in templates** | Minimal `{{if}}`, `{{range}}` - logic in handlers |

**Template Inheritance:**
```
layout/public.tmpl
  └── includes partial/head.tmpl
  └── includes partial/public/header.tmpl
  └── includes partial/public/nav.tmpl
  └── yields to page content
  └── includes partial/public/footer.tmpl
  └── includes partial/scripts.tmpl
```

### Partials Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **Shared partials** | `partial/head.tmpl`, `partial/scripts.tmpl` |
| **Context partials** | `partial/public/*`, `partial/admin/*` |
| **Component partials** | Reusable UI: `partial/toast.tmpl`, `partial/modal.tmpl` |
| **No page-specific partials** | If used once, it's not a partial |
| **Self-contained** | Partials include their own styles/scripts if needed |

**Mandatory Partials:**
```
partial/
├── head.tmpl           # <head> - meta, CSS links (REQUIRED)
├── scripts.tmpl        # JS includes before </body> (REQUIRED)
├── public/
│   ├── header.tmpl     # Public header (REQUIRED)
│   ├── nav.tmpl        # Public nav (REQUIRED)
│   └── footer.tmpl     # Public footer (REQUIRED)
└── admin/
    ├── header.tmpl     # Admin header (REQUIRED)
    ├── sidebar.tmpl    # Admin sidebar (REQUIRED)
    └── footer.tmpl     # Admin footer (REQUIRED)
```

**Optional Component Partials:**
```
partial/
├── toast.tmpl          # Toast notification container
├── modal.tmpl          # Reusable modal structure
├── pagination.tmpl     # Pagination controls
├── search.tmpl         # Search form
└── {project}/          # Project-specific partials
    └── *.tmpl
```

**Page Structure - Public:**

```
┌─────────────────────────────────────────┐
│              <header>                   │  ← public/header.tmpl
├─────────────────────────────────────────┤
│               <nav>                     │  ← public/nav.tmpl (TOP)
├─────────────────────────────────────────┤
│                                         │
│              <main>                     │  ← Page content
│                                         │
├─────────────────────────────────────────┤
│              <footer>                   │  ← public/footer.tmpl (BOTTOM)
└─────────────────────────────────────────┘
```

**Page Structure - Admin:**

```
┌─────────────────────────────────────────┐
│              <header>                   │  ← admin/header.tmpl
├──────────┬──────────────────────────────┤
│          │                              │
│  <aside> │         <main>               │  ← admin/sidebar.tmpl + content
│          │                              │
├──────────┴──────────────────────────────┤
│              <footer>                   │  ← admin/footer.tmpl
└─────────────────────────────────────────┘
```

**Nav vs Footer (NON-NEGOTIABLE):**

| Element | Position | Purpose | Contents |
|---------|----------|---------|----------|
| `<nav>` | TOP | Navigation | Links to app sections, user menu |
| `<footer>` | BOTTOM | Information | About, Privacy, Contact, Help, GitHub, version |

**Nav contains (app navigation):**
- Home link
- App-specific sections (project-defined)
- User menu (right side):
  - If logged in: Username dropdown → Profile, Settings, Logout
  - If logged out: Login link

**Nav does NOT contain:**
- API link (users access via /openapi if needed)
- Admin link (don't advertise - admins know where it is)
- Help link (belongs in footer)

**Default Navigation (nav.tmpl):**

```
Desktop:
┌─────────────────────────────────────────────────────────────────┐
│  weather                                      [User Icon] │  ← Header
├─────────────────────────────────────────────────────────────────┤
│  Home  |  [App Section 1]  |  [App Section 2]  |  ...           │  ← Nav
└─────────────────────────────────────────────────────────────────┘

Mobile:
┌─────────────────────────────────────────────────────────────────┐
│  weather                                      [User Icon] │  ← Header
├─────────────────────────────────────────────────────────────────┤
│                                                      [☰ Menu]   │  ← Nav row
└─────────────────────────────────────────────────────────────────┘
                                              ┌───────────────────┐
                                              │  Home             │
                                              │  App Section 1    │  ← Slide-in
                                              │  App Section 2    │     from right
                                              │  ...              │
                                              └───────────────────┘
```

```html
<!-- Header bar: site name + user icon -->
<header class="header">
  <a href="/" class="site-brand">weather</a>

  <!-- User icon (always visible, far right) -->
  <div class="user-menu">
    {{ if .User }}
      <!-- Logged in: user icon dropdown -->
      <div class="dropdown">
        <button class="dropdown-toggle user-icon" aria-label="User menu">
          <svg>...</svg>
        </button>
        <div class="dropdown-menu">
          <span class="dropdown-header">{{ .User.Username }}</span>
          <a href="/users">Profile</a>
          <a href="/users/settings">Settings</a>
          <hr />
          <a href="/auth/logout">Logout</a>
        </div>
      </div>
    {{ else }}
      <!-- Logged out: login icon -->
      <a href="/auth/login" class="user-icon" aria-label="Login">
        <svg>...</svg>
      </a>
    {{ end }}
  </div>
</header>

<!-- Nav bar: separate row below header (CSS-only mobile menu) -->
<nav class="nav">
  <!-- Hidden checkbox controls menu state - NO JavaScript -->
  <input type="checkbox" id="nav-toggle" class="nav-checkbox" hidden>

  <!-- Desktop: inline links | Mobile: hamburger only -->
  <div class="nav-links">
    <a href="/">Home</a>
    <!-- App-specific sections (project-defined) -->
  </div>

  <!-- Mobile: hamburger toggle (checkbox label) -->
  <label for="nav-toggle" class="nav-toggle" aria-label="Toggle navigation">☰</label>

  <!-- Slide-in panel for mobile -->
  <div class="nav-panel">
    <label for="nav-toggle" class="nav-close" aria-label="Close menu">✕</label>
    <a href="/">Home</a>
    <!-- App-specific sections (project-defined) -->
  </div>

  <!-- Overlay - clicking label unchecks checkbox, closing menu -->
  <label for="nav-toggle" class="nav-overlay"></label>
</nav>
```

**Mobile Menu Behavior:**
- Menu slides in from RIGHT edge
- Slides LEFT to open (right-to-left)
- Slides RIGHT to close (left-to-right)
- Overlay dims background, click to close
- User icon stays in header (NOT in menu) - keeps menu clean

**Smart Menu (NON-NEGOTIABLE):**
- If all nav links fit on screen → show inline links, NO hamburger
- If nav links overflow → show hamburger menu
- Detect dynamically on load and resize
- Don't show hamburger if not needed

**CSS-Only Mobile Menu (NO JavaScript):**
```css
/* Mobile slide-in menu using checkbox hack */
@media (max-width: 768px) {
  /* Hide hamburger on desktop, show on mobile */
  .nav-toggle { display: block; cursor: pointer; }
  .nav-links { display: none; }

  /* Slide-in panel */
  .nav-panel {
    position: fixed;
    top: 0;
    right: -280px;           /* Hidden off-screen right */
    width: 280px;
    height: 100vh;
    background: var(--bg-color);
    transition: right 0.3s ease;
    z-index: 1001;
  }

  /* Overlay (hidden by default) */
  .nav-overlay {
    display: none;
    position: fixed;
    inset: 0;
    background: rgba(0, 0, 0, 0.5);
    z-index: 1000;
    cursor: pointer;
  }

  /* When checkbox is checked: show menu and overlay */
  .nav-checkbox:checked ~ .nav-panel {
    right: 0;                /* Slide in from right */
  }

  .nav-checkbox:checked ~ .nav-overlay {
    display: block;
  }
}

@media (min-width: 769px) {
  /* Desktop: show inline links, hide hamburger */
  .nav-toggle, .nav-panel, .nav-overlay { display: none; }
  .nav-links { display: flex; }
}
```

**Mobile Responsive Rules:**
- Nav row below header: inline links or hamburger
- User icon ALWAYS in header (never in menu)
- Menu slides from right edge
- Touch-friendly: minimum 44x44px tap targets
- Overlay closes menu on tap (CSS label toggles checkbox - no JS)

**No Fixed/Pinned Elements (NON-NEGOTIABLE):**
- Header, nav, footer all scroll with page
- NOTHING pinned/fixed to viewport
- User scrolls down → header/nav scroll away
- User scrolls to bottom → footer appears

**Footer Position (NON-NEGOTIABLE):**
- Footer ALWAYS at bottom of page (not floating in middle)
- If content is short → footer still at bottom of viewport
- If content is long → footer below content (scroll to see)
- Use min-height layout to push footer down

```css
/* Footer at bottom, no fixed elements */
body {
  display: flex;
  flex-direction: column;
  min-height: 100vh;
}

main {
  flex: 1;  /* Grows to push footer to bottom */
}

/* NO position: fixed or position: sticky on header/nav/footer */
```

**Print Styles (NON-NEGOTIABLE):**

```css
@media print {
  /* Hide non-essential elements */
  header,
  nav,
  footer,
  .nav-toggle,
  .nav-panel,
  .nav-overlay,
  .no-print,
  button:not(.print-include),
  .toast,
  .modal {
    display: none !important;
  }

  /* Reset backgrounds for ink saving */
  body {
    background: white !important;
    color: black !important;
  }

  /* Ensure content is full width */
  main, .container {
    width: 100% !important;
    max-width: none !important;
    margin: 0 !important;
    padding: 0 !important;
  }

  /* Show URLs after links */
  a[href^="http"]:after {
    content: " (" attr(href) ")";
    font-size: 0.8em;
    color: #666;
  }

  /* Avoid page breaks inside elements */
  pre, blockquote, table, img {
    page-break-inside: avoid;
  }

  /* Start new sections on new page */
  h1, h2 {
    page-break-after: avoid;
  }
}
```

**Print utility classes:**
- `.no-print` - Hide element when printing
- `.print-only` - Show element only when printing (use `display: none` normally)
- `.print-include` - Exception for buttons that should print

**Footer contains (informational links):**
- Standard pages: About, Privacy, Contact, Help
- External links: GitHub
- Branding: project name, version, copyright

**Rule:** Every page template MUST include header, nav, and footer partials. No page may define its own header/nav/footer - use the shared partials only. This ensures:
- Consistent branding across all pages
- Single point of change for navigation updates
- Uniform user experience

**App-Specific Partials (Optional):**

Projects can create additional partials for functionality unique to that application. Place these in `partial/` alongside the mandatory ones.

| Example Partial | Project | Purpose |
|-----------------|---------|---------|
| `search-box.tmpl` | airports, jokes | Reusable search form component |
| `airport-card.tmpl` | airports | Airport info display card |
| `joke-card.tmpl` | jokes | Joke display with copy button |
| `map.tmpl` | airports | Embedded map component |
| `passphrase-generator.tmpl` | wordList | Generator form and output |
| `geoip-result.tmpl` | airports | GeoIP lookup result display |
| `code-block.tmpl` | gitignore | Syntax-highlighted code display |
| `pagination.tmpl` | any | Reusable pagination controls |
| `filters.tmpl` | any | Search/filter form for lists |
| `stats-card.tmpl` | any | Statistics display card |

**App-Specific Partials (add to existing structure):**

See **Template Structure** above for mandatory partials (`partial/public/*`, `partial/admin/*`, `partial/head.tmpl`, `partial/scripts.tmpl`).

Projects add app-specific partials alongside the mandatory ones:
```
src/server/template/partial/
├── public/                  # MANDATORY (see Template Structure)
├── admin/                   # MANDATORY (see Template Structure)
├── head.tmpl                # MANDATORY
├── scripts.tmpl             # MANDATORY
├── search-box.tmpl          # APP-SPECIFIC - search component
├── result-card.tmpl         # APP-SPECIFIC - result display
└── pagination.tmpl          # APP-SPECIFIC - pagination controls
```

**Usage in page templates:**
```go
{{ define "content" }}
<div class="search-section">
  {{ template "search-box" . }}
</div>

<div class="results">
  {{ range .Results }}
    {{ template "result-card" . }}
  {{ end }}
</div>

{{ template "pagination" .Pagination }}
{{ end }}
```

**Guidelines for app-specific partials:**
- Create a partial when the same HTML is used in 2+ places
- Keep partials focused on one component/purpose
- Pass only the data the partial needs
- Name clearly: `{thing}-{purpose}.tmpl` (e.g., `airport-card.tmpl`, `joke-list.tmpl`)

**Embedding Templates (NON-NEGOTIABLE):**

All templates and static assets MUST be embedded in the binary:

```go
package server

import "embed"

//go:embed template/*.tmpl template/**/*.tmpl
var templateFS embed.FS

//go:embed static/*
var staticFS embed.FS
```

**Template Usage:**
```go
{{ define "base" }}
<!DOCTYPE html>
<html lang="en">
<head>{{ template "head" . }}</head>
<body>
  {{ template "header" . }}
  {{ template "nav" . }}
  <main>{{ template "content" . }}</main>
  {{ template "footer" . }}
  {{ template "scripts" . }}
</body>
</html>
{{ end }}
```

### Embedded vs External Assets

| Type | Embedded in Binary | External (Downloaded) |
|------|-------------------|----------------------|
| Templates (`.tmpl`) | YES | NO |
| CSS files | YES | NO |
| JavaScript files | YES | NO |
| Images/Icons | YES | NO |
| Fonts | YES | NO |
| Application data (JSON) | YES | NO |
| GeoIP databases | NO | YES - downloaded on first run, updated weekly |
| IP/Domain Blocklists | NO | YES - downloaded on first run, updated daily |
| CVE databases | NO | YES - downloaded on first run, updated daily |
| SSL certificates | NO | YES - only when using ports 80,443 |

**External Data Rules:**
- Security-related data that needs frequent updates is NEVER embedded
- Downloaded automatically on first run if not present
- Updated automatically via built-in scheduler (see PART 19: SCHEDULER)
- All scheduler tasks configurable via admin panel
- Graceful degradation if download fails (continues without data)
- SSL certificates only generated/managed when running on ports `80,443`

**Benefits:**
- Single static binary deployment
- No external file dependencies at runtime
- Consistent layout across all pages
- Reusable components (DRY principle)
- Auto-escaping for security (XSS prevention)

### CSS Rules

| Bad | Good |
|-----|------|
| `<div style="color: red;">` | `<div class="error-text">` |
| `style="margin: 10px;"` | `class="spacing-sm"` |

**All styles MUST be in CSS files, not HTML elements.**

### Frontend UI Elements (NON-NEGOTIABLE)

**NEVER use default JavaScript UI elements. ALWAYS use custom styled components.**

| NEVER Use | ALWAYS Use Instead |
|-----------|---------------------|
| `alert()` | Custom modal with CSS classes |
| `confirm()` | Custom confirmation modal |
| `prompt()` | Custom input modal or inline form |
| Plain text inputs for options | Dropdowns (`<select>`) |
| Plain text for yes/no | Checkboxes or toggle switches |
| Plain text for multiple options | Radio buttons or dropdown |
| Inline text entry | Only when truly needed (search, names, etc.) |

**UI Element Guidelines:**

| Element | When to Use |
|---------|-------------|
| **Dropdown (`<select>`)** | Selecting from predefined options |
| **Checkbox** | Boolean on/off, enable/disable |
| **Toggle Switch** | Boolean with visual feedback |
| **Radio Buttons** | Mutually exclusive options (2-5 choices) |
| **Dropdown** | Mutually exclusive options (>5 choices) |
| **Multi-select** | Multiple selections from list |
| **Text Input** | Free-form text (names, URLs, search) |
| **Textarea** | Multi-line free-form text |
| **Number Input** | Numeric values with spin buttons |
| **Date/Time Picker** | Date and time selection |
| **Color Picker** | Color selection |
| **File Upload** | File selection with drag-drop |

**Modal Requirements:**
- Custom CSS-styled modals (no browser defaults)
- Backdrop overlay
- Close button (X) in corner
- Click outside to close (optional, configurable)
- Escape key to close
- Focus trap (tab stays within modal)
- Animated entrance/exit
- **Auto-close on action** - clicking any action button (OK, Yes, No, Cancel, Save, Delete, Submit, etc.) automatically closes the modal after performing the action. User should never need to click an action then manually close.

**Toast/Notification Requirements (NON-NEGOTIABLE):**
- Non-blocking notifications (never use JS alerts)
- Stackable - multiple toasts display vertically (max 5 visible)
- Auto-dismiss: 3 seconds (success/info), 5 seconds (warning), never (error)
- Click to dismiss - user can click X or toast body to dismiss early
- Pause on hover - hovering pauses auto-dismiss countdown
- Position: top-right corner, fixed position
- Animation: slide in from right, fade out on dismiss
- Types: success (✓), error (✗), warning (⚠), info (ℹ)
- Progress bar shows remaining time before auto-dismiss
- See "Toast Notifications" section in PART 16 for full implementation

## Layout

| Screen Size | Width |
|-------------|-------|
| ≥ 720px | 90% (5% margins) |
| < 720px | 98% (1% margins) |
| Footer | Always centered, always at bottom |

## Themes (NON-NEGOTIABLE - PROJECT-WIDE)

**Theme system applies to THE ENTIRE PROJECT - ALL interfaces share the same colors and settings:**
- Web interface (HTML pages)
- Admin panel
- Swagger UI
- GraphiQL interface
- CLI colored output
- TUI (bubbletea/lipgloss)
- Native GUI (GTK/Cocoa/Win32)
- ReadTheDocs documentation (if possible)
- All interactive elements

**Three Required Themes:**

| Theme | When Active | Default | Color Scheme |
|-------|-------------|---------|--------------|
| **Dark** | User selects dark OR system dark + auto mode | **YES** | Dark theme colors (see `dark.css`) |
| **Light** | User selects light OR system light + auto mode | No | Light theme colors (see `light.css`) |
| **Auto** | Follows system preference (light/dark) | No | System `prefers-color-scheme` |

**Critical Theme Rules (APPLY TO ENTIRE PROJECT):**
- **BOTH light AND dark themes MUST be easy to read**
- **NO color conflicts** - nothing should be invisible or unreadable in either theme
- **Sufficient contrast ratio** - minimum WCAG AA compliance (4.5:1) in both themes
- **Theme applies everywhere** - web UI, admin panel, Swagger, GraphQL, etc.
- **Theme switching MUST work seamlessly** without page reload
- **All interactive elements MUST be clearly visible** in both themes
- **Syntax highlighting MUST adapt** to theme (use appropriate colors for each theme)
- **User preference persisted** in localStorage or cookie
- **Default to dark** if no preference set

**Theme Implementation Location:**

| Component | File Location | Purpose |
|-----------|---------------|---------|
| **Common palette** | `src/common/theme/colors.go` | Shared colors (single source of truth) |
| Theme core logic | `src/server/theme.go` | Theme detection, switching, persistence |
| Swagger theming | `src/swagger/theme.go` | Swagger UI theme application |
| GraphQL theming | `src/graphql/theme.go` | GraphiQL theme application |
| Web UI theming | `src/server/template/` | HTML template theme classes |
| CSS variables | Embedded in templates | Theme-specific CSS custom properties |
| **TUI theming** | `src/client/tui/styles.go` | Lipgloss styles from palette |
| **CLI colors** | `src/client/cli/output.go` | ANSI colors from palette |
| **GUI theming** | `src/client/gui/theme_*.go` | Native widget theming |

### Unified Color Palette (NON-NEGOTIABLE)

**Colors are defined ONCE in Go and used everywhere - Web CSS, TUI, CLI, GUI.**

```go
// src/common/theme/colors.go
package theme

type Palette struct {
    Background string `json:"background"`
    Foreground string `json:"foreground"`
    Primary    string `json:"primary"`
    Secondary  string `json:"secondary"`
    Accent     string `json:"accent"`
    Success    string `json:"success"`
    Warning    string `json:"warning"`
    Error      string `json:"error"`
    Info       string `json:"info"`
    Surface    string `json:"surface"`
    SurfaceAlt string `json:"surface_alt"`
    Border     string `json:"border"`
    Muted      string `json:"muted"`
}

var Dark = Palette{
    Background: "#1a1b26", Foreground: "#c0caf5",
    Primary: "#7aa2f7", Secondary: "#9ece6a", Accent: "#bb9af7",
    Success: "#9ece6a", Warning: "#e0af68", Error: "#f7768e", Info: "#7dcfff",
    Surface: "#24283b", SurfaceAlt: "#1f2335", Border: "#414868", Muted: "#565f89",
}

var Light = Palette{
    Background: "#ffffff", Foreground: "#1a1b26",
    Primary: "#2e7de9", Secondary: "#587539", Accent: "#7847bd",
    Success: "#587539", Warning: "#8c6c3e", Error: "#c64343", Info: "#007197",
    Surface: "#f5f5f5", SurfaceAlt: "#e9e9ec", Border: "#c0caf5", Muted: "#6172b0",
}
```

### System Theme Detection (Cross-Platform)

| Platform | Detection Method | Notes |
|----------|------------------|-------|
| **Web** | `prefers-color-scheme` media query | CSS/JavaScript |
| **Linux** | `gsettings get org.gnome.desktop.interface color-scheme` | GNOME |
| **macOS** | `defaults read -g AppleInterfaceStyle` | Returns "Dark" if dark mode |
| **Windows** | Registry `AppsUseLightTheme` | 0 = dark, 1 = light |
| **Terminal** | `COLORFGBG` env or fallback to dark | Terminal-specific |

**See PART 36 for CLI/TUI/GUI implementation details.**

**Theme Detection Flow:**
```
1. Check user preference in localStorage/cookie
2. If no preference OR preference is "auto":
   - Check system preference via prefers-color-scheme media query
   - Apply matching theme (light or dark)
3. If preference is "light" or "dark":
   - Apply selected theme directly
4. Default to dark if all detection fails
```

**Theme Switching:**
- Provide theme toggle in UI (☀️ Light / 🌙 Dark / 🔄 Auto)
- Store preference in `localStorage.theme` or cookie
- Apply theme class to `<html>` element: `theme-light`, `theme-dark`
- NO page reload required - instant switching via CSS classes
- All components (Swagger, GraphQL, admin) switch simultaneously

**Accessibility Requirements:**
- Both themes MUST pass WCAG AA contrast requirements (4.5:1 minimum)
- Focus indicators MUST be visible in both themes
- Keyboard navigation MUST work identically in both themes
- Screen readers MUST work correctly in both themes
- No information conveyed by color alone

## Branding & SEO (NON-NEGOTIABLE)

**White labeling is cosmetic only - it changes what users see, not how the server works.**

### What Branding Changes

| Changes (User-Visible) | Does NOT Change (System) |
|------------------------|--------------------------|
| Page titles | Directory names (`weather/`) |
| Browser tab | System username (`weather`) |
| Header/logo text | Log filenames |
| Footer branding | Config paths |
| Email "From" name | Binary name |
| SEO meta tags | API routes |
| OpenGraph data | Service names |
| Swagger UI title | Container names |

### Configuration

```yaml
server:
  branding:
    # Display name (e.g., "Jokes API")
    title: "weather"
    # Short slogan (e.g., "The best jokes API")
    tagline: ""
    # Longer description for SEO/about
    description: ""

  seo:
    # Project-specific - define per app
    # e.g., ["jokes", "api", "humor", "free api"]
    keywords: []
    # Author/organization name
    author: ""
    # OpenGraph image URL for social sharing
    og_image: ""
    # Twitter @handle for cards
    twitter_handle: ""
```

### Where Branding Is Used

| Field | Used In |
|-------|---------|
| `title` | `<title>` tag, header, emails, footer, Swagger UI |
| `tagline` | Homepage hero section, meta description fallback |
| `description` | Meta description, OpenGraph description, about page |
| `keywords` | Meta keywords tag |
| `author` | Meta author tag |
| `og_image` | OpenGraph/Twitter card image |
| `twitter_handle` | Twitter card attribution |

### SEO Meta Tags (Generated)

```html
<head>
  <title>{title} - {tagline}</title>
  <meta name="description" content="{description}">
  <meta name="keywords" content="{keywords}">
  <meta name="author" content="{author}">

  <!-- OpenGraph -->
  <meta property="og:title" content="{title}">
  <meta property="og:description" content="{description}">
  <meta property="og:image" content="{og_image}">
  <meta property="og:type" content="website">
  <meta property="og:url" content="{current_url}">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="{title}">
  <meta name="twitter:description" content="{description}">
  <meta name="twitter:image" content="{og_image}">
  <meta name="twitter:site" content="{twitter_handle}">
</head>
```

### Static Files

| File | Purpose | Generated |
|------|---------|-----------|
| `/sitemap.xml` | Site map for search engines | Yes - auto-generated |
| `/favicon.ico` | Browser favicon | Embedded default, customizable |

### Admin Panel (/admin/server/branding)

| Element | Type | Description |
|---------|------|-------------|
| Title | Text input | Application display name |
| Tagline | Text input | Short slogan |
| Description | Textarea | Longer description for SEO |
| Keywords | Tag input | SEO keywords (comma-separated) |
| Author | Text input | Author/organization |
| OG Image | File upload / URL | Social sharing image |
| Twitter Handle | Text input | @handle |
| Favicon | File upload / URL | Custom favicon |
| Logo | File upload / URL | Custom logo (header) |

### Image Sources

**Logo, favicon, and OG image can be from local file or remote URL.**

| Source | Format | Example |
|--------|--------|---------|
| Local file | File upload | Upload via admin panel |
| Remote URL | URL input | `https://example.com/logo.png` |
| Embedded default | - | Built-in fallback |

### Image Scaling

**Images are automatically scaled/resized as needed:**

| Image | Sizes Generated |
|-------|-----------------|
| Logo | Original, 200px width (header), 50px width (mobile) |
| Favicon | 16x16, 32x32, 48x48, 180x180 (apple-touch-icon), 192x192, 512x512 |
| OG Image | Original, 1200x630 (OpenGraph standard) |

**Scaling Rules:**
- Preserve aspect ratio
- Generate multiple sizes on upload/fetch
- Cache scaled versions locally
- Re-fetch remote URLs periodically (configurable, default: daily)
- Fallback to embedded default if remote URL fails

### Defaults

| Field | Default Value |
|-------|---------------|
| `title` | `weather` |
| `tagline` | Empty |
| `description` | Empty |
| `keywords` | Empty |
| All others | Empty |

**Rule:** If `title` is empty, fall back to `weather`. Other fields are optional.

## Announcements (NON-NEGOTIABLE)

**Admin messages shown in UI for downtime notices, updates, etc.**

### Configuration

```yaml
web:
  announcements:
    enabled: true
    # List of announcement messages
    messages: []
```

### Announcement Structure

```yaml
messages:
  - id: "maintenance-2025-01"
    type: warning
    # warning, info, error, success
    title: "Scheduled Maintenance"
    message: "The server will be down for maintenance on Jan 15, 2025 from 2-4 AM UTC."
    start: "2025-01-14T00:00:00Z"
    # When to start showing
    end: "2025-01-15T04:00:00Z"
    # When to stop showing
    dismissible: true
    # User can dismiss
```

### Admin Panel (/admin/server/announcements)

| Element | Type | Description |
|---------|------|-------------|
| Enable announcements | Toggle | Turn announcements on/off |
| Announcement list | Table | All announcements |
| Add announcement | Button | Create new announcement |
| Type | Dropdown | warning, info, error, success |
| Title | Text input | Short title |
| Message | Textarea | Full message content |
| Start date | Datetime picker | When to start showing |
| End date | Datetime picker | When to stop showing |
| Dismissible | Toggle | Allow users to dismiss |
| Delete | Button | Remove announcement |

## CORS (NON-NEGOTIABLE)

**Default CORS policy allows all origins (`*`).**

### Configuration

```yaml
web:
  # CORS origin configuration
  # - "*": Allow all origins (default)
  # - "https://example.com": Single origin
  # - "https://example.com,https://app.example.com": Multiple origins (comma-separated)
  # - "": Disable CORS headers entirely
  cors: "*"
```

### CORS Headers

| Header | Value |
|--------|-------|
| `Access-Control-Allow-Origin` | Configured origin(s) or `*` |
| `Access-Control-Allow-Methods` | `GET, POST, PUT, PATCH, DELETE, OPTIONS` |
| `Access-Control-Allow-Headers` | `*` |
| `Access-Control-Allow-Credentials` | `true` (only when specific origin, not `*`) |
| `Access-Control-Max-Age` | `86400` (24 hours) |

### Behavior

| Scenario | Behavior |
|----------|----------|
| `cors: "*"` | Allow all origins, credentials NOT allowed |
| `cors: "https://example.com"` | Allow single origin, credentials allowed |
| `cors: "https://a.com,https://b.com"` | Allow listed origins, credentials allowed |
| `cors: ""` | No CORS headers (same-origin only) |
| Preflight (OPTIONS) | Return CORS headers, 204 No Content |

### Mode-Specific Behavior

| Mode | Default | Behavior |
|------|---------|----------|
| Production | `*` | Allow all origins by default (configure if needed) |
| Development | `*` | Allow all origins |

### Admin Panel (/admin/server/web)

| Element | Type | Description |
|---------|------|-------------|
| CORS Origins | Text input | Comma-separated list of allowed origins |
| Allow All | Toggle | Quick toggle for `*` (all origins) |
| Preview | Read-only | Shows resulting CORS headers |

## CSRF Protection (NON-NEGOTIABLE)

**ALL forms MUST have CSRF protection.**

### Configuration

```yaml
web:
  csrf:
    enabled: true
    # Token length in bytes
    token_length: 32
    cookie_name: csrf_token
    header_name: X-CSRF-Token
    # Secure cookie: auto, true, false
    secure: auto
```

### Implementation

- All forms include hidden CSRF token field
- All non-GET requests validate CSRF token
- Token stored in cookie and must match form/header value
- Tokens regenerated on login

## Footer Customization (NON-NEGOTIABLE)

### Configuration

```yaml
web:
  footer:
    # Google Analytics tracking ID (empty = disabled)
    # Example: UA-936146-1 or G-XXXXXXXXXX
    tracking_id: ""

    # Cookie consent banner (EU GDPR compliance) - REQUIRED
    # We use cookies for sessions, preferences, etc. - consent is mandatory
    cookie_consent:
      # enabled: always true (not configurable - we use cookies)
      message: "In accordance with the EU GDPR law this message is being displayed."
      policy_text: "Privacy Policy"
      policy_url: "/server/privacy"
      decline_text: "Decline"
      agree_text: "I Agree"

    # Custom branding HTML above the Application Footer
    # - Not set or "": Use default branding (built-in)
    # - " " (space): Disable branding, show only Application Footer
    # - Custom HTML: Use your own branding
    custom_html: ""
```

### Available Footer Variables

| Variable | Description |
|----------|-------------|
| `{currentyear}` | Current year (e.g., 2025) |
| `weather` | Project name |
| `apimgr` | Organization name |
| `{projectversion}` | Application version |
| `{builddatetime}` | Build date/time |

### Default Application Footer (Always Shown)

```html
<footer class="footer">
  <!-- Standard page links (always first) -->
  <p>
    <a href="/server/about">About</a>
    <span>•</span>
    <a href="/server/privacy">Privacy</a>
    <span>•</span>
    <a href="/server/contact">Contact</a>
    <span>•</span>
    <a href="/server/help">Help</a>
  </p>

  <br />

  <!-- Application branding -->
  <p>
    <a href="{PLATFORM_REPO_URL}" target="_blank">Made with</a> ❤️
    <span>•</span>
    <span>{projectversion}</span>
  </p>

  <br />

  <a href="/healthz">Last update: {builddatetime}</a>
</footer>
```

### Admin Panel (/admin/server/footer)

| Element | Type | Description |
|---------|------|-------------|
| Google Analytics ID | Text input | Tracking ID (empty = disabled) |
| Cookie consent message | Textarea | GDPR message text |
| Policy link text | Text input | Link text (e.g., "Privacy Policy") |
| Policy URL | Text input | Link to privacy policy |
| Decline button text | Text input | Decline button label |
| Agree button text | Text input | Agree button label |
| Custom branding HTML | Textarea | HTML above application footer |
| Preview | Preview pane | Shows rendered footer + banner |

**Note:** Cookie consent banner is always enabled (not toggleable) - we use cookies for sessions and preferences.

## Cookie Consent Banner (NON-NEGOTIABLE)

**Fixed bottom banner for GDPR/privacy compliance. ALWAYS enabled - we use cookies.**

**Admin configures all text via UI (message, policy link, button labels).**

### Banner Layout

```
┌─────────────────────────────────────────────────────────────────┐
│                                                                 │
│   {message} - {policy_link}                                     │
│                                                                 │
│        ┌──────────────┐    ┌──────────────────┐                │
│        │   Decline    │    │     I Agree      │                │
│        └──────────────┘    └──────────────────┘                │
│         (outline btn)        (filled btn)                       │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
  ↑ Fixed to bottom of viewport, above page footer
```

### Banner Rules

| Rule | Requirement |
|------|-------------|
| **Position** | Fixed bottom of viewport, full width |
| **Background** | Theme accent color (purple/magenta in dark theme) |
| **Message** | Centered, configurable via admin |
| **Policy link** | Inline after message, underlined |
| **Buttons** | Side by side, centered below message |
| **Decline button** | Outline/text style (left) |
| **Agree button** | Filled/solid style (right) |
| **Persistence** | Remember choice in localStorage, don't show again |
| **Z-index** | Above all content, below modals |

### Banner Behavior

| Action | Result |
|--------|--------|
| **I Agree** | Set `cookieConsent=accepted` in localStorage, hide banner, enable all cookies + tracking |
| **Decline** | Set `cookieConsent=declined` in localStorage, hide banner, session cookies only |
| **Already set** | Don't show banner if localStorage has cookieConsent |
| **First visit** | Always show banner until user responds |

### Implementation

```html
<!-- Cookie Consent Banner - ALWAYS shown until user responds (we use cookies) -->
<div id="cookie-consent" class="cookie-banner" style="display: none;">
  <p>
    <span class="message">{message}</span>
    <span class="separator"> - </span>
    <a href="{policy_url}" class="policy-link">{policy_text}</a>
  </p>
  <div class="buttons">
    <button class="btn-decline" onclick="declineCookies()">{decline_text}</button>
    <button class="btn-agree" onclick="acceptCookies()">{agree_text}</button>
  </div>
</div>

<script>
// Show banner if no prior consent (we always use cookies)
(function() {
  const consent = localStorage.getItem('cookieConsent');
  const banner = document.getElementById('cookie-consent');

  // No consent yet - show banner
  if (!consent && banner) {
    banner.style.display = 'block';
  }

  // Already accepted - enable full functionality
  if (consent === 'accepted') {
    enableAllCookies();
    loadTracking();
  }
  // Declined - session cookies only (handled server-side)
})();

function acceptCookies() {
  localStorage.setItem('cookieConsent', 'accepted');
  document.getElementById('cookie-consent').style.display = 'none';
  enableAllCookies();
  loadTracking();
}

function declineCookies() {
  localStorage.setItem('cookieConsent', 'declined');
  document.getElementById('cookie-consent').style.display = 'none';
  // Session cookies still work (essential), but no preference/tracking cookies
}

function enableAllCookies() {
  // Enable preference cookies (theme, language, etc.)
  document.cookie = "cookiesEnabled=true; path=/; max-age=31536000";
}

function loadTracking() {
  // Load Google Analytics if tracking_id is configured
  const trackingId = document.querySelector('meta[name="tracking-id"]')?.content;
  if (trackingId) {
    // Load GA script
  }
}
</script>

<style>
.cookie-banner {
  position: fixed;
  bottom: 0;
  left: 0;
  right: 0;
  background: var(--accent-color);  /* Theme accent (purple/magenta) */
  color: var(--accent-text);
  padding: 1.5rem;
  text-align: center;
  z-index: 9999;
}

.cookie-banner p {
  margin-bottom: 1rem;
}

.cookie-banner .policy-link {
  color: inherit;
  text-decoration: underline;
}

.cookie-banner .buttons {
  display: flex;
  justify-content: center;
  gap: 1rem;
}

.cookie-banner .btn-decline {
  background: transparent;
  border: 2px solid var(--accent-text);
  color: var(--accent-text);
  padding: 0.75rem 2rem;
  cursor: pointer;
}

.cookie-banner .btn-agree {
  background: var(--accent-text);
  border: 2px solid var(--accent-text);
  color: var(--accent-color);
  padding: 0.75rem 2rem;
  cursor: pointer;
}

/* Responsive - stack on mobile */
@media (max-width: 480px) {
  .cookie-banner .buttons {
    flex-direction: row;  /* Keep side by side even on mobile */
  }

  .cookie-banner .btn-decline,
  .cookie-banner .btn-agree {
    flex: 1;
  }
}
</style>
```

### Consent Logic

| Condition | Show Banner | Set Cookies | Load Tracking |
|-----------|-------------|-------------|---------------|
| No localStorage (first visit) | **Yes** | No (wait) | No (wait) |
| `cookieConsent=accepted` | No | **Yes** | If `tracking_id` set |
| `cookieConsent=declined` | No | **Session only** | No |

**Cookie consent is ALWAYS enabled - we use cookies for sessions and preferences.**

**Decline behavior:**
- Essential session cookies still set (required for app to function)
- Preference cookies not set
- Tracking/analytics never loaded

## Standard Pages (NON-NEGOTIABLE)

**ALL applications MUST have these standard pages. Content is defined per-application.**

### /server/about

**About the application - what it does, version info, and optionally Tor access.**

| Section | Description |
|---------|-------------|
| Application name | From branding config |
| Version | Current version |
| Description | From branding config or project-specific |
| Features | Key features list (project-specific) |
| Tor access | If Tor installed, show .onion address with copy button |
| Links | GitHub, documentation, etc. |

**Tor Section (shown only if `tor` binary is installed - auto-detected):**

```html
<!-- Example Tor section -->
<div class="tor-access">
  <h3>Tor Hidden Service</h3>
  <p>This application is also available via Tor for enhanced privacy.</p>
  <div class="onion-address">
    <code>{onion_address}</code>
    <button onclick="copyToClipboard()">[Copy]</button>
  </div>
  <p class="note">Requires Tor Browser or Tor-enabled browser.</p>
</div>
```

### /server/privacy

**Privacy policy - what data is collected, how it's used, retention, etc.**

| Section | Description |
|---------|-------------|
| Data collection | What data is collected |
| Data usage | How data is used |
| Data retention | How long data is kept |
| Third parties | What data is shared with third parties |
| Cookies | What cookies are used |
| User rights | How users can access/delete their data |
| Contact | How to contact for privacy concerns |

**Default template provided, customizable via admin panel.**

### /server/contact

**Contact form - sends message to admin or dedicated contact address.**

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| Name | Text | Yes | Sender's name |
| Email | Email | Yes | Sender's email (for reply) |
| Subject | Text | Yes | Message subject |
| Message | Textarea | Yes | Message body |
| Captcha | Captcha | Yes | Spam prevention |

**Submission sends email to `server.contact` address (or admin email if not set).**

### /server/help

**Help page - documentation and usage instructions for the application.**

| Section | Description |
|---------|-------------|
| Getting started | Quick start guide |
| Features | How to use key features |
| API Documentation | Links to Swagger (/openapi) and GraphQL (/graphql) - both in sync |
| FAQ | Frequently asked questions |
| Troubleshooting | Common issues and solutions |

**API Documentation section (always shown):**
```html
<div class="api-docs">
  <h3>API Documentation</h3>
  <p>This application provides a full REST API with interactive documentation.</p>
  <ul>
    <li><a href="/openapi">Swagger UI</a> - Interactive REST API explorer</li>
    <li><a href="/graphql">GraphiQL</a> - Interactive GraphQL explorer</li>
  </ul>
</div>
```

**Content is project-specific. Markdown supported.**

### /server/terms

**Terms of Service - legal terms for using the application.**

| Section | Description |
|---------|-------------|
| Acceptance | Agreement to terms by using the service |
| Account terms | User account responsibilities |
| Acceptable use | What is/isn't allowed |
| Content | User-generated content rules |
| Termination | When/how accounts can be terminated |
| Liability | Limitation of liability |
| Changes | How terms may be updated |
| Governing law | Jurisdiction |

**Default template provided, customizable via admin panel.**

### Configuration

```yaml
server:
  # Contact form recipient
  # If not set, uses admin email
  contact: ""

  pages:
    about:
      # Additional content for about page (markdown supported)
      content: ""
      # Show Tor section (auto-detected from tor.enabled, but can override)
      show_tor: auto

    privacy:
      # Privacy policy content (markdown supported)
      # If empty, uses default template
      content: ""

    contact:
      # Enable contact form
      enabled: true
      # Recipient email (if empty, uses server.contact or admin email)
      recipient: ""
      # Captcha type: recaptcha, hcaptcha, simple (built-in)
      captcha: simple
      # Success message after form submission
      success_message: "Thank you for your message. We'll respond soon."

    help:
      # Help page content (markdown supported)
      # Project-specific - must be defined per application
      content: ""

    terms:
      # Terms of service content (markdown supported)
      # If empty, uses default template
      content: ""
```

### Admin Panel (/admin/server/pages)

| Element | Type | Description |
|---------|------|-------------|
| **About Page** | | |
| Content | Markdown editor | Additional about page content |
| Show Tor section | Toggle | Show .onion address (auto/yes/no) |
| Preview | Button | Preview about page |
| **Privacy Policy** | | |
| Content | Markdown editor | Privacy policy content |
| Reset to default | Button | Restore default template |
| Preview | Button | Preview privacy page |
| **Contact Page** | | |
| Enable contact form | Toggle | Enable/disable contact form |
| Recipient email | Text input | Email to receive messages |
| Captcha type | Dropdown | recaptcha, hcaptcha, simple |
| Success message | Textarea | Message shown after submission |
| Test form | Button | Send test message |
| **Help Page** | | |
| Content | Markdown editor | Help/documentation content |
| Preview | Button | Preview help page |
| **Terms of Service** | | |
| Content | Markdown editor | Terms of service content |
| Reset to default | Button | Restore default template |
| Preview | Button | Preview terms page |

### /server/ API Endpoints

| Route | Method | Description |
|-------|--------|-------------|
| `/api/v1/server/about` | GET | About information (JSON) |
| `/api/v1/server/privacy` | GET | Privacy policy (JSON) |
| `/api/v1/server/contact` | POST | Submit contact form |
| `/api/v1/server/help` | GET | Help content (JSON) |
| `/api/v1/server/terms` | GET | Terms of service (JSON) |

### /server/ Frontend Routes

| Route | Description |
|-------|-------------|
| `/server/about` | About page (HTML) |
| `/server/privacy` | Privacy policy page (HTML) |
| `/server/contact` | Contact form page (HTML) |
| `/server/help` | Help page (HTML) |
| `/server/terms` | Terms of service page (HTML) |

**All /server/ pages follow standard frontend rules (PART 16):**
- Full HTML with header/footer
- Theme support (light/dark)
- Responsive layout
- Proper SEO meta tags

---


# PART 17: ADMIN PANEL (NON-NEGOTIABLE)

**ALL projects MUST have a full admin panel.**

## Admin Panel Isolation (NON-NEGOTIABLE)

**The admin panel is completely isolated from the public site.**

**Note:** `/admin` is the default path. It can be changed via `server.admin_path` config. See "Configurable Admin Path" section below.

| Rule | Description |
|------|-------------|
| **NEVER link to admin path** | No links to `/{admin_path}` on ANY public routes (`/**`) |
| **Intentional access only** | Users must manually type admin path in browser |
| **Separate authentication** | Admin account is ONLY valid for `/{admin_path}/**` routes |
| **No admin mentions** | Don't advertise admin panel existence anywhere |
| **Separate session** | Admin session is separate from user sessions |

### User Types

| User Type | Valid Routes | Authentication |
|-----------|--------------|----------------|
| **Admin** | `/{admin_path}/**` ONLY | Admin credentials (username/password) |
| **Guest/Anon** | `/**` (except `/{admin_path}`) | None |
| **Normal User** | `/**` (except `/{admin_path}`) | User account (if multi-user enabled) |

**Admin credentials are stored in `users.db` (admins table), NOT in config file.**

### Testing Admin Routes

**Admin authentication MUST be tested, not bypassed:**

| Testing Approach | Use For | Method |
|------------------|---------|--------|
| **Proper testing** | Automated tests, beta testing, CI/CD | Use setup token → create admin → test login |
| **Manual dev only** | Quick UI exploration while coding | Use `--debug` flag (bypasses auth) |

**Automated tests MUST:**
1. Verify unauthenticated requests are blocked
2. Use setup token to create admin account
3. Test login with valid credentials
4. Verify admin routes work with session
5. Verify invalid credentials are rejected

**See PART 29: TESTING & DEVELOPMENT for complete admin authentication testing examples.**

### Why Isolated?

- Security: Admin panel not discoverable
- Separation: Admin functions separate from user functions
- Simplicity: No confusion between admin and user roles
- Protection: Reduces attack surface

## Admin Route Hierarchy (NON-NEGOTIABLE)

**All admin routes follow a strict hierarchy. Routes MUST NOT conflict.**

### Route Structure

```
/{adminpath}/                          # Admin root (dashboard)
/{adminpath}/profile                   # Admin's own profile/preferences
/{adminpath}/preferences               # Admin's own preferences/settings
/{adminpath}/notifications             # Admin's own notifications
/{adminpath}/server/                   # Server management (EVERYTHING ELSE)
/{adminpath}/server/settings           # Server settings
/{adminpath}/server/ssl                # SSL/TLS configuration
/{adminpath}/server/email              # Email configuration
/{adminpath}/server/scheduler          # Scheduled tasks
/{adminpath}/server/logs               # Server logs
/{adminpath}/server/logs/audit         # Audit logs
/{adminpath}/server/backup             # Backup/restore
/{adminpath}/server/updates            # Update management
/{adminpath}/server/info               # Server information
/{adminpath}/server/metrics            # Metrics dashboard
/{adminpath}/server/network/           # Network settings
/{adminpath}/server/network/tor        # Tor configuration
/{adminpath}/server/network/geoip      # GeoIP settings
/{adminpath}/server/security/          # Security settings
/{adminpath}/server/security/auth      # Authentication config
/{adminpath}/server/security/tokens    # API token management
/{adminpath}/server/security/firewall  # Firewall rules
/{adminpath}/server/users/             # User management (if multi-user)
/{adminpath}/server/orgs/              # Org management (if orgs enabled)
/{adminpath}/server/cluster/           # Cluster management (if clustering)
/{adminpath}/server/agents/            # Agent management (if agents)
```

### Route Hierarchy Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **`/{adminpath}/` root** | Dashboard ONLY |
| **`/{adminpath}/profile`** | Admin's OWN profile (not server management) |
| **`/{adminpath}/preferences`** | Admin's OWN preferences (not server settings) |
| **`/{adminpath}/notifications`** | Admin's OWN notifications |
| **`/{adminpath}/server/*`** | ALL server management goes here |
| **No other direct children** | ONLY profile/preferences/notifications under `/{adminpath}/` |

### What Goes Where

| Route | Purpose | Example |
|-------|---------|---------|
| `/{adminpath}/` | Dashboard overview | System status, quick stats |
| `/{adminpath}/profile` | Admin's personal account | Change own password, 2FA |
| `/{adminpath}/preferences` | Admin's UI preferences | Theme, language, timezone |
| `/{adminpath}/server/*` | **EVERYTHING server-related** | Config, users, logs, etc. |

### INVALID Routes (NEVER DO THIS)

```
# WRONG - Server management at admin root level
/{adminpath}/settings          # ✗ WRONG - use /{adminpath}/server/settings
/{adminpath}/users             # ✗ WRONG - use /{adminpath}/server/users
/{adminpath}/logs              # ✗ WRONG - use /{adminpath}/server/logs
/{adminpath}/security          # ✗ WRONG - use /{adminpath}/server/security
/{adminpath}/email             # ✗ WRONG - use /{adminpath}/server/email
/{adminpath}/tor               # ✗ WRONG - use /{adminpath}/server/network/tor
/{adminpath}/tokens            # ✗ WRONG - use /{adminpath}/server/security/tokens
/{adminpath}/agents            # ✗ WRONG - use /{adminpath}/server/agents
/{adminpath}/cluster           # ✗ WRONG - use /{adminpath}/server/cluster

# CORRECT
/{adminpath}/profile           # ✓ Admin's own profile
/{adminpath}/preferences       # ✓ Admin's own preferences
/{adminpath}/server/settings   # ✓ Server settings
/{adminpath}/server/users      # ✓ User management
```

### API Route Hierarchy (Same Pattern)

```
/api/v1/admin/                         # Admin API root
/api/v1/admin/profile                  # Admin's own profile
/api/v1/admin/preferences              # Admin's own preferences
/api/v1/admin/server/                  # Server management API
/api/v1/admin/server/settings          # Server settings
/api/v1/admin/server/users             # User management
/api/v1/admin/server/agents            # Agent management
```

### Route Conflict Prevention

**New routes MUST be checked against existing routes:**

```go
// Admin route hierarchy validation
var validAdminRootPaths = map[string]bool{
    "":              true,  // Dashboard (/{adminpath}/)
    "profile":       true,  // Admin's own profile
    "preferences":   true,  // Admin's own preferences
    "notifications": true,  // Admin's own notifications
    "server":        true,  // Server management (has sub-routes)
}

func validateAdminRoute(path string) error {
    // Extract first segment after /{adminpath}/
    parts := strings.Split(strings.Trim(path, "/"), "/")
    if len(parts) == 0 {
        return nil // Root path is OK
    }

    firstSegment := parts[0]
    if !validAdminRootPaths[firstSegment] {
        return fmt.Errorf("invalid admin route: /%s/* - must use /server/* for server management", firstSegment)
    }
    return nil
}
```

### Why This Structure?

1. **Clear separation**: Admin's personal settings vs server management
2. **No conflicts**: Fixed set of root-level paths prevents collisions
3. **Scalability**: All new server features go under `/server/*`
4. **Predictability**: Developers know where to add new routes
5. **Security**: Easy to audit - only 4 valid root-level paths

## Configurable Admin Path (NON-NEGOTIABLE)

**The `/admin` path can be changed for security (obscurity).**

### Configuration

| Setting | Default | Description |
|---------|---------|-------------|
| `server.admin_path` | `admin` | Path segment for admin panel (no leading slash) |

**When changed, ALL admin routes update:**
- `/admin/**` → `/{admin_path}/**`
- `/api/v1/admin/**` → `/api/v1/{admin_path}/**`

### Validation Rules (NON-NEGOTIABLE)

| Rule | Action |
|------|--------|
| **Cannot conflict with existing routes** | Error and revert to `admin` |
| **Reserved paths blocked** | `api`, `static`, `assets`, `health`, `version`, etc. |
| **Valid characters only** | `[a-z0-9-]` (lowercase, numbers, hyphens) |
| **Min/max length** | 2-32 characters |
| **No leading/trailing hyphens** | `my-admin` ✓, `-admin-` ✗ |

**Path Normalization:** See PART 5 "Path Normalization (NON-NEGOTIABLE)" for global path cleanup rules that apply to `admin_path` and all other configurable paths.

### Route Conflict Detection

```go
// Check if new admin path conflicts with existing routes
func validateAdminPath(newPath string, router *mux.Router) error {
    // Normalize first
    newPath = normalizePath(newPath)
    // 1. Check reserved paths
    reserved := []string{"api", "static", "assets", "health", "version", "metrics", ".well-known"}
    for _, r := range reserved {
        if newPath == r {
            return fmt.Errorf("'%s' is a reserved path", newPath)
        }
    }

    // 2. Check existing routes
    existingRoutes := getRegisteredRoutes(router)
    for _, route := range existingRoutes {
        if strings.HasPrefix(route, "/"+newPath) {
            return fmt.Errorf("'%s' conflicts with existing route: %s", newPath, route)
        }
    }

    return nil
}
```

### WebUI Change Flow (NON-NEGOTIABLE)

**When admin path changed via WebUI (`/{admin_path}/server/settings`):**

```
1. User submits new admin path
2. Server validates (no conflicts, valid format)
3. If invalid → Show error, keep current path
4. If valid:
   a. Save to config
   b. Return success with new path
   c. Frontend shows "Reloading..." overlay
   d. Server triggers graceful reload
   e. After reload, frontend redirects to new path
```

**Frontend JavaScript:**
```javascript
async function changeAdminPath(newPath) {
    const response = await fetch(`/${currentAdminPath}/api/v1/admin/server/settings`, {
        method: 'PATCH',
        body: JSON.stringify({ admin_path: newPath })
    });

    if (response.ok) {
        const data = await response.json();
        // Show reload overlay
        showOverlay("Applying changes...");
        // Wait for server reload
        await waitForServerReady();
        // Redirect to new admin path
        window.location.href = `/${data.new_admin_path}/dashboard`;
    } else {
        showError(await response.json());
    }
}
```

### Internal Systems Update (NON-NEGOTIABLE)

**All internal systems MUST use the configured admin path:**

| System | Update Required |
|--------|-----------------|
| **Swagger/OpenAPI** | Base path for admin endpoints |
| **GraphQL** | Admin schema endpoint path |
| **WebSocket** | Admin notification channels |
| **CORS** | Allowed origins for admin path |
| **CSP** | Content Security Policy paths |
| **Session cookies** | Cookie path attribute |
| **Audit logs** | Log correct paths |
| **Error pages** | Login redirect URLs |

**Implementation:**
```go
// Global admin path accessor
func AdminPath() string {
    return config.Get().Server.AdminPath // default: "admin"
}

// Use in route registration
func RegisterAdminRoutes(r *mux.Router) {
    adminPath := AdminPath()
    admin := r.PathPrefix("/" + adminPath).Subrouter()
    // ... register routes

    api := r.PathPrefix("/api/v1/" + adminPath).Subrouter()
    // ... register API routes
}

// Use in templates
{{ .AdminPath }} // Available in all templates
```

### Restart vs Reload

| Change Type | Action | Downtime |
|-------------|--------|----------|
| **Admin path** | Graceful reload | None (routes re-registered) |
| **Port change** | Full restart | Brief (~1-2s) |

## Design Principles

| Principle | Description |
|-----------|-------------|
| Server Admin Focus | Designed for server administration, not end-users |
| Pretty | Clean, modern, professional design |
| Intuitive | Self-explanatory, no manual needed |
| Easy Navigation | Logical grouping, breadcrumbs, search |
| Frontend Rules | Dark theme (default), light/dark/auto themes, responsive, accessible |
| No JS Alerts | Custom modals, toasts, confirmations |
| Real-time Feedback | Show save status, validation errors inline |
| Mobile-Friendly | Works on all screen sizes |
| Keyboard Shortcuts | Power users can navigate quickly |

## Admin Panel Layout (NON-NEGOTIABLE)

### Overall Structure

```
┌─────────────────────────────────────────────────────────────────────────┐
│ HEADER                                                                   │
│ ┌─────────────────────────────────────────────────────────────────────┐ │
│ │ Logo/Title          Search...              [Status] [User] [Logout] │ │
│ └─────────────────────────────────────────────────────────────────────┘ │
├──────────────┬──────────────────────────────────────────────────────────┤
│   SIDEBAR    │                    MAIN CONTENT                          │
│              │                                                          │
│  Dashboard   │  ┌─────────────────────────────────────────────────────┐ │
│              │  │ Breadcrumb: Dashboard > Server > Settings           │ │
│  Server ▼    │  └─────────────────────────────────────────────────────┘ │
│   Settings   │                                                          │
│   SSL/TLS    │  ┌─────────────────────────────────────────────────────┐ │
│   Scheduler  │  │                                                     │ │
│   Logs       │  │              PAGE CONTENT                           │ │
│              │  │                                                     │ │
│  Security ▼  │  │                                                     │ │
│   Auth       │  │                                                     │ │
│   Tokens     │  │                                                     │ │
│   Firewall   │  │                                                     │ │
│              │  │                                                     │ │
│  Network ▼   │  │                                                     │ │
│   Tor        │  │                                                     │ │
│   GeoIP      │  │                                                     │ │
│              │  └─────────────────────────────────────────────────────┘ │
│  Users ▼     │                                                          │
│  (if multi)  │  ┌─────────────────────────────────────────────────────┐ │
│              │  │ FOOTER: Version | Docs | Status                     │ │
│  Cluster ▼   │  └─────────────────────────────────────────────────────┘ │
│  (if enabled)│                                                          │
│              │                                                          │
└──────────────┴──────────────────────────────────────────────────────────┘
```

### Header

| Element | Position | Description |
|---------|----------|-------------|
| Logo/Title | Left | Project name, clickable → dashboard |
| Search | Center | Global search (settings, logs, etc.) |
| Status Indicator | Right | ● Green (OK), ● Yellow (Warning), ● Red (Error) |
| Admin Name | Right | Current admin username |
| Logout | Right | Always visible, one-click logout |

### Sidebar Navigation

**Collapsible sidebar with grouped sections.**

```
📊 Dashboard

📦 Server
   ├── Settings
   ├── Branding
   ├── SSL/TLS
   ├── Scheduler
   ├── Email
   ├── Logs
   ├── Backup
   ├── Maintenance
   ├── Updates
   └── Info

🔒 Security
   ├── Authentication
   ├── API Tokens
   ├── Rate Limiting
   └── Firewall

🌐 Network
   ├── Tor
   ├── GeoIP
   └── Blocklists

👥 Users (if multi-user)
   ├── User List
   ├── Invites
   └── Roles

🔗 Cluster (if enabled)
   ├── Nodes
   ├── Add Node
   └── Settings

❓ Help
   └── Documentation
```

### Sidebar Behavior

| Feature | Description |
|---------|-------------|
| Collapsible | Click section header to expand/collapse |
| Active indicator | Highlight current page |
| Collapse all | Double-click header to collapse sidebar |
| Remember state | Persist expanded/collapsed state |
| Icons | Each section has icon for quick recognition |
| Mobile | Hamburger menu, slide-out drawer |

## /admin (Web Interface)

### Authentication

| Feature | Description |
|---------|-------------|
| Login page | `/admin` (when not logged in) |
| Login form | Username/password, centered card |
| Session | Cookie-based (30 days default, configurable) |
| CSRF | Protection on all forms |
| Remember Me | Option available (extends to 90 days) |
| Logout | Always visible in header |
| MFA | TOTP support (optional, configurable) |

## Server Admin Accounts (NON-NEGOTIABLE)

**Server admins are ADMINISTRATIVE ACCOUNTS for managing the application. They are NOT regular users.**

### Server Admin vs Regular Users

| Aspect | Server Admin | Regular User (PART 33) |
|--------|--------------|------------------------|
| **Purpose** | Manage server, configuration, other users | Use the application features |
| **Scope** | Server-wide administration | Own account and data only |
| **Storage** | `admins` table | `users` table |
| **Required** | **YES - all projects** | **OPTIONAL** (Multi-User feature) |
| **Login** | `/auth/login` → `/admin/*` | `/auth/login` → `/users/*` |
| **Access** | Admin panel (`/admin/*`) | User routes (`/users/*`) |
| **Created by** | Setup wizard, existing admin, or OIDC/LDAP | Registration or admin invitation |

**Important:** Server admins and regular users are completely separate account types stored in different database tables. A server admin is NOT a "privileged user" - they are a different kind of account entirely.

### Server Admin Behavior

| Route | Server Admin Access |
|-------|---------------------|
| `/admin/*` | Full access |
| `/users/*` | NO - treated as guest (redirect to `/admin`) |
| `/auth/login` | Login page |
| `/auth/logout` | Logout |
| Public routes (`/`, `/server/*`, etc.) | Guest view (no user-specific content) |

**Admin credentials are stored in `users.db` (`admins` table), NOT in config file.**

## First Run & Setup Wizard (NON-NEGOTIABLE)

**IMPORTANT: App works perfectly with sane defaults before setup.** Setup wizard is optional and allows customization. Server is fully functional immediately on first run.

### First Run Experience

**On first run, the application:**

1. Creates default `server.yml` with sane defaults
2. Creates empty `server.db` database
3. Auto-detects and configures SMTP (if available)
4. Selects random available port (64xxx range)
5. Generates one-time setup token
6. Displays startup information in console
7. **Starts serving immediately** - fully functional

**Console Output (First Run):**

```
╔══════════════════════════════════════════════════════════════════════╗
║                                                                      ║
║   WEATHER {projectversion}                                     ║
║                                                                      ║
║   Status: Running (first run - setup available)                      ║
║                                                                      ║
╠══════════════════════════════════════════════════════════════════════╣
║                                                                      ║
║   🌐 Web Interface:                                                   ║
║      http://localhost:64521                                          ║
║      http://192.168.1.100:64521                                      ║
║                                                                      ║
║   🔧 Admin Panel:                                                     ║
║      http://localhost:64521/admin                                    ║
║                                                                      ║
║   🔑 Setup Token (use at /admin):                                     ║
║      a1b2c3d4e5f67890abcdef1234567890                                ║
║                                                                      ║
║   📧 SMTP: Auto-detected (localhost:25)                               ║
║                                                                      ║
║   ⚠️  Save the setup token! It will not be shown again.               ║
║                                                                      ║
╚══════════════════════════════════════════════════════════════════════╝

[INFO] Server started successfully
[INFO] Listening on 0.0.0.0:64521
[INFO] SMTP auto-detected: localhost:25 (enabled)
```

### App Usability Before Setup

**The app is FULLY FUNCTIONAL before completing the setup wizard.**

| Feature | Available Before Setup? |
|---------|------------------------|
| Public API endpoints | ✓ Yes |
| Public web pages | ✓ Yes |
| Health checks (`/healthz`) | ✓ Yes |
| OpenAPI docs (`/openapi`) | ✓ Yes |
| GraphQL (if applicable) | ✓ Yes |
| Admin panel (`/admin`) | ✓ Yes (requires setup token) |
| Email features | ✓ Yes (if SMTP auto-detected) |
| Scheduled tasks | ✓ Yes (with defaults) |

**What Setup Wizard Provides:**
- Custom admin username/password (instead of generated)
- Customize app name/branding
- Configure optional features (Tor, SSL, multi-user)
- Receive API token for programmatic access

### Setup Flow

On first run, a one-time setup token is generated and displayed in console. Admin setup follows this flow:

| Step | Action |
|------|--------|
| 1 | Server generates one-time setup token (displayed in console ONCE) |
| 2 | User navigates to `/admin` |
| 3 | User enters setup token |
| 4 | Redirect to `/admin/server/setup` (setup wizard) |

**Setup Wizard Steps (`/admin/server/setup`):**

**Step 1: Create Admin Account**
| Field | Default | Notes |
|-------|---------|-------|
| Username | `administrator` | Changeable (username blocklist does NOT apply to admin) |
| Password | Random (generated) | User MUST copy, OR can enter custom + confirm |

**Step 2: API Token**
| Action | Notes |
|--------|-------|
| Auto-generate API token | User MUST copy (shown once) |
| Token is tied to admin account | Used for API access |

**Step 3: Server Configuration**
| Setting | Description |
|---------|-------------|
| App name | Display name for the application |
| Domain/FQDN | Primary domain (if known) |
| Mode | Production / Development |
| Timezone | Server timezone |

**Step 4: Security Settings**
| Setting | Default | Recommended | Description |
|---------|---------|-------------|-------------|
| Backup encryption password | (none) | **SET ONE** | Encrypts all backups (AES-256-GCM) |
| Enable 2FA for this admin | No | Yes | Adds TOTP to admin account |

**Step 5: Optional Services**
| Setting | Description |
|---------|-------------|
| Enable SSL | Configure HTTPS |
| Enable Multi-User | Enable regular user accounts (PART 33) |

**Step 6: Complete**
| Action | Notes |
|--------|-------|
| Save configuration | Write to `server.yml` |
| Mark setup complete | Setup token invalidated |
| Redirect to `/admin` | Logged in as admin |

**Setup Token Rules:**
- Generated on first run ONLY
- Displayed in console ONCE (never stored in plain text)
- Single use - invalidated after setup complete
- If lost, must reset database to regenerate
- Format: 32 hexadecimal characters (128-bit random)

## Multiple Server Admins (NON-NEGOTIABLE)

**Server admins CAN add additional server admins.**

| Method | Description |
|--------|-------------|
| **Manual creation** | Primary admin invites additional admin accounts via `/admin/server/admins` |
| **OIDC/LDAP group mapping** | Map external identity provider groups to server admin role |

### Admin Hierarchy

| Admin Type | Created By | Can Create Admins? | Can Delete Admins? |
|------------|------------|--------------------|--------------------|
| **Primary Admin** | Setup wizard | Yes | Yes (except self) |
| **Additional Admins** | Primary or other admin | Yes | Yes (except self and primary) |
| **OIDC/LDAP Admins** | Group mapping | Yes | Yes (except primary) |

**Rules:**
- Primary admin cannot be deleted (only via `--maintenance setup`)
- All admins have equal permissions (except deletion hierarchy)
- OIDC/LDAP admin access is automatic based on group membership
- Removing user from external group removes admin access on next login
- All admin actions are audited with admin username

### Admin Invite Flow

```
Admin Panel (/admin/server/admins)
┌─────────────────────────────────────────────────────────────┐
│  Server Administrators                                      │
├─────────────────────────────────────────────────────────────┤
│  Your Account: administrator                                │
│  Total Admins: 2                                            │
│  Currently Online: administrator, backup-admin              │
│                                                             │
│  [+ Invite New Admin]                                       │
└─────────────────────────────────────────────────────────────┘

Admin clicks "Invite New Admin"
         ↓
┌─────────────────────────────────────────────────────────────┐
│  Invite New Server Admin                                    │
├─────────────────────────────────────────────────────────────┤
│  Username: [                    ]                           │
│                                                             │
│  Invite expires in: [24 hours ▼]                            │
│                                                             │
│  [Cancel]  [Generate Invite]                                │
└─────────────────────────────────────────────────────────────┘

         ↓ (Invite generated)

┌─────────────────────────────────────────────────────────────┐
│  ✅ Admin Invite Created                                     │
├─────────────────────────────────────────────────────────────┤
│  Username: backup-admin                                     │
│                                                             │
│  Invite URL (share with new admin):                         │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ https://app.example.com/auth/invite/server/abc123...│    │
│  └─────────────────────────────────────────────────────┘    │
│  [Copy URL]                                                 │
│                                                             │
│  ⚠️  This link will only work ONCE and expires in 24 hours. │
│  The new admin will set their own password on first use.    │
│                                                             │
│  [Done]                                                     │
└─────────────────────────────────────────────────────────────┘
```

**Invite Rules:**
- Invite link is single-use (invalidated after first use or expiry)
- Default expiry: 24 hours (configurable: 1h, 6h, 24h, 48h, 7d)
- New admin can set their own username (username blocklist ignored for admins)
- New admin sets their own password and optional 2FA
- API token generated and shown once
- Invite creation logged to audit log

### OIDC/LDAP Admin Sync

**When a user authenticates via OIDC/LDAP and belongs to a mapped admin group:**

1. User authenticates with OIDC/LDAP provider
2. Server retrieves user's group memberships
3. If user is in `admin_groups` → create/update local admin record
4. Admin credentials synced to local database
5. On next login, even if OIDC/LDAP is down, local credentials work

**Local Sync Fields (`admins` table):**
| Field | Description |
|-------|-------------|
| `username` | From OIDC/LDAP claim |
| `password` | Argon2id hash (synced or set locally) |
| `source` | `local`, `oidc:{provider}`, `ldap` |
| `external_id` | Provider's user ID |
| `groups` | JSON array of cached group memberships |
| `last_sync` | Last successful sync timestamp |

**Fallback Behavior:**
| Scenario | Behavior |
|----------|----------|
| OIDC/LDAP available | Authenticate with provider, sync to local |
| OIDC/LDAP unavailable | Use cached local credentials |
| User removed from admin group | Next successful OIDC/LDAP login revokes admin |
| Provider permanently down | Local credentials continue to work |

## Server Admin Security (NON-NEGOTIABLE)

**ALL security settings that apply to the primary server admin ALSO apply to additional server admins.**

| Security Feature | Applies To | Required/Recommended |
|------------------|------------|---------------------|
| Password complexity requirements | All server admins | REQUIRED |
| TOTP 2FA support | All server admins | REQUIRED (usage recommended) |
| Passkey/WebAuthn support | All server admins | REQUIRED (usage recommended) |
| Recovery keys (when MFA enabled) | All server admins | REQUIRED |
| Session timeout | All server admins | REQUIRED |
| API token security | All server admins | REQUIRED |
| Audit logging | All server admins | REQUIRED |
| Rate limiting | All server admins | REQUIRED |
| IP restrictions (if configured) | All server admins | OPTIONAL |

**MFA for Server Admins:**
- Every project MUST support TOTP and Passkeys for server admins
- MFA is optional but STRONGLY recommended - admin chooses to enable
- This applies even to simple apps without regular users (e.g., `jokes`, `airports`)
- Admin panel shows clear prompts encouraging MFA setup

**No exceptions.** Additional admins do not get weaker security than the primary admin.

### Server Admin Account Security Details

**Server admins have access to the same account security features as regular users (when Multi-User is enabled).**

#### Passkeys/WebAuthn

| Feature | Description |
|---------|-------------|
| **Registration** | Admin can register multiple passkeys at `/admin/profile/security` |
| **Login** | Passkey can be used as primary login or as 2FA |
| **Device-bound** | Each passkey tied to specific device/authenticator |
| **Naming** | Admin names each passkey for identification |
| **Revocation** | Admin can revoke individual passkeys |
| **Backup** | Recovery keys provided when first passkey registered |

#### TOTP Two-Factor Authentication

| Feature | Description |
|---------|-------------|
| **Setup** | QR code + manual entry key at `/admin/profile/security` |
| **Apps supported** | Any TOTP app (Google Authenticator, Authy, 1Password, etc.) |
| **Backup codes** | 10 one-time recovery codes generated on setup |
| **Regenerate** | Can regenerate backup codes (invalidates old ones) |
| **Disable** | Requires current TOTP code or recovery key to disable |

#### Account Email vs Notification Email (NON-NEGOTIABLE)

**Server admins can configure separate email addresses for security vs general notifications.**

| Email Type | Purpose | Required | Examples |
|------------|---------|----------|----------|
| **Account Email** | Security-critical communications | YES | Password reset, 2FA recovery, security alerts, login from new device, session terminated |
| **Notification Email** | General notifications (non-security) | NO (defaults to account email) | System updates, backup completed, scheduled task failures, certificate expiry warnings |

**Rules:**
- Account email is set during setup (required)
- Notification email is optional (defaults to account email if not set)
- Both emails must be verified before use
- Account email changes require current password + 2FA (if enabled)
- Notification email changes only require current session
- **All email features require working SMTP** - if SMTP unavailable, no emails sent

**Admin Profile Email Settings:**
```
┌─────────────────────────────────────────────────────────────┐
│  Email Settings                                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Account Email (security notifications):                    │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ admin@example.com                            [Edit] │    │
│  └─────────────────────────────────────────────────────┘    │
│  Used for: password reset, 2FA recovery, security alerts    │
│                                                             │
│  Notification Email (general notifications):                │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ alerts@example.com                           [Edit] │    │
│  └─────────────────────────────────────────────────────┘    │
│  Used for: system updates, backup status, task failures    │
│  [ ] Use account email for all notifications                │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

#### Scoped Notification Preferences (NON-NEGOTIABLE)

**Server admins can enable/disable specific notification categories.**

| Category | Default | Description |
|----------|---------|-------------|
| **Security Alerts** | ON (locked) | Cannot disable - login from new device, password changed, 2FA changed |
| **Session Notifications** | ON | Session started from new location, session terminated |
| **System Status** | ON | Server errors, high resource usage, service degradation |
| **Backup Status** | ON | Backup completed, backup failed |
| **Certificate Alerts** | ON | SSL certificate expiring, renewal status |
| **Scheduled Tasks** | OFF | Task completed, task failed |
| **Updates Available** | ON | New version available |

**Notification Preferences UI:**
```
┌─────────────────────────────────────────────────────────────┐
│  Notification Preferences                                   │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Security (cannot be disabled):                             │
│  [✓] Security alerts (login, password, 2FA changes)        │
│                                                             │
│  Account:                                                   │
│  [✓] Session notifications                                  │
│                                                             │
│  System:                                                    │
│  [✓] System status alerts                                   │
│  [✓] Backup status                                          │
│  [✓] Certificate alerts                                     │
│  [ ] Scheduled task notifications                           │
│  [✓] Update notifications                                   │
│                                                             │
│  Delivery: [Email ▼]  (requires SMTP)                       │
│                                                             │
│  [Save Preferences]                                         │
└─────────────────────────────────────────────────────────────┘
```

**SMTP Requirement:**
- All email notifications require working SMTP configuration
- If SMTP unavailable, notifications shown in admin panel only (no email)
- SMTP status shown in notification preferences
- See PART 18: EMAIL & NOTIFICATIONS for SMTP configuration

#### Admin Appearance Settings (`/admin/profile/preferences`)

**Server admins can customize their admin panel appearance.**

| Setting | Type | Default | Description |
|---------|------|---------|-------------|
| `theme` | Select | `dark` | Theme (dark/light/auto) |
| `font_size` | Select | `medium` | Font size (small/medium/large) |
| `reduce_motion` | Toggle | Off | Reduce animations |
| `date_format` | Select | `YYYY-MM-DD` | Date display format |
| `time_format` | Select | `24h` | Time display format (12h/24h) |

**Admin Appearance Settings UI:**
```
┌─────────────────────────────────────────────────────────────┐
│  Appearance Settings                                        │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Theme                                                      │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐                       │
│  │  🌙     │ │  ☀️     │ │  💻     │                       │
│  │ Dark    │ │ Light   │ │ Auto    │                       │
│  └─────────┘ └─────────┘ └─────────┘ ↑ Default: Dark       │
│                                                             │
│  Font Size                                                  │
│  ○ Small                                                    │
│  ● Medium (default)                                         │
│  ○ Large                                                    │
│                                                             │
│  Accessibility                                              │
│  [OFF] Reduce motion                                        │
│        Minimize animations and transitions.                 │
│                                                             │
│  Date & Time                                                │
│  Date Format: [YYYY-MM-DD ▼]                               │
│  Time Format: [24h ▼]                                       │
│                                                             │
│  [Save Changes]                                             │
└─────────────────────────────────────────────────────────────┘
```

**Admin theme applies to:**
- Admin panel (`/admin/*`)
- Admin-accessible Swagger UI
- Admin-accessible GraphiQL

**Note:** Admin theme preference is independent of the site-wide default theme. The site default is dark, but each admin can choose their own preference.

## Server Admin Privacy (NON-NEGOTIABLE)

**Server admins CANNOT see other server admin accounts, similar to user privacy.**

| What Admin CAN See | What Admin CANNOT See |
|--------------------|----------------------|
| Own account details | Other admin usernames |
| Own API token (regenerate) | Other admin emails |
| Own 2FA status | Other admin passwords |
| Own session history | Other admin API tokens |
| Total admin count (number only) | Other admin 2FA secrets |
| | Other admin session data |

**Admin Panel (`/admin/server/admins`):**
```
┌─────────────────────────────────────────────────────────────┐
│  Server Administrators                                      │
├─────────────────────────────────────────────────────────────┤
│  Your Account: administrator                                │
│  Total Admins: 3                                            │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐    │
│  │  [Invite New Admin]                                 │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
│  Note: For security, you cannot view other admin accounts.  │
│  Each admin manages their own credentials independently.    │
└─────────────────────────────────────────────────────────────┘
```

**Why This Restriction?**
- **Separation of trust**: Compromised admin cannot enumerate other admins
- **Privacy**: Admin credentials are personal, not shared
- **Security**: Prevents admin-to-admin attacks
- **Audit integrity**: Each admin accountable for own actions only

**What Admins CAN Do With Other Admins:**
| Action | Allowed? | Notes |
|--------|----------|-------|
| Know total count | ✓ | Number only, no details |
| See who is logged in | ✓ | Username only (e.g., "administrator logged in") |
| Add new admin (invite) | ✓ | Creates invite, credentials shown once to new admin |
| Remove admin (non-primary) | ✓ | By username only (must know it) |
| View other admin details | ✗ | Privacy by design |
| Reset other admin password | ✗ | Each admin manages own credentials |
| Disable other admin 2FA | ✗ | Use `--maintenance setup` for recovery |

### Admin Session Visibility

**Admins can see which other admins are currently logged in (username only).**

```
Admin Panel Header:
┌─────────────────────────────────────────────────────────────┐
│  {app_name} Admin    │  🟢 2 admins online  │  🔔  │  [You] │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼ (click to expand)
                       ┌──────────────────┐
                       │  Admins Online   │
                       ├──────────────────┤
                       │  🟢 administrator │
                       │  🟢 backup-admin  │
                       └──────────────────┘
```

**What IS Shown:** Username of logged-in admins, online status, total count

**What is NOT Shown:** IP address, session duration, last activity, device/browser info

### Admin Recovery

**Additional admins (non-primary) who lose access:**

| Scenario | Recovery Method |
|----------|-----------------|
| Forgot password | Use own recovery keys OR contact primary admin |
| Lost 2FA + recovery keys | Contact primary admin to delete account, re-invite |
| OIDC/LDAP admin locked out | Fix in identity provider, or primary admin removes mapping |

**Primary admin CANNOT:**
- Reset other admin's password directly
- View other admin's credentials
- Disable other admin's 2FA directly

**Primary admin CAN:**
- Delete the additional admin account entirely
- Re-invite them (they set up fresh credentials)

### Login Page (`/admin`)

```
┌─────────────────────────────────────────┐
│                                         │
│         ┌───────────────────┐           │
│         │   {Project Name}  │           │
│         │   Admin Panel     │           │
│         ├───────────────────┤           │
│         │                   │           │
│         │  Username: [____] │           │
│         │  Password: [____] │           │
│         │                   │           │
│         │  [ ] Remember me  │           │
│         │                   │           │
│         │    [  Login  ]    │           │
│         │                   │           │
│         └───────────────────┘           │
│                                         │
│              {projectversion}           │
└─────────────────────────────────────────┘
```

**Login page rules:**
- Centered card on dark background
- Project name/logo at top
- No links to public site
- Version number at bottom (small)
- No "Forgot password" (admin resets via CLI if needed)

### Dashboard (`/admin/dashboard`)

**Overview of server status and system resources at a glance.**

```
┌─────────────────────────────────────────────────────────────────────────┐
│ Dashboard                                                                │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐ │
│  │   STATUS     │  │   UPTIME     │  │   REQUESTS   │  │   ERRORS     │ │
│  │   ● Online   │  │   5d 12h 3m  │  │   12,345     │  │   23         │ │
│  │              │  │              │  │   (24h)      │  │   (24h)      │ │
│  └──────────────┘  └──────────────┘  └──────────────┘  └──────────────┘ │
│                                                                         │
│  ┌─────────────────────────────────┐  ┌─────────────────────────────┐   │
│  │ SYSTEM RESOURCES                │  │ QUICK ACTIONS               │   │
│  │                                 │  │                             │   │
│  │ CPU:    [████████░░] 78%        │  │ [Restart Server]            │   │
│  │ Memory: [██████░░░░] 62%        │  │ [Clear Cache]               │   │
│  │ Disk:   [████░░░░░░] 45%        │  │ [Create Backup]             │   │
│  │                                 │  │ [View Logs]                 │   │
│  └─────────────────────────────────┘  └─────────────────────────────┘   │
│                                                                         │
│  ┌─────────────────────────────────┐  ┌─────────────────────────────┐   │
│  │ RECENT ACTIVITY                 │  │ SCHEDULED TASKS             │   │
│  │                                 │  │                             │   │
│  │ 10:30 Config updated            │  │ SSL Renewal    in 23 days   │   │
│  │ 10:15 Admin login               │  │ GeoIP Update   in 2 days    │   │
│  │ 09:45 Backup completed          │  │ Auto Backup    in 5 hours   │   │
│  │ 09:00 SSL renewed               │  │ Session Clean  in 45 min    │   │
│  └─────────────────────────────────┘  └─────────────────────────────┘   │
│                                                                         │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │ ALERTS / WARNINGS                                                │    │
│  │                                                                  │    │
│  │ ⚠️  SSL certificate expires in 23 days                          │    │
│  │ ⚠️  Disk usage above 80% threshold                              │    │
│  │ ℹ️  Update available: v1.2.4                                    │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### Dashboard Widgets

| Widget | Content |
|--------|---------|
| Status | Online/Maintenance/Error indicator |
| Uptime | Time since last restart |
| Requests | Request count (24h) |
| Errors | Error count (24h) |
| System Resources | CPU, Memory, Disk usage bars |
| Quick Actions | Common admin tasks |
| Recent Activity | Last 5-10 audit log entries |
| Scheduled Tasks | Next scheduled tasks |
| Alerts | Warnings and notifications |

### Required Admin Pages

| Route | Page | Description |
|-------|------|-------------|
| `/admin` | Login | Login form (if not authenticated) |
| `/admin/dashboard` | Dashboard | Overview, stats, quick actions |
| `/admin/server/settings` | Server Settings | Port, mode, FQDN, etc. |
| `/admin/server/branding` | Branding | Title, logo, favicon, colors |
| `/admin/server/ssl` | SSL/TLS | Certificates, Let's Encrypt |
| `/admin/server/scheduler` | Scheduler | View/edit scheduled tasks |
| `/admin/server/email` | Email | SMTP settings, templates |
| `/admin/server/logs` | Logs | View access, error, audit logs |
| `/admin/server/security/auth` | Authentication | Password, MFA, sessions |
| `/admin/server/security/tokens` | API Tokens | Generate, revoke tokens |
| `/admin/server/security/ratelimit` | Rate Limiting | Configure rate limits |
| `/admin/server/security/firewall` | Firewall | IP allow/block lists |
| `/admin/server/network/tor` | Tor | View .onion address, status (auto-enabled if installed) |
| `/admin/server/network/geoip` | GeoIP | Country blocking, database updates |
| `/admin/server/network/blocklists` | Blocklists | IP/domain blocklists |
| `/admin/server/moderation/users` | Users | User moderation (if multi-user) |
| `/admin/server/users/invites` | Invites | Invite codes (if multi-user) |
| `/admin/server/backup` | Backup | Create/restore backups |
| `/admin/server/maintenance` | Maintenance | Maintenance mode |
| `/admin/server/updates` | Updates | Check/apply updates |
| `/admin/server/info` | Server Info | Version, environment, deps |
| `/admin/server/cluster/nodes` | Nodes | Cluster node management |
| `/admin/server/cluster/add` | Add Node | Generate join token |
| `/admin/help` | Help | Documentation links |

### Settings Page Layout

**Standard layout for all settings pages.**

```
┌─────────────────────────────────────────────────────────────────────────┐
│ Server Settings                                              [Save All] │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  General                                                                │
│  ─────────────────────────────────────────────────────────────────────  │
│                                                                         │
│  Port                                                                   │
│  [64580        ]  ⓘ The port the server listens on                     │
│                   ⚠️ Requires restart                                   │
│                                                                         │
│  Mode                                                                   │
│  [Production ▼]   ⓘ Production enforces strict host validation         │
│                                                                         │
│  FQDN                                                                   │
│  [api.example.com]  ⓘ Fully qualified domain name (auto-detected)      │
│                                                                         │
│  ─────────────────────────────────────────────────────────────────────  │
│                                                                         │
│  Process                                                                │
│  ─────────────────────────────────────────────────────────────────────  │
│                                                                         │
│  Daemonize                                                              │
│  [○ Off]            ⓘ Detach from terminal on start (for manual start) │
│                     ⚠️ Requires restart. Don't use with systemd/docker. │
│                                                                         │
│  ─────────────────────────────────────────────────────────────────────  │
│                                                                         │
│  Advanced                                                    [Expand ▼] │
│  ─────────────────────────────────────────────────────────────────────  │
│                                                                         │
│                                                                         │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │                                            [Cancel] [Save]      │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### Form Elements (NON-NEGOTIABLE)

| Element | Visual | Usage |
|---------|--------|-------|
| **Toggle** | `[● On]` / `[○ Off]` | Boolean on/off (preferred for enable/disable) |
| **Checkbox** | `[✓]` / `[ ]` | Boolean, multiple selections, opt-in features |
| **Dropdown** | `[Value ▼]` | Selection from predefined list |
| **Text** | `[value_____]` | Single-line string |
| **Number** | `[123_______]` | Numeric values (port, limit, count) |
| **Password** | `[••••••] 👁` | Secrets with show/hide toggle |
| **Textarea** | Multi-line box | JSON, lists, long text |
| **Tags** | `[tag1][tag2][+]` | Multiple values (IPs, keywords) |
| **File** | `[Choose File]` | Upload (logos, certs) |
| **Color** | `[#FF5733] 🎨` | Color picker |
| **Duration** | `[5] [minutes ▼]` | Time with unit dropdown |
| **Readonly** | `value (locked)` | Display only, not editable |

### Form Behavior

| Feature | Description |
|---------|-------------|
| Tooltips | ⓘ icon shows help on hover |
| Validation | Real-time, inline error messages |
| Unsaved indicator | Show when form has unsaved changes |
| Save feedback | Toast notification on save |
| Confirm dangerous | Modal for destructive actions |
| Restart warning | ⚠️ icon if setting requires restart |
| Default values | Show default in placeholder |
| Live reload | No ⚠️ = changes apply immediately |

### Server Settings Field Definitions

**`/admin/server/settings` - All fields with control types:**

#### General Section

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `port` | Number | `64580` | ⚠️ Yes | Server listen port |
| `mode` | Dropdown | `production` | ⚠️ Yes | `production` / `development` |
| `fqdn` | Text | (auto) | No | Fully qualified domain name |
| `address` | Text | `[::]` | ⚠️ Yes | Listen address |

#### Process Section

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `daemonize` | Toggle | Off | ⚠️ Yes | Detach from terminal on start |
| `pidfile` | Toggle | On | ⚠️ Yes | Create PID file |

#### Branding Section

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `title` | Text | `weather` | No | App display name |
| `tagline` | Text | (empty) | No | Short slogan |
| `description` | Textarea | (empty) | No | SEO/about description |
| `logo` | File | (none) | No | Logo image upload |
| `favicon` | File | (none) | No | Favicon upload |
| `theme` | Dropdown | `auto` | No | `auto` / `light` / `dark` |
| `accent_color` | Color | `#007bff` | No | Primary accent color |

#### SEO Section

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `keywords` | Tags | (empty) | No | Meta keywords |
| `author` | Text | (empty) | No | Author/org name |
| `og_image` | File | (none) | No | OpenGraph image |
| `twitter_handle` | Text | (empty) | No | Twitter @handle |

#### Security Section (`/admin/server/security`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `admin_path` | Text | `admin` | Reload | Custom admin panel path (see PART 17) |
| `rate_limit.enabled` | Toggle | On | No | Enable rate limiting |
| `rate_limit.requests` | Number | `120` | No | Requests per window |
| `rate_limit.window` | Duration | `1 minute` | No | Rate limit window |
| `cors.enabled` | Toggle | On | No | Enable CORS |
| `cors.origins` | Tags | `*` | No | Allowed origins |
| `cors.methods` | Checkbox group | GET,POST,etc | No | Allowed methods |
| `csp.enabled` | Toggle | On | No | Content Security Policy |
| `hsts.enabled` | Toggle | On | No | HTTP Strict Transport Security |
| `hsts.max_age` | Duration | `1 year` | No | HSTS max age |

#### Account Lockout Section

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `soft_lock_attempts` | Number | `5` | No | Attempts before soft lock |
| `soft_lock_duration` | Duration | `15 min` | No | Soft lock duration |
| `hard_lock_attempts` | Number | `10` | No | Attempts before hard lock |
| `hard_lock_duration` | Duration | `1 hour` | No | Hard lock duration |
| `permanent_lock_attempts` | Number | `15` | No | Attempts before permanent lock |

#### IP Blocking Section

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `ip_block.enabled` | Toggle | On | No | Enable IP blocking |
| `ip_block.escalation` | Toggle | On | No | Escalating block durations |
| `ip_block.first_duration` | Duration | `1 hour` | No | First block duration |
| `ip_block.max_duration` | Duration | `7 days` | No | Maximum block duration |
| `allowlist` | Tags | (empty) | No | IPs never blocked |
| `blocklist` | Tags | (empty) | No | IPs always blocked |

#### SSL/TLS Section (`/admin/server/security/ssl`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `ssl.enabled` | Toggle | Off | ⚠️ Yes | Enable HTTPS |
| `ssl.cert` | File/Text | (auto) | ⚠️ Yes | Certificate path or upload |
| `ssl.key` | File/Text | (auto) | ⚠️ Yes | Private key path or upload |
| `ssl.min_version` | Dropdown | `TLS 1.2` | ⚠️ Yes | Minimum TLS version |
| `ssl.letsencrypt.enabled` | Toggle | Off | No | Use Let's Encrypt |
| `ssl.letsencrypt.email` | Text | (required) | No | Contact email |
| `ssl.letsencrypt.staging` | Toggle | Off | No | Use LE staging server |
| `ssl.letsencrypt.challenge` | Dropdown | `http-01` | No | Challenge type |

#### Authentication Section (`/admin/server/security/auth`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `session.timeout` | Duration | `24 hours` | No | Session expiry |
| `session.extend_on_activity` | Toggle | On | No | Extend on activity |
| `mfa.enabled` | Toggle | Off | No | Require MFA for admins |
| `mfa.methods` | Checkbox group | TOTP | No | Allowed MFA methods |
| `password.min_length` | Number | `8` | No | Minimum password length |
| `password.require_uppercase` | Toggle | On | No | Require uppercase |
| `password.require_number` | Toggle | On | No | Require number |
| `password.require_special` | Toggle | Off | No | Require special char |

#### Backup Section (`/admin/server/backup`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `backup.enabled` | Toggle | On | No | Enable scheduled backups (backup_daily) |
| `backup.hourly_enabled` | Toggle | Off | No | Enable hourly incremental (backup_hourly) |
| `backup.schedule` | Text | `0 2 * * *` | No | Daily backup cron schedule |
| `backup.retention.max_backups` | Number | `1` | No | Daily full backups to keep (≥1) |
| `backup.retention.keep_weekly` | Number | `0` | No | Weekly backups (Sunday) - 0 = disabled |
| `backup.retention.keep_monthly` | Number | `0` | No | Monthly backups (1st) - 0 = disabled |
| `backup.retention.keep_yearly` | Number | `0` | No | Yearly backups (Jan 1st) - 0 = disabled |
| `backup.encryption.enabled` | Toggle | Off | No | Encrypt backups |
| `backup.encryption.password` | Password | (none) | No | Encryption password |

#### Email/SMTP Section (`/admin/server/email`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `smtp.host` | Text | (autodetect) | No | SMTP server |
| `smtp.port` | Number | `587` | No | SMTP port |
| `smtp.username` | Text | (none) | No | SMTP username |
| `smtp.password` | Password | (none) | No | SMTP password |
| `smtp.tls` | Dropdown | `auto` | No | `auto`/`starttls`/`tls`/`none` |
| `from.name` | Text | (app title) | No | Sender name |
| `from.email` | Text | `no-reply@{fqdn}` | No | Sender email |
| `[Test Connection]` | Button | - | - | Send test email |

#### Notifications Section (`/admin/server/notifications`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `notifications.backup_success` | Toggle | Off | No | Notify on backup success |
| `notifications.backup_failure` | Toggle | On | No | Notify on backup failure |
| `notifications.ssl_expiring` | Toggle | On | No | Notify SSL expiring |
| `notifications.ssl_expiring_days` | Number | `14` | No | Days before expiry |
| `notifications.security_alerts` | Toggle | On | No | Security event alerts |
| `notifications.update_available` | Toggle | On | No | New version available |

#### Scheduler Section (`/admin/server/scheduler`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `scheduler.enabled` | Toggle | On | No | Enable scheduler |
| Task rows with: | | | | |
| - Task name | Readonly | - | - | Task identifier |
| - Enabled | Toggle | varies | No | Enable/disable task |
| - Schedule | Text | cron expr | No | Cron expression |
| - Last run | Readonly | timestamp | - | Last execution |
| - Next run | Readonly | timestamp | - | Next execution |
| - `[Run Now]` | Button | - | - | Trigger immediately |

#### URL Detection Section (`/admin/server/url`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `url_detection.learning` | Toggle | On | No | Learn domain patterns |
| `url_detection.min_samples` | Number | `3` | No | Min samples for wildcard |
| `url_detection.sample_window` | Duration | `5 min` | No | Sample time window |
| `url_detection.log_changes` | Toggle | On | No | Log domain changes |
| `url_detection.live_reload` | Toggle | On | No | Live reload on detection |
| Detected domains | Readonly | - | - | Currently detected FQDNs |
| Inferred wildcard | Readonly | - | - | `*.example.com` if detected |

#### Tor Section (`/admin/server/tor`) - *if tor installed*

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `tor.enabled` | Toggle | (auto) | No | Enable hidden service |
| `tor.onion_address` | Readonly | - | - | `.onion` address |
| `tor.status` | Readonly | - | - | Running/Stopped |
| `[Copy Address]` | Button | - | - | Copy onion to clipboard |

#### GeoIP Section (`/admin/server/geoip`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `geoip.enabled` | Toggle | On | No | Enable GeoIP lookups |
| `geoip.auto_update` | Toggle | On | No | Auto-update databases |
| `geoip.update_schedule` | Text | `0 3 * * *` | No | Update cron schedule |
| `geoip.country_block` | Tags | (empty) | No | Blocked country codes |
| `geoip.country_allow` | Tags | (empty) | No | Allowed country codes |
| Database status | Readonly | - | - | Last update, size |

### Control Type Guidelines

| When to use | Control |
|-------------|---------|
| Enable/disable feature | **Toggle** |
| Yes/no with label | **Checkbox** |
| Multiple options (2-5) | **Dropdown** |
| Multiple options (5+) | **Searchable dropdown** |
| Select multiple | **Checkbox group** or **Tags** |
| Free text, short | **Text** |
| Free text, long | **Textarea** |
| Number with constraints | **Number** (with min/max) |
| Secret value | **Password** |
| Time period | **Duration** (number + unit dropdown) |
| List of values | **Tags** |
| File upload | **File** |
| Read-only info | **Readonly** |
| Trigger action | **Button** |

### Log Viewer (`/admin/server/logs`)

```
┌─────────────────────────────────────────────────────────────────────────┐
│ Logs                                                                     │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  [Access ▼]  [Last 100 ▼]  [Search...        ]  [Auto-refresh: ON]     │
│                                                                         │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │ 2025-01-15 10:30:45  GET  /api/v1/healthz 200  12ms  192.168.1.1│    │
│  │ 2025-01-15 10:30:44  POST /api/v1/data    201  45ms  192.168.1.2│    │
│  │ 2025-01-15 10:30:43  GET  /healthz        200  2ms   192.168.1.1│    │
│  │ 2025-01-15 10:30:42  GET  /api/v1/users   401  5ms   10.0.0.50  │    │
│  │ ...                                                              │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                         │
│  [< Prev]  Page 1 of 50  [Next >]           [Download] [Clear Logs]    │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### Log Types

| Log | Description |
|-----|-------------|
| Access | HTTP request logs |
| Error | Application errors |
| Audit | Security/admin events |
| Security | Auth failures, blocked IPs |
| Debug | Debug output (dev mode) |

### Keyboard Shortcuts

| Shortcut | Action |
|----------|--------|
| `g d` | Go to Dashboard |
| `g s` | Go to Settings |
| `g l` | Go to Logs |
| `/` | Focus search |
| `Esc` | Close modal/menu |
| `Ctrl+S` | Save current form |
| `?` | Show shortcuts help |

## /admin Authentication Flow

```
User visits /admin
       │
       ▼
Check for valid admin session
       │
       ├─► No session/expired
       │   │
       │   ▼
       │   Show login form
       │   │
       │   ▼
       │   User submits credentials
       │   │
       │   ▼
       │   Validate against admins table
       │   │
       │   ├─► Invalid: Show error, log attempt
       │   │
       │   └─► Valid credentials
       │       │
       │       ▼
       │       Check if 2FA enabled (TOTP or Passkey)
       │       │
       │       ├─► No 2FA: Create session, redirect to dashboard
       │       │
       │       └─► 2FA enabled
       │           │
       │           ▼
       │           Show 2FA prompt (TOTP code or Passkey)
       │           │
       │           ├─► Invalid: Show error, allow retry
       │           │
       │           └─► Valid: Create session, redirect to dashboard
       │
       └─► Valid session
           │
           ▼
           Show requested admin page
```

## Admin Session vs User Session

| Aspect | Admin Session | User Session |
|--------|---------------|--------------|
| Cookie name | `admin_session` | `user_session` |
| Valid routes | `/admin/**` only | `/**` except `/admin/**` |
| Stored in | `server.db` (admin_sessions) | `users.db` (user_sessions) |
| Credentials | `admins` table | `users` table |
| Default duration | 30 days | 7 days |
| MFA | Optional (TOTP) | Optional (TOTP) |

### Scheduler Management (Admin Panel)

The admin panel MUST include a scheduler section with:

| Feature | Description |
|---------|-------------|
| **Task List** | View all scheduled tasks with status |
| **Next Run** | Show next scheduled run time for each task |
| **Last Run** | Show last run time and result (success/failure) |
| **Run History** | View history of past runs with timestamps |
| **Manual Trigger** | Button to manually run any task |
| **Enable/Disable** | Toggle tasks on/off |
| **Edit Schedule** | Modify task frequency (cron-style or preset) |
| **Task Details** | View task configuration and logs |

**Preset Schedules:**
- `hourly` - Every hour
- `daily` - Once per day (configurable time)
- `weekly` - Once per week (configurable day/time)
- `monthly` - Once per month (configurable day/time)
- `custom` - Cron expression

## /api/v1/admin (REST API)

### Authentication

`Authorization: Bearer {token}`

**These admin API routes are ALWAYS available, regardless of whether Multi-User (PART 33) is implemented.**

### Admin - Server (`/api/v1/admin/server/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/setup` | GET | Get setup status |
| `/api/v1/admin/server/setup/verify` | POST | Verify setup token |
| `/api/v1/admin/server/setup/account` | POST | Create admin account (Step 1) |
| `/api/v1/admin/server/setup/token` | POST | Generate API token (Step 2) |
| `/api/v1/admin/server/setup/config` | POST | Save server config (Step 3) |
| `/api/v1/admin/server/setup/security` | POST | Security settings (Step 4) |
| `/api/v1/admin/server/setup/services` | POST | Configure services (Step 5) |
| `/api/v1/admin/server/setup/complete` | POST | Complete setup wizard (Step 6) |
| `/api/v1/admin/server/settings` | GET | Get server settings |
| `/api/v1/admin/server/settings` | PATCH | Update server settings |
| `/api/v1/admin/server/status` | GET | Server status (detailed) |
| `/api/v1/admin/server/stats` | GET | Statistics |
| `/api/v1/admin/server/restart` | POST | Restart server |

### Admin - Server Admins (`/api/v1/admin/server/admins/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/admins` | GET | List server admins |
| `/api/v1/admin/server/admins/{id}` | GET | Get admin details |
| `/api/v1/admin/server/admins/{id}` | DELETE | Delete admin |
| `/api/v1/admin/server/admins/{id}/disable` | POST | Disable admin |
| `/api/v1/admin/server/admins/{id}/enable` | POST | Enable admin |
| `/api/v1/admin/server/admins/invite` | POST | Generate admin invite link |

### Admin - Profile (`/api/v1/admin/profile/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/profile` | GET | Get admin profile |
| `/api/v1/admin/profile` | PATCH | Update admin profile |
| `/api/v1/admin/profile/password` | POST | Change admin password |
| `/api/v1/admin/profile/token` | GET | Get current API token (masked) |
| `/api/v1/admin/profile/token` | POST | Regenerate API token |
| `/api/v1/admin/profile/preferences` | GET | Get admin preferences (theme, notifications) |
| `/api/v1/admin/profile/preferences` | PATCH | Update admin preferences |

### Admin - Branding (`/api/v1/admin/server/branding/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/branding` | GET | Get branding settings |
| `/api/v1/admin/server/branding` | PATCH | Update branding |

### Admin - SSL (`/api/v1/admin/server/ssl/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/ssl` | GET | Get SSL settings |
| `/api/v1/admin/server/ssl` | PATCH | Update SSL settings |
| `/api/v1/admin/server/ssl/renew` | POST | Force certificate renewal |

### Admin - Tor (`/api/v1/admin/server/tor/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/tor` | GET | Get Tor status |
| `/api/v1/admin/server/tor` | PATCH | Update Tor settings |
| `/api/v1/admin/server/tor/regenerate` | POST | Regenerate .onion address |
| `/api/v1/admin/server/tor/vanity` | GET | Get vanity generation status |
| `/api/v1/admin/server/tor/vanity` | POST | Start vanity generation |
| `/api/v1/admin/server/tor/vanity` | DELETE | Cancel vanity generation |
| `/api/v1/admin/server/tor/vanity/apply` | POST | Apply vanity address |
| `/api/v1/admin/server/tor/import` | POST | Import external keys |

### Admin - Web (`/api/v1/admin/server/web/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/web` | GET | Get web settings |
| `/api/v1/admin/server/web` | PATCH | Update web settings |
| `/api/v1/admin/server/web/robots` | GET | Get robots.txt config |
| `/api/v1/admin/server/web/robots` | PATCH | Update robots.txt |
| `/api/v1/admin/server/web/robots/preview` | GET | Preview robots.txt |
| `/api/v1/admin/server/web/security` | GET | Get security.txt config |
| `/api/v1/admin/server/web/security` | PATCH | Update security.txt |
| `/api/v1/admin/server/web/security/preview` | GET | Preview security.txt |

### Admin - Pages (`/api/v1/admin/server/pages/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/pages` | GET | Get all page settings |
| `/api/v1/admin/server/pages/about` | GET | Get about page content |
| `/api/v1/admin/server/pages/about` | PATCH | Update about page |
| `/api/v1/admin/server/pages/privacy` | GET | Get privacy policy |
| `/api/v1/admin/server/pages/privacy` | PATCH | Update privacy policy |
| `/api/v1/admin/server/pages/contact` | GET | Get contact page settings |
| `/api/v1/admin/server/pages/contact` | PATCH | Update contact page |
| `/api/v1/admin/server/pages/help` | GET | Get help page content |
| `/api/v1/admin/server/pages/help` | PATCH | Update help page |

### Admin - Email (`/api/v1/admin/server/email/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/email` | GET | Get email settings |
| `/api/v1/admin/server/email` | PATCH | Update email settings |
| `/api/v1/admin/server/email/test` | POST | Send test email |
| `/api/v1/admin/server/email/templates` | GET | List email templates |
| `/api/v1/admin/server/email/templates/{name}` | GET | Get template |
| `/api/v1/admin/server/email/templates/{name}` | PUT | Update template |
| `/api/v1/admin/server/email/templates/{name}/reset` | POST | Reset to default |
| `/api/v1/admin/server/email/templates/{name}/preview` | POST | Preview template |

### Admin - Scheduler (`/api/v1/admin/server/scheduler/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/scheduler` | GET | List scheduled tasks |
| `/api/v1/admin/server/scheduler/{id}` | GET | Get task details |
| `/api/v1/admin/server/scheduler/{id}` | PATCH | Update task |
| `/api/v1/admin/server/scheduler/{id}/run` | POST | Run task now |
| `/api/v1/admin/server/scheduler/{id}/enable` | POST | Enable task |
| `/api/v1/admin/server/scheduler/{id}/disable` | POST | Disable task |

### Admin - Backup (`/api/v1/admin/server/backup/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/backup` | GET | List backups |
| `/api/v1/admin/server/backup` | POST | Create backup |
| `/api/v1/admin/server/backup/{id}` | GET | Get backup details |
| `/api/v1/admin/server/backup/{id}` | DELETE | Delete backup |
| `/api/v1/admin/server/backup/{id}/download` | GET | Download backup file |
| `/api/v1/admin/server/backup/restore` | POST | Restore from backup |

### Admin - Logs (`/api/v1/admin/server/logs/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/logs` | GET | List log files |
| `/api/v1/admin/server/logs/{type}` | GET | Get log entries |
| `/api/v1/admin/server/logs/{type}/download` | GET | Download log file |

## Agent Management (OPTIONAL - When Agent is Enabled)

**Agent management routes are only available when the project includes an agent component.**

**See PART 36 for full agent binary and setup details.**

### Admin Panel (`/{adminpath}/server/agents`)

**Main agent dashboard showing all registered agents:**

```
┌─────────────────────────────────────────────────────────────────────────────┐
│  /{adminpath}/server/agents                                                         │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  Connected Agents                                              [+ Add Agent] │
│  ─────────────────────────────────────────────────────────────────────────  │
│                                                                             │
│  │ Name              │ Status    │ Connected     │ Last Seen    │ Health   │
│  ├───────────────────┼───────────┼───────────────┼──────────────┼──────────│
│  │ web-server-01     │ ● Online  │ 2h 15m        │ Just now     │ ✓ Good   │
│  │ web-server-02     │ ● Online  │ 2h 14m        │ 5s ago       │ ✓ Good   │
│  │ db-primary        │ ● Online  │ 5d 3h         │ 2s ago       │ ⚠ Warn   │
│  │ db-replica        │ ○ Offline │ —             │ 3 days ago   │ ✗ Error  │
│  │ cache-01          │ ● Online  │ 12h 30m       │ 1s ago       │ ✓ Good   │
│  └───────────────────┴───────────┴───────────────┴──────────────┴──────────┘
│                                                                             │
│  Summary: 4 online, 1 offline                                               │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

**Table Columns:**
| Column | Description |
|--------|-------------|
| **Name** | Agent hostname (link to detail page) |
| **Status** | ● Online / ○ Offline |
| **Connected** | Duration since agent connected (or — if offline) |
| **Last Seen** | Time since last heartbeat/report |
| **Health** | ✓ Good / ⚠ Warn / ✗ Error (based on agent metrics) |

### Admin Panel (`/{adminpath}/server/agents/{name}`)

**Detailed view of a single agent:**

```
┌─────────────────────────────────────────────────────────────────────────────┐
│  /{adminpath}/server/agents/web-server-01                         [← Back to List] │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  web-server-01                                             ● Online         │
│  ───────────────────────────────────────────────────────────────────────    │
│                                                                             │
│  ┌─ System Info ─────────────────────────────────────────────────────────┐  │
│  │                                                                       │  │
│  │  Hostname:    web-server-01                                           │  │
│  │  OS:          Linux (Ubuntu 22.04)                                    │  │
│  │  Arch:        amd64                                                   │  │
│  │  Agent Ver:   1.0.0                                                   │  │
│  │  Uptime:      45 days, 3 hours                                        │  │
│  │  Tags:        production, web-tier, us-east-1                         │  │
│  │                                                                       │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│  ┌─ Connection ──────────────────────────────────────────────────────────┐  │
│  │                                                                       │  │
│  │  Status:      ● Connected                                             │  │
│  │  Connected:   2h 15m ago                                              │  │
│  │  Last Report: Just now (every 60s)                                    │  │
│  │  IP Address:  192.168.1.100                                           │  │
│  │                                                                       │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│  ┌─ System Metrics ──────────────────────────────────────────────────────┐  │
│  │                                                                       │  │
│  │  CPU:     ████████░░░░░░░░░░░░  42%                                   │  │
│  │  Memory:  ██████████████░░░░░░  72% (5.8GB / 8GB)                     │  │
│  │  Disk:    ████████████░░░░░░░░  62% (124GB / 200GB)                   │  │
│  │  Network: ↓ 1.2 MB/s  ↑ 450 KB/s                                      │  │
│  │  Load:    2.45 / 4.12 / 3.87                                          │  │
│  │                                                                       │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│  ┌─ Actions ─────────────────────────────────────────────────────────────┐  │
│  │                                                                       │  │
│  │  [Refresh Now]  [View Logs]  [Edit Tags]  [Regenerate Token]          │  │
│  │                                                                       │  │
│  │  [Remove Agent]  ← Requires confirmation                              │  │
│  │                                                                       │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Admin Panel (`/{adminpath}/server/agents/add`)

**Simple agent registration page:**

```
┌─────────────────────────────────────────────────────────────────────────────┐
│  /{adminpath}/server/agents/add                                   [← Back to List] │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  Add New Agent                                                              │
│  ───────────────────────────────────────────────────────────────────────    │
│                                                                             │
│  Agent Name (optional):                                                     │
│  ┌─────────────────────────────────────────────────────────────────────┐    │
│  │                                                                     │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
│  Leave blank to use hostname. Equivalent to: hostname -s                    │
│                                                                             │
│  Tags (optional):                                                           │
│  ┌─────────────────────────────────────────────────────────────────────┐    │
│  │ production, web-tier                                                │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
│  Comma-separated. Used for filtering and grouping.                          │
│                                                                             │
│  Token Expiry:                                                              │
│  ○ 1 hour                                                                   │
│  ● 24 hours (recommended)                                                   │
│  ○ 7 days                                                                   │
│  ○ Never expires                                                            │
│                                                                             │
│  [Generate Agent Token]                                                     │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘

         ↓ (Token generated)

┌─────────────────────────────────────────────────────────────────────────────┐
│  ✅ Agent Token Generated                                                    │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  Run this command on the target host:                                       │
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐    │
│  │ curl -sSL https://app.example.com/install-agent | sh -s -- \        │    │
│  │   --server https://app.example.com \                                │    │
│  │   --token adm_agt_abc123def456ghi789jkl012mno345pqr678              │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
│  [Copy to Clipboard]                                                        │
│                                                                             │
│  Or manually:                                                               │
│  ┌─────────────────────────────────────────────────────────────────────┐    │
│  │ projectname-agent --server https://app.example.com \                │    │
│  │   --token adm_agt_abc123def456ghi789jkl012mno345pqr678              │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
│  [Copy to Clipboard]                                                        │
│                                                                             │
│  ⚠️  Token expires in 24 hours and can only be used once.                   │
│                                                                             │
│  [Done]                                                                     │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

**Server generates the complete command string:**
```go
func GenerateAgentConnectionCommand(serverURL, token string) string {
    return fmt.Sprintf("projectname-agent --server %s --token %s", serverURL, token)
}
```

**Agent Name Default:**
```go
// Go equivalent of hostname -s
func getDefaultAgentName() string {
    hostname, err := os.Hostname()
    if err != nil {
        return "unknown"
    }
    // hostname -s returns short hostname (before first dot)
    if idx := strings.Index(hostname, "."); idx > 0 {
        return hostname[:idx]
    }
    return hostname
}
```

### Agent Connection Notifications (NON-NEGOTIABLE)

**When an agent connects, server WebUI shows real-time notification:**

```
┌─────────────────────────────────────────────────────────────────────────────┐
│  🔔 Notification                                                      [×]   │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ✅ web-server-01 has connected                                             │
│  Agent is now sending data to server for admin scope                        │
│                                                                             │
│  [View Agent]  [Dismiss]                                                    │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

**Notification content by scope:**

| Scope | Notification Message |
|-------|---------------------|
| Admin | "{name} has connected. Agent is now sending data to server for admin scope" |
| User | "{name} has connected. Agent is now sending data for user {username}" |
| Org | "{name} has connected. Agent is now sending data for org {orgname}" |

**Notification triggers:**
- Agent first connection (registration complete)
- Agent reconnection after disconnect
- Agent status change (online/offline)

### Admin Panel (`/{adminpath}/server/agents/remove`)

**Agent removal page with confirmation:**

```
┌─────────────────────────────────────────────────────────────────────────────┐
│  /{adminpath}/server/agents/remove                                [← Back to List] │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  Remove Agent                                                               │
│  ───────────────────────────────────────────────────────────────────────    │
│                                                                             │
│  Select agent to remove:                                                    │
│                                                                             │
│  ┌───────────────────┬───────────┬──────────────────────────────────────┐   │
│  │ Name              │ Status    │ Last Seen                            │   │
│  ├───────────────────┼───────────┼──────────────────────────────────────┤   │
│  │ ○ web-server-01   │ ● Online  │ Just now                             │   │
│  │ ○ web-server-02   │ ● Online  │ 5s ago                               │   │
│  │ ○ db-primary      │ ● Online  │ 2s ago                               │   │
│  │ ○ db-replica      │ ○ Offline │ 3 days ago                           │   │
│  │ ○ cache-01        │ ● Online  │ 1s ago                               │   │
│  └───────────────────┴───────────┴──────────────────────────────────────┘   │
│                                                                             │
│  [Remove Selected]                                                          │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘

         ↓ (Agent selected, click Remove)

┌─────────────────────────────────────────────────────────────────────────────┐
│                                                                             │
│  ⚠️  Remove Agent                                                           │
│                                                                             │
│  Are you sure you want to remove agent "db-replica"?                        │
│                                                                             │
│  This will:                                                                 │
│  • Revoke the agent's authentication token                                  │
│  • Remove the agent from the dashboard                                      │
│  • Delete all historical metrics for this agent                             │
│                                                                             │
│  The agent binary on the remote host will NOT be uninstalled.               │
│  You must manually run: projectname-agent --service uninstall               │
│                                                                             │
│              [No, Cancel]        [Yes, Remove Agent]                        │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Scoped Agents API (NON-NEGOTIABLE)

**Agents can belong to admin, user, or org scope. Same API pattern, different routes.**

| Scope | Base Route | Owner Token | Agent Token |
|-------|------------|-------------|-------------|
| Admin | `/api/v1/admin/server/agents/` | `adm_` | `adm_agt_` |
| User | `/api/v1/users/agents/` | `usr_` | `usr_agt_` |
| Org | `/api/v1/orgs/{slug}/agents/` | `org_` | `org_agt_` |

**Same endpoints for all scopes (replace `{base}` with scope route above):**

| Endpoint | Method | Token | Description |
|----------|--------|-------|-------------|
| `{base}` | GET | Owner | List agents |
| `{base}` | POST | Owner | Create agent token |
| `{base}/{name}` | GET | Owner | Get agent details |
| `{base}/{name}` | PATCH | Owner | Update agent (tags, name) |
| `{base}/{name}` | DELETE | Owner | Remove agent |
| `{base}/{name}/token` | POST | Owner | Regenerate agent token |
| `{base}/{name}/metrics` | GET | Owner | Get agent metrics history |
| `{base}/register` | POST | Agent | Agent self-registration (one-time) |
| `{base}/heartbeat` | POST | Agent | Agent health check / keepalive |
| `{base}/report` | POST | Agent | Submit collected data (project-specific) |

**Token Access:**
- Owner tokens (`adm_`, `usr_`, `org_`): Full agent management (CRUD, view metrics)
- Agent tokens (`adm_agt_`, `usr_agt_`, `org_agt_`): Limited to register, heartbeat, report (own data only)

**Examples:**
```
# Admin agent (server infrastructure)
POST /api/v1/admin/server/agents/register
Authorization: Bearer adm_agt_abc123...

# User agent (personal SaaS monitoring)
POST /api/v1/users/agents/register
Authorization: Bearer usr_agt_xyz789...

# Org agent (organization resources)
POST /api/v1/orgs/acme-corp/agents/register
Authorization: Bearer org_agt_def456...
```

**Agent Data Views (Project-Specific):**

Agent data can be exposed via project-specific routes for different audiences:

| Route | Description | Example |
|-------|-------------|---------|
| `/{admin_path}/server/agents/*` | Admin management UI | Full control |
| `/users/agents/*` | User's agent dashboard | Personal agents |
| `/orgs/{slug}/agents/*` | Org agent dashboard | Org agents |
| `/{custom}/status` | Public status page | Status dashboard |

Define project-specific data views in PART 37.

### Agent Database Schema

```sql
-- agents table (supports all scopes)
CREATE TABLE agents (
    id TEXT PRIMARY KEY,                    -- UUID
    name TEXT NOT NULL,                     -- hostname or custom name

    -- Scope (which owner)
    scope TEXT NOT NULL,                    -- 'admin', 'user', 'org'
    owner_id TEXT,                          -- NULL for admin, user_id for user, org_id for org
    token_prefix TEXT NOT NULL,             -- 'adm_agt_', 'usr_agt_', 'org_agt_'
    token_hash TEXT NOT NULL,               -- SHA-256 hash of full token

    -- System info (from agent)
    hostname TEXT,
    os TEXT,                                -- linux, windows, darwin
    arch TEXT,                              -- amd64, arm64
    version TEXT,                           -- Agent version

    -- Tags
    tags TEXT,                              -- JSON array: ["prod", "web"]

    -- Connection tracking
    status TEXT DEFAULT 'pending',          -- pending, online, offline
    ip_address TEXT,
    connected_at TIMESTAMP,
    last_seen_at TIMESTAMP,

    -- Metadata
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    UNIQUE(scope, owner_id, name)           -- Name unique within scope+owner
);

CREATE INDEX idx_agents_scope_owner ON agents(scope, owner_id);

-- agent_metrics table (for historical data)
CREATE TABLE agent_metrics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    agent_id TEXT NOT NULL REFERENCES agents(id) ON DELETE CASCADE,

    -- Metrics
    cpu_percent REAL,
    memory_percent REAL,
    memory_used_bytes INTEGER,
    memory_total_bytes INTEGER,
    disk_percent REAL,
    disk_used_bytes INTEGER,
    disk_total_bytes INTEGER,
    network_rx_bytes INTEGER,
    network_tx_bytes INTEGER,
    load_1 REAL,
    load_5 REAL,
    load_15 REAL,

    -- Custom metrics (JSON)
    custom_metrics TEXT,

    recorded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_agent_metrics_agent_time ON agent_metrics(agent_id, recorded_at);
```

---


# PART 18: EMAIL & NOTIFICATIONS (NON-NEGOTIABLE)

## Overview

**ALL projects MUST have customizable email templates.**

Email templates allow server admins to customize ALL notification messages, including account-related emails (password reset, email verification, login alerts, etc.). Default templates with sane defaults are embedded in the binary; custom templates are stored in `{config_dir}/template/email/`.

**Key Points:**
- ALL email templates are fully customizable via the admin panel
- Account emails (password reset, verification, security alerts) follow the same customization pattern as server notification emails
- Each template has sensible defaults that work out-of-the-box
- Changes take effect immediately (live reload)

## Template Storage

| Type | Location |
|------|----------|
| Default templates | Embedded in binary (`src/server/template/email/`) |
| Custom templates | `{config_dir}/template/email/` |

**Behavior:**
- If custom template exists → use custom
- If not → fall back to embedded default
- Reset to default → delete custom file

## SMTP Configuration (NON-NEGOTIABLE)

### SMTP Auto-Detection

**On first run, the server automatically detects local SMTP servers.**

| Check | Hosts | Ports |
|-------|-------|-------|
| 1 | `localhost` | 25, 587, 465 |
| 2 | `127.0.0.1` | 25, 587, 465 |
| 3 | `172.17.0.1` (Docker host) | 25, 587, 465 |
| 4 | Gateway IP | 25, 587, 465 |

**Auto-Detection Process:**
1. Try each host/port combination
2. Attempt SMTP handshake (EHLO)
3. First successful connection is used
4. Save to `server.yml` and enable email features
5. If all fail → email features disabled (not an error)

**Connection Test (when host is set):**
1. On every startup, test configured SMTP connection
2. Attempt SMTP handshake (EHLO)
3. If success → email enabled
4. If fail → email disabled, log warning, continue running
5. Retry on next startup

### SMTP Config

```yaml
server:
  notifications:
    email:
      smtp:
        # If empty: autodetect. If set: test connection.
        host: ""
        port: 587
        username: ""
        password: ""
        # TLS mode: auto, starttls, tls, none
        tls: auto
      from:
        # Default: app title
        name: ""
        # Default: no-reply@{fqdn}
        email: ""
```

### Environment Variable Priority

`SMTP_*` env vars override config file settings. Useful for containers.

| Env Var | Config Path | Default |
|---------|-------------|---------|
| `SMTP_HOST` | `smtp.host` | (autodetect) |
| `SMTP_PORT` | `smtp.port` | 587 |
| `SMTP_USERNAME` | `smtp.username` | (none) |
| `SMTP_PASSWORD` | `smtp.password` | (none) |
| `SMTP_TLS` | `smtp.tls` | auto |
| `SMTP_FROM_NAME` | `from.name` | (app title) |
| `SMTP_FROM_EMAIL` | `from.email` | no-reply@{fqdn} |

### SMTP Requirement

**ALL emails require a valid and working SMTP server. No SMTP = No emails. Don't even try.**

| Rule | Description |
|------|-------------|
| **No SMTP configured** | Email functionality completely disabled |
| **SMTP configured but invalid** | Validate on save, reject invalid config |
| **SMTP configured and working** | Email functionality enabled |

**Behavior When No SMTP:**

| Feature | Behavior |
|---------|----------|
| Password reset | Feature hidden/disabled, show "Contact administrator" |
| Email verification | Skipped entirely (emails auto-verified) |
| Login alerts | Not sent, not attempted, not logged |
| Welcome email | Not sent, not attempted |
| Security alerts | Not sent, not attempted |
| All notifications | Not sent, not attempted |

**DO NOT:**
- ❌ Attempt to send emails without valid SMTP
- ❌ Queue emails hoping SMTP will be configured later
- ❌ Log "would have sent email" messages
- ❌ Show email-related options if SMTP not configured

**DO:**
- ✓ Check SMTP status once at startup and on config change
- ✓ Completely disable email features if no SMTP
- ✓ Hide email-dependent UI elements when SMTP unavailable
- ✓ Show clear message: "Email features require SMTP configuration"

**Admin Panel:**
- If SMTP not configured, show banner: "⚠️ SMTP not configured. Email features disabled. [Configure SMTP](/admin/server/email)"
- Email-dependent features (password reset link, etc.) hidden until SMTP configured
- Test email button validates SMTP actually works before enabling email features

## Default Templates

**Note:** Templates are defined for all functionality but are ONLY used when SMTP is configured. When SMTP is not configured:
- Templates exist but are never rendered or sent
- `email_verify` template is not used - email addresses are auto-verified
- All email-dependent features are hidden/disabled

| Template | Purpose | Account Email? |
|----------|---------|:--------------:|
| `welcome` | New user registration / admin setup | ✓ |
| `password_reset` | Password reset request | ✓ |
| `email_verify` | Email address verification | ✓ |
| `login_alert` | New login detected | ✓ |
| `security_alert` | Security event (failed logins, etc.) | ✓ |
| `mfa_reminder` | Gentle prompt to enable MFA (periodic) | ✓ |
| `2fa_enabled` | 2FA activated on account | ✓ |
| `2fa_disabled` | 2FA removed from account | ✓ |
| `password_changed` | Password was changed | ✓ |
| `backup_complete` | Backup finished successfully | ✗ |
| `backup_failed` | Backup error | ✗ |
| `ssl_expiring` | Certificate expiration warning | ✗ |
| `ssl_renewed` | Certificate renewed successfully | ✗ |
| `scheduler_error` | Scheduled task failed | ✗ |
| `breach_notification` | Data breach notification to affected users | ✓ |
| `breach_admin_alert` | Breach detected alert to server admins | ✗ |
| `test` | Test email | ✗ |

**Account Email (✓):** Must follow Account Email Requirements (visible link, disclaimer, etc.)

## Sane Defaults (NON-NEGOTIABLE)

**ALL email templates MUST have sensible defaults that work immediately without configuration.**

| Template | Default Subject | Default Behavior |
|----------|-----------------|------------------|
| `welcome` | `Welcome to {app_name}` | Sent to new users on registration (if enabled) and to admin on first setup |
| `password_reset` | `Password Reset Request - {app_name}` | 24-hour expiry, includes IP address |
| `email_verify` | `Verify Your Email - {app_name}` | 48-hour expiry |
| `login_alert` | `New Login Detected - {app_name}` | Includes IP, location (if GeoIP enabled), device |
| `security_alert` | `Security Alert - {app_name}` | Generic alert for various security events |
| `mfa_reminder` | `Secure Your Account - {app_name}` | Periodic reminder, includes setup link, dismissable |
| `2fa_enabled` | `Two-Factor Authentication Enabled - {app_name}` | Confirmation of 2FA activation |
| `2fa_disabled` | `Two-Factor Authentication Disabled - {app_name}` | Warning about 2FA removal |
| `password_changed` | `Your Password Was Changed - {app_name}` | Confirmation of password change |
| `backup_complete` | `Backup Complete - {app_name}` | Includes filename and size |
| `backup_failed` | `Backup Failed - {app_name}` | Includes error message |
| `ssl_expiring` | `SSL Certificate Expiring - {app_name}` | Sent 30, 14, 7, 3, 1 days before expiry |
| `ssl_renewed` | `SSL Certificate Renewed - {app_name}` | Confirmation of renewal |
| `scheduler_error` | `Scheduled Task Failed - {app_name}` | Includes task name and error |
| `breach_notification` | `Important Security Notice - {app_name}` | Compliance-aware, includes breach details, recommended actions |
| `breach_admin_alert` | `[{severity}] Security Breach Detected - {app_name}` | Immediate alert, includes detection details, action required |
| `test` | `Test Email - {app_name}` | Simple test message |

**Default Sender:**
- From Name: `{app_name}` (defaults to binary name if not set)
- From Address: `no-reply@{fqdn}` (defaults to `no-reply@localhost` if FQDN not set)
- Reply-To: `{admin_email}` (if set, otherwise omitted)

**Default Expiry Times:**
| Link Type | Default Expiry | Configurable? |
|-----------|----------------|---------------|
| Password reset | 24 hours | Yes |
| Email verification | 48 hours | Yes |
| Account recovery | 1 hour | Yes |
| Setup token | 24 hours | No (security) |

**MFA Reminder Schedule:**
| Recipient | First Reminder | Repeat | Stop When |
|-----------|----------------|--------|-----------|
| Server admin | 7 days after first login | Every 6 months | MFA enabled or dismissed permanently |
| Regular user | 7 days after registration | Every 6 months | MFA enabled or dismissed permanently |

- Reminders shown in-app (dismissable banner) - always works
- Email reminders only sent if SMTP is working (check `server.notifications.email.enabled`)
- User/admin can permanently dismiss reminders in settings
- Never more than one reminder per 6-month period
- Include one-click "Set up now" and "Don't remind me" links

**SMTP Check for Email Reminders:**
```go
// Check if email reminders can be sent
func canSendEmailReminder() bool {
    cfg := config.Get()
    return cfg.Server.Notifications.Email.Enabled &&
           cfg.Server.Notifications.Email.SMTP.Host != ""
}
```

## Template Format

Templates use simple `{variable}` syntax:

```
Subject: Your {app_name} backup completed
---
Hello,

Your backup completed successfully.

Filename: {filename}
Size: {size}
Time: {timestamp}

--
{app_name}
{app_url}
```

**Format Rules:**
- First line: `Subject: ...`
- Separator: `---` (three dashes on own line)
- Body: Plain text with variables
- Variables: `{variable_name}` syntax

## Global Variables (Available in All Templates)

| Variable | Description |
|----------|-------------|
| `{app_name}` | Application name/title |
| `{app_url}` | Application URL (full FQDN, e.g., `https://api.example.com`) |
| `{fqdn}` | Server FQDN only (e.g., `api.example.com`) |
| `{onion_url}` | Tor .onion URL (if enabled) |
| `{admin_email}` | Admin email address |
| `{recipient_email}` | Email address this message is being sent to |
| `{recipient_username}` | Username of the account (if applicable) |
| `{timestamp}` | Current date/time |
| `{year}` | Current year |

## Account Email Requirements (NON-NEGOTIABLE)

**ALL account-related emails MUST include:**

| Requirement | Description |
|-------------|-------------|
| **Why sent** | Clear explanation of why this email was sent |
| **Who it's for** | The recipient email address (visible in body) |
| **App identity** | App name AND full FQDN |
| **Visible link** | Plaintext URL (not just a button) - users can copy/paste |
| **Disclaimer** | "If you did not request this, ignore this message" (where applicable) |
| **No action if unsolicited** | Never include links that delete/modify without prior auth |

**Account-related emails include:**
- Welcome (user registration)
- Password reset
- Email verification
- Login alerts
- Security alerts
- 2FA changes
- Account recovery

### Example: User Welcome Email (Required Format)

```
Subject: Welcome to {app_name}
---
WELCOME TO {APP_NAME}

This email was sent to: {recipient_email}
From: {app_name} ({fqdn})

Hello {recipient_username},

Welcome to {app_name}! Your account has been created successfully.

To get started, log in at:

{login_url}

You can manage your profile and settings at:

{profile_url}

────────────────────────────────────────────────────────────────────────
GETTING STARTED

- Complete your profile
- Enable two-factor authentication for added security
- Explore the features available to you

If you have any questions, contact us at {admin_email}.
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: Admin Welcome Email (Required Format)

```
Subject: Welcome to {app_name} - Admin Setup Complete
---
ADMIN SETUP COMPLETE

This email was sent to: {recipient_email}
From: {app_name} ({fqdn})

Congratulations! Your {app_name} instance is now configured.

Admin Panel: {admin_url}
Username: {admin_username}

────────────────────────────────────────────────────────────────────────
IMPORTANT NEXT STEPS

1. Log in to the admin panel and review your settings
2. Configure SMTP for email notifications
3. Enable SSL/TLS for secure connections
4. Set up regular backups
5. Enable two-factor authentication

Keep your admin credentials secure. If you lose access, use:
  weather --maintenance setup
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: Password Reset Email (Required Format)

```
Subject: Password Reset Request - {app_name}
---
PASSWORD RESET REQUEST

This email was sent to: {recipient_email}
From: {app_name} ({fqdn})
Requested at: {timestamp}
Request IP: {ip}

Someone requested a password reset for the account associated with this
email address on {app_name} ({fqdn}).

To reset your password, visit the following link:

{reset_link}

This link expires in {expires}.

────────────────────────────────────────────────────────────────────────
⚠️  DID NOT REQUEST THIS?

If you did not request a password reset, you can safely ignore this email.
Your password will not be changed unless you click the link above.

No action is required on your part.
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: Email Verification (Required Format)

```
Subject: Verify Your Email - {app_name}
---
EMAIL VERIFICATION

This email was sent to: {recipient_email}
From: {app_name} ({fqdn})
Sent at: {timestamp}

You (or someone) requested to add this email address to an account on
{app_name} ({fqdn}).

To verify this email address, visit the following link:

{verify_link}

This link expires in {expires}.

────────────────────────────────────────────────────────────────────────
⚠️  DID NOT REQUEST THIS?

If you did not request to add this email to an account, you can safely
ignore this email. No account will be created or linked.

No action is required on your part.
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: Login Alert (Required Format)

```
Subject: New Login Detected - {app_name}
---
NEW LOGIN DETECTED

This alert was sent to: {recipient_email}
Account: {recipient_username}
From: {app_name} ({fqdn})

A new login was detected on your account:

  Time:     {time}
  IP:       {ip}
  Location: {location}
  Device:   {device}

If this was you, no action is required.

────────────────────────────────────────────────────────────────────────
⚠️  NOT YOU?

If you did not log in, your account may be compromised. Take action:

1. Change your password immediately:
   {app_url}/auth/password/forgot

2. Review your active sessions:
   {app_url}/settings/sessions

3. Enable 2FA if not already enabled:
   {app_url}/settings/security
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: Security Alert (Required Format)

```
Subject: Security Alert - {app_name}
---
SECURITY ALERT

This alert was sent to: {recipient_email}
Account: {recipient_username}
From: {app_name} ({fqdn})
Time: {timestamp}

{event}

Details:
  Source IP: {ip}
  {details}

────────────────────────────────────────────────────────────────────────
⚠️  RECOMMENDED ACTIONS

If this activity was not you:

1. Change your password immediately:
   {app_url}/auth/password/forgot

2. Review account activity:
   {app_url}/settings/security

3. Contact support if needed:
   {admin_email}
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: 2FA Disabled Alert (Required Format)

```
Subject: Two-Factor Authentication Disabled - {app_name}
---
2FA DISABLED

This alert was sent to: {recipient_email}
Account: {recipient_username}
From: {app_name} ({fqdn})
Time: {timestamp}

Two-factor authentication has been disabled on your account.

Method used: {method}
  (password, recovery key, or admin action)

────────────────────────────────────────────────────────────────────────
⚠️  DID NOT DO THIS?

If you did not disable 2FA, your account may be compromised:

1. Change your password immediately:
   {app_url}/auth/password/forgot

2. Re-enable 2FA:
   {app_url}/settings/security

3. Contact support:
   {admin_email}
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: Password Changed Alert (Required Format)

```
Subject: Your Password Was Changed - {app_name}
---
PASSWORD CHANGED

This alert was sent to: {recipient_email}
Account: {recipient_username}
From: {app_name} ({fqdn})
Time: {timestamp}

The password for your account was successfully changed.

Method: {method}
IP Address: {ip}

If you made this change, no action is required.

────────────────────────────────────────────────────────────────────────
⚠️  DID NOT CHANGE YOUR PASSWORD?

If you did not change your password, your account may be compromised:

1. Reset your password immediately:
   {app_url}/auth/password/forgot

2. Review your account security:
   {app_url}/settings/security

3. Contact support:
   {admin_email}
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: Breach Notification (Required Format)

```
Subject: Important Security Notice - {app_name}
---
IMPORTANT SECURITY NOTICE

This notice was sent to: {recipient_email}
Account: {recipient_username}
From: {app_name} ({fqdn})
Date: {timestamp}
Reference: {breach_id}

We are writing to inform you of a security incident that may have affected
your account on {app_name}.

────────────────────────────────────────────────────────────────────────
WHAT HAPPENED

{breach_summary}

Date discovered: {breach_date}
Incident type: {breach_type}
────────────────────────────────────────────────────────────────────────

────────────────────────────────────────────────────────────────────────
WHAT INFORMATION WAS INVOLVED

The following categories of data may have been affected:

{affected_data}
────────────────────────────────────────────────────────────────────────

────────────────────────────────────────────────────────────────────────
WHAT WE ARE DOING

We take the security of your information seriously. Upon discovering this
incident, we immediately:

- Secured affected systems and contained the incident
- Launched a comprehensive investigation
- Notified relevant authorities as required by law
- Enhanced our security measures to prevent future incidents

{notification_deadline}
────────────────────────────────────────────────────────────────────────

────────────────────────────────────────────────────────────────────────
WHAT YOU SHOULD DO

We recommend you take the following steps to protect your account:

{recommended_actions}

1. Change your password immediately:
   {app_url}/auth/password/forgot

2. Review your account activity:
   {app_url}/users/security

3. Enable two-factor authentication if not already enabled:
   {app_url}/users/security/2fa

4. Monitor your accounts for any suspicious activity
────────────────────────────────────────────────────────────────────────

────────────────────────────────────────────────────────────────────────
CONTACT INFORMATION

If you have questions or need assistance:

Email: {contact_email}
{contact_phone}
{dpo_contact}

Reference this ID in all communications: {breach_id}
────────────────────────────────────────────────────────────────────────

{regulatory_notice}

We sincerely apologize for any concern or inconvenience this may cause.
We remain committed to protecting your information and will continue to
take steps to enhance our security measures.

--
{app_name}
{app_url}
```

**Compliance-Specific Regulatory Notices:**

The `{regulatory_notice}` variable is automatically populated based on enabled compliance standards:

| Compliance | Regulatory Notice Content |
|------------|---------------------------|
| GDPR | "This notification is provided in accordance with Article 34 of the General Data Protection Regulation (GDPR). You have the right to lodge a complaint with your local data protection authority." |
| HIPAA | "This notification is provided in accordance with the HIPAA Breach Notification Rule (45 CFR §§ 164.400-414). For questions about your health information rights, contact the HHS Office for Civil Rights." |
| CCPA | "Under the California Consumer Privacy Act, you have the right to know what personal information was collected and to request deletion. Visit our privacy page for more information." |
| LGPD | "Esta notificação é fornecida de acordo com a Lei Geral de Proteção de Dados (LGPD). Você tem o direito de apresentar reclamação à ANPD (Autoridade Nacional de Proteção de Dados)." |
| PIPEDA | "This notification is provided in accordance with Canada's Personal Information Protection and Electronic Documents Act (PIPEDA). You may contact the Office of the Privacy Commissioner of Canada." |
| APPI | "This notification is provided in accordance with Japan's Act on the Protection of Personal Information. You may contact the Personal Information Protection Commission." |
| PDPA | "This notification is provided in accordance with Singapore's Personal Data Protection Act. You may contact the Personal Data Protection Commission." |

**When Multiple Standards Apply:** All applicable regulatory notices are included, with the most restrictive notification timeline met.

### Example: Breach Admin Alert (Required Format)

```
Subject: [{severity}] Security Breach Detected - {app_name}
---
🚨 SECURITY BREACH DETECTED

Server: {app_name} ({fqdn})
Time: {timestamp}
Breach ID: {breach_id}

────────────────────────────────────────────────────────────────────────
SEVERITY: {severity}
TYPE: {breach_type}
DETECTION: {detection_method}
────────────────────────────────────────────────────────────────────────

SUMMARY:
{breach_summary}

────────────────────────────────────────────────────────────────────────
DETAILS

Detection trigger: {trigger}
Source IP: {source_ip}
Affected scope: {affected_scope}
Estimated affected users: {affected_users}
Affected data categories: {affected_data}
────────────────────────────────────────────────────────────────────────

────────────────────────────────────────────────────────────────────────
AUTO-ACTIONS TAKEN

{auto_actions}
────────────────────────────────────────────────────────────────────────

────────────────────────────────────────────────────────────────────────
COMPLIANCE REQUIREMENTS

{compliance_requirements}

Notification deadline: {notify_deadline}
────────────────────────────────────────────────────────────────────────

────────────────────────────────────────────────────────────────────────
IMMEDIATE ACTION REQUIRED

1. Review breach details:
   {admin_url}/compliance/breaches/{breach_id}

2. Start investigation (if not auto-started):
   {admin_url}/compliance/breaches/{breach_id}/investigate

3. Assess containment status

4. Prepare user notifications if required
────────────────────────────────────────────────────────────────────────

This is an automated security alert from {app_name}.
Do not reply to this email.

--
{app_name} Security System
{app_url}
```

## Template-Specific Variables

**Note:** Account-related templates (marked ✓ above) also have access to `{recipient_email}`, `{recipient_username}`, and `{fqdn}` from global variables.

### welcome

**Two variants:** Admin welcome (first setup) and User welcome (registration).

**Admin Welcome Variables:**
| Variable | Description |
|----------|-------------|
| `{admin_url}` | Admin panel URL |
| `{admin_username}` | Initial admin username |

**User Welcome Variables:**
| Variable | Description |
|----------|-------------|
| `{recipient_username}` | New user's username |
| `{recipient_email}` | New user's email address |
| `{login_url}` | Login page URL |
| `{profile_url}` | User profile URL |

**When Sent:**
| Scenario | Template Used | Recipient |
|----------|---------------|-----------|
| First admin setup | Admin welcome | Server admin email |
| User registration (if enabled) | User welcome | New user's email |
| Admin creates user | User welcome | New user's email |
| User invited via invite code | User welcome | Invited user's email |

### password_reset
| Variable | Description |
|----------|-------------|
| `{reset_link}` | Password reset URL (full URL, visible in email) |
| `{expires}` | Link expiration time (e.g., "24 hours") |
| `{ip}` | Requesting IP address |

### email_verify
| Variable | Description |
|----------|-------------|
| `{verify_link}` | Email verification URL (full URL, visible in email) |
| `{expires}` | Link expiration time |

### login_alert
| Variable | Description |
|----------|-------------|
| `{ip}` | Login IP address |
| `{location}` | GeoIP location (if available) |
| `{device}` | User agent / device info |
| `{time}` | Login time |

### security_alert
| Variable | Description |
|----------|-------------|
| `{event}` | Security event type |
| `{ip}` | Source IP address |
| `{details}` | Event details |

### 2fa_enabled
| Variable | Description |
|----------|-------------|
| `{method}` | 2FA method enabled (TOTP, WebAuthn, etc.) |
| `{ip}` | IP address where 2FA was enabled |

### 2fa_disabled
| Variable | Description |
|----------|-------------|
| `{method}` | How 2FA was disabled (password, recovery key, admin) |
| `{ip}` | IP address where 2FA was disabled |

### password_changed
| Variable | Description |
|----------|-------------|
| `{ip}` | IP address where password was changed |
| `{method}` | How changed (direct, reset link, admin reset) |

### backup_complete / backup_failed
| Variable | Description |
|----------|-------------|
| `{filename}` | Backup filename |
| `{size}` | Backup file size |
| `{error}` | Error message (failed only) |

### ssl_expiring / ssl_renewed
| Variable | Description |
|----------|-------------|
| `{fqdn}` | Domain name on certificate |
| `{expires_in}` | Days until expiration |
| `{expiry_date}` | Expiration date |
| `{valid_until}` | New validity date (renewed only) |

### scheduler_error
| Variable | Description |
|----------|-------------|
| `{task_name}` | Failed task name |
| `{error}` | Error message |
| `{next_run}` | Next scheduled run |

### breach_notification

**Compliance-Aware Template:** This template automatically adjusts content based on enabled compliance standards.

| Variable | Description |
|----------|-------------|
| `{breach_id}` | Unique breach identifier for reference |
| `{breach_date}` | Date/time breach was discovered |
| `{breach_type}` | Type of breach (unauthorized access, data exposure, etc.) |
| `{affected_data}` | Categories of data potentially affected |
| `{breach_summary}` | Brief description of what happened |
| `{recommended_actions}` | List of recommended user actions |
| `{contact_email}` | Contact email for breach inquiries |
| `{contact_phone}` | Contact phone (if configured) |
| `{dpo_contact}` | Data Protection Officer contact (GDPR/LGPD) |
| `{regulatory_notice}` | Compliance-specific regulatory text (auto-generated) |
| `{notification_deadline}` | Compliance deadline met (e.g., "within 72 hours") |

### breach_admin_alert

**Sent to all server admins immediately when a breach is detected (automated or manual).**

| Variable | Description |
|----------|-------------|
| `{breach_id}` | Unique breach identifier |
| `{severity}` | Severity level (CRITICAL, HIGH, MEDIUM, LOW) |
| `{breach_type}` | Type of breach |
| `{breach_summary}` | Brief description |
| `{detection_method}` | How detected (automated/manual/external) |
| `{trigger}` | Specific detection trigger (e.g., "brute_force", "anomaly") |
| `{source_ip}` | Source IP address (if applicable) |
| `{affected_scope}` | Scope description (single user, multiple users, system-wide) |
| `{affected_users}` | Estimated number of affected users |
| `{affected_data}` | Data categories potentially affected |
| `{auto_actions}` | List of automated actions taken |
| `{compliance_requirements}` | Applicable compliance standards and their requirements |
| `{notify_deadline}` | Deadline for user notification (based on strictest standard) |
| `{admin_url}` | Admin panel URL |

## Admin Panel (/admin/server/email/templates)

| Element | Type | Description |
|---------|------|-------------|
| Template list | Table | All templates with status (default/custom) |
| Edit button | Button | Open template editor |
| Subject field | Text input | Editable subject line |
| Body editor | Textarea | Template body with syntax highlighting |
| Variable reference | Sidebar | Available variables for selected template |
| Preview button | Button | Render template with sample data |
| Send Test | Button | Send test email to specific address |
| Save button | Button | Save custom template |
| Reset to default | Button | Delete custom, restore embedded (confirmation required) |

**Editor Features:**
- Syntax highlighting for `{variables}`
- Variable autocomplete
- Live preview with sample data
- Validation (warn if unknown variables used)

### Template Preview

**Live preview renders the template with sample data as you edit.**

```
Email Template Editor (/admin/server/email/templates/password_reset)
┌─────────────────────────────────────────────────────────────┐
│  Template: password_reset                    [Default] [Custom]│
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Subject:                                                   │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ Password Reset Request - {app_name}                 │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
│  Body:                              │  Available Variables: │
│  ┌────────────────────────────────┐ │  {app_name}           │
│  │ PASSWORD RESET REQUEST         │ │  {app_url}            │
│  │                                │ │  {fqdn}               │
│  │ This email was sent to:        │ │  {recipient_email}    │
│  │ {recipient_email}              │ │  {recipient_username} │
│  │ From: {app_name} ({fqdn})      │ │  {reset_link}         │
│  │                                │ │  {expires}            │
│  │ To reset your password:        │ │  {ip}                 │
│  │ {reset_link}                   │ │  {timestamp}          │
│  │                                │ │                       │
│  └────────────────────────────────┘ │  Click to insert ↑    │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  📧 Preview (with sample data):                              │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ Subject: Password Reset Request - My App            │    │
│  │ ─────────────────────────────────────────────────── │    │
│  │ PASSWORD RESET REQUEST                              │    │
│  │                                                     │    │
│  │ This email was sent to: user@example.com            │    │
│  │ From: My App (app.example.com)                      │    │
│  │                                                     │    │
│  │ To reset your password:                             │    │
│  │ https://app.example.com/auth/reset/abc123...        │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
│  [Send Test Email]  [Reset to Default]  [Save]              │
└─────────────────────────────────────────────────────────────┘
```

**Sample Data for Preview:**
| Variable | Sample Value |
|----------|--------------|
| `{app_name}` | Current app name from config |
| `{app_url}` | Current app URL |
| `{fqdn}` | Current FQDN |
| `{recipient_email}` | `user@example.com` |
| `{recipient_username}` | `sampleuser` |
| `{reset_link}` | `https://{fqdn}/auth/reset/sample123...` |
| `{verify_link}` | `https://{fqdn}/auth/verify/sample123...` |
| `{expires}` | `24 hours` |
| `{ip}` | `192.168.1.100` |
| `{timestamp}` | Current timestamp |
| `{admin_email}` | Admin email from config |

### Send Test Email

**Send a test email to verify the template renders correctly.**

```
Send Test Email Dialog
┌─────────────────────────────────────────────────────────────┐
│  Send Test Email                                            │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Template: password_reset                                   │
│                                                             │
│  Send to: [admin@example.com              ]                 │
│           (defaults to your admin email)                    │
│                                                             │
│  ⚠️ This will send a real email using current SMTP settings. │
│  The email will contain sample data, not real user data.    │
│                                                             │
│  [Cancel]  [Send Test]                                      │
└─────────────────────────────────────────────────────────────┘
```

**Test Email Rules:**
- Requires valid SMTP configuration
- Defaults to current admin's email address
- Can specify any email address
- Uses sample data (not real user data)
- Subject prefixed with `[TEST]` to identify test emails
- Test sends logged to audit log

**After Sending:**
```
┌─────────────────────────────────────────────────────────────┐
│  ✅ Test Email Sent                                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Sent to: admin@example.com                                 │
│  Template: password_reset                                   │
│  Subject: [TEST] Password Reset Request - My App            │
│                                                             │
│  Check your inbox to verify the email looks correct.        │
│                                                             │
│  [Close]                                                    │
└─────────────────────────────────────────────────────────────┘
```

### Template Validation

**Templates are validated before saving:**

| Check | Error Message |
|-------|---------------|
| Unknown variable | `Unknown variable: {foo}. Did you mean {fqdn}?` |
| Missing required variable | `Account emails must include {recipient_email}` |
| Empty subject | `Subject cannot be empty` |
| Empty body | `Body cannot be empty` |
| Invalid syntax | `Invalid template syntax at line 5` |

**Warnings (non-blocking):**
- Using deprecated variables
- Very long subject line (>78 chars)
- Missing recommended sections (e.g., disclaimer for account emails)

## Notification Systems (NON-NEGOTIABLE)

**Two notification systems available. WebUI is always available. Email requires SMTP.**

| System | Availability | Use When |
|--------|--------------|----------|
| **WebUI (Toast/Banner)** | Always available | User is actively using the app |
| **Email** | Requires valid SMTP | User is away, needs permanent record, critical alerts |

## WebUI Notification System

**The WebUI has a built-in notification system for both server admins and users. This is ALWAYS available regardless of SMTP configuration.**

### How It Works

| Component | Description |
|-----------|-------------|
| **Toast** | Pop-up notifications in corner of screen |
| **Banner** | Persistent bar at top of page |
| **Notification Center** | Bell icon with history of notifications |
| **Badge Count** | Unread notification count on bell icon |

### Notification Center

**Both server admins and users have a notification center accessible via bell icon in the header.**

```
┌─────────────────────────────────────────────────────────────┐
│  Header                                    🔔 (3)  [User]   │
└─────────────────────────────────────────────────────────────┘
                                               │
                                               ▼
                              ┌────────────────────────────────┐
                              │  Notifications                 │
                              ├────────────────────────────────┤
                              │  🔴 SSL certificate expiring   │
                              │     in 3 days                  │
                              │     2 hours ago                │
                              ├────────────────────────────────┤
                              │  ✅ Backup completed           │
                              │     backup_2025-01-15.tar.gz   │
                              │     5 hours ago                │
                              ├────────────────────────────────┤
                              │  ⚠️ Login from new location    │
                              │     192.168.1.100 (New York)   │
                              │     Yesterday                  │
                              ├────────────────────────────────┤
                              │  [Mark all read]  [Clear all]  │
                              └────────────────────────────────┘
```

### WebUI Notification Types

| Type | Icon | Use For | Auto-dismiss |
|------|------|---------|--------------|
| `success` | ✅ | Completed actions, confirmations | 5 seconds |
| `info` | ℹ️ | Informational, status updates | 5 seconds |
| `warning` | ⚠️ | Non-critical issues, expiring items | 10 seconds |
| `error` | ❌ | Failures, critical issues | Manual dismiss |
| `security` | 🔒 | Security-related alerts | Manual dismiss |

### Toast vs Banner vs Notification Center

| Element | Use For | Behavior |
|---------|---------|----------|
| **Toast** | Immediate feedback for user actions | Auto-dismiss, stacks in corner |
| **Banner** | Persistent alerts requiring attention | Stays until dismissed or resolved |
| **Notification Center** | History of all notifications | Persists across sessions, stored in DB |

**When to Use Each:**

| Scenario | Toast | Banner | Center |
|----------|:-----:|:------:|:------:|
| Settings saved | ✓ | | |
| Form validation error | ✓ | | |
| Backup complete | ✓ | | ✓ |
| SSL expiring soon | | ✓ | ✓ |
| Update available | | ✓ | ✓ |
| Login from new IP | ✓ | | ✓ |
| Password changed | ✓ | | ✓ |
| SMTP not configured | | ✓ | |
| Scheduler task failed | ✓ | | ✓ |

## Server Admin Notifications

**Notifications shown to server admins in `/admin/*` routes.**

| Event | Toast | Banner | Center | Description |
|-------|:-----:|:------:|:------:|-------------|
| Settings saved | ✓ | | | Confirmation of config save |
| Config validation error | ✓ | | | Invalid config value |
| Backup started | ✓ | | | Backup in progress |
| Backup complete | ✓ | | ✓ | Backup finished |
| Backup failed | ✓ | | ✓ | Backup error |
| SSL expiring (7+ days) | | | ✓ | Warning in center only |
| SSL expiring (<3 days) | | ✓ | ✓ | Urgent banner |
| SSL renewed | ✓ | | ✓ | Certificate renewed |
| SSL renewal failed | ✓ | ✓ | ✓ | Critical - needs attention |
| Update available | | ✓ | ✓ | New version available |
| Scheduler task failed | ✓ | | ✓ | Task error |
| New admin login | | | ✓ | Another admin logged in |
| SMTP not configured | | ✓ | | Persistent warning |
| Database connection issue | | ✓ | ✓ | Critical warning |
| Disk space low | | ✓ | ✓ | System warning |
| GeoIP database outdated | | | ✓ | Update needed |
| Tor address ready | ✓ | | | Onion address generated |

## User Notifications (Multi-User Mode)

**Notifications shown to regular users in `/users/*` routes.**

| Event | Toast | Banner | Center | Description |
|-------|:-----:|:------:|:------:|-------------|
| Profile updated | ✓ | | | Settings saved |
| Password changed | ✓ | | ✓ | Security confirmation |
| Email verified | ✓ | | ✓ | Verification complete |
| 2FA enabled | ✓ | | ✓ | Security confirmation |
| 2FA disabled | ✓ | | ✓ | Security warning |
| Login from new IP | | | ✓ | Security notice |
| Login from new device | | | ✓ | Security notice |
| Session expired | ✓ | | | Re-login required |
| API token created | ✓ | | ✓ | Token generated |
| API token revoked | ✓ | | ✓ | Token deleted |
| Account suspended | | ✓ | | Admin action notice |
| Password reset required | | ✓ | | Admin-initiated reset |
| Recovery keys running low | | | ✓ | Only 1-2 keys left |

## Notification vs Email Decision Matrix

**WebUI notifications are ALWAYS used when the user is active. Email is ONLY used when:**
1. SMTP is configured AND working
2. The event warrants a permanent record OR
3. The user may be away and needs to be alerted

| Event | WebUI | Email | Reason |
|-------|:-----:|:-----:|--------|
| Settings saved | ✓ | ✗ | Immediate feedback only |
| Backup complete | ✓ | Optional | Quick confirmation |
| Backup failed | ✓ | ✓ | Critical - needs attention |
| SSL expiring (7+ days) | ✓ | ✗ | Warning, not urgent |
| SSL expiring (<3 days) | ✓ | ✓ | Urgent - needs action |
| SSL renewed | ✓ | ✗ | Informational |
| Login from new IP | ✓ | ✓ | Security - permanent record |
| Security alert | ✓ | ✓ | Critical - needs record |
| Scheduler task failed | ✓ | ✓ | Needs attention when away |
| Scheduler task success | ✗ | ✗ | No notification needed |
| Password changed | ✓ | ✓ | Security - confirmation |
| Token regenerated | ✓ | ✓ | Security - confirmation |
| 2FA enabled/disabled | ✓ | ✓ | Security - confirmation |
| Tor address regenerated | ✓ | ✗ | User initiated |
| Update available | ✓ | Optional | Informational |
| Update installed | ✓ | ✓ | Important change record |
| Welcome (new user) | ✓ | ✓ | Onboarding |
| Email verification | ✗ | ✓ | Requires email link |
| Password reset | ✗ | ✓ | Requires email link |

### Decision Logic

```
1. Is user actively using the app?
   → Always show WebUI notification (toast/center)

2. Is SMTP configured?
   → No: WebUI only, no email attempt
   → Yes: Continue to step 3

3. Is it critical (failure, security, urgent)?
   → Send email

4. Does user need a record when away?
   → Send email

5. Is it just confirmation of user action?
   → WebUI only (no email)

6. Is it routine success?
   → No notification needed
```

## Notification Storage

**WebUI notifications are stored in the database for persistence.**

| Storage | Server Admin | Regular User |
|---------|--------------|--------------|
| Table | `admin_notifications` | `user_notifications` |
| Retention | 30 days (configurable) | 30 days (configurable) |
| Max stored | 100 per admin | 100 per user |
| Sync | Real-time via WebSocket | Real-time via WebSocket |

**Notification Record:**
```json
{
  "id": "notif_01HQXYZ",
  "type": "warning",
  "title": "SSL Certificate Expiring",
  "message": "Certificate expires in 3 days",
  "link": "/{adminpath}/server/ssl",
  "read": false,
  "created_at": "2025-01-15T10:30:00Z"
}
```

## Sane Defaults

| Setting | Default | Description |
|---------|---------|-------------|
| Toast position | `top-right` | Corner for toast notifications |
| Toast duration | `5` seconds | Auto-dismiss time (0 = manual) |
| Error dismiss | `manual` | Errors require manual dismiss |
| Notification retention | `30` days | How long to keep in center |
| Max notifications | `100` | Per user/admin limit |
| Real-time updates | `enabled` | WebSocket for instant updates |

## Notification Preferences

**Both server admins and users can configure their notification preferences.**

### Admin Notification Preferences (`/admin/profile/notifications`)

| Category | Events | Default | Can Disable? |
|----------|--------|---------|--------------|
| **Security** | Login alerts, 2FA changes, password changes | All ON | No (required) |
| **Server** | SSL expiring, updates available, disk space | All ON | Yes |
| **Backup** | Backup complete, backup failed | Failed ON, Complete OFF | Yes |
| **Scheduler** | Task failed, task manual run | Failed ON | Yes |
| **Other Admins** | Admin login/logout | ON | Yes |

**Security notifications cannot be disabled** - these are critical for account security.

```
Admin Notification Preferences (/admin/profile/notifications)
┌─────────────────────────────────────────────────────────────┐
│  Notification Preferences                                   │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  🔒 Security (cannot be disabled)                           │
│     ☑ Login from new IP/device                              │
│     ☑ Password changed                                      │
│     ☑ 2FA enabled/disabled                                  │
│     ☑ API token regenerated                                 │
│                                                             │
│  ⚙️ Server                                          WebUI Email│
│     SSL certificate expiring                        [✓]  [✓] │
│     SSL certificate renewed                         [✓]  [ ] │
│     Update available                                [✓]  [ ] │
│     Disk space low                                  [✓]  [✓] │
│                                                             │
│  💾 Backup                                                   │
│     Backup completed                                [✓]  [ ] │
│     Backup failed                                   [✓]  [✓] │
│                                                             │
│  📅 Scheduler                                                │
│     Task failed                                     [✓]  [✓] │
│     Task manually triggered                         [✓]  [ ] │
│                                                             │
│  👥 Other Admins                                             │
│     Admin logged in                                 [✓]  [ ] │
│     Admin logged out                                [ ]  [ ] │
│                                                             │
│  [Save Preferences]                                         │
└─────────────────────────────────────────────────────────────┘
```

### User Notification Preferences (`/users/settings/notifications`)

| Category | Events | Default | Can Disable? |
|----------|--------|---------|--------------|
| **Security** | Login alerts, password changes, 2FA changes | All ON | No (required) |
| **Account** | Email verified, profile updated | All ON | Yes |
| **Sessions** | Session expired, new device | All ON | Partial |

```
User Notification Preferences (/users/settings/notifications)
┌─────────────────────────────────────────────────────────────┐
│  Notification Preferences                                   │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  🔒 Security (cannot be disabled)                           │
│     ☑ Login from new IP/device                              │
│     ☑ Password changed                                      │
│     ☑ 2FA enabled/disabled                                  │
│     ☑ Recovery key used                                     │
│                                                             │
│  👤 Account                                         WebUI Email│
│     Email verified                                  [✓]  [✓] │
│     Profile updated                                 [✓]  [ ] │
│                                                             │
│  🔑 Sessions                                                 │
│     Session expired                                 [✓]  [ ] │
│     Logged in from new device                       [✓]  [✓] │
│                                                             │
│  [Save Preferences]                                         │
└─────────────────────────────────────────────────────────────┘
```

### Preference Storage

| User Type | Storage | Key |
|-----------|---------|-----|
| Server Admin | `admin_preferences` table | `admin_id` |
| Regular User | `user_preferences` table | `user_id` |

**Preference Schema:**
```json
{
  "notifications": {
    "webui": {
      "backup_complete": true,
      "backup_failed": true,
      "ssl_expiring": true,
      "admin_login": true
    },
    "email": {
      "backup_complete": false,
      "backup_failed": true,
      "ssl_expiring": true,
      "admin_login": false
    }
  }
}
```

## Configuration

```yaml
server:
  notifications:
    # WebUI notifications (always enabled)
    webui:
      position: top-right
      # top-right, top-left, bottom-right, bottom-left
      duration: 5
      # seconds (0 = manual dismiss)

    # Email notifications
    # enabled is auto-set based on SMTP availability (no manual toggle)
    # All SMTP settings can be overridden via SMTP_* env vars
    email:
      smtp:
        # If empty: autodetect local SMTP on startup
        # If set: test connection on startup
        host: ""
        port: 587
        username: ""
        password: ""
        # TLS mode: auto, starttls, tls, none
        tls: auto
      from:
        # Default: app title
        name: ""
        # Default: no-reply@{fqdn}
        email: ""

      # Per-event email settings (override defaults)
      events:
        startup: false
        shutdown: false
        backup_complete: false
        backup_failed: true
        ssl_expiring: true
        ssl_renewed: false
        login_alert: true
        security_alert: true
        scheduler_error: true
        password_changed: true
        token_regenerated: true
        update_available: false
        update_installed: true
```

---


# PART 19: SCHEDULER (NON-NEGOTIABLE)

## Built-in Scheduler

**ALL projects MUST have a built-in scheduler that is ALWAYS RUNNING.**

### Core Requirements

| Requirement | Description |
|-------------|-------------|
| **Always Running** | Scheduler starts with application and runs until shutdown |
| **Persistent State** | Task state survives restarts (stored in server.db) |
| **Automatic Recovery** | Missed tasks run on startup if within catch-up window |
| **Cluster Aware** | Only one node runs each task in cluster mode |
| **No External Dependencies** | Built-in, no cron or external scheduler needed |

## NEVER Use External Schedulers (NON-NEGOTIABLE)

**The built-in scheduler handles ALL scheduled tasks. NEVER use external schedulers.**

### Prohibited External Schedulers

| Platform | NEVER Use | Reason |
|----------|-----------|--------|
| **Linux** | cron, crond, crontab, systemd timers, at, anacron | Built-in scheduler handles this |
| **Windows** | Task Scheduler, schtasks, at | Built-in scheduler handles this |
| **macOS** | launchd, cron, at | Built-in scheduler handles this |
| **Container** | Kubernetes CronJob, Docker cron containers | Built-in scheduler handles this |
| **Cloud** | AWS CloudWatch Events, Azure Scheduler, GCP Cloud Scheduler | Built-in scheduler handles this |

### Why Built-in Only?

| Reason | Explanation |
|--------|-------------|
| **Single source of truth** | All schedules visible in admin panel |
| **Cluster aware** | External cron doesn't know about cluster nodes |
| **State tracking** | Tracks last run, next run, success/failure |
| **Catch-up logic** | Runs missed tasks on restart |
| **No deployment complexity** | No cron files to manage, sync, or debug |
| **Portable** | Works identically on all platforms |
| **Observable** | Logs, metrics, admin UI for all tasks |

### What If User Asks for Cron?

**User request:** "Can I run the backup via cron instead?"

**Correct response:**
```
The application has a built-in scheduler that handles backups.

To configure backup schedule:
1. Go to Admin Panel → Server → Backup
2. Set schedule to your preferred time
3. The built-in scheduler will run it automatically

External schedulers (cron, Task Scheduler, etc.) are not supported
because the built-in scheduler provides:
- Cluster-aware execution
- Automatic catch-up for missed runs
- State tracking and logging
- Admin panel visibility
```

### Exceptions (NONE)

**There are NO exceptions to this rule:**

| Scenario | Answer |
|----------|--------|
| "Cron is more reliable" | No - built-in is just as reliable |
| "I already have cron set up" | No - use built-in instead |
| "I need to run at boot" | No - built-in runs at boot |
| "I need complex schedules" | No - built-in supports full cron syntax |
| "I want to trigger externally" | Use API endpoint instead of scheduler |

### Built-in Tasks (Required)

Every project MUST include these scheduled tasks:

| Task | Default Schedule | Purpose | Skippable |
|------|-----------------|---------|-----------|
| `ssl.renewal` | Daily at 03:00 | Renew `{config_dir}/ssl/letsencrypt/{fqdn}/` certs 7 days before expiry | No |
| `geoip.update` | Weekly (Sunday 03:00) | Download/update MaxMind GeoLite2 databases | Yes |
| `blocklist.update` | Daily at 04:00 | Download/update IP/domain blocklists | Yes |
| `cve.update` | Daily at 05:00 | Download/update CVE/security databases | Yes |
| `session.cleanup` | Every 15 minutes | Remove expired sessions | No |
| `token.cleanup` | Every 15 minutes | Remove expired tokens | No |
| `log.rotation` | Daily at 00:00 | Rotate and compress old logs | No |
| `backup_daily` | Daily at 02:00 | Full backup + daily incremental (default: 2 files) | Yes |
| `backup_hourly` | Hourly | Hourly incremental (disabled by default) | Yes |
| `healthcheck.self` | Every 5 minutes | Self-health verification | No |
| `tor.health` | Every 10 minutes | Check Tor connectivity, restart if needed | No (when Tor installed) |
| `cluster.heartbeat` | Every 30 seconds | Cluster node heartbeat (cluster mode only) | No |

### Task Configuration

```yaml
server:
  scheduler:
    # Scheduler is ALWAYS running - no enable/disable setting
    # Individual tasks can be enabled/disabled below

    # Timezone for scheduled tasks (default: America/New_York)
    timezone: America/New_York

    # Catch-up window: run missed tasks if within this duration
    catch_up_window: 1h

    # Built-in tasks (can adjust schedule, cannot disable critical tasks)
    tasks:
      # Daily at 03:00 (after backup at 02:00)
      ssl_renewal:
        schedule: "0 3 * * *"
        enabled: true

      # Weekly Sunday at 03:00
      geoip_update:
        schedule: "0 3 * * 0"
        enabled: true

      # Daily at 04:00
      blocklist_update:
        schedule: "0 4 * * *"
        enabled: true
        retry_on_fail: true
        retry_delay: 1h

      # Daily at 05:00
      cve_update:
        schedule: "0 5 * * *"
        enabled: true
        retry_on_fail: true
        retry_delay: 1h

      # Every 15 minutes
      session_cleanup:
        schedule: "@every 15m"
        enabled: true

      # Every 15 minutes
      token_cleanup:
        schedule: "@every 15m"
        enabled: true

      # Daily at midnight
      log_rotation:
        schedule: "0 0 * * *"
        enabled: true
        # Delete logs older than 30 days
        max_age: 30d
        # Rotate when log exceeds 100MB
        max_size: 100MB
        compress: true

      # Daily backup at 02:00 (admin can disable)
      backup_daily:
        schedule: "0 2 * * *"
        enabled: true
        # Verify after creation (all checks must pass)
        verify: true
        # Creates: weather_backup_YYYY-MM-DD.tar.gz[.enc] (full)
        #          weather-daily.tar.gz[.enc] (incremental)
        retention:
          max_backups: 1     # 1-365: daily full backups to keep
          keep_weekly: 0     # 0-52: Sunday backups (0 = disabled)
          keep_monthly: 0    # 0-12: 1st of month backups (0 = disabled)
          keep_yearly: 0     # 0-10: January 1st backups (0 = disabled)

      # Hourly incremental backup (disabled by default)
      backup_hourly:
        schedule: "@hourly"
        enabled: false
        # Creates: weather-hourly.tar.gz[.enc] (incremental since daily)
        # Always 1 file (replaced each hour)

      # Every 5 minutes
      healthcheck_self:
        schedule: "@every 5m"
        enabled: true

      # Every 10 minutes (only runs if Tor installed)
      tor_health:
        schedule: "@every 10m"
        enabled: true
        # Auto-restart if unhealthy
        restart_on_fail: true
```

### Schedule Format

| Format | Example | Description |
|--------|---------|-------------|
| Cron | `0 2 * * *` | Standard cron (minute hour day month weekday) |
| `@hourly` | `@hourly` | Every hour at minute 0 |
| `@daily` | `@daily` | Every day at 00:00 |
| `@weekly` | `@weekly` | Every Sunday at 00:00 |
| `@monthly` | `@monthly` | First day of month at 00:00 |
| `@every Xm` | `@every 5m` | Every X minutes |
| `@every Xh` | `@every 2h` | Every X hours |

### Scheduler State (Persistent)

Task state is stored in `server.db`:

| Column | Type | Description |
|--------|------|-------------|
| `task_id` | String | Unique task identifier |
| `task_name` | String | Human-readable name |
| `schedule` | String | Cron/interval expression |
| `last_run` | Timestamp | When task last completed |
| `last_status` | String | success, failed, skipped |
| `last_error` | String | Error message if failed |
| `next_run` | Timestamp | Scheduled next execution |
| `run_count` | Integer | Total successful runs |
| `fail_count` | Integer | Total failed runs |
| `enabled` | Boolean | Is task enabled |
| `locked_by` | String | Node ID holding lock (cluster mode) |
| `locked_at` | Timestamp | When lock was acquired |

### Startup Behavior

```
Application Start
       │
       ▼
Load scheduler state from database
       │
       ▼
Check for missed tasks (within catch_up_window)
       │
       ├─► Found missed tasks
       │   │
       │   ▼
       │   Queue missed tasks for immediate execution
       │   (in order of original scheduled time)
       │
       ▼
Start scheduler loop
       │
       ▼
Scheduler runs continuously until shutdown
```

### Cluster Mode Task Distribution

In cluster mode, tasks are distributed to prevent duplicate execution:

| Task Type | Execution |
|-----------|-----------|
| **Global Tasks** | Run on ONE node only (leader election) |
| **Local Tasks** | Run on EVERY node |

**Global Tasks (run once per cluster):**
- `ssl.renewal`
- `geoip.update`
- `blocklist.update`
- `backup`

**Local Tasks (run on each node):**
- `session.cleanup`
- `token.cleanup`
- `healthcheck.self`
- `cluster.heartbeat`

### Task Locking (Cluster Mode)

```
Task Ready to Run
       │
       ▼
Attempt to acquire lock in database
       │
       ├─► Lock acquired
       │   │
       │   ▼
       │   Execute task
       │   │
       │   ▼
       │   Release lock, update last_run
       │
       └─► Lock held by another node
           │
           ▼
           Skip execution (other node handling it)
```

**Lock timeout:** 5 minutes (auto-release if node dies during task)

### Task Execution Flow

```
Task Triggered (scheduled or manual)
       │
       ▼
Check if enabled
       │
       ├─► Disabled: Skip
       │
       ▼
Acquire lock (cluster mode)
       │
       ├─► Lock failed: Skip (another node running)
       │
       ▼
Execute task
       │
       ├─► Success
       │   │
       │   ▼
       │   Update: last_run, last_status=success, run_count++
       │   Log to audit log
       │
       └─► Failure
           │
           ▼
           Update: last_status=failed, last_error, fail_count++
           Log to audit log
           Send notification (if configured)
           Schedule retry (if retryable)
```

### Retry Policy

| Setting | Default | Description |
|---------|---------|-------------|
| `max_retries` | 3 | Maximum retry attempts |
| `retry_delay` | 5m | Delay between retries |
| `backoff` | exponential | Delay multiplier (5m, 10m, 20m) |

### Admin Panel (/admin/server/scheduler)

| Section | Contents |
|---------|----------|
| **Task List** | All tasks with status, next run, last run |
| **Task Detail** | Full history, logs, configuration |
| **Run Now** | Button to trigger immediate execution |
| **Enable/Disable** | Toggle for tasks (admin can enable/disable backup) |
| **History** | Last 100 executions per task |

**Admin UI - Scheduler Overview:**

```
┌─────────────────────────────────────────────────────────────────────────────┐
│  SCHEDULED TASKS                                            [Run All Now]   │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  Task                 Schedule        Last Run           Next Run    Status │
│  ───────────────────────────────────────────────────────────────────────── │
│  ✓ Backup Daily       02:00 daily     Today 02:00 (15s)  Tomorrow    ✓     │
│  ○ Backup Hourly      Hourly          -                  -           ○     │
│  ✓ SSL Renewal        03:00 daily     Today 03:00 (1s)   Tomorrow    ✓     │
│  ✓ GeoIP Update       03:00 Sunday    Jan 12 03:00 (45s) Jan 19      ✓     │
│  ✓ Session Cleanup    Every 15m       14:15 (0.1s)       14:30       ✓     │
│  ✓ Token Cleanup      Every 15m       14:15 (0.1s)       14:30       ✓     │
│  ✓ Log Rotation       00:00 daily     Today 00:00 (2s)   Tomorrow    ✓     │
│  ✓ Health Check       Every 5m        14:25 (0.1s)       14:30       ✓     │
│                                                                             │
│  Legend: ✓ Success  ● Running  ✗ Failed  ○ Pending  ◐ Skipped             │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

**Admin UI - Task Detail (Backup):**

```
┌─────────────────────────────────────────────────────────────────────────────┐
│  TASK: Backup                               [Enable/Disable] [Run Now]      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  Status:      ✓ Enabled                                                    │
│  Schedule:    0 2 * * * (Daily at 02:00)                                   │
│  Type:        Global (runs on one cluster node)                            │
│  Last Run:    2025-01-15 02:00:05 (15.1s)                                  │
│  Next Run:    2025-01-16 02:00:00                                          │
│  Run Count:   342 successful, 2 failed                                     │
│                                                                             │
│  Retention:   Keep 2 (yesterday's full + daily incremental)                │
│  Encryption:  ✓ Enabled (compliance mode)                                  │
│                                                                             │
│  ─────────────────────────────────────────────────────────────────────────  │
│  CURRENT BACKUPS                                                            │
│  ─────────────────────────────────────────────────────────────────────────  │
│  File                                   Size      Created          Status  │
│  myapp_backup_2025-01-15.tar.gz.enc    23MB      Today 02:00      ✓       │
│  myapp-daily.tar.gz.enc                 5MB      Today 02:00      ✓       │
│                                                                             │
│  ─────────────────────────────────────────────────────────────────────────  │
│  RECENT HISTORY                                                             │
│  ─────────────────────────────────────────────────────────────────────────  │
│  Date                 Duration   Status   Details                          │
│  2025-01-15 02:00     15.1s      ✓        Verified: 2 backups, 28MB       │
│  2025-01-14 02:00     14.8s      ✓        Verified: 2 backups, 27MB       │
│  2025-01-13 02:00     45.2s      ✗        Error: disk full                │
│                                                                             │
│  [View Full History]  [Download Backup]  [Restore...]                      │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

**Task List Columns:**

| Column | Description |
|--------|-------------|
| Task Name | Human-readable name |
| Status | ● running, ✓ success, ✗ failed, ○ pending, ◐ skipped |
| Schedule | Cron expression or interval |
| Last Run | Timestamp and duration |
| Next Run | Scheduled time |
| Actions | Enable/Disable, Run Now, View History |

**Backup Tasks:**

| Task | Schedule | Default | Description |
|------|----------|---------|-------------|
| `backup_daily` | 02:00 daily | Enabled | Full backup + daily incremental |
| `backup_hourly` | Hourly | Disabled | Hourly incremental |

| Setting | Default | Description |
|---------|---------|-------------|
| `max_backups` | 1 | Daily full backups to keep |
| `keep_weekly` | 0 | Sunday backups (0 = disabled) |
| `keep_monthly` | 0 | 1st of month (0 = disabled) |
| `keep_yearly` | 0 | January 1st (0 = disabled) |
| Verify | Yes | All checks must pass |

**What backup_daily creates (default: 2 files):**
- `weather_backup_YYYY-MM-DD.tar.gz[.enc]` - Full backup (yesterday's)
- `weather-daily.tar.gz[.enc]` - Daily incremental

**What backup_hourly creates (if enabled: +1 file):**
- `weather-hourly.tar.gz[.enc]` - Hourly incremental

### API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/scheduler` | GET | List all tasks |
| `/api/v1/admin/server/scheduler/{id}` | GET | Get task details |
| `/api/v1/admin/server/scheduler/{id}` | PATCH | Update task settings |
| `/api/v1/admin/server/scheduler/{id}/run` | POST | Run task immediately |
| `/api/v1/admin/server/scheduler/{id}/enable` | POST | Enable task |
| `/api/v1/admin/server/scheduler/{id}/disable` | POST | Disable task |
| `/api/v1/admin/server/scheduler/{id}/history` | GET | Get execution history |

### Shutdown Behavior

```
Shutdown Signal Received
       │
       ▼
Stop accepting new task executions
       │
       ▼
Wait for running tasks to complete (max 30 seconds)
       │
       ├─► Tasks completed
       │   │
       │   ▼
       │   Release all locks
       │
       └─► Timeout
           │
           ▼
           Force release locks
           Mark interrupted tasks for retry on next start
       │
       ▼
Save scheduler state to database
       │
       ▼
Shutdown complete
```

### Implementation Requirements

1. **Use Go's time/ticker** - No external cron libraries required
2. **Database-backed state** - All state in server.db, survives restarts
3. **Graceful shutdown** - Complete running tasks, release locks
4. **Cluster-safe** - Distributed locking for global tasks
5. **Audit logging** - All task executions logged
6. **Notifications** - Failed tasks trigger notifications (if configured)

---


# PART 20: GEOIP (NON-NEGOTIABLE)

## Overview

**ALL projects MUST have built-in GeoIP support using sapics/ip-location-db.**

GeoIP databases are NEVER embedded - they are downloaded on first run and updated via scheduler.

## Configuration

```yaml
server:
  geoip:
    enabled: true

    # Directory for downloaded MMDB files
    dir: "{config_dir}/security/geoip"

    # Update schedule (handled by scheduler, see PART 18)
    # Default: weekly on Sunday 03:00

    # Block countries by ISO 3166-1 alpha-2 code
    deny_countries: []

    # Which databases to download and use
    # All use MMDB format, IPv4 and IPv6 support
    databases:
      # ASN lookup - AS number and organization name
      asn: true
      # Country lookup - country code (ISO 3166-1)
      country: true
      # City lookup - city, region, postal, coordinates, timezone
      city: true
      # WHOIS lookup - registrant info combined with ASN
      whois: true
```

## Database Sources (ip-location-db)

All databases from [sapics/ip-location-db](https://github.com/sapics/ip-location-db) - no API key required.

| Database | File | CDN URL |
|----------|------|---------|
| ASN | `asn.mmdb` | `https://cdn.jsdelivr.net/npm/@ip-location-db/asn-mmdb/asn.mmdb` |
| Country | `country.mmdb` | `https://cdn.jsdelivr.net/npm/@ip-location-db/geo-whois-asn-country-mmdb/geo-whois-asn-country.mmdb` |
| City | `city.mmdb` | `https://cdn.jsdelivr.net/npm/@ip-location-db/dbip-city-mmdb/dbip-city-ipv4.mmdb` |
| WHOIS | `whois.mmdb` | `https://cdn.jsdelivr.net/npm/@ip-location-db/geo-whois-asn-country-mmdb/geo-whois-asn-country.mmdb` |

**Database Contents:**

| Database | Fields Available |
|----------|------------------|
| ASN | `autonomous_system_number`, `autonomous_system_organization` |
| Country | `country_code` (ISO 3166-1 alpha-2) |
| City | `city`, `region`, `postal_code`, `latitude`, `longitude`, `timezone` |
| WHOIS | `registrant_org`, `asn`, `country_code` (combined lookup) |

## Admin Panel (/admin/server/network/geoip)

| Element | Type | Description |
|---------|------|-------------|
| Enable GeoIP | Toggle | Turn GeoIP on/off |
| Deny countries | Tag input | ISO 3166-1 alpha-2 codes to block |
| ASN database | Toggle | Enable ASN lookups |
| Country database | Toggle | Enable country lookups |
| City database | Toggle | Enable city lookups |
| WHOIS database | Toggle | Enable WHOIS lookups |
| Last update | Read-only | When databases were last updated |
| Update now | Button | Force immediate update |

---


# PART 21: METRICS (NON-NEGOTIABLE)

## Overview

**ALL projects MUST have built-in Prometheus-compatible metrics support for production monitoring.**

| Feature | Description |
|---------|-------------|
| Format | Prometheus text exposition format |
| Endpoint | `/metrics` (configurable) |
| Authentication | Optional bearer token |
| Library | `github.com/prometheus/client_golang` |

## Configuration

```yaml
server:
  metrics:
    enabled: true
    endpoint: /metrics

    # Include system metrics (CPU, memory, disk, goroutines)
    include_system: true

    # Include Go runtime metrics
    include_runtime: true

    # Optional Bearer token for authentication
    token: ""

    # Histogram buckets for request duration (seconds)
    duration_buckets: [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]

    # Histogram buckets for request size (bytes)
    size_buckets: [100, 1000, 10000, 100000, 1000000, 10000000]
```

## Metrics Categories

| Category | Metrics | Description |
|----------|---------|-------------|
| **HTTP** | Requests, duration, size, status codes | Request-level metrics |
| **Database** | Queries, duration, connections, errors | Database performance |
| **Cache** | Hits, misses, evictions, size | Cache effectiveness |
| **Scheduler** | Tasks run, duration, failures | Background task health |
| **System** | CPU, memory, disk, goroutines | System resources |
| **Business** | Users, sessions, API calls | Application-specific |

## Metrics Implementation

### Core Metrics Package

```go
// src/server/metrics/metrics.go
package metrics

import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    // HTTP metrics
    HTTPRequestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "weather_http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "path", "status"},
    )

    HTTPRequestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "weather_http_request_duration_seconds",
            Help:    "HTTP request duration in seconds",
            Buckets: []float64{0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10},
        },
        []string{"method", "path"},
    )

    HTTPRequestSize = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "weather_http_request_size_bytes",
            Help:    "HTTP request size in bytes",
            Buckets: []float64{100, 1000, 10000, 100000, 1000000, 10000000},
        },
        []string{"method", "path"},
    )

    HTTPResponseSize = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "weather_http_response_size_bytes",
            Help:    "HTTP response size in bytes",
            Buckets: []float64{100, 1000, 10000, 100000, 1000000, 10000000},
        },
        []string{"method", "path"},
    )

    HTTPActiveRequests = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_http_active_requests",
            Help: "Number of active HTTP requests",
        },
    )

    // Database metrics
    DBQueriesTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "weather_db_queries_total",
            Help: "Total number of database queries",
        },
        []string{"operation", "table"},
    )

    DBQueryDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "weather_db_query_duration_seconds",
            Help:    "Database query duration in seconds",
            Buckets: []float64{0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1},
        },
        []string{"operation", "table"},
    )

    DBConnectionsOpen = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_db_connections_open",
            Help: "Number of open database connections",
        },
    )

    DBConnectionsInUse = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_db_connections_in_use",
            Help: "Number of database connections in use",
        },
    )

    DBErrors = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "weather_db_errors_total",
            Help: "Total number of database errors",
        },
        []string{"operation", "error_type"},
    )

    // Cache metrics
    CacheHits = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "weather_cache_hits_total",
            Help: "Total number of cache hits",
        },
        []string{"cache"},
    )

    CacheMisses = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "weather_cache_misses_total",
            Help: "Total number of cache misses",
        },
        []string{"cache"},
    )

    CacheEvictions = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "weather_cache_evictions_total",
            Help: "Total number of cache evictions",
        },
        []string{"cache"},
    )

    CacheSize = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "weather_cache_size",
            Help: "Current cache size (items)",
        },
        []string{"cache"},
    )

    CacheBytes = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "weather_cache_bytes",
            Help: "Current cache size (bytes)",
        },
        []string{"cache"},
    )

    // Scheduler metrics
    SchedulerTasksTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "weather_scheduler_tasks_total",
            Help: "Total number of scheduled tasks executed",
        },
        []string{"task", "status"},
    )

    SchedulerTaskDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "weather_scheduler_task_duration_seconds",
            Help:    "Scheduled task duration in seconds",
            Buckets: []float64{0.1, 0.5, 1, 5, 10, 30, 60, 300, 600},
        },
        []string{"task"},
    )

    SchedulerTasksRunning = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "weather_scheduler_tasks_running",
            Help: "Number of currently running scheduled tasks",
        },
        []string{"task"},
    )

    SchedulerLastRun = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "weather_scheduler_last_run_timestamp",
            Help: "Timestamp of last task run",
        },
        []string{"task"},
    )

    // Authentication metrics
    AuthAttempts = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "weather_auth_attempts_total",
            Help: "Total authentication attempts",
        },
        []string{"method", "status"},
    )

    AuthSessionsActive = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_auth_sessions_active",
            Help: "Number of active sessions",
        },
    )

    // Business metrics
    UsersTotal = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_users_total",
            Help: "Total number of registered users",
        },
    )

    UsersActive = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_users_active",
            Help: "Number of users active in last 24 hours",
        },
    )

    APITokensActive = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_api_tokens_active",
            Help: "Number of active API tokens",
        },
    )

    // Application info
    AppInfo = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "weather_app_info",
            Help: "Application information",
        },
        []string{"version", "commit", "build_date", "go_version"},
    )

    AppUptime = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_app_uptime_seconds",
            Help: "Application uptime in seconds",
        },
    )

    AppStartTime = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_app_start_timestamp",
            Help: "Application start timestamp",
        },
    )
)

// Init initializes application info metrics
func Init(version, commit, buildDate string) {
    AppInfo.WithLabelValues(version, commit, buildDate, runtime.Version()).Set(1)
    AppStartTime.SetToCurrentTime()
}
```

### Metrics Middleware

```go
// src/server/middleware_metrics.go
package server

import (
    "net/http"
    "strconv"
    "time"

    "github.com/apimgr/weather/src/server/metrics"
)

// metricsMiddleware records HTTP metrics for all requests
func (s *Server) metricsMiddleware(next http.Handler) http.Handler {
    if !s.config.Metrics.Enabled {
        return next
    }

    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()

        // Track active requests
        metrics.HTTPActiveRequests.Inc()
        defer metrics.HTTPActiveRequests.Dec()

        // Get normalized path (remove IDs for cardinality control)
        path := normalizePath(r.URL.Path)

        // Record request size
        if r.ContentLength > 0 {
            metrics.HTTPRequestSize.WithLabelValues(r.Method, path).Observe(float64(r.ContentLength))
        }

        // Wrap response writer
        rw := &metricsResponseWriter{ResponseWriter: w, status: http.StatusOK}

        // Process request
        next.ServeHTTP(rw, r)

        // Record metrics
        duration := time.Since(start).Seconds()
        status := strconv.Itoa(rw.status)

        metrics.HTTPRequestsTotal.WithLabelValues(r.Method, path, status).Inc()
        metrics.HTTPRequestDuration.WithLabelValues(r.Method, path).Observe(duration)
        metrics.HTTPResponseSize.WithLabelValues(r.Method, path).Observe(float64(rw.size))
    })
}

type metricsResponseWriter struct {
    http.ResponseWriter
    status int
    size   int
}

func (rw *metricsResponseWriter) WriteHeader(status int) {
    rw.status = status
    rw.ResponseWriter.WriteHeader(status)
}

func (rw *metricsResponseWriter) Write(b []byte) (int, error) {
    n, err := rw.ResponseWriter.Write(b)
    rw.size += n
    return n, err
}

// normalizePath normalizes URL path for consistent metric labels
// Replaces dynamic segments (UUIDs, IDs) with placeholders
func normalizePath(path string) string {
    // Replace UUIDs
    path = uuidRegex.ReplaceAllString(path, ":id")
    // Replace numeric IDs
    path = numericIDRegex.ReplaceAllString(path, ":id")
    return path
}

var (
    uuidRegex      = regexp.MustCompile(`[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}`)
    numericIDRegex = regexp.MustCompile(`/\d+(?:/|$)`)
)
```

### Database Metrics Wrapper

```go
// src/server/store/metrics.go
package store

import (
    "context"
    "database/sql"
    "time"

    "github.com/apimgr/weather/src/server/metrics"
)

// MetricsDB wraps sql.DB with metrics
type MetricsDB struct {
    *sql.DB
}

func (m *MetricsDB) QueryContext(ctx context.Context, query string, args ...any) (*sql.Rows, error) {
    start := time.Now()
    rows, err := m.DB.QueryContext(ctx, query, args...)
    duration := time.Since(start).Seconds()

    op, table := parseQuery(query)
    metrics.DBQueriesTotal.WithLabelValues(op, table).Inc()
    metrics.DBQueryDuration.WithLabelValues(op, table).Observe(duration)

    if err != nil {
        metrics.DBErrors.WithLabelValues(op, classifyError(err)).Inc()
    }
    return rows, err
}

func (m *MetricsDB) ExecContext(ctx context.Context, query string, args ...any) (sql.Result, error) {
    start := time.Now()
    result, err := m.DB.ExecContext(ctx, query, args...)
    duration := time.Since(start).Seconds()

    op, table := parseQuery(query)
    metrics.DBQueriesTotal.WithLabelValues(op, table).Inc()
    metrics.DBQueryDuration.WithLabelValues(op, table).Observe(duration)

    if err != nil {
        metrics.DBErrors.WithLabelValues(op, classifyError(err)).Inc()
    }
    return result, err
}

// UpdateConnectionMetrics updates connection pool metrics
func (m *MetricsDB) UpdateConnectionMetrics() {
    stats := m.DB.Stats()
    metrics.DBConnectionsOpen.Set(float64(stats.OpenConnections))
    metrics.DBConnectionsInUse.Set(float64(stats.InUse))
}

func parseQuery(query string) (operation, table string) {
    // Simple query parsing for metrics labels
    query = strings.TrimSpace(strings.ToUpper(query))
    parts := strings.Fields(query)
    if len(parts) == 0 {
        return "unknown", "unknown"
    }

    operation = parts[0]
    switch operation {
    case "SELECT", "DELETE":
        for i, p := range parts {
            if p == "FROM" && i+1 < len(parts) {
                return strings.ToLower(operation), strings.ToLower(parts[i+1])
            }
        }
    case "INSERT":
        for i, p := range parts {
            if p == "INTO" && i+1 < len(parts) {
                return "insert", strings.ToLower(parts[i+1])
            }
        }
    case "UPDATE":
        if len(parts) > 1 {
            return "update", strings.ToLower(parts[1])
        }
    }
    return strings.ToLower(operation), "unknown"
}

func classifyError(err error) string {
    errStr := err.Error()
    switch {
    case strings.Contains(errStr, "connection"):
        return "connection"
    case strings.Contains(errStr, "timeout"):
        return "timeout"
    case strings.Contains(errStr, "constraint"):
        return "constraint"
    case strings.Contains(errStr, "duplicate"):
        return "duplicate"
    default:
        return "other"
    }
}
```

### Cache Metrics Wrapper

```go
// src/server/cache/metrics.go
package cache

import (
    "time"

    "github.com/apimgr/weather/src/server/metrics"
)

// MetricsCache wraps a cache with metrics
type MetricsCache struct {
    cache Cache
    name  string
}

func NewMetricsCache(cache Cache, name string) *MetricsCache {
    return &MetricsCache{cache: cache, name: name}
}

func (m *MetricsCache) Get(key string) (any, bool) {
    value, found := m.cache.Get(key)
    if found {
        metrics.CacheHits.WithLabelValues(m.name).Inc()
    } else {
        metrics.CacheMisses.WithLabelValues(m.name).Inc()
    }
    return value, found
}

func (m *MetricsCache) Set(key string, value any, ttl time.Duration) {
    m.cache.Set(key, value, ttl)
    m.updateSizeMetrics()
}

func (m *MetricsCache) Delete(key string) {
    m.cache.Delete(key)
    m.updateSizeMetrics()
}

func (m *MetricsCache) OnEviction(key string, value any) {
    metrics.CacheEvictions.WithLabelValues(m.name).Inc()
}

func (m *MetricsCache) updateSizeMetrics() {
    stats := m.cache.Stats()
    metrics.CacheSize.WithLabelValues(m.name).Set(float64(stats.Items))
    metrics.CacheBytes.WithLabelValues(m.name).Set(float64(stats.Bytes))
}
```

### Scheduler Metrics

```go
// src/scheduler/metrics.go
package scheduler

import (
    "time"

    "github.com/apimgr/weather/src/server/metrics"
)

// RecordTaskStart records when a task starts
func RecordTaskStart(taskName string) {
    metrics.SchedulerTasksRunning.WithLabelValues(taskName).Inc()
}

// RecordTaskEnd records when a task ends
func RecordTaskEnd(taskName string, duration time.Duration, err error) {
    metrics.SchedulerTasksRunning.WithLabelValues(taskName).Dec()
    metrics.SchedulerTaskDuration.WithLabelValues(taskName).Observe(duration.Seconds())
    metrics.SchedulerLastRun.WithLabelValues(taskName).SetToCurrentTime()

    status := "success"
    if err != nil {
        status = "error"
    }
    metrics.SchedulerTasksTotal.WithLabelValues(taskName, status).Inc()
}
```

### System Metrics Collector

```go
// src/server/metrics/system.go
package metrics

import (
    "runtime"
    "time"

    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
    "github.com/shirou/gopsutil/v3/cpu"
    "github.com/shirou/gopsutil/v3/disk"
    "github.com/shirou/gopsutil/v3/mem"
)

var (
    // System metrics
    SystemCPUUsage = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_system_cpu_usage_percent",
            Help: "Current CPU usage percentage",
        },
    )

    SystemMemoryUsage = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_system_memory_usage_percent",
            Help: "Current memory usage percentage",
        },
    )

    SystemMemoryUsed = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_system_memory_used_bytes",
            Help: "Memory used in bytes",
        },
    )

    SystemMemoryTotal = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_system_memory_total_bytes",
            Help: "Total memory in bytes",
        },
    )

    SystemDiskUsage = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "weather_system_disk_usage_percent",
            Help: "Disk usage percentage",
        },
        []string{"path"},
    )

    SystemDiskUsed = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "weather_system_disk_used_bytes",
            Help: "Disk used in bytes",
        },
        []string{"path"},
    )

    SystemDiskTotal = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "weather_system_disk_total_bytes",
            Help: "Total disk in bytes",
        },
        []string{"path"},
    )

    // Go runtime metrics
    GoGoroutines = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_go_goroutines",
            Help: "Number of goroutines",
        },
    )

    GoMemAlloc = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_go_mem_alloc_bytes",
            Help: "Bytes allocated and in use",
        },
    )

    GoMemSys = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "weather_go_mem_sys_bytes",
            Help: "Bytes obtained from system",
        },
    )

    GoGCRuns = promauto.NewCounter(
        prometheus.CounterOpts{
            Name: "weather_go_gc_runs_total",
            Help: "Total number of GC runs",
        },
    )

    GoGCPauseTotal = promauto.NewCounter(
        prometheus.CounterOpts{
            Name: "weather_go_gc_pause_total_seconds",
            Help: "Total GC pause time in seconds",
        },
    )
)

// SystemCollector collects system metrics periodically
type SystemCollector struct {
    dataDir  string
    interval time.Duration
    stop     chan struct{}
    lastGC   uint32
}

func NewSystemCollector(dataDir string, interval time.Duration) *SystemCollector {
    return &SystemCollector{
        dataDir:  dataDir,
        interval: interval,
        stop:     make(chan struct{}),
    }
}

func (c *SystemCollector) Start() {
    go c.collect()
}

func (c *SystemCollector) Stop() {
    close(c.stop)
}

func (c *SystemCollector) collect() {
    ticker := time.NewTicker(c.interval)
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            c.collectCPU()
            c.collectMemory()
            c.collectDisk()
            c.collectRuntime()
        case <-c.stop:
            return
        }
    }
}

func (c *SystemCollector) collectCPU() {
    if percent, err := cpu.Percent(0, false); err == nil && len(percent) > 0 {
        SystemCPUUsage.Set(percent[0])
    }
}

func (c *SystemCollector) collectMemory() {
    if vmem, err := mem.VirtualMemory(); err == nil {
        SystemMemoryUsage.Set(vmem.UsedPercent)
        SystemMemoryUsed.Set(float64(vmem.Used))
        SystemMemoryTotal.Set(float64(vmem.Total))
    }
}

func (c *SystemCollector) collectDisk() {
    if usage, err := disk.Usage(c.dataDir); err == nil {
        SystemDiskUsage.WithLabelValues(c.dataDir).Set(usage.UsedPercent)
        SystemDiskUsed.WithLabelValues(c.dataDir).Set(float64(usage.Used))
        SystemDiskTotal.WithLabelValues(c.dataDir).Set(float64(usage.Total))
    }
}

func (c *SystemCollector) collectRuntime() {
    var m runtime.MemStats
    runtime.ReadMemStats(&m)

    GoGoroutines.Set(float64(runtime.NumGoroutine()))
    GoMemAlloc.Set(float64(m.Alloc))
    GoMemSys.Set(float64(m.Sys))

    // Track GC runs (delta since last collection)
    if m.NumGC > c.lastGC {
        GoGCRuns.Add(float64(m.NumGC - c.lastGC))
        c.lastGC = m.NumGC
    }

    // Total GC pause time
    GoGCPauseTotal.Add(float64(m.PauseTotalNs) / 1e9)
}
```

### Metrics Handler

```go
// src/server/handler/metrics.go
package handler

import (
    "net/http"

    "github.com/prometheus/client_golang/prometheus/promhttp"
)

// MetricsHandler returns the Prometheus metrics handler with optional auth
func MetricsHandler(token string) http.Handler {
    handler := promhttp.Handler()

    if token == "" {
        return handler
    }

    // Wrap with bearer token authentication
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        auth := r.Header.Get("Authorization")
        if auth != "Bearer "+token {
            http.Error(w, "Unauthorized", http.StatusUnauthorized)
            return
        }
        handler.ServeHTTP(w, r)
    })
}
```

### Uptime Updater

```go
// src/server/metrics/uptime.go
package metrics

import (
    "time"
)

var startTime = time.Now()

// StartUptimeUpdater updates uptime metric periodically
func StartUptimeUpdater() {
    go func() {
        ticker := time.NewTicker(1 * time.Second)
        defer ticker.Stop()

        for range ticker.C {
            AppUptime.Set(time.Since(startTime).Seconds())
        }
    }()
}
```

## Metrics Endpoint Output

```
# HELP weather_http_requests_total Total number of HTTP requests
# TYPE weather_http_requests_total counter
weather_http_requests_total{method="GET",path="/api/v1/users",status="200"} 1523
weather_http_requests_total{method="POST",path="/api/v1/users",status="201"} 42

# HELP weather_http_request_duration_seconds HTTP request duration in seconds
# TYPE weather_http_request_duration_seconds histogram
weather_http_request_duration_seconds_bucket{method="GET",path="/api/v1/users",le="0.01"} 1400
weather_http_request_duration_seconds_bucket{method="GET",path="/api/v1/users",le="0.1"} 1520
weather_http_request_duration_seconds_bucket{method="GET",path="/api/v1/users",le="+Inf"} 1523
weather_http_request_duration_seconds_sum{method="GET",path="/api/v1/users"} 12.456
weather_http_request_duration_seconds_count{method="GET",path="/api/v1/users"} 1523

# HELP weather_db_connections_open Number of open database connections
# TYPE weather_db_connections_open gauge
weather_db_connections_open 5

# HELP weather_cache_hits_total Total number of cache hits
# TYPE weather_cache_hits_total counter
weather_cache_hits_total{cache="sessions"} 8234
weather_cache_hits_total{cache="users"} 1523

# HELP weather_app_info Application information
# TYPE weather_app_info gauge
weather_app_info{version="1.2.3",commit="abc123",build_date="2025-01-15",go_version="go1.23"} 1

# HELP weather_app_uptime_seconds Application uptime in seconds
# TYPE weather_app_uptime_seconds gauge
weather_app_uptime_seconds 86423.5
```

## Alerting Rules (Prometheus)

```yaml
# alerts.yml - Example Prometheus alerting rules
groups:
  - name: weather_alerts
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: |
          sum(rate(weather_http_requests_total{status=~"5.."}[5m]))
          / sum(rate(weather_http_requests_total[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate (> 5%)"
          description: "Error rate is {{ $value | humanizePercentage }}"

      # High latency
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95, rate(weather_http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High p95 latency (> 1s)"
          description: "p95 latency is {{ $value | humanizeDuration }}"

      # Database connection pool exhausted
      - alert: DBConnectionPoolExhausted
        expr: |
          weather_db_connections_in_use / weather_db_connections_open > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Database connection pool > 90% used"

      # High memory usage
      - alert: HighMemoryUsage
        expr: weather_system_memory_usage_percent > 90
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Memory usage > 90%"

      # Disk space low
      - alert: DiskSpaceLow
        expr: weather_system_disk_usage_percent > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Disk usage > 85%"

      # Application down
      - alert: ApplicationDown
        expr: up{job="weather"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "weather is down"

      # Goroutine leak
      - alert: GoroutineLeak
        expr: |
          weather_go_goroutines > 1000
          and increase(weather_go_goroutines[1h]) > 100
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Possible goroutine leak"
          description: "Goroutines: {{ $value }}"

      # Scheduler task failing
      - alert: SchedulerTaskFailing
        expr: |
          increase(weather_scheduler_tasks_total{status="error"}[1h]) > 3
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: "Scheduler task {{ $labels.task }} failing"
```

## Grafana Dashboard

```json
{
  "title": "WEATHER Metrics",
  "panels": [
    {
      "title": "Request Rate",
      "type": "graph",
      "targets": [
        {"expr": "sum(rate(weather_http_requests_total[5m]))"}
      ]
    },
    {
      "title": "Error Rate",
      "type": "graph",
      "targets": [
        {"expr": "sum(rate(weather_http_requests_total{status=~\"5..\"}[5m])) / sum(rate(weather_http_requests_total[5m]))"}
      ]
    },
    {
      "title": "Latency (p50, p95, p99)",
      "type": "graph",
      "targets": [
        {"expr": "histogram_quantile(0.50, rate(weather_http_request_duration_seconds_bucket[5m]))", "legendFormat": "p50"},
        {"expr": "histogram_quantile(0.95, rate(weather_http_request_duration_seconds_bucket[5m]))", "legendFormat": "p95"},
        {"expr": "histogram_quantile(0.99, rate(weather_http_request_duration_seconds_bucket[5m]))", "legendFormat": "p99"}
      ]
    },
    {
      "title": "Active Requests",
      "type": "stat",
      "targets": [
        {"expr": "weather_http_active_requests"}
      ]
    },
    {
      "title": "Database Connections",
      "type": "graph",
      "targets": [
        {"expr": "weather_db_connections_open", "legendFormat": "open"},
        {"expr": "weather_db_connections_in_use", "legendFormat": "in_use"}
      ]
    },
    {
      "title": "Cache Hit Rate",
      "type": "graph",
      "targets": [
        {"expr": "sum(rate(weather_cache_hits_total[5m])) / (sum(rate(weather_cache_hits_total[5m])) + sum(rate(weather_cache_misses_total[5m])))"}
      ]
    },
    {
      "title": "Memory Usage",
      "type": "gauge",
      "targets": [
        {"expr": "weather_system_memory_usage_percent"}
      ]
    },
    {
      "title": "Goroutines",
      "type": "graph",
      "targets": [
        {"expr": "weather_go_goroutines"}
      ]
    },
    {
      "title": "Uptime",
      "type": "stat",
      "targets": [
        {"expr": "weather_app_uptime_seconds"}
      ]
    }
  ]
}
```

## Admin Panel (/admin/server/metrics)

| Element | Type | Description |
|---------|------|-------------|
| Enable metrics | Toggle | Turn metrics on/off |
| Endpoint | Text input | Metrics endpoint path (default: /metrics) |
| Include system metrics | Toggle | Include CPU/memory/disk |
| Include runtime metrics | Toggle | Include Go runtime stats |
| Authentication token | Text input | Bearer token (empty = no auth) |
| Prometheus URL | Info | Display scrape URL for Prometheus config |

---


# PART 22: BACKUP & RESTORE (NON-NEGOTIABLE)

## Backup Command

```bash
weather --maintenance backup [filename]
```

### Backup Contents

| Content | Included | Notes |
|---------|----------|-------|
| `server.yml` | ✓ Always | Configuration file |
| `server.db` | ✓ Always | Main database (admin credentials, settings) |
| `users.db` | ✓ If exists | User database (multi-user mode) |
| `{config_dir}/template/` | ✓ If exists | Custom email templates |
| `{config_dir}/theme/` | ✓ If exists | Custom themes |
| `{config_dir}/ssl/` | Optional | SSL certificates (flag: `--include-ssl`) |
| `{data_dir}/` | Optional | Data files (flag: `--include-data`) |

### Admin Credentials in Backup

**Yes, admin credentials are included in the backup (`server.db`).**

| Credential | Included | Format |
|------------|----------|--------|
| Admin username | ✓ | Plain text |
| Admin password | ✓ | Hashed (Argon2id) |
| Admin API token | ✓ | Hashed (SHA-256) |
| Admin 2FA secret | ✓ | Encrypted |
| Admin recovery keys | ✓ | Hashed |
| Additional admin accounts | ✓ | Same as above |
| OIDC/LDAP admin mappings | ✓ | Configuration only |

### Backup Format

- Single `.tar.gz` file (or `.tar.gz.enc` if encrypted)
- Filename: `weather_backup_YYYY-MM-DD_HHMMSS.tar.gz[.enc]`
- Includes manifest with version info
- Encrypted if backup password was set during setup

**Manifest (`manifest.json`):**
```json
{
  "version": "1.0.0",
  "created_at": "2025-01-15T10:30:00Z",
  "created_by": "administrator",
  "app_version": "1.2.3",
  "contents": [
    "server.yml",
    "server.db",
    "users.db",
    "template/",
    "ssl/"
  ],
  "encrypted": true,
  "encryption_method": "AES-256-GCM",
  "checksum": "sha256:abc123..."
}
```

### Backup Encryption

**Encryption is OPTIONAL unless compliance mode is enabled.**

| Compliance Mode | Backup Password | Behavior |
|-----------------|-----------------|----------|
| Disabled | Not set | Unencrypted backups (`.tar.gz`) |
| Disabled | Set | Encrypted backups (`.tar.gz.enc`) |
| **Enabled** | Not set | **Backups BLOCKED** until password set |
| **Enabled** | Set | Encrypted backups (required) |

| Aspect | Details |
|--------|---------|
| Algorithm | AES-256-GCM |
| Key Derivation | Argon2id (password → encryption key) |
| File Extension | `.tar.gz` (unencrypted) or `.tar.gz.enc` (encrypted) |
| Password Storage | **NEVER stored** - admin must remember |

**How Encryption Works:**
1. Backup creates `.tar.gz` archive in memory
2. Password is run through Argon2id to derive 256-bit key
3. Archive is encrypted with AES-256-GCM
4. Encrypted file saved as `.tar.gz.enc`
5. Unencrypted archive never touches disk

**Encryption Configuration:**

```yaml
server:
  backup:
    encryption:
      enabled: true       # true if password was set
      # Password is NEVER stored - prompted on-demand
  compliance:
    enabled: false        # HIPAA, SOC2, etc.
    # If true, backup.encryption.enabled MUST be true
```

**Compliance Mode Enforcement:**

When `server.compliance.enabled: true`:
- Backups will NOT run unless encryption password is set
- WebUI shows mandatory password setup dialog
- CLI shows error with instructions to set password
- Scheduled backups skip with audit log warning

```
┌─────────────────────────────────────────┐
│  ⚠️  Backup Password Required           │
├─────────────────────────────────────────┤
│  Compliance mode requires encrypted     │
│  backups. Set a backup password.        │
│                                         │
│  Password:         [••••••••••••]       │
│  Confirm Password: [••••••••••••]       │
│  Hint (optional):  [______________]     │
│                                         │
│           [Cancel]  [Save & Enable]     │
└─────────────────────────────────────────┘
```

**Setting/Changing Backup Password:**

| Action | Location | Notes |
|--------|----------|-------|
| Set during setup | Setup wizard Step 4 | Optional (unless compliance) |
| Set later | `/admin/server/backup` | Click "Set Encryption Password" |
| Change password | `/admin/server/backup` | New backups use new password |
| Remove encryption | Only if compliance disabled | Cannot remove if compliance enabled |

**Important:**
- Old backups encrypted with old password still need old password to restore
- Password hint can be stored (optional): "Hint: First pet's name + year"
- No password recovery - if lost, backups are unrecoverable

**CLI Backup with Encryption:**

```bash
# If encryption password set during setup:
weather --maintenance backup
# Prompts for password, creates encrypted backup

# Override with explicit password:
weather --maintenance backup --password "mypassword"

# Restore encrypted backup:
weather --maintenance restore backup.tar.gz.enc
# Prompts for password
```

**API Backup with Encryption:**

```
POST /api/v1/admin/server/backup
Content-Type: application/json

{
  "password": "backup-encryption-password"
}
```

**Note:** The `password` field is required if encryption is enabled.

**Warning Shown if Encryption Not Enabled:**

```
┌─────────────────────────────────────────────────────────────────────┐
│  ⚠️  BACKUP ENCRYPTION NOT CONFIGURED                               │
│                                                                      │
│  Your backups are NOT encrypted. If someone gains access to your    │
│  backup files, they can read all data including admin credentials.  │
│                                                                      │
│  [Set Encryption Password]  [Remind Me Later]  [Don't Show Again]   │
└─────────────────────────────────────────────────────────────────────┘
```

Shown on:
- First backup if encryption not configured
- `/admin/server/backup` page (dismissable)

### Backup Retention

**Storage management: keep backups based on retention policy.**

| Setting | Default | Valid | Description |
|---------|---------|-------|-------------|
| `max_backups` | 1 | ≥1 | Daily full backups to keep |
| `keep_weekly` | 0 | ≥0 | Weekly backups (Sunday) - 0 = disabled |
| `keep_monthly` | 0 | ≥0 | Monthly backups (1st) - 0 = disabled |
| `keep_yearly` | 0 | ≥0 | Yearly backups (Jan 1st) - 0 = disabled |

**Falsey Values (all disabled):** `0`, `false`, `no`, `none`, `disable`, `disabled`, `off`

**Configuration:**

```yaml
server:
  backup:
    retention:
      max_backups: 1     # 1-365: daily full backups
      keep_weekly: 0     # 0-52: Sunday backups (0 = disabled)
      keep_monthly: 0    # 0-12: 1st of month (0 = disabled)
      keep_yearly: 0     # 0-10: January 1st (0 = disabled)
```

**Default: 2 files total** (yesterday's full + today's incremental)

**With hourly enabled: 3 files total** (+ hourly incremental from `backup_hourly` task)

**With retention options:** `max_backups + keep_weekly + keep_monthly + keep_yearly + incrementals`

**Backup Creation Flow (backup_daily task at 02:00):**

```
1. Create full backup: weather_backup_YYYY-MM-DD.tar.gz[.enc]
2. Verify full backup (all checks must pass)
3. Create daily incremental: weather-daily.tar.gz[.enc]
4. Verify daily incremental (all checks must pass)
5. If ALL verifications pass:
   - Apply retention policy (delete old backups per retention settings)
6. If ANY verification fails:
   - Delete failed backup file
   - Keep existing valid backups
   - Alert admin
   - Retry on next scheduled run
```

**Verification (NON-NEGOTIABLE):**

Every backup is verified **immediately after creation** - backups must be 100% working:

| Check | Description | Failure = |
|-------|-------------|-----------|
| File exists | Backup file was written | Fatal |
| Size > 0 | File is not empty | Fatal |
| Checksum valid | SHA-256 matches manifest | Fatal |
| Decrypt test | If encrypted, verify password works | Fatal |
| Manifest readable | Can parse manifest.json | Fatal |
| **Content extraction** | Test extract all files to temp dir | Fatal |
| **Database integrity** | Verify SQLite/dump is valid | Fatal |

**All checks must pass. If ANY check fails:**
- Delete the failed backup immediately
- Alert admin (WebUI notification + audit log)
- Do NOT delete any existing backups
- Retry backup on next scheduled run

**Only delete old backups if new backup passes ALL verification checks.**

**Admin UI:**

```
┌─────────────────────────────────────────────────────────────────────┐
│  BACKUP RETENTION                                                    │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  Daily full backups (max_backups):    [1    ] ← required, ≥1        │
│  Weekly backups (keep_weekly):        [0    ] ← 0 = disabled        │
│  Monthly backups (keep_monthly):      [0    ] ← 0 = disabled        │
│  Yearly backups (keep_yearly):        [0    ] ← 0 = disabled        │
│                                                                      │
│  [✓] Auto-delete old backups after successful backup                │
│                                                                      │
│  Current storage: 23 MB (2 files: yesterday + daily incremental)    │
│                                                                      │
│  Hourly incremental:                                                 │
│  [ ] Enable backup_hourly task (creates 3rd file)                   │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘
```

**Audit Events:**

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `backup.created` | Backup created and verified | Filename, size, encrypted, verification status |
| `backup.retention_cleanup` | Old backups deleted | Deleted files, reason, remaining count |
| `backup.verification_failed` | Backup verification failed | Filename, check that failed |
| `backup.daily_updated` | Daily incremental updated | Filename, changes since last |

### Backup Files Created (Single Task at 02:00)

**The backup task creates TWO files each run:**

| File | Description | Retention |
|------|-------------|-----------|
| `weather_backup_YYYY-MM-DD.tar.gz[.enc]` | Full backup (yesterday's data) | Controlled by `max_backups` |
| `weather-daily.tar.gz[.enc]` | Daily incremental (changes since full) | Always 1 (replaced each run) |
| `weather-hourly.tar.gz[.enc]` | Hourly incremental (if enabled) | Always 1 (replaced each run) |

### Retention Configuration

```yaml
server:
  backup:
    retention:
      # Full backups to keep (default: 1 = yesterday only)
      max_backups: 1
      # Optional: keep weekly backup (e.g., every Sunday's backup)
      keep_weekly: 0
      # Optional: keep monthly backup (e.g., 1st of month)
      keep_monthly: 0
      # Optional: keep yearly backup (e.g., Jan 1st)
      keep_yearly: 0
```

**Retention Settings:**

| Setting | Default | Valid | Description |
|---------|---------|-------|-------------|
| `max_backups` | 1 | ≥1 | Daily full backups to keep |
| `keep_weekly` | 0 | ≥0 | Weekly backups (Sunday) - 0 = disabled |
| `keep_monthly` | 0 | ≥0 | Monthly backups (1st) - 0 = disabled |
| `keep_yearly` | 0 | ≥0 | Yearly backups (Jan 1st) - 0 = disabled |

**Falsey Values (all mean disabled):**
- `0`, `false`, `no`, `none`, `disable`, `disabled`, `off`

**Validation (warn, don't error - server must start):**

| Value | Behavior |
|-------|----------|
| Valid number ≥ 0 | Accept |
| `max_backups: 0` | Warn, use default (1) |
| Negative number | Warn, use default |
| Non-numeric | Warn, use default |

**Warning Thresholds (accept but warn):**

| Setting | Warn If | Reason |
|---------|---------|--------|
| `max_backups` | > 7 | More than a week of daily backups |
| `keep_weekly` | > 8 | More than 2 months of weekly backups |
| `keep_monthly` | > 12 | More than a year of monthly backups |
| `keep_yearly` | > 2 | More than 2 years of yearly backups |

**Warning Examples (logged, server starts):**
```
WARN: max_backups: 0 invalid, using default 1
WARN: keep_monthly: -5 invalid, using default 0
WARN: max_backups: 30 exceeds recommended 7 (30 days of daily backups)
WARN: keep_monthly: 24 exceeds recommended 12 (2 years of monthly backups)
```

**WebUI Confirmation for High Values:**
```
┌─────────────────────────────────────────────────────────┐
│  ⚠️ Confirm Backup Retention                            │
├─────────────────────────────────────────────────────────┤
│  max_backups: 30 will retain 30 days of daily backups.  │
│  Recommended: 7 or less.                                │
│                                                         │
│  Estimated storage: ~15 GB (based on current backups)   │
│                                                         │
│              [Cancel]  [Save Anyway]                    │
└─────────────────────────────────────────────────────────┘
```

**Default: 2 files total (yesterday + today's incremental)**

**With hourly enabled: 3 files total** (yesterday + daily + hourly incrementals)

**Retention Priority Order:**
```
1. Yearly (Jan 1st) - highest priority, never deleted if in keep_yearly count
2. Monthly (1st of month) - next priority
3. Weekly (Sunday) - next priority
4. Daily (max_backups) - lowest priority, oldest deleted first
```

**Example: Default settings (max=1, weekly=0, monthly=0, yearly=0)**
```
Backups on disk:
  myapp_backup_2025-01-15.tar.gz.enc    ← Yesterday (full)
  myapp-daily.tar.gz.enc                 ← Today (incremental)

Total: 2 files
```

**Example: Keep 1 weekly + 1 monthly + 1 yearly**
```yaml
retention:
  max_backups: 1
  keep_weekly: 1
  keep_monthly: 1
  keep_yearly: 1
```
```
Backups on disk (January 15, 2025):
  myapp_backup_2025-01-15.tar.gz.enc    ← Yesterday (daily)
  myapp_backup_2025-01-12.tar.gz.enc    ← Last Sunday (weekly)
  myapp_backup_2025-01-01.tar.gz.enc    ← 1st of Jan 2025 (monthly + yearly)
  myapp-daily.tar.gz.enc                 ← Incremental

Total: 4 files
```

**Example: Full retention over a year**
```yaml
retention:
  max_backups: 1
  keep_weekly: 1
  keep_monthly: 1
  keep_yearly: 1
```
```
Backups on disk (January 15, 2026):
  myapp_backup_2026-01-15.tar.gz.enc    ← Yesterday (daily)
  myapp_backup_2026-01-12.tar.gz.enc    ← Last Sunday (weekly)
  myapp_backup_2026-01-01.tar.gz.enc    ← 1st of Jan 2026 (monthly + yearly)
  myapp_backup_2025-12-01.tar.gz.enc    ← 1st of Dec 2025 (monthly, kept until Feb)
  myapp_backup_2025-01-01.tar.gz.enc    ← 1st of Jan 2025 (yearly)
  myapp-daily.tar.gz.enc                 ← Incremental

Total: 6 files (1 daily + 1 weekly + 2 monthly + 1 yearly + incremental)
```

**Backup Cleanup Logic (runs after successful backup):**
```
1. Mark all backups from January 1st as "yearly" (keep up to keep_yearly)
2. Mark all backups from 1st of month as "monthly" (keep up to keep_monthly)
3. Mark all backups from Sunday as "weekly" (keep up to keep_weekly)
4. Mark remaining backups as "daily" (keep up to max_backups)
5. Delete unmarked backups, oldest first
6. Daily incremental is always replaced (only 1 exists)

Note: A single backup can satisfy multiple retention types (e.g., Jan 1st 2025
on a Sunday counts as daily + weekly + monthly + yearly - uses highest priority)
```

**Daily incremental is NOT counted** in retention - it's always exactly 1 file that gets replaced.

### Cluster Backup Rules (NON-NEGOTIABLE)

**In cluster mode, EVERY node must maintain its own valid backups.**

| Rule | Description |
|------|-------------|
| **Per-node backups** | Each node creates and stores its own backups |
| **Same retention** | All nodes use same `max_backups` setting |
| **Same schedule** | All nodes backup at same time (staggered by 5min per node) |
| **Same encryption** | All nodes use same encryption password |
| **Local storage** | Backups stored in node's local `{backup_dir}` |
| **Shared storage (optional)** | Can configure shared NFS/S3 for centralized backups |

**Cluster Backup Verification:**
```
┌─────────────────────────────────────────────────────────────────┐
│  CLUSTER BACKUP STATUS                                          │
├─────────────────────────────────────────────────────────────────┤
│  Node              Last Backup      Status    Backups  Daily   │
│  ─────────────────────────────────────────────────────────────  │
│  node1.example.com 2025-01-15 02:05 ✓ Valid   4/4      ✓       │
│  node2.example.com 2025-01-15 02:10 ✓ Valid   4/4      ✓       │
│  node3.example.com 2025-01-15 02:15 ✓ Valid   4/4      ✓       │
│                                                                 │
│  [Backup All Now]  [Verify All]  [Download from Node...]       │
└─────────────────────────────────────────────────────────────────┘
```

**Cluster Backup Alerts:**
- Alert if ANY node has no valid backups
- Alert if ANY node's daily backup is missing or invalid
- Alert if nodes have different backup counts (sync issue)

## Restore Command

```bash
weather --maintenance restore <backup-file>
```

### Restore Password Handling

**If backup is encrypted (`.tar.gz.enc`), password is required.**

| Interface | Password Not Provided | Behavior |
|-----------|----------------------|----------|
| **CLI** | Interactive prompt | Prompts: `Enter backup password:` |
| **CLI** | `--password` flag | Uses provided password |
| **WebUI** | Shows dialog | Password input dialog before restore |
| **API** | Returns 400 error | `{"error": "password_required", "message": "Encrypted backup requires password"}` |

**CLI Restore:**

```bash
# Encrypted backup - prompts for password
weather --maintenance restore backup_2025-01-15.tar.gz.enc
Enter backup password: ••••••••••••
Verifying backup integrity... OK
Restoring...

# Encrypted backup - password via flag
weather --maintenance restore backup_2025-01-15.tar.gz.enc --password "mypassword"

# Unencrypted backup - no password needed
weather --maintenance restore backup_2025-01-15.tar.gz
```

**WebUI Restore:**

```
┌─────────────────────────────────────────┐
│  🔐 Encrypted Backup                    │
├─────────────────────────────────────────┤
│  This backup is encrypted.              │
│  Enter the backup password to restore.  │
│                                         │
│  Password: [••••••••••••]               │
│                                         │
│           [Cancel]  [Restore]           │
└─────────────────────────────────────────┘
```

**API Restore:**

```bash
# Encrypted backup - password required
POST /api/v1/admin/server/restore
{
  "backup_file": "backup_2025-01-15.tar.gz.enc",
  "password": "backup-encryption-password"
}

# Unencrypted backup - no password
POST /api/v1/admin/server/restore
{
  "backup_file": "backup_2025-01-15.tar.gz"
}
```

### Restore Verification

**Before restoring, the backup is verified:**

| Check | Description | Failure Action |
|-------|-------------|----------------|
| File exists | Backup file found | Error: file not found |
| File readable | Can open file | Error: permission denied |
| Format valid | Valid tar.gz or tar.gz.enc | Error: invalid format |
| Decrypt test | If encrypted, password works | Error: invalid password |
| Checksum valid | SHA-256 matches manifest | Error: backup corrupted |
| Manifest valid | Can parse manifest.json | Error: invalid manifest |
| Version compatible | App version can restore this backup | Warning: version mismatch |

**Only proceed with restore if ALL verification checks pass.**

### Restore Behavior

| Scenario | Behavior |
|----------|----------|
| **Restore to same server** | Overwrites current config and database |
| **Restore to new server** | Primary admin must re-authenticate |
| **Version mismatch** | Warning shown, schema updates applied if needed |

### Primary Admin Re-Setup on Restore

**When restoring a backup to a NEW server, the primary admin must re-authenticate:**

```
Restore completed. Primary admin re-authentication required.

A new setup token has been generated:

  Setup Token: a1b2c3d4e5f67890abcdef1234567890

Go to: https://{fqdn}:{port}/admin

Enter the setup token to verify you are the server administrator.
Your existing password and settings will be preserved.
```

**Why Re-Authentication?**
- Prevents stolen backup from granting immediate admin access
- Verifies person restoring has server-level access (can see console)
- Preserves existing admin credentials (just requires re-verification)

**What is Preserved:**
- Admin username
- Admin password (still valid after re-auth)
- Admin 2FA settings
- Admin API token
- All configuration
- All user accounts

**What Requires Re-Setup:**
- Initial setup token verification (one-time)

### Additional Admins on Restore

| Admin Type | Restore Behavior |
|------------|------------------|
| **Primary Admin** | Must re-authenticate with setup token |
| **Additional Admins (local)** | Can log in immediately with existing credentials |
| **OIDC/LDAP Admins** | Can log in if OIDC/LDAP provider accessible |

## Admin Recovery Command

```bash
weather --maintenance setup
```

**Purpose:** Resets admin credentials and generates a new setup token. This is the ONLY way for a server admin to recover access if they have lost their password, API token, AND recovery keys.

### What It Does

| Action | Description |
|--------|-------------|
| **Clears admin password** | Admin password is set to null/empty |
| **Clears admin API token** | Admin API token is invalidated |
| **Generates new setup token** | One-time setup token displayed in console |
| **Preserves everything else** | User accounts, data, configuration unchanged |

### What It Does NOT Do

| Preserved | Description |
|-----------|-------------|
| **User accounts** | All user accounts remain intact |
| **User passwords** | No user credentials are modified |
| **User data** | All user data is preserved |
| **Configuration** | All settings except admin credentials |
| **Database** | No data is deleted or modified |
| **SSL certificates** | Certificates remain valid |

### Usage

```bash
# Stop the service first (recommended)
weather --service stop

# Run setup reset
weather --maintenance setup

# Output:
# ╔══════════════════════════════════════════════════════════════════╗
# ║                     ADMIN CREDENTIALS RESET                      ║
# ╠══════════════════════════════════════════════════════════════════╣
# ║  Admin password and API token have been cleared.                 ║
# ║                                                                  ║
# ║  NEW SETUP TOKEN (copy this now, shown ONCE):                    ║
# ║  ┌────────────────────────────────────────────────────────────┐  ║
# ║  │  a1b2c3d4e5f67890abcdef1234567890                          │  ║
# ║  └────────────────────────────────────────────────────────────┘  ║
# ║                                                                  ║
# ║  1. Start the service: weather --service start             ║
# ║  2. Go to: http://{fqdn}:{port}/admin                            ║
# ║  3. Enter the setup token above                                  ║
# ║  4. Create new admin account via setup wizard                    ║
# ╚══════════════════════════════════════════════════════════════════╝

# Start the service
weather --service start
```

### Security Considerations

| Consideration | Requirement |
|---------------|-------------|
| **Requires root/admin** | Must have console/SSH access to run binary |
| **Console access required** | Setup token only displayed in terminal |
| **One-time token** | Token expires after use or after 24 hours |
| **Logged** | Action logged to audit log (if available) |
| **Service should be stopped** | Recommended to stop service first |

### When to Use

| Scenario | Use `--maintenance setup` |
|----------|---------------------------|
| Admin forgot password | ✓ Yes |
| Admin lost API token | ✓ Yes |
| Admin lost recovery keys | ✓ Yes |
| Admin locked out of 2FA | ✓ Yes (only if no recovery keys) |
| User forgot password | ✗ No (use password reset) |
| User locked out | ✗ No (admin can help via UI) |
| Routine password change | ✗ No (use /{adminpath}/profile) |

### Recovery Flow

```
┌─────────────────────────────────────────────────────────────────┐
│                    ADMIN RECOVERY FLOW                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Admin locked out (no password, no token, no recovery keys)     │
│                           │                                     │
│                           ▼                                     │
│  Server admin runs: weather --maintenance setup           │
│                           │                                     │
│                           ▼                                     │
│  Admin credentials cleared, new setup token generated           │
│                           │                                     │
│                           ▼                                     │
│  Admin visits /admin and enters setup token                     │
│                           │                                     │
│                           ▼                                     │
│  Setup wizard: Create new admin account                         │
│  (username, password, API token, 2FA optional)                  │
│                           │                                     │
│                           ▼                                     │
│  Admin access restored, new recovery keys issued                │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---


# PART 23: UPDATE COMMAND (NON-NEGOTIABLE)

## --update Command

```bash
--update [command]
```

**Alias:** `--maintenance update` is an alias for `--update yes`

## Commands

| Command | Description |
|---------|-------------|
| `yes` (default) | Check and perform in-place update with restart |
| `check` | Check for updates without installing (no privileges required) |
| `branch {stable\|beta\|daily}` | Set update branch |

### Exit Codes

| Code | Meaning |
|------|---------|
| 0 | Successful update or no update available |
| 1 | Error |

**HTTP 404 from GitHub API means no updates available (already current).**

### Update Branches

| Branch | Release Type | Tag Pattern | Example |
|--------|--------------|-------------|---------|
| `stable` (default) | Release | `v*`, `*.*.*` | `v1.0.0` |
| `beta` | Pre-release | `*-beta` | `202512051430-beta` |
| `daily` | Pre-release | `YYYYMMDDHHMMSS` | `20251205143022` |

### Examples

```bash
# Check for updates (no privileges required)
weather --update check

# Perform update (these are equivalent)
weather --update
weather --update yes
weather --maintenance update

# Switch channels
weather --update branch beta
weather --update branch daily
weather --update branch stable
```

---



# PART 24: PRIVILEGE ESCALATION & SERVICE (NON-NEGOTIABLE)

## Overview

Application user creation **REQUIRES** privilege escalation. If the user cannot escalate privileges, the application runs as the current user with user-level directories.

## Escalation Detection by OS

### Linux
```
Escalation Methods (in order):
1. Already root (EUID == 0)
2. sudo (if user is in sudoers/wheel group)
3. su (if user knows root password)
4. pkexec (PolicyKit, if available)
5. doas (OpenBSD-style, if configured)
```

### macOS
```
Escalation Methods (in order):
1. Already root (EUID == 0)
2. sudo (user must be in admin group)
3. osascript with administrator privileges (GUI prompt)
```

### BSD
```
Escalation Methods (in order):
1. Already root (EUID == 0)
2. doas (OpenBSD default, others if configured)
3. sudo (if installed and configured)
4. su (if user knows root password)
```

### Windows
```
Escalation Methods (in order):
1. Already Administrator (elevated token)
2. UAC prompt (requires GUI)
3. runas (command line, requires admin password)
```

## User Creation Logic

```
ON --service --install:

1. Check if can escalate privileges
   ├─ YES: Continue with privileged installation
   │   ├─ Create system user/group (UID/GID 100-999)
   │   ├─ Use system directories (/etc, /var/lib, /var/log)
   │   ├─ Install service (systemd/launchd/rc.d/Windows Service)
   │   └─ Set ownership to created user
   │
   └─ NO: Fall back to user installation
       ├─ Skip user creation (run as current user)
       ├─ Use user directories (~/.config, ~/.local/share)
       ├─ Skip system service installation
       └─ Offer alternative (cron, user systemd, launchctl user agent)
```

## System User Requirements (NON-NEGOTIABLE)

| Requirement | Value |
|-------------|-------|
| Username | `weather` |
| Group | `weather` |
| UID/GID | **Must match** - same value for both UID and GID |
| UID/GID Range | 100-999 (system user range) |
| Shell | `/sbin/nologin` or `/usr/sbin/nologin` |
| Home | Config directory (`/etc/apimgr/weather`) or data directory (`/var/lib/apimgr/weather`) |
| Type | System user (no password, no login) |
| Gecos | `weather service account` |

### UID/GID Selection Logic

**The UID and GID MUST be the same value.** Find an unused ID where both UID and GID are available:

```
1. Start at 999 (top of system range)
2. Check if UID is unused (not in /etc/passwd)
3. Check if GID is unused (not in /etc/group)
4. If both available → use this value for both UID and GID
5. If either taken → decrement and repeat
6. Stop at 100 (bottom of system range)
7. If no ID found → error (system has no available IDs)
```

### Go Implementation

```go
func findAvailableSystemID() (int, error) {
    // Start from top of system range, work down
    for id := 999; id >= 100; id-- {
        // Check if UID is available
        if _, err := user.LookupId(strconv.Itoa(id)); err == nil {
            continue
            // UID exists, try next
        }

        // Check if GID is available
        if _, err := user.LookupGroupId(strconv.Itoa(id)); err == nil {
            continue
            // GID exists, try next
        }

        // Both available
        return id, nil
    }
    return 0, fmt.Errorf("no available UID/GID in system range 100-999")
}
```

### Platform-Specific Commands

**Linux:**
```bash
# Create group with specific GID
groupadd --system --gid {id} weather

# Create user with matching UID, same primary group
useradd --system --uid {id} --gid {id} \
  --home-dir /etc/apimgr/weather \
  --shell /sbin/nologin \
  --comment "weather service account" \
  weather
```

### macOS Service Account (NON-NEGOTIABLE)

**macOS services (launchd) MUST NOT run as logged-in user or root.**

| Option | Security | Recommendation |
|--------|----------|----------------|
| root | HIGH privileges - dangerous | NO |
| Logged-in User | User privileges - insecure | NO |
| `_www` | Web server account | NO (wrong purpose) |
| **Dedicated service user** | Minimal privileges, isolated | **RECOMMENDED** |

**Default: Dedicated system user with matching UID/GID**

macOS uses `dscl` (Directory Service Command Line) to create system users. The user is hidden from login screen and has no shell access.

**macOS UID/GID Ranges:**

| Range | Purpose |
|-------|---------|
| 0-99 | System accounts (reserved) |
| 100-499 | System services (use this range) |
| 500+ | Regular users |

**Create Service Account:**
```bash
# Find available ID in 100-499 range (same logic as Linux but different range)
# Start at 499, work down until both UID and GID are available

# Create group with specific GID
dscl . -create /Groups/weather
dscl . -create /Groups/weather PrimaryGroupID {id}
dscl . -create /Groups/weather Password "*"

# Create user with matching UID
dscl . -create /Users/weather
dscl . -create /Users/weather UniqueID {id}
dscl . -create /Users/weather PrimaryGroupID {id}
dscl . -create /Users/weather UserShell /usr/bin/false
dscl . -create /Users/weather RealName "weather service account"
dscl . -create /Users/weather NFSHomeDirectory /usr/local/var/apimgr/weather
dscl . -create /Users/weather Password "*"

# Hide user from login window
dscl . -create /Users/weather IsHidden 1
```

**launchd plist with UserName:**
```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
    <key>Label</key>
    <string>apimgr.weather</string>

    <key>ProgramArguments</key>
    <array>
        <string>/usr/local/bin/weather</string>
    </array>

    <!-- Run as dedicated service user, NOT root -->
    <key>UserName</key>
    <string>weather</string>

    <key>GroupName</key>
    <string>weather</string>

    <key>RunAtLoad</key>
    <true/>

    <key>KeepAlive</key>
    <true/>

    <key>WorkingDirectory</key>
    <string>/usr/local/var/apimgr/weather</string>

    <key>StandardOutPath</key>
    <string>/usr/local/var/log/apimgr/weather/stdout.log</string>

    <key>StandardErrorPath</key>
    <string>/usr/local/var/log/apimgr/weather/stderr.log</string>
</dict>
</plist>
```

**macOS Directory Structure:**

| Directory | Path | Purpose |
|-----------|------|---------|
| Binary | `/usr/local/bin/weather` | Executable |
| Config | `/usr/local/etc/apimgr/weather/` | Configuration files |
| Data | `/usr/local/var/apimgr/weather/` | Application data |
| Logs | `/usr/local/var/log/apimgr/weather/` | Log files |
| launchd plist | `/Library/LaunchDaemons/apimgr.weather.plist` | Service definition |

**Go Implementation (macOS):**
```go
// +build darwin

func findAvailableMacOSSystemID() (int, error) {
    // macOS system services use 100-499 range
    for id := 499; id >= 100; id-- {
        // Check if UID is available
        if _, err := user.LookupId(strconv.Itoa(id)); err == nil {
            continue
        }

        // Check if GID is available
        if _, err := user.LookupGroupId(strconv.Itoa(id)); err == nil {
            continue
        }

        return id, nil
    }
    return 0, fmt.Errorf("no available UID/GID in macOS system range 100-499")
}

func createMacOSServiceUser(name string, id int, homeDir string) error {
    commands := [][]string{
        // Create group
        {"dscl", ".", "-create", "/Groups/" + name},
        {"dscl", ".", "-create", "/Groups/" + name, "PrimaryGroupID", strconv.Itoa(id)},
        {"dscl", ".", "-create", "/Groups/" + name, "Password", "*"},
        // Create user
        {"dscl", ".", "-create", "/Users/" + name},
        {"dscl", ".", "-create", "/Users/" + name, "UniqueID", strconv.Itoa(id)},
        {"dscl", ".", "-create", "/Users/" + name, "PrimaryGroupID", strconv.Itoa(id)},
        {"dscl", ".", "-create", "/Users/" + name, "UserShell", "/usr/bin/false"},
        {"dscl", ".", "-create", "/Users/" + name, "RealName", name + " service account"},
        {"dscl", ".", "-create", "/Users/" + name, "NFSHomeDirectory", homeDir},
        {"dscl", ".", "-create", "/Users/" + name, "Password", "*"},
        {"dscl", ".", "-create", "/Users/" + name, "IsHidden", "1"},
    }

    for _, cmd := range commands {
        if err := exec.Command(cmd[0], cmd[1:]...).Run(); err != nil {
            return fmt.Errorf("failed to run %v: %w", cmd, err)
        }
    }
    return nil
}
```

**FreeBSD:**
```bash
# Create user and group with matching ID
pw groupadd -n weather -g {id}
pw useradd -n weather -u {id} -g {id} \
  -d /var/lib/apimgr/weather \
  -s /usr/sbin/nologin \
  -c "weather service account"
```

### Windows Service Account (NON-NEGOTIABLE)

**Windows services MUST NOT run as logged-in user or Administrator.**

| Option | Security | Recommendation |
|--------|----------|----------------|
| Local System | HIGH privileges - dangerous | NO |
| Administrator | HIGH privileges - dangerous | NO |
| Logged-in User | User privileges - insecure | NO |
| Local Service | Limited privileges | OK for network-less services |
| Network Service | Limited + network access | OK for network services |
| **Virtual Service Account** | Minimal privileges, isolated | **RECOMMENDED** |
| Managed Service Account | Domain-managed, auto-password | Enterprise environments |

**Default: Virtual Service Account (VSA)**

Virtual Service Accounts are automatically managed by Windows, require no password management, and have minimal privileges. They are created automatically when the service is installed.

**Service Account Format:** `NT SERVICE\weather`

```powershell
# Create service with Virtual Service Account (automatic)
New-Service -Name "weather" `
  -BinaryPathName "C:\Program Files\apimgr\weather\weather.exe" `
  -DisplayName "weather" `
  -Description "weather service" `
  -StartupType Automatic

# Service automatically runs as NT SERVICE\weather
# No user creation needed - Windows manages it
```

**Directory Permissions:**
```powershell
# Grant Virtual Service Account access to config/data directories
$acl = Get-Acl "C:\ProgramData\apimgr\weather"
$rule = New-Object System.Security.AccessControl.FileSystemAccessRule(
    "NT SERVICE\weather",
    "FullControl",
    "ContainerInherit,ObjectInherit",
    "None",
    "Allow"
)
$acl.SetAccessRule($rule)
Set-Acl "C:\ProgramData\apimgr\weather" $acl
```

**Go Implementation (Windows):**
```go
// +build windows

import "golang.org/x/sys/windows/svc/mgr"

func installWindowsService() error {
    m, err := mgr.Connect()
    if err != nil {
        return err
    }
    defer m.Disconnect()

    exePath, _ := os.Executable()

    // Create service - runs as Virtual Service Account by default
    // when ServiceStartName is empty or "NT SERVICE\{name}"
    s, err := m.CreateService(
        "weather",
        exePath,
        mgr.Config{
            DisplayName:     "weather",
            Description:     "weather service",
            StartType:       mgr.StartAutomatic,
            // Empty = Virtual Service Account
            ServiceStartName: "",
        },
    )
    if err != nil {
        return err
    }
    defer s.Close()

    return nil
}
```

**Windows Directory Structure:**

| Directory | Path | Purpose |
|-----------|------|---------|
| Binary | `C:\Program Files\apimgr\weather\` | Executable |
| Config | `C:\ProgramData\apimgr\weather\config\` | Configuration files |
| Data | `C:\ProgramData\apimgr\weather\data\` | Application data |
| Logs | `C:\ProgramData\apimgr\weather\logs\` | Log files |

### Home Directory Selection

| Directory | Use When |
|-----------|----------|
| Config dir (`/etc/apimgr/weather`) | Default - user needs access to config files |
| Data dir (`/var/lib/apimgr/weather`) | When data dir contains user-writable content |

**Note:** Home directory must exist before user creation. Create directories first, then user, then set ownership.

---


# PART 25: SERVICE SUPPORT (NON-NEGOTIABLE)

## Built-in Service Support

**ALL projects MUST have built-in service support for ALL service managers:**

| Service Manager | OS | Template |
|-----------------|-----|----------|
| systemd | Linux | See below |
| runit | Linux | See below |
| Windows Service Manager | Windows | Built-in Go library |
| launchd | macOS | See PART 24 |
| rc.d | BSD | See below |

**See PART 24 for user creation, privilege escalation, and installation logic.**

## systemd Unit File Template

```ini
[Unit]
Description=weather service
Documentation=https://apimgr.github.io/weather
After=network-online.target
Wants=network-online.target

[Service]
Type=simple
User=weather
Group=weather
ExecStart=/usr/local/bin/weather
Restart=on-failure
RestartSec=5
StandardOutput=journal
StandardError=journal

# Security hardening
NoNewPrivileges=yes
ProtectSystem=strict
ProtectHome=yes
PrivateTmp=yes
ReadWritePaths=/var/lib/apimgr/weather
ReadWritePaths=/var/log/apimgr/weather

[Install]
WantedBy=multi-user.target
```

**Installation path:** `/etc/systemd/system/weather.service`

## runit Service Template

```
/etc/sv/weather/
├── run           # Main service script
├── log/
│   └── run       # Logging script
└── supervise/    # Auto-created by runit
```

**run script:**
```bash
#!/bin/sh
exec chpst -u weather:weather /usr/local/bin/weather 2>&1
```

**log/run script:**
```bash
#!/bin/sh
exec svlogd -tt /var/log/apimgr/weather
```

## rc.d Script Template (BSD)

```bash
#!/bin/sh

# PROVIDE: weather
# REQUIRE: NETWORKING
# KEYWORD: shutdown

. /etc/rc.subr

name="weather"
rcvar="weather_enable"
command="/usr/local/bin/weather"
weather_user="weather"

load_rc_config $name
run_rc_command "$1"
```

**Installation path:** `/usr/local/etc/rc.d/weather`

## Windows Service

Use `golang.org/x/sys/windows/svc` for Windows service integration:

```go
// +build windows

import "golang.org/x/sys/windows/svc"

func runAsService() error {
    return svc.Run("weather", &windowsService{})
}

type windowsService struct{}

func (ws *windowsService) Execute(args []string, r <-chan svc.ChangeRequest, s chan<- svc.Status) (bool, uint32) {
    s <- svc.Status{State: svc.StartPending}
    // Start your service
    s <- svc.Status{State: svc.Running, Accepts: svc.AcceptStop | svc.AcceptShutdown}

    for c := range r {
        switch c.Cmd {
        case svc.Stop, svc.Shutdown:
            s <- svc.Status{State: svc.StopPending}
            // Clean shutdown
            return false, 0
        }
    }
    return false, 0
}
```

---



# PART 26: MAKEFILE (NON-NEGOTIABLE)

**Six core targets. DO NOT ADD MORE.**

## Targets

| Target | Purpose | Output Location | When to Use |
|--------|---------|-----------------|-------------|
| `dev` | Quick development build | `${TMPDIR}/${PROJECTORG}.XXXXXX/` | Active coding, quick tests |
| `host` | Production test build | `binaries/` (with version) | Test prod builds locally |
| `build` | Full release (all 8 platforms) | `binaries/` | Before release |
| `test` | Run unit tests | Coverage report | After code changes |
| `release` | Release with source archive | `releases/` | Creating releases |
| `docker` | Build and push container | `$REGISTRY` | Container deployment |

## Versioning (NON-NEGOTIABLE)

**See PART 13: HEALTH & VERSIONING for complete versioning rules (SemVer, sources, format).**

### Version File: `release.txt`

- Source of truth for stable version (see PART 13)
- Semantic versioning: `MAJOR.MINOR.PATCH` (e.g., `1.2.3`)

### Version Tag `v` Prefix Rules (NON-NEGOTIABLE)

**CRITICAL: Only add `v` prefix to NUMERIC semantic versions, NEVER to text versions.**

**Rule: Add `v` prefix ONLY if tag is a NUMBER (semantic version X.Y.Z), NEVER if it's TEXT.**

**When creating git tags:**
- ✓ Numeric versions: `git tag v0.2.0` or `git tag 0.2.0` (both become v0.2.0)
- ✓ Text versions: `git tag dev` or `git tag beta` (stay as dev, beta - NO v)
- ✗ NEVER create: `git tag vdev`, `git tag vbeta` (wrong!)

**When extracting VERSION variable from tag:**
- Git tag `v1.2.3` → VERSION=`1.2.3` (strip v for internal use)
- Git tag `dev` → VERSION=`dev` (no v to strip)
- Git tag `beta` → VERSION=`beta` (no v to strip)

| Tag Input | Type | Add `v`? | Display As | Why |
|-----------|------|----------|------------|-----|
| `0.2.0` | Number (semver) | ✓ YES | `v0.2.0` | Numeric version gets v |
| `1.2.3` | Number (semver) | ✓ YES | `v1.2.3` | Numeric version gets v |
| `v1.2.0` | Number (has v) | ✗ NO | `v1.2.0` | Already has v |
| `1.2.3-rc1` | Number (semver+suffix) | ✓ YES | `v1.2.3-rc1` | Numeric version gets v |
| `dev` | Text | ✗ NO | `dev` | Text version NO v |
| `beta` | Text | ✗ NO | `beta` | Text version NO v |
| `daily` | Text | ✗ NO | `daily` | Text version NO v |
| `20251218060432` | Timestamp | ✗ NO | `20251218060432` | Not semver NO v |
| `20251218060432-beta` | Timestamp+text | ✗ NO | `20251218060432-beta` | Not semver NO v |

**Examples of WRONG:**
- ❌ `vdev` - NEVER add v to text
- ❌ `vbeta` - NEVER add v to text
- ❌ `v20251218` - NEVER add v to timestamps
- ❌ `vv0.3.0` - NEVER double the v prefix

**Examples of CORRECT:**
- ✓ `dev` - Text version, no v
- ✓ `beta` - Text version, no v
- ✓ `v0.2.0` - Numeric version, has v (input: 0.2.0 or v0.2.0)
- ✓ `v1.2.3` - Numeric version, has v (input: 1.2.3 or v1.2.3)
- ✓ `20251218-beta` - Timestamp+text, no v

```bash
# Shell function to format version tag (prevents vv prefix, only adds v to numbers)
format_version_tag() {
    local tag="$1"

    # Step 1: If already starts with v, return as-is (prevents vv0.3.0)
    if [[ "$tag" == v* ]]; then
        echo "$tag"
        return
    fi

    # Step 2: If it's a semantic version (starts with digit.digit.digit), add v
    # Matches: 0.2.0, 1.2.3, 10.5.2-rc1
    # Does NOT match: dev, beta, daily, 20251218
    if [[ "$tag" =~ ^[0-9]+\.[0-9]+\.[0-9]+ ]]; then
        echo "v$tag"        # 0.2.0 → v0.2.0
    else
        echo "$tag"         # dev → dev (no v)
    fi
}

# Usage examples:
# format_version_tag "0.2.0"         → "v0.2.0"
# format_version_tag "v0.2.0"        → "v0.2.0" (not vv0.2.0)
# format_version_tag "dev"           → "dev" (not vdev)
# format_version_tag "beta"          → "beta" (not vbeta)
# format_version_tag "20251218-beta" → "20251218-beta" (not v...)
```

### Version Priority

1. `VERSION` environment variable (if set)
2. `release.txt` file (if exists)
3. Create `release.txt` with `0.1.0` (first release)

## Binary Naming (NON-NEGOTIABLE)

### Naming Pattern

**Pattern: `weather[-type]-{os}-{arch}[.exe]`**

| Binary | Host Build | Distribution |
|--------|------------|--------------|
| **Server** | `weather` | `weather-{os}-{arch}` |
| **CLI** | `weather-cli` | `weather-cli-{os}-{arch}` |
| **Agent** | `weather-agent` | `weather-agent-{os}-{arch}` |

### Examples

| Binary | Host | Linux AMD64 | Windows AMD64 |
|--------|------|-------------|---------------|
| Server | `jokes` | `jokes-linux-amd64` | `jokes-windows-amd64.exe` |
| CLI | `jokes-cli` | `jokes-cli-linux-amd64` | `jokes-cli-windows-amd64.exe` |
| Agent | `jokes-agent` | `jokes-agent-linux-amd64` | `jokes-agent-windows-amd64.exe` |

### Directory Structure

```
binaries/
├── weather                      # Host server
├── weather-cli                  # Host CLI (if src/client/ exists)
├── weather-agent                # Host agent (if src/agent/ exists)
├── weather-linux-amd64          # Server distributions
├── weather-linux-arm64
├── weather-darwin-amd64
├── weather-darwin-arm64
├── weather-windows-amd64.exe
├── weather-windows-arm64.exe
├── weather-freebsd-amd64
├── weather-freebsd-arm64
├── weather-cli-linux-amd64      # CLI distributions
├── weather-cli-linux-arm64
├── ...
├── weather-agent-linux-amd64    # Agent distributions
├── weather-agent-linux-arm64
└── ...
```

### Local/Testing

| Context | Path |
|---------|------|
| Temp build | `$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}.XXXXXX")/weather` |

**If built with musl → strip binary before release. Final name has NO `-musl` suffix.**

## Build Matrix

| OS | Architectures |
|----|---------------|
| Linux | amd64, arm64 |
| macOS (Darwin) | amd64, arm64 |
| Windows | amd64, arm64 |
| FreeBSD | amd64, arm64 |

## Makefile Implementation

```makefile
# Infer PROJECTNAME and PROJECTORG from git remote or directory path (NEVER hardcode)
PROJECTNAME := $(shell git remote get-url origin 2>/dev/null | sed -E 's|.*/([^/]+)(\.git)?$$|\1|' || basename "$$(pwd)")
PROJECTORG := $(shell git remote get-url origin 2>/dev/null | sed -E 's|.*/([^/]+)/[^/]+(\.git)?$$|\1|' || basename "$$(dirname "$$(pwd)")")

# Version: env var > release.txt > default
VERSION ?= $(shell cat release.txt 2>/dev/null || echo "0.1.0")

# Build info - use TZ env var or system timezone
# Format: "Thu Dec 17, 2025 at 18:19:24 EST"
BUILD_DATE := $(shell date +"%%a %%b %%d, %%Y at %%H:%%M:%%S %%Z")
COMMIT_ID := $(shell git rev-parse --short HEAD 2>/dev/null || echo "unknown")
# COMMIT_ID used directly - no VCS_REF alias

# Linker flags to embed build info
LDFLAGS := -s -w \
	-X 'main.Version=$(VERSION)' \
	-X 'main.CommitID=$(COMMIT_ID)' \
	-X 'main.BuildDate=$(BUILD_DATE)'

# Directories
BINDIR := binaries
RELDIR := releases

# Go directories (persistent across builds)
GODIR := $(HOME)/.local/share/go
GOCACHE := $(HOME)/.local/share/go/build

# Build targets
PLATFORMS := linux/amd64 linux/arm64 darwin/amd64 darwin/arm64 windows/amd64 windows/arm64 freebsd/amd64 freebsd/arm64

# Docker - Set REGISTRY based on your platform (ghcr.io, registry.gitlab.com, git.example.com)
REGISTRY ?= ghcr.io/$(PROJECTORG)/$(PROJECTNAME)
GO_DOCKER := docker run --rm \
	-v $(PWD):/build \
	-v $(GOCACHE):/root/.cache/go-build \
	-v $(GODIR):/go \
	-w /build \
	-e CGO_ENABLED=0 \
	golang:alpine

.PHONY: build host release docker test dev clean

# =============================================================================
# BUILD - Build all platforms + host binary (via Docker with cached modules)
# =============================================================================
build: clean
	@mkdir -p $(BINDIR)
	@echo "Building version $(VERSION)..."
	@mkdir -p $(GOCACHE) $(GODIR)

	# Tidy and download modules
	@echo "Tidying and downloading Go modules..."
	@$(GO_DOCKER) go mod tidy
	@$(GO_DOCKER) go mod download

	# Build for host OS/ARCH
	@echo "Building host binary..."
	@$(GO_DOCKER) sh -c "GOOS=$$(go env GOOS) GOARCH=$$(go env GOARCH) \
		go build -ldflags \"$(LDFLAGS)\" -o $(BINDIR)/$(PROJECTNAME) ./src"

	# Build all platforms
	@for platform in $(PLATFORMS); do \
		OS=$${platform%/*}; \
		ARCH=$${platform#*/}; \
		OUTPUT=$(BINDIR)/$(PROJECTNAME)-$$OS-$$ARCH; \
		[ "$$OS" = "windows" ] && OUTPUT=$$OUTPUT.exe; \
		echo "Building $$OS/$$ARCH..."; \
		$(GO_DOCKER) sh -c "GOOS=$$OS GOARCH=$$ARCH \
			go build -ldflags \"$(LDFLAGS)\" \
			-o $$OUTPUT src" || exit 1; \
	done

	@echo "Build complete: $(BINDIR)/"

# =============================================================================
# HOST - Build host binaries only (fast development builds)
# =============================================================================
host: clean
	@mkdir -p $(BINDIR)
	@echo "Building host binaries version $(VERSION)..."
	@mkdir -p $(GOCACHE) $(GODIR)

	# Tidy and download modules
	@echo "Tidying and downloading Go modules..."
	@$(GO_DOCKER) go mod tidy
	@$(GO_DOCKER) go mod download

	# Build server binary
	@echo "Building $(PROJECTNAME)..."
	@$(GO_DOCKER) sh -c "GOOS=$$(go env GOOS) GOARCH=$$(go env GOARCH) \
		go build -ldflags \"$(LDFLAGS)\" -o $(BINDIR)/$(PROJECTNAME) ./src"

	# Build CLI binary (if exists)
	@if [ -d "src/client" ]; then \
		echo "Building $(PROJECTNAME)-cli..."; \
		$(GO_DOCKER) sh -c "GOOS=$$(go env GOOS) GOARCH=$$(go env GOARCH) \
			go build -ldflags \"$(LDFLAGS)\" -o $(BINDIR)/$(PROJECTNAME)-cli ./src/client"; \
	fi

	# Build agent binary (if exists)
	@if [ -d "src/agent" ]; then \
		echo "Building $(PROJECTNAME)-agent..."; \
		$(GO_DOCKER) sh -c "GOOS=$$(go env GOOS) GOARCH=$$(go env GOARCH) \
			go build -ldflags \"$(LDFLAGS)\" -o $(BINDIR)/$(PROJECTNAME)-agent ./src/agent"; \
	fi

	@echo "Host build complete: $(BINDIR)/"

# =============================================================================
# RELEASE - Manual local release (stable only)
# =============================================================================
release: build
	@mkdir -p $(RELDIR)
	@echo "Preparing release $(VERSION)..."

	# Create version.txt
	@echo "$(VERSION)" > $(RELDIR)/version.txt

	# Copy binaries to releases (strip if needed)
	@for f in $(BINDIR)/$(PROJECTNAME)-*; do \
		[ -f "$$f" ] || continue; \
		strip "$$f" 2>/dev/null || true; \
		cp "$$f" $(RELDIR)/; \
	done

	# Create source archive (exclude VCS and build artifacts)
	@tar --exclude='.git' --exclude='.github' --exclude='.gitea' \
		--exclude='binaries' --exclude='releases' --exclude='*.tar.gz' \
		-czf $(RELDIR)/$(PROJECTNAME)-$(VERSION)-source.tar.gz .

	# Delete existing release/tag if exists
	@gh release delete $(VERSION) --yes 2>/dev/null || true
	@git tag -d $(VERSION) 2>/dev/null || true
	@git push origin :refs/tags/$(VERSION) 2>/dev/null || true

	# Create new release (stable)
	@gh release create $(VERSION) $(RELDIR)/* \
		--title "$(PROJECTNAME) $(VERSION)" \
		--notes "Release $(VERSION)" \
		--latest

	@echo "Release complete: $(VERSION)"

# =============================================================================
# DOCKER - Build and push container to registry (set REGISTRY env var)
# =============================================================================
# Uses multi-stage Dockerfile - Go compilation happens inside Docker
# No pre-built binaries needed
docker:
	@echo "Building Docker image $(VERSION)..."

	# Ensure buildx is available
	@docker buildx version > /dev/null 2>&1 || (echo "docker buildx required" && exit 1)

	# Create/use builder
	@docker buildx create --name $(PROJECTNAME)-builder --use 2>/dev/null || \
		docker buildx use $(PROJECTNAME)-builder

	# Build and push multi-arch (multi-stage Dockerfile handles Go compilation)
	@docker buildx build \
		-f docker/Dockerfile \
		--platform linux/amd64,linux/arm64 \
		--build-arg VERSION="$(VERSION)" \
		--build-arg BUILD_DATE="$(BUILD_DATE)" \
		--build-arg COMMIT_ID="$(COMMIT_ID)" \
		-t $(REGISTRY):$(VERSION) \
		-t $(REGISTRY):latest \
		--push \
		.

	@echo "Docker push complete: $(REGISTRY):$(VERSION)"

# =============================================================================
# TEST - Run all tests with coverage enforcement (via Docker)
# =============================================================================
test:
	@echo "Running tests with coverage..."
	@mkdir -p $(GOCACHE) $(GODIR)
	@$(GO_DOCKER) go mod download
	@$(GO_DOCKER) go test -v -cover -coverprofile=coverage.out ./...
	@COVERAGE=$$($(GO_DOCKER) go tool cover -func=coverage.out | grep total | awk '{print $$3}' | sed 's/%//'); \
	if [ $$(echo "$$COVERAGE < 100" | bc -l) -eq 1 ]; then \
		echo "ERROR: Coverage is $$COVERAGE%, must be 100%"; \
		exit 1; \
	fi
	@echo "Tests complete - Coverage: 100% ✓"

# =============================================================================
# DEV - Quick build for local development/testing (to random temp dir)
# =============================================================================
# Fast: host platform only, no ldflags, random temp dir for isolation
# Builds server + CLI + agent (if they exist)
dev:
	@mkdir -p $(GOCACHE) $(GODIR)
	@$(GO_DOCKER) go mod tidy
	@BUILD_DIR=$$(mktemp -d "$${TMPDIR:-/tmp}/$(PROJECTORG).XXXXXX") && \
		echo "Quick dev build to $$BUILD_DIR..." && \
		$(GO_DOCKER) go build -o $$BUILD_DIR/$(PROJECTNAME) ./src && \
		echo "Built: $$BUILD_DIR/$(PROJECTNAME)" && \
		if [ -d "src/client" ]; then \
			$(GO_DOCKER) go build -o $$BUILD_DIR/$(PROJECTNAME)-cli ./src/client && \
			echo "Built: $$BUILD_DIR/$(PROJECTNAME)-cli"; \
		fi && \
		if [ -d "src/agent" ]; then \
			$(GO_DOCKER) go build -o $$BUILD_DIR/$(PROJECTNAME)-agent ./src/agent && \
			echo "Built: $$BUILD_DIR/$(PROJECTNAME)-agent"; \
		fi && \
		echo "Test:  docker run --rm -v $$BUILD_DIR:/app alpine:latest /app/$(PROJECTNAME) --help"

# =============================================================================
# CLEAN - Remove build artifacts
# =============================================================================
clean:
	@rm -rf $(BINDIR) $(RELDIR)
```

## Embedded Build Info (NON-NEGOTIABLE)

Every binary MUST have these values embedded at build time:

| Variable | Example | Description |
|----------|---------|-------------|
| `Version` | `1.2.3` | Semantic version from release.txt |
| `CommitID` | `a1b2c3d` | Git short commit hash |
| `BuildDate` | `Thu Dec 17, 2025 at 18:19:24 EST` | Build timestamp with timezone |

**Go code requirement** (in `main.go` or `version.go`):

```go
// Build info - set via -ldflags at build time
var (
    Version   = "dev"
    CommitID  = "unknown"
    BuildDate = "unknown"
)
```

**Build date format:** Uses build system timezone or `TZ` env var.

## Go Module Caching

All Docker builds use persistent Go module caching to avoid re-downloading dependencies:

| Cache | Host Path | Container Path |
|-------|-----------|----------------|
| Go directory | `~/.local/share/go` | `/go` |
| Build cache | `~/.local/share/go/build` | `/root/.cache/go-build` |

**Benefits:**
- First build downloads modules once
- Subsequent builds use cached modules
- Shared across all projects on the same machine
- Significantly faster builds after first run

## Target Details

### `make build`

1. **Runs `clean` first** (removes previous build artifacts)
2. Creates cache directories if needed
3. Downloads Go modules (cached)
4. Creates `binaries/` directory
5. Builds host binary: `binaries/weather`
6. Builds all platform binaries: `binaries/weather-{os}-{arch}`
7. Uses `CGO_ENABLED=0` for static binaries
8. Embeds Version, CommitID, BuildDate via `-ldflags`
9. All builds via Docker (`golang:alpine`)

### `make release`

1. Runs `build` first
2. Creates `releases/version.txt` with current version
3. Strips binaries (removes symbols)
4. Creates source archive (excludes `.git`, `.github`, `.gitea`, `binaries/`, `releases/`)
5. Deletes existing GitHub release/tag if exists
6. Creates new GitHub release marked as `--latest`
7. Uses `gh` CLI - **manual local release only**

### `make docker`

1. Uses `docker buildx` for multi-arch builds
2. Multi-stage Dockerfile handles Go compilation (no pre-built binaries)
3. Context is project root, Dockerfile at `docker/Dockerfile`
4. Builds for `linux/amd64` and `linux/arm64`
5. Pushes to `$REGISTRY:{version}` and `:latest`
6. Passes VERSION, BUILD_DATE, COMMIT_ID as build args
7. Layer caching: Go modules cached in builder stage

### `make test`

1. Downloads Go modules (cached)
2. Runs tests inside Docker container (`golang:alpine`)
3. Mounts project directory to `/build`
4. Runs `go test` with coverage
5. Tests all packages (`./...`)
6. Container removed after completion (`--rm`)

### `make dev`

1. Quick build for local development/testing
2. Builds host platform only (fastest)
3. No `-ldflags` (version info not embedded)
4. Outputs to `{tempdir}/apimgr.XXXXXX/weather` (isolated, org-identifiable)
5. Uses Docker (`golang:alpine`) - keeps host clean
6. Easy cleanup: `rm -rf "${TMPDIR:-/tmp}"/${PROJECTORG}.*/` or auto-deleted on reboot

### `make host`

1. **Runs `clean` first** (removes previous build artifacts)
2. Builds host platform binaries only (fast)
3. Outputs to `binaries/` (server, cli, agent if applicable)
4. Full `-ldflags` (version info embedded)
5. Uses Docker (`golang:alpine`) - keeps host clean
6. **Use for local testing before full cross-platform build**

**When to use (Local Development - NOT CI/CD):**

| Command | Purpose | Output | When to Use |
|---------|---------|--------|-------------|
| `make dev` | **Development & Debugging** | `${TMPDIR}/${PROJECTORG}.XXXXXX/` | Active coding, quick tests, debugging |
| `make host` | **Production Testing** | `binaries/` (with version) | Test production builds locally before release |
| `make build` | **Full Release Build** | `binaries/` (all 8 platforms) | Before tagging release, cross-platform verification |
| `make test` | **Unit Tests** | Coverage report | After code changes, before commits |

**Local Development Workflow:**

| Stage | Command | Purpose |
|-------|---------|---------|
| **1. Coding** | `make dev` | Rapid iteration - builds to temp dir, no version info |
| **2. Quick Test** | Run binary in Docker | Debug with curl, file, bash tools |
| **3. Unit Tests** | `make test` | Verify logic, coverage |
| **4. Integration** | `./tests/run_tests.sh` | Full server + CLI + agent tests |
| **5. Production Test** | `make host` | Build with version info to `binaries/` |
| **6. Release** | `make build` | Full cross-platform build (8 platforms) |

**Debugging in Docker (Local Development):**

```bash
# After make dev, test in Docker with debug tools
BUILD_DIR=$(ls -td ${TMPDIR:-/tmp}/${PROJECTORG}.*/ | head -1)
docker run --rm -it \
  -v "$BUILD_DIR:/app" \
  alpine:latest sh -c "
    apk add --no-cache curl bash file jq
    /app/$WEATHER --help
    /app/$WEATHER --version
    # Debug interactively...
  "
```

**Integration Tests:**

| Script | Container | Best For |
|--------|-----------|----------|
| `./tests/run_tests.sh` | Auto-detect | General testing (picks best available) |
| `./tests/docker.sh` | Docker `alpine:latest` | Quick integration tests |
| `./tests/incus.sh` | Incus `debian:latest` | **PREFERRED** - Full OS, systemd, realistic |

**Typical workflow:**
```bash
# Active development
make dev                # Quick build to temp dir
make test               # Unit tests

# Before commit
./tests/run_tests.sh    # Integration tests (auto-detects incus/docker)

# Before release
make host               # Production build locally
./tests/incus.sh        # Full systemd testing (PREFERRED)
make build              # Full cross-platform build
```

## Directory Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **binaries/** | Build output only - temporary, gitignored |
| **releases/** | Release artifacts only - packaged for distribution |
| **version.txt** | Every release includes `version.txt` with current version |

## NEVER Copy or Symlink Binaries (NON-NEGOTIABLE)

**Binaries are NEVER copied or symlinked. They stay in `binaries/` until explicitly moved for release.**

### Prohibited Actions

| Action | Example | Why Prohibited |
|--------|---------|----------------|
| **Symlink to PATH** | `ln -s binaries/app /usr/local/bin/app` | Creates maintenance nightmare |
| **Copy to system dirs** | `cp binaries/app /usr/local/bin/` | Stale binaries, version confusion |
| **Symlink for testing** | `ln -s ../binaries/app test/app` | Use full path instead |
| **Copy between dirs** | `cp binaries/app releases/app` | Use CI/CD release process |
| **Install locally** | Any form of "installing" the binary | Run from `binaries/` directly |

### Correct Usage

| Task | WRONG | CORRECT |
|------|-------|---------|
| **Run binary** | `ln -s binaries/app ~/bin/app && app` | `./binaries/app` or `binaries/app` |
| **Test binary** | `cp binaries/app /tmp/ && /tmp/app` | `./binaries/app --test` |
| **Release** | `cp binaries/* releases/` | CI/CD handles release artifacts |
| **Deploy** | Copy binary to server | Use container or package manager |

### Why This Rule Exists

| Problem | Description |
|---------|-------------|
| **Stale binaries** | Symlinks/copies don't auto-update when you rebuild |
| **Version confusion** | Which binary is running? The copy or the original? |
| **Debug nightmare** | "I fixed it but it's still broken" = running old copy |
| **Path pollution** | Binaries scattered across system |
| **No cleanup** | Copies left behind, consuming space |

### The Only Exception: CI/CD Release

The **only** time binaries are copied is during CI/CD release process, where they are:
1. Built fresh by CI/CD
2. Stripped (debug symbols removed)
3. Uploaded directly to release (GitHub Releases, registry, etc.)

**This is handled by CI/CD, not manual commands.**

## Release Artifacts (NON-NEGOTIABLE)

**Every GitHub release MUST include these files:**

### Server Binaries (Always)

| File | Description |
|------|-------------|
| `weather-linux-amd64` | Linux AMD64 server binary |
| `weather-linux-arm64` | Linux ARM64 server binary |
| `weather-darwin-amd64` | macOS AMD64 server binary |
| `weather-darwin-arm64` | macOS ARM64 (Apple Silicon) server binary |
| `weather-windows-amd64.exe` | Windows AMD64 server binary |
| `weather-windows-arm64.exe` | Windows ARM64 server binary |
| `weather-freebsd-amd64` | FreeBSD AMD64 server binary |
| `weather-freebsd-arm64` | FreeBSD ARM64 server binary |

### CLI Binaries (If Project Has CLI)

| File | Description |
|------|-------------|
| `weather-cli-linux-amd64` | Linux AMD64 CLI binary |
| `weather-cli-linux-arm64` | Linux ARM64 CLI binary |
| `weather-cli-darwin-amd64` | macOS AMD64 CLI binary |
| `weather-cli-darwin-arm64` | macOS ARM64 (Apple Silicon) CLI binary |
| `weather-cli-windows-amd64.exe` | Windows AMD64 CLI binary |
| `weather-cli-windows-arm64.exe` | Windows ARM64 CLI binary |
| `weather-cli-freebsd-amd64` | FreeBSD AMD64 CLI binary |
| `weather-cli-freebsd-arm64` | FreeBSD ARM64 CLI binary |

### Metadata Files (Always)

| File | Description | Example Content |
|------|-------------|-----------------|
| `version.txt` | Version string only | `1.2.3`, `20251218060432-beta`, `20251218060432` |
| `weather-{version}-source.tar.gz` | Source code archive | Excludes `.git`, `.github`, `binaries/`, `releases/` |

### version.txt Content

| Release Type | version.txt Content |
|--------------|---------------------|
| Stable | `1.2.3` (semver without `v` prefix) |
| Beta | `20251205143022-beta` (timestamp-beta) |
| Daily | `20251218060432` (timestamp only) |

## Release Types

### Stable Release

| Property | Value |
|----------|-------|
| Trigger | Git tag push with semver pattern (`v*`, `*.*.*`) |
| Version format | Semantic (`X.Y.Z`) - NUMBERS only |
| Git tag | `v1.2.3`, `v0.2.0`, or `1.2.3` (numeric versions) |
| Release name | `v{version}` (always with v: `v1.2.3`, `v0.2.0`) |
| version.txt | `{version}` (without `v`: `1.2.3`, `0.2.0`) |
| GitHub release | Yes, marked as latest |

**Examples:**
- Git tag `v1.2.3` → Release `v1.2.3`, version.txt `1.2.3`
- Git tag `0.2.0` → Release `v0.2.0`, version.txt `0.2.0`

### Beta Release

| Property | Value |
|----------|-------|
| Trigger | Push to `beta` branch |
| Version format | `{YYYYMMDDHHMMSS}-beta` - TEXT, NO `v` prefix |
| Release name | `{YYYYMMDDHHMMSS}-beta` (e.g., `20251205143022-beta`) |
| version.txt | `{YYYYMMDDHHMMSS}-beta` |
| GitHub release | Yes, marked as pre-release |

**Example:**
- Beta build → Release `20251205143022-beta`, version.txt `20251205143022-beta`
- NO `v` prefix (not a semantic version)

### Daily Build

| Property | Value |
|----------|-------|
| Trigger | Daily schedule (3am UTC) + push to main/master |
| Version format | `{YYYYMMDDHHMMSS}` - TIMESTAMP, NO `v` prefix |
| Release name | `daily` (single rolling release) |
| version.txt | `{YYYYMMDDHHMMSS}` (e.g., `20251218060432`) |
| GitHub release | Yes, **replaces previous daily** |
| Max releases | **1** (always overwrites previous daily) |

**Example:**
- Daily build → Release name `daily`, version.txt `20251218060432`
- NO `v` prefix (not a semantic version)

**Daily Build Rules:**
- Only ONE daily release exists at any time
- Each daily build **deletes and replaces** the previous `daily` release
- Prevents accumulation of thousands of releases

## Version Tag Summary (Quick Reference)

| Release Type | Git Tag | Has `v` Prefix? | Release Name | version.txt |
|--------------|---------|-----------------|--------------|-------------|
| **Stable** | `v1.2.3` or `1.2.3` | ✓ YES (numbers) | `v1.2.3` | `1.2.3` |
| **Stable** | `v0.2.0` or `0.2.0` | ✓ YES (numbers) | `v0.2.0` | `0.2.0` |
| **Beta** | (branch push) | ✗ NO (timestamp) | `20251205-beta` | `20251205-beta` |
| **Daily** | (branch push) | ✗ NO (timestamp) | `daily` | `20251218` |
| **Dev** | `dev` | ✗ NO (text) | `dev` | `dev` |

**NEVER:**
- ❌ `vdev`, `vbeta`, `vdaily` (text versions never get v)
- ❌ `v20251218` (timestamps never get v)
- ❌ `vv1.2.3` (don't double the v)

## Version Files

| File | Purpose | When Updated |
|------|---------|--------------|
| `release.txt` | Source of truth for stable version | Manual |
| `releases/version.txt` | Included in release archive | During release build |

## Release Summary

| Type | Method | Version Example | Max Releases |
|------|--------|-----------------|--------------|
| Stable | CI/CD (tag) or `make release` (local) | `1.2.3` | Unlimited |
| Beta | CI/CD only | `20251205143022-beta` | Unlimited |
| Daily | CI/CD only | `20251218060432` | **1** (rolling) |

**Note:** `make release` is for manual local releases only. All automated releases use CI/CD (GitHub Actions, Gitea Actions, or GitLab CI depending on git host).

---


# PART 27: DOCKER (NON-NEGOTIABLE)

## Docker Directory Structure (NON-NEGOTIABLE)

All Docker-related files MUST be in `docker/`:

```
docker/
├── Dockerfile              # Production Dockerfile
├── Dockerfile.dev          # Development Dockerfile (optional)
├── docker-compose.yml      # Production compose (NO debug options)
├── docker-compose.dev.yml  # Development compose (DEBUG commented)
├── docker-compose.test.yml # Test compose (DEBUG=true enabled)
└── rootfs/                 # Container filesystem overlay
    └── usr/
        └── local/
            └── bin/
                └── entrypoint.sh  # Container entrypoint (REQUIRED)
```

**Build Context:**
- Docker build context is project root (`.`)
- Dockerfile specified with `-f docker/Dockerfile`
- Multi-stage build: Go binary compiled in builder stage
- rootfs copied from `docker/rootfs/`

**Rules:**
- NEVER place Dockerfile or docker-compose.yml in project root
- ALWAYS use `docker/` directory for all Docker files
- ALWAYS use `entrypoint.sh` for container startup
- ALWAYS use multi-stage build (no pre-built binaries needed)
- rootfs structure mirrors container filesystem

## Dockerfile Requirements

| Requirement | Value |
|-------------|-------|
| Location | `docker/Dockerfile` |
| **Build type** | **Multi-stage** (builder + runtime) |
| Builder stage | `golang:alpine` |
| Runtime stage | `alpine:latest` |
| Meta labels | All OCI labels (see below) |
| Required packages | git, curl, bash, tini, tor |
| Tor handling | Installed but **binary controls** (see PART 32) |
| Binary location | `/usr/local/bin/weather` |
| Entrypoint script | `/usr/local/bin/entrypoint.sh` |
| Init system | **tini** |
| Internal port | **80** |
| **ENV MODE** | **development** (allows localhost, .local, .test, etc.) |

### Container Paths (NON-NEGOTIABLE)

**Container directory structure - organized by component:**

| Path | Purpose |
|------|---------|
| `/config/weather/` | Binary's {config_dir} (server.yml, etc.) |
| `/config/weather/security/` | Security databases (geoip, blocklists, cve, trivy) |
| `/config/weather/tor/` | Tor config (torrc) - binary owns Tor |
| `/config/{servicename}/` | External service configs (valkey, nginx, etc.) |
| `/data/weather/` | Binary's {data_dir} |
| `/data/weather/tor/` | Tor data (hidden service keys) - binary owns Tor |
| `/data/db/{dbtype}/` | Database data (postgres, valkey, mssql, etc.) |
| `/data/log/weather/` | App logs (access.log, error.log, tor.log, etc.) |
| `/data/log/{servicename}/` | Service logs (nginx, caddy, etc.) |
| `/data/backups/weather/` | Backup archives |
| `/data/{servicename}/` | External service data (nginx, apache, etc.) |
| `/usr/local/bin/weather` | Application binary |
| `/root/Dockerfile` | Build reference and backup |

**Key principle:** Binary owns Tor completely - Tor dirs are under `weather/`, not separate.

### OCI Meta Labels (Required)

All Dockerfiles MUST include these labels:

| Label | Value |
|-------|-------|
| `maintainer` | `{maintainer_name} <{maintainer_email}>` |
| `org.opencontainers.image.vendor` | `apimgr` |
| `org.opencontainers.image.authors` | `apimgr` |
| `org.opencontainers.image.title` | `weather` |
| `org.opencontainers.image.base.name` | `weather` |
| `org.opencontainers.image.description` | `Containerized version of weather` |
| `org.opencontainers.image.licenses` | License (e.g., `MIT`) |
| `org.opencontainers.image.created` | `${BUILD_DATE}` (ARG) |
| `org.opencontainers.image.version` | `${VERSION}` (ARG) |
| `org.opencontainers.image.schema-version` | `${VERSION}` (ARG) |
| `org.opencontainers.image.revision` | `${COMMIT_ID}` (ARG) |
| `org.opencontainers.image.url` | `{PLATFORM_REPO_URL}` |
| `org.opencontainers.image.source` | `{PLATFORM_REPO_URL}` |
| `org.opencontainers.image.documentation` | `{PLATFORM_REPO_URL}` |
| `org.opencontainers.image.vcs-type` | `Git` |
| `com.github.containers.toolbox` | `false` |

### Multi-Arch Manifest Annotations (NON-NEGOTIABLE)

**For multi-arch images, OCI labels MUST also be set as manifest annotations.**

Container registries (GHCR, Docker Hub, etc.) read metadata from the manifest index for multi-arch images, not from individual image configs. Without manifest annotations, registry pages show no description.

| Where | How | What For |
|-------|-----|----------|
| Dockerfile `LABEL` | Image config | Single-arch images, `docker inspect` |
| Workflow `labels:` | Image config | Per-architecture metadata |
| Workflow `annotations:` | Manifest index | Registry display, multi-arch images |

**The `manifest:` prefix tells buildx to apply annotations to the manifest list:**

```yaml
annotations: |
  manifest:org.opencontainers.image.description=My app description
  manifest:org.opencontainers.image.title=myapp
  manifest:org.opencontainers.image.version=1.0.0
```

See the docker.yml workflow for the complete list of required annotations.

### Dockerfile Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **NEVER modify ENTRYPOINT** | Always use entrypoint.sh for customization |
| **NEVER modify CMD** | Pass commands to entrypoint.sh instead |
| **STOPSIGNAL** | Use `SIGRTMIN+3` for proper shutdown |
| **ENTRYPOINT format** | `[ "tini", "-p", "SIGTERM", "--", "/usr/local/bin/entrypoint.sh" ]` |
| **HEALTHCHECK timing** | Start: 10m, Interval: 5m, Timeout: 15s |
| **Customization** | ALL customization via entrypoint.sh |

### Dockerfile Example (Multi-Stage)

**Location:** `docker/Dockerfile`

```dockerfile
# =============================================================================
# Build Stage - Compile Go binary
# =============================================================================
FROM golang:alpine AS builder

# Install git and bash (git: required for go mod download; bash: for build scripts)
RUN apk add --no-cache git bash

ARG TARGETARCH
ARG VERSION=dev
ARG BUILD_DATE
ARG COMMIT_ID

WORKDIR /build

# Copy go.mod first for layer caching
COPY go.mod go.sum ./
RUN go mod download

# Copy source and build
COPY . .
RUN CGO_ENABLED=0 GOOS=linux GOARCH=${TARGETARCH} go build \
    -ldflags "-s -w -X 'main.Version=${VERSION}' -X 'main.CommitID=${COMMIT_ID}' -X 'main.BuildDate=${BUILD_DATE}'" \
    -o /build/binary/weather src

# =============================================================================
# Runtime Stage - Minimal Alpine image
# =============================================================================
FROM alpine:latest

# ARGs for build-time values (set by docker build --build-arg)
ARG VERSION=dev
ARG BUILD_DATE
ARG COMMIT_ID
ARG LICENSE=MIT

# Static Labels
LABEL maintainer="{maintainer_name} <{maintainer_email}>" \
      org.opencontainers.image.vendor="apimgr" \
      org.opencontainers.image.authors="apimgr" \
      org.opencontainers.image.title="weather" \
      org.opencontainers.image.base.name="weather" \
      org.opencontainers.image.description="Containerized version of weather" \
      org.opencontainers.image.url="{PLATFORM_REPO_URL}" \
      org.opencontainers.image.source="{PLATFORM_REPO_URL}" \
      org.opencontainers.image.documentation="{PLATFORM_REPO_URL}" \
      org.opencontainers.image.vcs-type="Git" \
      com.github.containers.toolbox="false"

# Dynamic Labels (from ARGs)
LABEL org.opencontainers.image.licenses="${LICENSE}" \
      org.opencontainers.image.created="${BUILD_DATE}" \
      org.opencontainers.image.version="${VERSION}" \
      org.opencontainers.image.schema-version="${VERSION}" \
      org.opencontainers.image.revision="${COMMIT_ID}"

# Install required packages
# NOTE: Tor binary installed but NOT configured here - binary handles all Tor setup (see PART 32)
RUN apk add --no-cache \
    git \
    curl \
    bash \
    tini \
    tor

# NO directory creation - binary handles ALL setup based on env vars
# This allows users to override CONFIG_DIR, DATA_DIR, etc.
# Docker volume mounts auto-create mount points

# Copy binary from builder stage (multi-stage build)
COPY --from=builder /build/binary/weather /usr/local/bin/weather

# Copy BUILD-TIME overlay (entrypoint.sh) from docker/rootfs/ into image
# Note: This is docker/rootfs/ (build context), NOT runtime ./rootfs/ volumes
COPY docker/rootfs/ /

# Copy Dockerfile to image (for reference and backup)
COPY docker/Dockerfile /root/Dockerfile

# Make all binaries/scripts in /usr/local/bin executable (755)
RUN chmod 755 /usr/local/bin/*

# Set environment
# Note: Tor available (binary installed) but server binary controls Tor startup (see PART 32)
ENV MODE=development \
    TZ=America/New_York

# Expose internal port (always 80)
EXPOSE 80

# Stop signal for graceful shutdown
STOPSIGNAL SIGRTMIN+3

# Health check (long start period for services that need initialization)
HEALTHCHECK --start-period=10m --interval=5m --timeout=15s --retries=3 \
    CMD /usr/local/bin/weather --status || exit 1

# Use tini as init with signal propagation
# -p SIGTERM: propagate SIGTERM to child processes
ENTRYPOINT [ "tini", "-p", "SIGTERM", "--", "/usr/local/bin/entrypoint.sh" ]
```

**Multi-Stage Build Benefits:**
- Self-contained - no pre-built binaries required
- Layer caching - `go.mod` copied first for faster rebuilds
- `TARGETARCH` automatically set by docker buildx (`amd64` or `arm64`)
- Works perfectly with `docker buildx --platform linux/amd64,linux/arm64`

**Notes:**
- **NEVER modify ENTRYPOINT or CMD** - all customization goes in `entrypoint.sh`
- `STOPSIGNAL SIGRTMIN+3` allows entrypoint.sh to handle shutdown gracefully
- `tini -p SIGTERM` propagates SIGTERM to all child processes
- docker.yml workflow needs NO binary build step - just docker buildx

### Entrypoint Script (REQUIRED)

**Location:** `docker/rootfs/usr/local/bin/entrypoint.sh`

**Entrypoint is MINIMAL.** It only does:
1. Set environment variables/flags
2. Start other services if needed (supervisord, etc.)
3. Start server binary
4. Handle signals for graceful shutdown

**Binary handles EVERYTHING else:** directories, permissions, user/group, Tor, etc.

```bash
#!/usr/bin/env bash
set -e

# =============================================================================
# Container Entrypoint Script - MINIMAL
# Only: set env, start services, start binary, handle signals
# Binary handles: directories, permissions, user/group, Tor, etc.
# =============================================================================

APP_NAME="weather"
APP_BIN="/usr/local/bin/${APP_NAME}"

# Export environment defaults (binary reads these)
export TZ="${TZ:-America/New_York}"
export CONFIG_DIR="${CONFIG_DIR:-/config/${APP_NAME}}"
export DATA_DIR="${DATA_DIR:-/data/${APP_NAME}}"

# Track background PIDs for cleanup
declare -a PIDS=()

log() { echo "[entrypoint] $(date '+%Y-%m-%d %H:%M:%S') $*"; }

# Signal handling for graceful shutdown
cleanup() {
    log "Shutdown signal received..."
    for ((i=${#PIDS[@]}-1; i>=0; i--)); do
        kill -TERM "${PIDS[i]}" 2>/dev/null || true
    done
    wait
    exit 0
}
trap cleanup SIGTERM SIGINT SIGQUIT

# =============================================================================
# Start services (add supervisord, etc. here if needed)
# =============================================================================
# Example: Start supervisord for multi-service containers
# if [ -f /etc/supervisord.conf ]; then
#     /usr/bin/supervisord -c /etc/supervisord.conf &
#     PIDS+=($!)
# fi

# =============================================================================
# Start main application
# =============================================================================
log "Starting ${APP_NAME}..."

# Build flags from environment
FLAGS="--address ${ADDRESS:-0.0.0.0} --port ${PORT:-80}"
[ "${DEBUG:-false}" = "true" ] && FLAGS="$FLAGS --debug"

# Start binary (binary handles ALL setup: dirs, perms, user/group, Tor, etc.)
exec $APP_BIN $FLAGS "$@"
```

### Entrypoint Features

| Feature | Description |
|---------|-------------|
| **Environment defaults** | Sets `TZ`, `CONFIG_DIR`, `DATA_DIR` |
| **Flag building** | Constructs CLI flags from env vars (`ADDRESS`, `PORT`, `DEBUG`) |
| **Signal handling** | Graceful shutdown on SIGTERM/SIGINT/SIGQUIT |
| **Service startup** | Optional: start supervisord or other services before binary |
| **Binary exec** | Runs server binary with `exec` (replaces shell) |

**Entrypoint does NOT:**
- Create directories (binary does this)
- Set permissions (binary does this)
- Create user/group (binary does this)
- Manage Tor (binary does this - see PART 32)
- Any runtime initialization (binary does this)

**Server binary handles EVERYTHING** - entrypoint just sets env and starts it.

### Why SIGRTMIN+3?

| Reason | Description |
|--------|-------------|
| **Systemd compatibility** | SIGRTMIN+3 is used by systemd for clean shutdown |
| **Container orchestration** | Works well with Docker, Podman, Kubernetes |
| **Graceful multi-process** | Allows entrypoint.sh to coordinate shutdown of all services |
| **Avoids race conditions** | Gives time for proper cleanup before forced termination |

### Environment Variables (Entrypoint)

| Variable | Default | Description |
|----------|---------|-------------|
| `TZ` | `America/New_York` | Timezone for app and scheduler |
| `MODE` | `development` | `production` (strict) or `development` (relaxed) |
| `DEBUG` | `false` | Enable ALL debug features (pprof, expvar, detailed logging) |
| `ADDRESS` | `0.0.0.0` | Listen address |
| `PORT` | `80` | Listen port (update docker-compose ports: to match) |

**MODE vs DEBUG:**
- `MODE=development`: Relaxed security, verbose logging, no caching (sensible for local dev)
- `MODE=production`: Strict security, minimal logging, caching enabled
- `DEBUG=true`: Enables debug endpoints (`/debug/*`), regardless of MODE

**Note:** Boolean env vars accept all truthy/falsy values (see Boolean Values table). Examples: `DEBUG=yes`, `DEBUG=enable`, `DEBUG=1`, `DEBUG=oui`.

**Note:** Tor is auto-enabled if the `tor` binary is installed. No `ENABLE_TOR` flag needed. Docker image always includes Tor.

## Docker Compose Requirements (NON-NEGOTIABLE)

**Location:** `docker/docker-compose.yml`

| Requirement | Value |
|-------------|-------|
| `build:` | **NEVER include** |
| `version:` | **NEVER include** |
| `name:` | `weather` (top-level) |
| `container_name:` | `weather-{servicename}` |
| Main service name | `server` (not `app`) |
| `pull_policy:` | `always` |
| `restart:` | `always` |
| `x-logging:` | Anchor for consistent logging (see below) |
| Network | Custom `weather` with `external: false` |
| Environment variables | **Hardcode with sane defaults** (NEVER use .env files) |
| **environment: MODE** | **production** (strict host validation) |

### Docker Compose Structure (NON-NEGOTIABLE)

```yaml
# weather - {brief description}
# nginx proxy address - http://172.17.0.1:{port}

name: weather

x-logging: &default-logging
  options:
    max-size: '5m'
    max-file: '1'
  driver: json-file

services:
  server:
    image: {PLATFORM_CONTAINER_REGISTRY}/apimgr/weather:latest
    container_name: weather-server
    hostname: ${BASE_HOST_NAME:-$HOSTNAME}
    restart: always
    pull_policy: always
    logging: *default-logging
    environment:
      - MODE=production
      - PORT=80
      - DEBUG=false
      - TZ=${TZ:-America/New_York}
    volumes:
      - './rootfs/config:/config:z'
      - './rootfs/data:/data:z'
    ports:
      - '172.17.0.1:64580:80'
    healthcheck:
      test: /usr/local/bin/weather --status
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 90s
    networks:
      - weather

networks:
  weather:
    name: weather
    external: false
```

### Docker Compose Field Reference

| Field | Value | Description |
|-------|-------|-------------|
| `name:` | `weather` | Top-level compose project name |
| `container_name:` | `weather-{servicename}` | e.g., `jokes-server`, `jokes-db`, `jokes-cache` |
| Main service | `server` | Primary application service (not `app`) |
| `hostname:` | `${BASE_HOST_NAME:-$HOSTNAME}` | Uses env or system hostname |
| `restart:` | `always` | Always restart on failure |
| `pull_policy:` | `always` | Always pull latest image |
| `logging:` | `*default-logging` | Use the logging anchor |
| `networks:` | `weather` | Isolated network per project |

### Logging Anchor (NON-NEGOTIABLE)

**Every docker-compose.yml MUST include the x-logging anchor:**

```yaml
x-logging: &default-logging
  options:
    max-size: '5m'    # Max 5MB per log file
    max-file: '1'     # Keep only 1 log file
  driver: json-file   # JSON format for parsing
```

**Every service MUST use the anchor:**
```yaml
services:
  server:
    logging: *default-logging
```

### Multi-Service Example

```yaml
# weather - with Redis cache
# nginx proxy address - http://172.17.0.1:64580

name: weather

x-logging: &default-logging
  options:
    max-size: '5m'
    max-file: '1'
  driver: json-file

services:
  server:
    image: ghcr.io/apimgr/weather:latest
    container_name: weather-server
    hostname: ${BASE_HOST_NAME:-$HOSTNAME}
    restart: always
    pull_policy: always
    logging: *default-logging
    environment:
      - MODE=production
      - PORT=80
      - DEBUG=false
      - TZ=${TZ:-America/New_York}
    volumes:
      - './rootfs/config:/config:z'
      - './rootfs/data:/data:z'
    ports:
      - '172.17.0.1:64580:80'
    healthcheck:
      test: /usr/local/bin/weather --status
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 90s
    depends_on:
      cache:
        condition: service_healthy
    networks:
      - weather

  cache:
    image: redis:alpine
    container_name: weather-cache
    hostname: ${BASE_HOST_NAME:-$HOSTNAME}
    restart: always
    pull_policy: always
    logging: *default-logging
    volumes:
      - './rootfs/data/redis:/data:z'
    healthcheck:
      test: redis-cli ping || exit 1
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    networks:
      - weather

networks:
  weather:
    name: weather
    external: false
```

### Service Naming Convention

| Service Type | Service Name | Container Name Example |
|--------------|--------------|------------------------|
| Main application | `server` | `pastebin-server` |
| All-in-one | `server` | `quotesvc-server` |
| Database | `db` | `linktree-db` |
| Cache (Redis/Valkey) | `cache` | `echoip-cache` |
| Search (Meilisearch) | `search` | `gitmsg-search` |
| Queue (RabbitMQ) | `queue` | `notifier-queue` |
| Proxy (Nginx) | `proxy` | `gateway-proxy` |

### All-in-One vs Multi-Service (NON-NEGOTIABLE)

**Choose based on project complexity:**

| Type | When to Use | Services in Container |
|------|-------------|----------------------|
| **All-in-One** | Simple projects, single binary | App + embedded DB + optional cache |
| **Multi-Service** | Complex projects, scaling needs | Separate containers per service |

**All-in-One Container:**

⚠️ **Not best practice, but easy to deploy.** Trade-off: simplicity over scalability.

- Single container runs everything
- Uses SQLite (embedded) or embedded key-value store
- Valkey/Redis runs inside container via supervisor or embedded
- Service name: `server`
- Container name: `weather-server`
- Simpler deployment, single image
- **Trade-offs:** No horizontal scaling, single point of failure, harder to debug

**All-in-One Files:**

| File | Purpose |
|------|---------|
| `docker/Dockerfile.aio` | All-in-one Dockerfile (debian-based) |
| `docker/all-in-one.yml` | All-in-one docker-compose |
| `docker/Dockerfile` | Standard Dockerfile (alpine-based, app only) |
| `docker/docker-compose.yml` | Standard docker-compose (multi-service) |

**All-in-One docker-compose (`docker/all-in-one.yml`):**

```yaml
# weather - All-in-One (app + embedded DB)
# nginx proxy address - http://172.17.0.1:64580
# Usage: docker compose -f all-in-one.yml up -d

name: weather

x-logging: &default-logging
  options:
    max-size: '5m'
    max-file: '1'
  driver: json-file

services:
  server:
    image: ghcr.io/apimgr/weather-aio:latest
    container_name: weather-server
    hostname: ${BASE_HOST_NAME:-$HOSTNAME}
    restart: always
    pull_policy: always
    logging: *default-logging
    environment:
      - MODE=production
      - PORT=80
      - DEBUG=false
      - TZ=${TZ:-America/New_York}
    volumes:
      - './rootfs/config:/config:z'
      - './rootfs/data:/data:z'
    ports:
      - '172.17.0.1:64580:80'
    healthcheck:
      test: /usr/local/bin/weather --status
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 90s
    networks:
      - weather

networks:
  weather:
    name: weather
    external: false
```

## All-in-One Database and Cache

**Database:** PostgreSQL (preferred for AIO)
- Better defaults out of the box
- Strong ACID compliance
- Superior handling of concurrent connections
- Built-in connection pooling

**Cache:** Valkey (Redis-compatible)
- Low memory footprint
- Persistence via AOF
- Unix socket for local communication (faster than TCP)

**Port Exposure:** Only port 80 (server) is exposed. Database (5432) and cache (6379) ports are internal-only - no external access.

| Service | Internal Port | External Port | Access |
|---------|---------------|---------------|--------|
| App | 80 | 80 | Exposed |
| PostgreSQL | 5432 | - | Internal only |
| Valkey | 6379 (or socket) | - | Internal only |
| Tor | 9050 | - | Internal only |

**All-in-One Dockerfile (`docker/Dockerfile.aio`):**

```dockerfile
# All-in-One Dockerfile - includes app + postgresql + valkey + tor
# Base: debian:latest (stable, broad compatibility)
# Image name: {PLATFORM_CONTAINER_REGISTRY}/apimgr/weather-aio:latest
# PORTS: Only 80 exposed (db/cache are internal-only)

FROM debian:latest

LABEL org.opencontainers.image.source="{PLATFORM_REPO_URL}"
LABEL org.opencontainers.image.description="weather - all-in-one container"
LABEL org.opencontainers.image.licenses="MIT"

# Install dependencies (PostgreSQL + Valkey + Tor + Supervisor)
RUN apt-get update && apt-get install -y --no-install-recommends \
    ca-certificates \
    curl \
    postgresql \
    postgresql-contrib \
    valkey \
    supervisor \
    tor \
    tzdata \
    && rm -rf /var/lib/apt/lists/*

# Create directories - organized by component
RUN mkdir -p /config/weather /config/weather/security /config/weather/tor \
             /config/valkey /config/postgres \
             /data/weather /data/weather/tor \
             /data/db/postgres /data/db/valkey \
             /data/log/weather /data/backups/weather \
             /run/postgresql /run/valkey \
    && chown -R postgres:postgres /data/db/postgres /run/postgresql

# Copy configs and entrypoint
COPY docker/rootfs/ /

# Copy application binary from builder or pre-built
COPY weather /usr/local/bin/
RUN chmod +x /usr/local/bin/weather /usr/local/bin/entrypoint.sh

# Default environment
ENV MODE=production \
    PORT=80 \
    DEBUG=false \
    TZ=America/New_York \
    PGDATA=/data/db \
    DB_HOST=/run/postgresql \
    DB_NAME=weather \
    DB_USER=weather \
    VALKEY_SOCKET=/run/valkey/valkey.sock

# Only expose app port - db/cache are internal
EXPOSE 80

HEALTHCHECK --interval=10s --timeout=5s --start-period=90s --retries=3 \
    CMD timeout 10s bash -c ':> /dev/tcp/127.0.0.1/80' || exit 1

ENTRYPOINT ["/usr/local/bin/entrypoint.sh"]
```

**All-in-One supervisor config (`docker/rootfs/etc/supervisor/conf.d/services.conf`):**

```ini
[supervisord]
nodaemon=true
logfile=/data/log/supervisord.log
pidfile=/var/run/supervisord.pid

[program:postgresql]
command=/usr/lib/postgresql/15/bin/postgres -D /data/db
user=postgres
autostart=true
autorestart=true
priority=10
stdout_logfile=/data/log/postgresql.log
stderr_logfile=/data/log/postgresql.log

[program:valkey]
command=/usr/bin/valkey-server /etc/valkey/valkey-aio.conf
autostart=true
autorestart=true
priority=20
stdout_logfile=/data/log/valkey.log
stderr_logfile=/data/log/valkey.log

[program:tor]
command=/usr/bin/tor -f /etc/tor/torrc
autostart=%(ENV_TOR_ENABLED)s
autorestart=true
priority=30
stdout_logfile=/data/log/tor.log
stderr_logfile=/data/log/tor.log

[program:app]
command=/usr/local/bin/weather
autostart=true
autorestart=true
priority=100
stdout_logfile=/data/log/app.log
stderr_logfile=/data/log/app.log
```

**All-in-One PostgreSQL config (`docker/rootfs/etc/postgresql/postgresql-aio.conf`):**

```ini
# PostgreSQL configuration optimized for AIO containers
# Low memory footprint, single-container deployment

# Connection settings (unix socket only - no TCP)
listen_addresses = ''
unix_socket_directories = '/run/postgresql'
max_connections = 50

# Memory (conservative for AIO - adjust based on container limits)
shared_buffers = 64MB
effective_cache_size = 128MB
work_mem = 4MB
maintenance_work_mem = 32MB

# WAL settings (balanced durability/performance)
wal_level = replica
max_wal_size = 256MB
min_wal_size = 64MB
checkpoint_completion_target = 0.9

# Query planner
random_page_cost = 1.1
effective_io_concurrency = 200

# Logging
log_destination = 'stderr'
logging_collector = off
log_min_duration_statement = 1000
log_line_prefix = '%t [%p]: '

# Autovacuum (lighter for AIO)
autovacuum_max_workers = 2
autovacuum_naptime = 60s

# Disable features not needed for AIO
ssl = off
```

**All-in-One Valkey config (`docker/rootfs/etc/valkey/valkey-aio.conf`):**

```ini
# Valkey configuration optimized for AIO containers
# Low memory, unix socket, persistent

# Network (unix socket only - no TCP, faster + more secure)
port 0
unixsocket /run/valkey/valkey.sock
unixsocketperm 770

# Memory (conservative for AIO)
maxmemory 64mb
maxmemory-policy allkeys-lru

# Persistence (AOF for durability)
dir /data/cache
appendonly yes
appendfsync everysec
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 32mb

# Disable RDB (AOF is sufficient for AIO)
save ""

# Performance
tcp-keepalive 300
timeout 0

# Logging
loglevel notice
logfile ""

# Security (no password needed - socket only, container internal)
protected-mode no
```

**All-in-One entrypoint.sh (`docker/rootfs/usr/local/bin/entrypoint.sh`):**

```bash
#!/bin/bash
set -e

# Set timezone
if [ -n "$TZ" ]; then
    ln -snf /usr/share/zoneinfo/$TZ /etc/localtime
    echo $TZ > /etc/timezone
fi

# Setup directories for external services (PostgreSQL, Valkey)
# NOTE: App/Tor directories are created by the server binary, not entrypoint
# Database dirs: /data/db/{dbtype}/
mkdir -p /data/db/postgres /data/db/valkey /run/postgresql /run/valkey
chown -R postgres:postgres /data/db/postgres /run/postgresql
chmod 700 /data/db/postgres
chmod 755 /run/valkey

# Initialize PostgreSQL if not already done
if [ ! -f /data/db/postgres/PG_VERSION ]; then
    echo "Initializing PostgreSQL database..."
    su - postgres -c "/usr/lib/postgresql/15/bin/initdb -D /data/db/postgres"

    # Copy optimized config
    cp /etc/postgresql/postgresql-aio.conf /data/db/postgres/postgresql.conf

    # Start PostgreSQL temporarily to create database and user
    su - postgres -c "/usr/lib/postgresql/15/bin/pg_ctl -D /data/db/postgres -l /data/log/postgres/init.log start"
    sleep 3

    # Create application database and user
    su - postgres -c "psql -c \"CREATE USER ${DB_USER:-weather} WITH PASSWORD '${DB_PASSWORD:-weather}';\""
    su - postgres -c "psql -c \"CREATE DATABASE ${DB_NAME:-weather} OWNER ${DB_USER:-weather};\""
    su - postgres -c "psql -c \"GRANT ALL PRIVILEGES ON DATABASE ${DB_NAME:-weather} TO ${DB_USER:-weather};\""

    # Stop PostgreSQL (supervisor will start it)
    su - postgres -c "/usr/lib/postgresql/15/bin/pg_ctl -D /data/db/postgres stop"
fi

# Set Tor enabled flag for supervisor
export TOR_ENABLED="${TOR_ENABLED:-false}"

# Start supervisor (manages postgresql + valkey + tor + app)
exec /usr/bin/supervisord -c /etc/supervisor/supervisord.conf
```

**Image Names:**

| Image | Dockerfile | Description |
|-------|------------|-------------|
| `{name}:latest` | `Dockerfile` | Standard image (app only, alpine) |
| `{name}-aio:latest` | `Dockerfile.aio` | All-in-one (app + postgresql + valkey + tor, debian) |

**AIO Environment Variables:**

| Variable | Default | Description |
|----------|---------|-------------|
| `MODE` | `production` | Application mode |
| `PORT` | `80` | Application port |
| `DEBUG` | `false` | Debug mode |
| `TZ` | `America/New_York` | Timezone |
| `DB_NAME` | `weather` | PostgreSQL database name |
| `DB_USER` | `weather` | PostgreSQL username |
| `DB_PASSWORD` | `weather` | PostgreSQL password |
| `TOR_ENABLED` | `false` | Enable Tor hidden service |

**App Connection Strings (internal):**

```go
// PostgreSQL via unix socket (faster than TCP)
dbURL := "postgres:///projectname?host=/run/postgresql"

// Valkey via unix socket
valkeyURL := "unix:///run/valkey/valkey.sock"
```

**Build Commands:**

```bash
# Standard image (context is project root)
docker build -t {PLATFORM_CONTAINER_REGISTRY}/apimgr/weather:latest -f docker/Dockerfile .

# All-in-one image (context is project root)
docker build -t {PLATFORM_CONTAINER_REGISTRY}/apimgr/weather-aio:latest -f docker/Dockerfile.aio .
```

**When to use All-in-One:**
- Simple APIs with SQLite storage
- Projects that don't need horizontal scaling
- Minimal infrastructure requirements
- Self-contained deployment (single `docker pull && docker run`)

**When to use Multi-Service:**
- Need separate database (PostgreSQL, MySQL)
- Cache needs dedicated resources
- Horizontal scaling of specific components
- Microservice architecture

### Two `rootfs/` Contexts (CRITICAL - Understand This)

**There are TWO completely different `rootfs/` directories - do not confuse them:**

| Context | Location | Purpose | In Repo? |
|---------|----------|---------|----------|
| **Build-time** | `docker/rootfs/` | Container overlay (entrypoint.sh) | YES |
| **Runtime** | `./rootfs/` in docker-compose | Volume mounts (config, data) | NEVER |

**Build-time `docker/rootfs/`** (in repo):
```
docker/
├── Dockerfile           # COPY docker/rootfs/ / ← copies into container image
├── docker-compose.yml
└── rootfs/              # BUILD overlay - committed to git
    └── usr/local/bin/
        └── entrypoint.sh
```

**Runtime `./rootfs/`** (never in repo):
```
# Production (server admin's choice of location):
/path/to/deployment/
├── docker-compose.yml   # copied from repo
└── rootfs/              # RUNTIME - created on server
    ├── config/
    └── data/

# Development (temp dir):
$TEMP_DIR/
├── docker-compose.yml   # copied from repo
└── rootfs/              # RUNTIME - created in temp
    ├── config/
    └── data/
```

**Why same name works:** The `./rootfs/` path in docker-compose.yml is relative to where docker-compose runs from, not where it lives in the repo. Dockerfile's `COPY docker/rootfs/ /` uses build context (`.` project root).

### Volume Paths (Host Side)

**Docker-compose.yml uses only 2 volumes:**

| Volume Mount | Purpose |
|--------------|---------|
| `./rootfs/config:/config:z` | Configuration files (organized by component) |
| `./rootfs/data:/data:z` | All persistent data (organized by component) |

**Container internal structure (organized by component):**

| Container Path | Contents |
|----------------|----------|
| `/config/weather/` | Binary's {config_dir} - server.yml, etc. |
| `/config/weather/security/` | TLS certs, keys, security DBs |
| `/config/weather/tor/` | Tor config (torrc) - binary owns Tor |
| `/config/{servicename}/` | External service configs (valkey, nginx, etc.) |
| `/data/weather/` | Binary's {data_dir} |
| `/data/weather/tor/` | Tor data (hidden service keys) - binary owns Tor |
| `/data/db/{dbtype}/` | Database data (postgres, valkey, sqlite, etc.) |
| `/data/log/weather/` | App logs (access.log, error.log, tor.log) |
| `/data/log/{servicename}/` | Service logs (nginx, caddy, etc.) |
| `/data/backups/weather/` | Backup files |
| `/data/{servicename}/` | External service data (nginx, apache, etc.) |

**Rules:**
- Production volumes use `:z` suffix (SELinux shared label)
- Development volumes omit `:z` (not needed in temp dir)
- `docker/rootfs/` is for container overlay (entrypoint.sh) - NOT for runtime volumes
- NEVER create runtime `rootfs/` in the project repo

### Running Docker Compose (NON-NEGOTIABLE)

**NEVER run docker compose in the project directory.**

**Always use temp directory workflow:**
1. Create unique temp dir with apimgr prefix
2. Copy `docker/docker-compose.yml` to temp dir
3. Create `rootfs/` structure in temp dir
4. Run docker compose from temp dir
5. Data lives in temp dir, isolated from project

```bash
# Setup (uses OS temp dir: {ostempdir}/apimgr/weather-XXXXXX/)
# Set PROJECT_ROOT to your actual project location
PROJECT_ROOT="$(git rev-parse --show-toplevel)"  # Use git top-level
# Or use absolute path: PROJECT_ROOT="/path/to/your/project"
mkdir -p "${TMPDIR:-/tmp}/${PROJECTORG}"
TEMP_DIR=$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}/$WEATHER-XXXXXX")
mkdir -p "$TEMP_DIR/rootfs/config" "$TEMP_DIR/rootfs/data"

# Copy docker-compose.yml
cp "$PROJECT_ROOT/docker/docker-compose.yml" "$TEMP_DIR/"

# Run from temp dir - ./rootfs/ resolves to $TEMP_DIR/rootfs/
cd "$TEMP_DIR" && docker compose up -d

# Stop and cleanup
cd "$TEMP_DIR" && docker compose down
rm -rf "$TEMP_DIR"
```

**Example paths:**
```
/tmp/netutils/pastebin-aB3xY9/      # Example: pastebin project
/tmp/apimgr/jokes-k9mN2p/           # Example: jokes project
/tmp/casapps/linktree-Qw5rT1/       # Example: different org
```

**Why temp dir:**
- Project directory stays clean
- Data isolated from source code
- Multiple instances possible
- Safe cleanup

**NEVER:**
- Run docker compose in project directory
- Run docker compose with `--project-directory` pointing to project root
- Mount volumes to `{project_root}/rootfs/`

### Port Mapping (NON-NEGOTIABLE)

| Mode | Format | Example |
|------|--------|---------|
| Development | `{randomport}:80` | `64580:80` |
| Production | `172.17.0.1:{randomport}:80` | `172.17.0.1:64580:80` |

**Rules:**
- Internal port defaults to `80` (override with `PORT` env var)
- External port is random unused port in `64xxx` range
- Production binds to Docker bridge IP (`172.17.0.1`) for security
- Development binds to all interfaces for easier access
- If changing internal port, update docker-compose port mapping to match

### Environment Variables (NON-NEGOTIABLE)

**ALL environment variables MUST be hardcoded with sane defaults. NEVER require .env files.**

| Rule | Description |
|------|-------------|
| **NEVER** | Use `${VAR}` or `${VAR:-default}` syntax requiring .env |
| **NEVER** | Create `.env`, `.env.example`, `.env.sample` files |
| **ALWAYS** | Hardcode values directly in docker-compose.yml |
| **ALWAYS** | Use sane, working defaults |

**Why hardcoded defaults?**
- Works out of the box - no setup required
- No confusion about required variables
- No outdated .env.example files
- Users can override by editing docker-compose.yml directly

### Docker Compose (Development)

**Location:** `docker/docker-compose.dev.yml`

**Development mode with optional debug. MUST use temp directory workflow.**

```yaml
name: weather-dev

services:
  weather:
    image: {PLATFORM_CONTAINER_REGISTRY}/apimgr/weather:latest
    container_name: weather-dev
    restart: unless-stopped
    environment:
      # Development: relaxed security, verbose logging, no caching
      # Does NOT enable debug endpoints - uncomment DEBUG=true for that
      - MODE=development
      - TZ=America/New_York
      # DEBUG: Uncomment to enable pprof, expvar, detailed request logging
      # - DEBUG=true
    ports:
      # Development: accessible from all interfaces
      - "64580:80"
    volumes:
      # TEMP DIR WORKFLOW: ./rootfs/ resolves to $TEMP_DIR/rootfs/
      # NEVER run from project directory - always use temp dir workflow
      - ./rootfs/config:/config
      - ./rootfs/data:/data
    networks:
      - weather-dev

networks:
  weather-dev:
    name: weather-dev
    external: false
```

**Run:**
```bash
mkdir -p "${TMPDIR:-/tmp}/apimgr"
TEMP_DIR=$(mktemp -d "${TMPDIR:-/tmp}/apimgr/weather-XXXXXX")
mkdir -p "$TEMP_DIR/rootfs/config" "$TEMP_DIR/rootfs/data"
cp docker/docker-compose.dev.yml "$TEMP_DIR/docker-compose.yml"
cd "$TEMP_DIR" && docker compose up -d
```

### Docker Compose (Production)

**Location:** `docker/docker-compose.yml`

**Production has NO debug options. Debug must be set via CLI if needed.**

```yaml
name: weather

services:
  weather:
    image: {PLATFORM_CONTAINER_REGISTRY}/apimgr/weather:latest
    container_name: weather
    restart: unless-stopped
    environment:
      # Production: strict security, minimal logging, caching enabled
      # NO debug options - debug must be explicitly set via CLI if needed
      - MODE=production
      - TZ=America/New_York
      # DOMAIN (optional - auto-detects from reverse proxy headers)
      # - DOMAIN=myapp.com,www.myapp.com
      # SMTP (optional - autodetects if not set)
      # - SMTP_HOST=smtp.example.com
      # - SMTP_PORT=587
      # - SMTP_USERNAME=user
      # - SMTP_PASSWORD=pass
    ports:
      # Production: bound to Docker bridge only (reverse proxy handles external)
      - "172.17.0.1:64580:80"
    volumes:
      # TEMP DIR WORKFLOW: ./rootfs/ resolves to $TEMP_DIR/rootfs/
      # NEVER run from project directory - always use temp dir workflow
      - ./rootfs/config:/config:z
      - ./rootfs/data:/data:z
    networks:
      - weather

networks:
  weather:
    name: weather
    external: false
```

**Run:**
```bash
mkdir -p "${TMPDIR:-/tmp}/apimgr"
TEMP_DIR=$(mktemp -d "${TMPDIR:-/tmp}/apimgr/weather-XXXXXX")
mkdir -p "$TEMP_DIR/rootfs/config" "$TEMP_DIR/rootfs/data"
cp docker/docker-compose.yml "$TEMP_DIR/"
cd "$TEMP_DIR" && docker compose up -d
```

### Docker Compose (Test)

**Location:** `docker/docker-compose.test.yml`

**For running tests in CI/CD or locally. Debug enabled for test visibility. MUST use temp directory workflow.**

```yaml
name: weather-test

services:
  weather:
    image: {PLATFORM_CONTAINER_REGISTRY}/apimgr/weather:latest
    container_name: weather-test
    restart: "no"
    environment:
      - MODE=development
      - DEBUG=true
      - TZ=America/New_York
    ports:
      - "64581:80"
    volumes:
      # TEMP DIR WORKFLOW: ./rootfs/ resolves to $TEMP_DIR/rootfs/
      # NEVER run from project directory - always use temp dir workflow
      - ./rootfs/config:/config
      - ./rootfs/data:/data
    networks:
      - weather-test

networks:
  weather-test:
    name: weather-test
    external: false
```

**Run:**
```bash
mkdir -p "${TMPDIR:-/tmp}/apimgr"
TEMP_DIR=$(mktemp -d "${TMPDIR:-/tmp}/apimgr/weather-XXXXXX")
mkdir -p "$TEMP_DIR/rootfs/config" "$TEMP_DIR/rootfs/data"
cp docker/docker-compose.test.yml "$TEMP_DIR/docker-compose.yml"
cd "$TEMP_DIR" && docker compose up --abort-on-container-exit
rm -rf "$TEMP_DIR"  # Cleanup after tests
```

### Docker Compose with Database Example

**Location:** `docker/docker-compose.yml`

```yaml
name: weather

services:
  weather:
    image: {PLATFORM_CONTAINER_REGISTRY}/apimgr/weather:latest
    container_name: weather
    restart: unless-stopped
    depends_on:
      - postgres
    environment:
      # Tor auto-enabled (tor binary installed in image)
      - MODE=production
      - TZ=America/New_York
      # DOMAIN (optional - containers behind reverse proxy auto-detect from headers)
      # Only set if NOT behind reverse proxy, comma-separated list supported
      # - DOMAIN=myapp.com,www.myapp.com,api.myapp.com
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=weather
      - DB_USER=weather
      - DB_PASS=weather
    ports:
      # Production: bound to Docker bridge only (reverse proxy handles external)
      - "172.17.0.1:64580:80"
    volumes:
      - ./rootfs/config:/config:z
      - ./rootfs/data:/data:z
    networks:
      - weather

  postgres:
    image: postgres:alpine
    container_name: weather-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=weather
      - POSTGRES_USER=weather
      - POSTGRES_PASSWORD=weather
      - TZ=America/New_York
    volumes:
      - ./rootfs/data/db/postgres:/var/lib/postgresql/data:z
    networks:
      - weather

networks:
  weather:
    name: weather
    external: false
```

**Run:** Use temp directory workflow (see "Running Docker Compose" section above).

## Container Configuration

| Setting | Value |
|---------|-------|
| Internal port | **80** (always) |
| Config dir | `/config/weather/` (binary's {config_dir}) |
| Security dir | `/config/weather/security/` |
| Tor config dir | `/config/weather/tor/` (binary owns Tor) |
| Data dir | `/data/weather/` (binary's {data_dir}) |
| Tor data dir | `/data/weather/tor/` (binary owns Tor) |
| Database dir | `/data/db/{dbtype}/` (postgres, valkey, sqlite) |
| Log dir | `/data/log/weather/` |
| Backup dir | `/data/backups/weather/` |
| Binary | `/usr/local/bin/weather` |
| HEALTHCHECK | `{binary} --status` |

**Path Mapping (Container vs Host):**

| Container Path | Host Path | Purpose |
|----------------|-----------|---------|
| `/config` | `./rootfs/config` | Configuration root (organized by component) |
| `/data` | `./rootfs/data` | Data root (organized by component) |
| `/config/weather/` | `./rootfs/config/weather/` | Binary's config |
| `/data/weather/` | `./rootfs/data/weather/` | Binary's data |
| `/data/db/` | `./rootfs/data/db/` | Database data |
| `/data/log/` | `./rootfs/data/log/` | Log files |

## Tor in Container

**Tor is included in the container image and auto-enabled (no configuration needed).**

| Behavior | Description |
|----------|-------------|
| Auto-detection | Tor starts automatically if `tor` binary is installed |
| Always enabled | Docker image includes `tor`, so always enabled in containers |
| Data persistence | Tor keys in `/data/weather/tor/site/` (survives restart) |
| .onion address | Persists across container restarts via volume mount |
| Binary owns Tor | Tor dirs under `weather/`, not separate service |

## Container Detection

**Assume running in container if tini init system (PID 1) is detected.**

| When in Container | Behavior |
|-------------------|----------|
| Show setup token | On first run - one-time setup token displayed in console for `/admin` access |
| Defaults | Use container-appropriate defaults |
| Logging | Log to stdout/stderr (captured by container runtime) |
| Tor | Application manages Tor process internally |

## Image Tags (NON-NEGOTIABLE)

### Release Tags (Production)

| Tag | Description | Example |
|-----|-------------|---------|
| `{PLATFORM_CONTAINER_REGISTRY}/apimgr/weather:latest` | Latest stable release | `ghcr.io/myorg/myapp:latest` |
| `{PLATFORM_CONTAINER_REGISTRY}/apimgr/weather:{version}` | Specific version | `ghcr.io/myorg/myapp:1.2.3` |
| `{PLATFORM_CONTAINER_REGISTRY}/apimgr/weather:{YYMM}` | Year/month tag | `ghcr.io/myorg/myapp:2512` |
| `{PLATFORM_CONTAINER_REGISTRY}/apimgr/weather:{commit}` | Git commit (7 char) | `ghcr.io/myorg/myapp:abc1234` |

### Development Tags (Local)

| Tag | Description | Example |
|-----|-------------|---------|
| `weather:dev` | Local development build | `myapp:dev` |
| `weather:test` | Local test build | `myapp:test` |

### Registry

| Environment | Registry |
|-------------|----------|
| Release | Platform container registry (ghcr.io, registry.gitlab.com, etc.) |
| Development | Local Docker daemon only |

### Tag Rules

1. **Release builds** MUST push to `{PLATFORM_CONTAINER_REGISTRY}/apimgr/weather`
2. **Development builds** MUST use local-only tags (no registry prefix)
3. **NEVER push `:dev` or `:test` tags to production registry**
4. All release images built for `linux/amd64` AND `linux/arm64`

---


# PART 28: CI/CD WORKFLOWS (NON-NEGOTIABLE)

**All projects MUST have CI/CD workflows appropriate for their git hosting platform.**

## CI/CD vs Local Development (IMPORTANT)

**CI/CD workflows are DIFFERENT from local development. Do NOT mix them.**

| Aspect | Local Development | CI/CD Workflows |
|--------|-------------------|-----------------|
| **Go installation** | Docker `golang:alpine` | `actions/setup-go@v5` or runner's Go |
| **Caching** | GODIR/GOCACHE in `~/.local/share/go` | CI-native caching (setup-go has built-in) |
| **Build command** | `make dev`, `make host`, `make build` | Direct `go build` with explicit flags |
| **Testing** | Docker/Incus containers | Runner environment |
| **Makefile** | ALWAYS use Makefile targets | NEVER use Makefile (explicit commands) |

**CI/CD workflows MUST:**
- Use explicit `go build` commands with all flags visible
- Use CI-native caching (NOT local GODIR/GOCACHE paths)
- Set VERSION, COMMIT_ID, BUILD_DATE explicitly
- Build all platforms in matrix

**CI/CD workflows MUST NOT:**
- Reference local user paths like `~/.local/share/go` (use `/tmp/` or CI-native caching)
- Use Makefile targets (commands must be explicit for visibility)
- Depend on local Docker containers for builds (GitHub/Gitea Actions use native Go)

| Git Host | CI System | Config Location | Self-Hosted |
|----------|-----------|-----------------|-------------|
| GitHub | GitHub Actions | `.github/workflows/*.yml` | No (github.com only) |
| Gitea | Gitea Actions | `.gitea/workflows/*.yml` | Yes |
| Forgejo | Forgejo Actions | `.forgejo/workflows/*.yml` | Yes (self-hosted only) |
| GitLab | GitLab CI | `.gitlab-ci.yml` | Yes |

**Note:** Forgejo is a fork of Gitea - Forgejo Actions are compatible with Gitea Actions. Use `.forgejo/workflows/` for Forgejo or `.gitea/workflows/` (both work).

# GITHUB ACTIONS

**GitHub Actions only works with github.com (no self-hosted option).**

## Workflow Files

| File | Trigger | Purpose |
|------|---------|---------|
| `release.yml` | Tag push (`v*`, `*.*.*`) | Production releases |
| `beta.yml` | Push to `beta` branch | Beta releases |
| `daily.yml` | Daily at 3am UTC + push to main/master | Daily builds |
| `docker.yml` | Version tag, push to main/master/beta | Docker images |

## Build Info Variables

All workflows MUST set these environment variables:

```yaml
# Set in "Set build info" step, NOT as static env:
#   echo "VERSION=${GITHUB_REF_NAME#v}" >> $GITHUB_ENV
#   echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
#   echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITHUB_ENV
# Then use in build step:
#   LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
```

## Release Workflow (Stable)

**File:** `.github/workflows/release.yml`

```yaml
name: Release

on:
  push:
    tags:
      - 'v*'
      - '[0-9]*.[0-9]*.[0-9]*'

env:
  PROJECTNAME: weather

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - goos: linux
            goarch: amd64
          - goos: linux
            goarch: arm64
          - goos: darwin
            goarch: amd64
          - goos: darwin
            goarch: arm64
          - goos: windows
            goarch: amd64
            ext: .exe
          - goos: windows
            goarch: arm64
            ext: .exe
          - goos: freebsd
            goarch: amd64
          - goos: freebsd
            goarch: arm64

    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: 'stable'

      - name: Set build info
        run: |
          echo "VERSION=${GITHUB_REF_NAME#v}" >> $GITHUB_ENV
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITHUB_ENV

      - name: Build server
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}${{ matrix.ext }} ./src

      # CLI build - only if src/client/ directory exists
      - name: Build CLI
        if: hashFiles('src/client/') != ''
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli${{ matrix.ext }} ./src/client

      - name: Upload server artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}${{ matrix.ext }}

      - name: Upload CLI artifact
        if: hashFiles('src/client/') != ''
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli${{ matrix.ext }}

  release:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: binaries
          merge-multiple: true

      - name: Set version
        run: |
          TAG="${GITHUB_REF_NAME}"
          # VERSION for version.txt (strip v if present)
          echo "VERSION=${TAG#v}" >> $GITHUB_ENV
          # RELEASE_TAG: add v prefix only if semver without v
          if [[ "$TAG" == v* ]]; then
            echo "RELEASE_TAG=$TAG" >> $GITHUB_ENV
          elif [[ "$TAG" =~ ^[0-9]+\.[0-9]+\.[0-9]+ ]]; then
            echo "RELEASE_TAG=v$TAG" >> $GITHUB_ENV
          else
            echo "RELEASE_TAG=$TAG" >> $GITHUB_ENV
          fi

      - name: Create version.txt
        run: echo "${{ env.VERSION }}" > binaries/version.txt

      - name: Create source archive
        run: |
          tar --exclude='.git' --exclude='.github' --exclude='.gitea' \
            --exclude='binaries' --exclude='releases' --exclude='*.tar.gz' \
            -czf binaries/${{ env.PROJECTNAME }}-${{ env.VERSION }}-source.tar.gz .

      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ env.RELEASE_TAG }}
          files: binaries/*
          generate_release_notes: true
          make_latest: true
```

## Beta Workflow

**File:** `.github/workflows/beta.yml`

```yaml
name: Beta Release

on:
  push:
    branches:
      - beta

env:
  PROJECTNAME: weather

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - goos: linux
            goarch: amd64
          - goos: linux
            goarch: arm64

    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: 'stable'

      - name: Set build info
        run: |
          echo "VERSION=$(date -u +"%Y%m%d%H%M%S")-beta" >> $GITHUB_ENV
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITHUB_ENV

      - name: Build server
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }} ./src

      # CLI build - only if src/client/ directory exists
      - name: Build CLI
        if: hashFiles('src/client/') != ''
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli ./src/client

      - name: Upload server artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}

      - name: Upload CLI artifact
        if: hashFiles('src/client/') != ''
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli

  release:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: binaries
          merge-multiple: true

      - name: Set version
        run: echo "VERSION=$(date -u +"%Y%m%d%H%M%S")-beta" >> $GITHUB_ENV

      - name: Create version.txt
        run: echo "${{ env.VERSION }}" > binaries/version.txt

      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ env.VERSION }}
          files: binaries/*
          prerelease: true
          generate_release_notes: true
```

## Daily Workflow

**File:** `.github/workflows/daily.yml`

```yaml
name: Daily Build

on:
  schedule:
    - cron: '0 3 * * *'  # 3am UTC daily
  push:
    branches:
      - main
      - master
  workflow_dispatch:

env:
  PROJECTNAME: weather

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - goos: linux
            goarch: amd64
          - goos: linux
            goarch: arm64

    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: 'stable'

      - name: Set build info
        run: |
          echo "VERSION=$(date -u +"%Y%m%d%H%M%S")" >> $GITHUB_ENV
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITHUB_ENV

      - name: Build server
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }} ./src

      # CLI build - only if src/client/ directory exists
      - name: Build CLI
        if: hashFiles('src/client/') != ''
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli ./src/client

      - name: Upload server artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}

      - name: Upload CLI artifact
        if: hashFiles('src/client/') != ''
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli

  release:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: binaries
          merge-multiple: true

      - name: Set version
        run: echo "VERSION=$(date -u +"%Y%m%d%H%M%S")" >> $GITHUB_ENV

      - name: Create version.txt
        run: echo "${{ env.VERSION }}" > binaries/version.txt

      - name: Delete previous daily release
        run: |
          gh release delete daily --yes 2>/dev/null || true
          git push origin :refs/tags/daily 2>/dev/null || true
        env:
          GH_TOKEN: ${{ github.token }}

      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: daily
          name: "Daily Build ${{ env.VERSION }}"
          files: binaries/*
          prerelease: true
          body: "Daily build: ${{ env.VERSION }}"
```

## Docker Workflow

### Image Types

| Image | Dockerfile | Tag Suffix | Base | Contents |
|-------|------------|------------|------|----------|
| **Standard** | `docker/Dockerfile` | (none) | alpine | App only |
| **All-in-One** | `docker/Dockerfile.aio` | `-aio` | debian | App + PostgreSQL + Valkey + Tor |

### Triggers and Tags

| Trigger | Standard Tags | All-in-One Tags |
|---------|---------------|-----------------|
| **Any push** (all branches) | `devel`, `{COMMIT_ID}` | `devel-aio`, `{COMMIT_ID}-aio` |
| Push to beta branch | `devel`, `beta`, `{COMMIT_ID}` | `devel-aio`, `beta-aio`, `{COMMIT_ID}-aio` |
| Version tag (`v*`, `*.*.*`) | `{version}`, `latest`, `YYMM` | `{version}-aio`, `aio`, `YYMM-aio` |

**Notes:**
- `{COMMIT_ID}` = short SHA (7 characters) from `git rev-parse --short HEAD`
- `YYMM` = year/month (e.g., `2512`)
- Built for `linux/amd64` and `linux/arm64` using `docker buildx`
- Registry: `ghcr.io`
- Standard uses `latest`, All-in-One uses `aio` as the "latest" equivalent

**File:** `.github/workflows/docker.yml`

```yaml
name: Docker Build

on:
  push:
    branches: ['**']  # ALL branches
    tags:
      - 'v*'
      - '*.*.*'
  workflow_dispatch:

env:
  PROJECTNAME: weather
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build-standard:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - uses: actions/checkout@v4

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set build info
        run: |
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
          echo "YYMM=$(date +"%y%m")" >> $GITHUB_ENV
          if [[ "${{ github.ref }}" == refs/tags/* ]]; then
            VERSION="${GITHUB_REF#refs/tags/}"
            echo "VERSION=${VERSION#v}" >> $GITHUB_ENV
            echo "IS_TAG=true" >> $GITHUB_ENV
          else
            echo "VERSION=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
            echo "IS_TAG=false" >> $GITHUB_ENV
          fi
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITHUB_ENV

      - name: Determine tags (standard)
        id: tags
        run: |
          TAGS="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.COMMIT_ID }}"

          if [[ "${{ env.IS_TAG }}" == "true" ]]; then
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.VERSION }}"
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest"
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.YYMM }}"
          else
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:devel"
            if [[ "${{ github.ref }}" == refs/heads/beta ]]; then
              TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:beta"
            fi
          fi

          echo "tags=$TAGS" >> $GITHUB_OUTPUT

      - name: Build and push (standard)
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ steps.tags.outputs.tags }}
          build-args: |
            VERSION=${{ env.VERSION }}
            BUILD_DATE=${{ env.BUILD_DATE }}
            COMMIT_ID=${{ env.COMMIT_ID }}
          labels: |
            org.opencontainers.image.vendor=apimgr
            org.opencontainers.image.authors=apimgr
            org.opencontainers.image.title=${{ env.PROJECTNAME }}
            org.opencontainers.image.description=${{ env.PROJECTNAME }} - standard image (alpine)
            org.opencontainers.image.version=${{ env.VERSION }}
            org.opencontainers.image.created=${{ env.BUILD_DATE }}
            org.opencontainers.image.revision=${{ env.COMMIT_ID }}
            org.opencontainers.image.url=${{ github.server_url }}/${{ github.repository }}
            org.opencontainers.image.source=${{ github.server_url }}/${{ github.repository }}
            org.opencontainers.image.documentation=${{ github.server_url }}/${{ github.repository }}
            org.opencontainers.image.licenses=MIT
          annotations: |
            manifest:org.opencontainers.image.vendor=apimgr
            manifest:org.opencontainers.image.authors=apimgr
            manifest:org.opencontainers.image.title=${{ env.PROJECTNAME }}
            manifest:org.opencontainers.image.description=${{ env.PROJECTNAME }} - standard image (alpine)
            manifest:org.opencontainers.image.version=${{ env.VERSION }}
            manifest:org.opencontainers.image.created=${{ env.BUILD_DATE }}
            manifest:org.opencontainers.image.revision=${{ env.COMMIT_ID }}
            manifest:org.opencontainers.image.url=${{ github.server_url }}/${{ github.repository }}
            manifest:org.opencontainers.image.source=${{ github.server_url }}/${{ github.repository }}
            manifest:org.opencontainers.image.documentation=${{ github.server_url }}/${{ github.repository }}
            manifest:org.opencontainers.image.licenses=MIT

  build-aio:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - uses: actions/checkout@v4

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set build info
        run: |
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
          echo "YYMM=$(date +"%y%m")" >> $GITHUB_ENV
          if [[ "${{ github.ref }}" == refs/tags/* ]]; then
            VERSION="${GITHUB_REF#refs/tags/}"
            echo "VERSION=${VERSION#v}" >> $GITHUB_ENV
            echo "IS_TAG=true" >> $GITHUB_ENV
          else
            echo "VERSION=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
            echo "IS_TAG=false" >> $GITHUB_ENV
          fi
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITHUB_ENV

      - name: Determine tags (all-in-one)
        id: tags
        run: |
          # AIO uses separate image name: {repo}-aio:{tag}
          AIO_IMAGE="${{ env.IMAGE_NAME }}-aio"
          TAGS="${{ env.REGISTRY }}/${AIO_IMAGE}:${{ env.COMMIT_ID }}"

          if [[ "${{ env.IS_TAG }}" == "true" ]]; then
            TAGS="$TAGS,${{ env.REGISTRY }}/${AIO_IMAGE}:${{ env.VERSION }}"
            TAGS="$TAGS,${{ env.REGISTRY }}/${AIO_IMAGE}:latest"
            TAGS="$TAGS,${{ env.REGISTRY }}/${AIO_IMAGE}:${{ env.YYMM }}"
          else
            TAGS="$TAGS,${{ env.REGISTRY }}/${AIO_IMAGE}:devel"
            if [[ "${{ github.ref }}" == refs/heads/beta ]]; then
              TAGS="$TAGS,${{ env.REGISTRY }}/${AIO_IMAGE}:beta"
            fi
          fi

          echo "tags=$TAGS" >> $GITHUB_OUTPUT

      - name: Build and push (all-in-one)
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile.aio
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ steps.tags.outputs.tags }}
          build-args: |
            VERSION=${{ env.VERSION }}
            BUILD_DATE=${{ env.BUILD_DATE }}
            COMMIT_ID=${{ env.COMMIT_ID }}
          labels: |
            org.opencontainers.image.vendor=apimgr
            org.opencontainers.image.authors=apimgr
            org.opencontainers.image.title=${{ env.PROJECTNAME }}-aio
            org.opencontainers.image.description=${{ env.PROJECTNAME }} - all-in-one (debian + postgresql + valkey + tor)
            org.opencontainers.image.version=${{ env.VERSION }}
            org.opencontainers.image.created=${{ env.BUILD_DATE }}
            org.opencontainers.image.revision=${{ env.COMMIT_ID }}
            org.opencontainers.image.url=${{ github.server_url }}/${{ github.repository }}
            org.opencontainers.image.source=${{ github.server_url }}/${{ github.repository }}
            org.opencontainers.image.documentation=${{ github.server_url }}/${{ github.repository }}
            org.opencontainers.image.licenses=MIT
          annotations: |
            manifest:org.opencontainers.image.vendor=apimgr
            manifest:org.opencontainers.image.authors=apimgr
            manifest:org.opencontainers.image.title=${{ env.PROJECTNAME }}-aio
            manifest:org.opencontainers.image.description=${{ env.PROJECTNAME }} - all-in-one (debian + postgresql + valkey + tor)
            manifest:org.opencontainers.image.version=${{ env.VERSION }}
            manifest:org.opencontainers.image.created=${{ env.BUILD_DATE }}
            manifest:org.opencontainers.image.revision=${{ env.COMMIT_ID }}
            manifest:org.opencontainers.image.url=${{ github.server_url }}/${{ github.repository }}
            manifest:org.opencontainers.image.source=${{ github.server_url }}/${{ github.repository }}
            manifest:org.opencontainers.image.documentation=${{ github.server_url }}/${{ github.repository }}
            manifest:org.opencontainers.image.licenses=MIT
```

**Image Tag Summary:**

| Use Case | Standard Image | All-in-One Image |
|----------|----------------|------------------|
| Latest stable | `{name}:latest` | `{name}-aio:latest` |
| Specific version | `{name}:1.2.3` | `{name}-aio:1.2.3` |
| Development | `{name}:devel` | `{name}-aio:devel` |
| Beta | `{name}:beta` | `{name}-aio:beta` |
| Commit | `{name}:abc1234` | `{name}-aio:abc1234` |

---

# GITEA / FORGEJO ACTIONS

**For projects hosted on Gitea or Forgejo (cloud or self-hosted), use these equivalent workflows.**

Forgejo is a community fork of Gitea - workflows are fully compatible between them.

| Platform | Directory | Variables | Self-Hosted |
|----------|-----------|-----------|-------------|
| Gitea | `.gitea/workflows/` | `GITEA_*`, `${{ gitea.* }}` | Yes (gitea.com + self-hosted) |
| Forgejo | `.forgejo/workflows/` | `FORGEJO_*`, `${{ forgejo.* }}` | Yes (self-hosted only) |

**Compatibility:** Forgejo also reads `.gitea/workflows/` and accepts `GITEA_*` variables for backwards compatibility.

Key differences from GitHub Actions:
- Directory: `.gitea/workflows/` or `.forgejo/workflows/`
- Use `gitea.com/actions/*` actions or compatible GitHub Actions
- Registry: Auto-detected from server URL (works with self-hosted)
- Some GitHub-specific variables have Gitea/Forgejo equivalents (see mapping table below)

## Self-Hosted Configuration

**Gitea:**

| Setting | Value |
|---------|-------|
| Gitea version | 1.19+ (Actions support) |
| Enable Actions | Site Administration → Actions → Enable Actions |
| Runner | Register runner via `act_runner` |
| Container Registry | Enable in Site Administration → Packages |
| Token | User Settings → Applications → Generate Access Token |

**Forgejo:**

| Setting | Value |
|---------|-------|
| Forgejo version | 1.21+ (Actions support) |
| Enable Actions | Site Administration → Actions → Enable Actions |
| Runner | Register runner via `forgejo-runner` (or `act_runner`) |
| Container Registry | Enable in Site Administration → Packages |
| Token | User Settings → Applications → Generate Access Token |

For self-hosted runners, change `runs-on: ubuntu-latest` to your runner label.

## Workflow Files

| File | Trigger | Purpose |
|------|---------|---------|
| `release.yml` | Tag push (`v*`, `*.*.*`) | Production releases |
| `beta.yml` | Push to `beta` branch | Beta releases |
| `daily.yml` | Daily at 3am UTC + push to main/master | Daily builds |
| `docker.yml` | Version tag, push to main/master/beta | Docker images |

## Release Workflow (Stable)

**File:** `.gitea/workflows/release.yml`

```yaml
name: Release

on:
  push:
    tags:
      - 'v*'
      - '[0-9]*.[0-9]*.[0-9]*'

env:
  PROJECTNAME: weather

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - goos: linux
            goarch: amd64
          - goos: linux
            goarch: arm64
          - goos: darwin
            goarch: amd64
          - goos: darwin
            goarch: arm64
          - goos: windows
            goarch: amd64
            ext: .exe
          - goos: windows
            goarch: arm64
            ext: .exe
          - goos: freebsd
            goarch: amd64
          - goos: freebsd
            goarch: arm64

    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: 'stable'

      - name: Set build info
        run: |
          echo "VERSION=${GITEA_REF_NAME#v}" >> $GITEA_ENV
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITEA_ENV
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITEA_ENV

      - name: Build server
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}${{ matrix.ext }} ./src

      # CLI build - only if src/client/ directory exists
      - name: Build CLI
        if: hashFiles('src/client/') != ''
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli${{ matrix.ext }} ./src/client

      - name: Upload server artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}${{ matrix.ext }}

      - name: Upload CLI artifact
        if: hashFiles('src/client/') != ''
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli${{ matrix.ext }}

  release:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: binaries
          merge-multiple: true

      - name: Set version
        run: |
          TAG="${GITEA_REF_NAME}"
          # VERSION for version.txt (strip v if present)
          echo "VERSION=${TAG#v}" >> $GITEA_ENV
          # RELEASE_TAG: add v prefix only if semver without v
          if [[ "$TAG" == v* ]]; then
            echo "RELEASE_TAG=$TAG" >> $GITEA_ENV
          elif [[ "$TAG" =~ ^[0-9]+\.[0-9]+\.[0-9]+ ]]; then
            echo "RELEASE_TAG=v$TAG" >> $GITEA_ENV
          else
            echo "RELEASE_TAG=$TAG" >> $GITEA_ENV
          fi

      - name: Create version.txt
        run: echo "${{ env.VERSION }}" > binaries/version.txt

      - name: Create source archive
        run: |
          tar --exclude='.git' --exclude='.github' --exclude='.gitea' \
            --exclude='binaries' --exclude='releases' --exclude='*.tar.gz' \
            -czf binaries/${{ env.PROJECTNAME }}-${{ env.VERSION }}-source.tar.gz .

      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ env.RELEASE_TAG }}
          files: binaries/*
          generate_release_notes: true
          make_latest: true
```

## Beta Workflow

**File:** `.gitea/workflows/beta.yml`

```yaml
name: Beta Release

on:
  push:
    branches:
      - beta

env:
  PROJECTNAME: weather

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - goos: linux
            goarch: amd64
          - goos: linux
            goarch: arm64

    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: 'stable'

      - name: Set build info
        run: |
          echo "VERSION=$(date -u +"%Y%m%d%H%M%S")-beta" >> $GITEA_ENV
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITEA_ENV
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITEA_ENV

      - name: Build server
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }} ./src

      # CLI build - only if src/client/ directory exists
      - name: Build CLI
        if: hashFiles('src/client/') != ''
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli ./src/client

      - name: Upload server artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}

      - name: Upload CLI artifact
        if: hashFiles('src/client/') != ''
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli

  release:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: binaries
          merge-multiple: true

      - name: Set version
        run: echo "VERSION=$(date -u +"%Y%m%d%H%M%S")-beta" >> $GITEA_ENV

      - name: Create version.txt
        run: echo "${{ env.VERSION }}" > binaries/version.txt

      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ env.VERSION }}
          files: binaries/*
          prerelease: true
          generate_release_notes: true
```

## Daily Workflow

**File:** `.gitea/workflows/daily.yml`

```yaml
name: Daily Build

on:
  schedule:
    - cron: '0 3 * * *'  # 3am UTC daily
  push:
    branches:
      - main
      - master
  workflow_dispatch:

env:
  PROJECTNAME: weather

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - goos: linux
            goarch: amd64
          - goos: linux
            goarch: arm64

    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: 'stable'

      - name: Set build info
        run: |
          echo "VERSION=$(date -u +"%Y%m%d%H%M%S")" >> $GITEA_ENV
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITEA_ENV
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITEA_ENV

      - name: Build server
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }} ./src

      # CLI build - only if src/client/ directory exists
      - name: Build CLI
        if: hashFiles('src/client/') != ''
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli ./src/client

      - name: Upload server artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}

      - name: Upload CLI artifact
        if: hashFiles('src/client/') != ''
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli

  release:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: binaries
          merge-multiple: true

      - name: Set version
        run: echo "VERSION=$(date -u +"%Y%m%d%H%M%S")" >> $GITEA_ENV

      - name: Create version.txt
        run: echo "${{ env.VERSION }}" > binaries/version.txt

      - name: Delete previous daily release
        run: |
          # Use Gitea API to delete previous daily release
          curl -X DELETE \
            -H "Authorization: token ${{ secrets.GITEA_TOKEN }}" \
            "${{ gitea.server_url }}/api/v1/repos/${{ gitea.repository }}/releases/tags/daily" || true
          git push origin :refs/tags/daily 2>/dev/null || true

      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: daily
          name: "Daily Build ${{ env.VERSION }}"
          files: binaries/*
          prerelease: true
          body: "Daily build: ${{ env.VERSION }}"
```

## Docker Workflow

**File:** `.gitea/workflows/docker.yml`

```yaml
name: Docker Build

on:
  push:
    branches: ['**']  # ALL branches
    tags:
      - 'v*'
      - '*.*.*'
  workflow_dispatch:

env:
  PROJECTNAME: weather
  # Registry auto-detected from Gitea instance (works with self-hosted)
  # Format: {gitea-server}/owner/repo -> extracts server for registry
  IMAGE_NAME: ${{ gitea.repository }}

jobs:
  build-standard:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - uses: actions/checkout@v4

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Set registry from server URL
        run: |
          # Extract registry from Gitea server URL (works with self-hosted)
          # Example: https://git.example.com -> git.example.com
          SERVER_URL="${{ gitea.server_url }}"
          REGISTRY="${SERVER_URL#https://}"
          REGISTRY="${REGISTRY#http://}"
          echo "REGISTRY=${REGISTRY}" >> $GITEA_ENV

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ gitea.actor }}
          password: ${{ secrets.GITEA_TOKEN }}

      - name: Set build info
        run: |
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITEA_ENV
          echo "YYMM=$(date +"%y%m")" >> $GITEA_ENV
          if [[ "${{ gitea.ref }}" == refs/tags/* ]]; then
            VERSION="${GITEA_REF_NAME}"
            echo "VERSION=${VERSION#v}" >> $GITEA_ENV  # Strip 'v' prefix
            echo "IS_TAG=true" >> $GITEA_ENV
          else
            echo "VERSION=$(git rev-parse --short HEAD)" >> $GITEA_ENV
            echo "IS_TAG=false" >> $GITEA_ENV
          fi
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITEA_ENV

      - name: Determine tags (standard)
        id: tags
        run: |
          # Use self-hosted registry URL
          TAGS="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.COMMIT_ID }}"

          if [[ "${{ env.IS_TAG }}" == "true" ]]; then
            # Release tag - version, latest, YYMM
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.VERSION }}"
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest"
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.YYMM }}"
          else
            # All pushes get devel tag
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:devel"

            # Beta branch also gets beta tag
            if [[ "${{ gitea.ref }}" == refs/heads/beta ]]; then
              TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:beta"
            fi
          fi

          echo "tags=$TAGS" >> $GITEA_OUTPUT

      - name: Build and push (standard)
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ steps.tags.outputs.tags }}
          build-args: |
            VERSION=${{ env.VERSION }}
            BUILD_DATE=${{ env.BUILD_DATE }}
            COMMIT_ID=${{ env.COMMIT_ID }}
          labels: |
            org.opencontainers.image.vendor=apimgr
            org.opencontainers.image.authors=apimgr
            org.opencontainers.image.title=${{ env.PROJECTNAME }}
            org.opencontainers.image.description=${{ env.PROJECTNAME }} - standard image (alpine)
            org.opencontainers.image.version=${{ env.VERSION }}
            org.opencontainers.image.created=${{ env.BUILD_DATE }}
            org.opencontainers.image.revision=${{ env.COMMIT_ID }}
            org.opencontainers.image.url=${{ gitea.server_url }}/${{ gitea.repository }}
            org.opencontainers.image.source=${{ gitea.server_url }}/${{ gitea.repository }}
            org.opencontainers.image.documentation=${{ gitea.server_url }}/${{ gitea.repository }}
            org.opencontainers.image.licenses=MIT
          annotations: |
            manifest:org.opencontainers.image.vendor=apimgr
            manifest:org.opencontainers.image.authors=apimgr
            manifest:org.opencontainers.image.title=${{ env.PROJECTNAME }}
            manifest:org.opencontainers.image.description=${{ env.PROJECTNAME }} - standard image (alpine)
            manifest:org.opencontainers.image.version=${{ env.VERSION }}
            manifest:org.opencontainers.image.created=${{ env.BUILD_DATE }}
            manifest:org.opencontainers.image.revision=${{ env.COMMIT_ID }}
            manifest:org.opencontainers.image.url=${{ gitea.server_url }}/${{ gitea.repository }}
            manifest:org.opencontainers.image.source=${{ gitea.server_url }}/${{ gitea.repository }}
            manifest:org.opencontainers.image.documentation=${{ gitea.server_url }}/${{ gitea.repository }}
            manifest:org.opencontainers.image.licenses=MIT

  build-aio:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - uses: actions/checkout@v4

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Set registry from server URL
        run: |
          SERVER_URL="${{ gitea.server_url }}"
          REGISTRY="${SERVER_URL#https://}"
          REGISTRY="${REGISTRY#http://}"
          echo "REGISTRY=${REGISTRY}" >> $GITEA_ENV

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ gitea.actor }}
          password: ${{ secrets.GITEA_TOKEN }}

      - name: Set build info
        run: |
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITEA_ENV
          echo "YYMM=$(date +"%y%m")" >> $GITEA_ENV
          if [[ "${{ gitea.ref }}" == refs/tags/* ]]; then
            VERSION="${GITEA_REF_NAME}"
            echo "VERSION=${VERSION#v}" >> $GITEA_ENV
            echo "IS_TAG=true" >> $GITEA_ENV
          else
            echo "VERSION=$(git rev-parse --short HEAD)" >> $GITEA_ENV
            echo "IS_TAG=false" >> $GITEA_ENV
          fi
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITEA_ENV

      - name: Determine tags (all-in-one)
        id: tags
        run: |
          # AIO uses separate image name: {repo}-aio:{tag}
          AIO_IMAGE="${{ env.IMAGE_NAME }}-aio"
          TAGS="${{ env.REGISTRY }}/${AIO_IMAGE}:${{ env.COMMIT_ID }}"

          if [[ "${{ env.IS_TAG }}" == "true" ]]; then
            TAGS="$TAGS,${{ env.REGISTRY }}/${AIO_IMAGE}:${{ env.VERSION }}"
            TAGS="$TAGS,${{ env.REGISTRY }}/${AIO_IMAGE}:latest"
            TAGS="$TAGS,${{ env.REGISTRY }}/${AIO_IMAGE}:${{ env.YYMM }}"
          else
            TAGS="$TAGS,${{ env.REGISTRY }}/${AIO_IMAGE}:devel"
            if [[ "${{ gitea.ref }}" == refs/heads/beta ]]; then
              TAGS="$TAGS,${{ env.REGISTRY }}/${AIO_IMAGE}:beta"
            fi
          fi

          echo "tags=$TAGS" >> $GITEA_OUTPUT

      - name: Build and push (all-in-one)
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile.aio
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ steps.tags.outputs.tags }}
          build-args: |
            VERSION=${{ env.VERSION }}
            BUILD_DATE=${{ env.BUILD_DATE }}
            COMMIT_ID=${{ env.COMMIT_ID }}
          labels: |
            org.opencontainers.image.vendor=apimgr
            org.opencontainers.image.authors=apimgr
            org.opencontainers.image.title=${{ env.PROJECTNAME }}-aio
            org.opencontainers.image.description=${{ env.PROJECTNAME }} - all-in-one (debian + postgresql + valkey + tor)
            org.opencontainers.image.version=${{ env.VERSION }}
            org.opencontainers.image.created=${{ env.BUILD_DATE }}
            org.opencontainers.image.revision=${{ env.COMMIT_ID }}
            org.opencontainers.image.url=${{ gitea.server_url }}/${{ gitea.repository }}
            org.opencontainers.image.source=${{ gitea.server_url }}/${{ gitea.repository }}
            org.opencontainers.image.documentation=${{ gitea.server_url }}/${{ gitea.repository }}
            org.opencontainers.image.licenses=MIT
          annotations: |
            manifest:org.opencontainers.image.vendor=apimgr
            manifest:org.opencontainers.image.authors=apimgr
            manifest:org.opencontainers.image.title=${{ env.PROJECTNAME }}-aio
            manifest:org.opencontainers.image.description=${{ env.PROJECTNAME }} - all-in-one (debian + postgresql + valkey + tor)
            manifest:org.opencontainers.image.version=${{ env.VERSION }}
            manifest:org.opencontainers.image.created=${{ env.BUILD_DATE }}
            manifest:org.opencontainers.image.revision=${{ env.COMMIT_ID }}
            manifest:org.opencontainers.image.url=${{ gitea.server_url }}/${{ gitea.repository }}
            manifest:org.opencontainers.image.source=${{ gitea.server_url }}/${{ gitea.repository }}
            manifest:org.opencontainers.image.documentation=${{ gitea.server_url }}/${{ gitea.repository }}
            manifest:org.opencontainers.image.licenses=MIT
```

## Variable Mapping (GitHub → Gitea → Forgejo)

| GitHub | Gitea | Forgejo | Description |
|--------|-------|---------|-------------|
| `${{ github.* }}` | `${{ gitea.* }}` | `${{ forgejo.* }}` | Context variables |
| `GITHUB_ENV` | `GITEA_ENV` | `FORGEJO_ENV` | Environment file |
| `GITHUB_OUTPUT` | `GITEA_OUTPUT` | `FORGEJO_OUTPUT` | Output file |
| `GITHUB_REF_NAME` | `GITEA_REF_NAME` | `FORGEJO_REF_NAME` | Reference name |
| `github.token` | `secrets.GITEA_TOKEN` | `secrets.FORGEJO_TOKEN` | Auth token |
| `github.actor` | `gitea.actor` | `forgejo.actor` | Username |
| `github.repository` | `gitea.repository` | `forgejo.repository` | Repo path |
| `github.server_url` | `gitea.server_url` | `forgejo.server_url` | Server URL |

**Note:** Forgejo accepts both `FORGEJO_*` and `GITEA_*` variables for backwards compatibility.

**Notes:**
- Most GitHub Actions work on Gitea/Forgejo with minimal changes
- Use `secrets.GITEA_TOKEN` or `secrets.FORGEJO_TOKEN` for authentication
- Works with gitea.com, self-hosted Gitea, and self-hosted Forgejo
- Container registry auto-detected from server URL (e.g., `git.example.com/owner/repo`)
- Self-hosted runners: change `runs-on: ubuntu-latest` to your runner label
- Forgejo can use `.gitea/workflows/` directory for Gitea compatibility
- Some advanced GitHub features may not be available on older versions

---

# GITLAB CI

**For projects hosted on GitLab (gitlab.com or self-hosted), use this equivalent CI/CD configuration.**

GitLab CI uses a single `.gitlab-ci.yml` file in the repository root with stages instead of separate workflow files.

## Self-Hosted Configuration

| Setting | Value |
|---------|-------|
| GitLab version | 13.0+ (recommended 15.0+) |
| Runners | Register via `gitlab-runner register` |
| Container Registry | Enable in Admin Area → Settings → Container Registry |
| CI/CD Variables | Project → Settings → CI/CD → Variables |

All `$CI_*` variables are auto-populated by GitLab (works with self-hosted).

## Key Differences from GitHub/Gitea Actions

| Feature | GitHub/Gitea Actions | GitLab CI |
|---------|---------------------|-----------|
| Config location | `.github/workflows/*.yml` | `.gitlab-ci.yml` (single file) |
| Job grouping | Separate workflow files | Stages in single file |
| Triggers | `on:` block | `rules:` or `only/except` |
| Secrets | `${{ secrets.NAME }}` | `$NAME` (CI/CD variables) |
| Artifacts | `actions/upload-artifact` | `artifacts:` block |
| Matrix builds | `strategy.matrix` | `parallel:matrix` |
| Container registry | `ghcr.io` | `$CI_REGISTRY` |

## GitLab CI Configuration

**File:** `.gitlab-ci.yml`

```yaml
# GitLab CI/CD Pipeline for weather
# Equivalent to GitHub Actions: release.yml, beta.yml, daily.yml, docker.yml

variables:
  PROJECTNAME: "weather"
  PROJECTORG: "apimgr"
  CGO_ENABLED: "0"
  GOOS: linux
  GOARCH: amd64

stages:
  - build
  - test
  - package
  - release
  - docker

# =============================================================================
# BUILD TEMPLATES
# =============================================================================

.go-build-template: &go-build
  image: golang:alpine
  before_script:
    - apk add --no-cache git bash
    - export VERSION="${CI_COMMIT_TAG#v}"
    - export COMMIT_ID="${CI_COMMIT_SHORT_SHA}"
    - export BUILD_DATE="$(date +"%a %b %d, %Y at %H:%M:%S %Z")"
    - export LDFLAGS="-s -w -X 'main.Version=${VERSION}' -X 'main.CommitID=${COMMIT_ID}' -X 'main.BuildDate=${BUILD_DATE}'"

# =============================================================================
# RELEASE BUILDS (Tag Push: v* or semver)
# =============================================================================

build:linux-amd64:
  <<: *go-build
  stage: build
  variables:
    GOOS: linux
    GOARCH: amd64
  script:
    - go build -ldflags "${LDFLAGS}" -o $WEATHER-linux-amd64 ./src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $WEATHER-cli-linux-amd64 ./src/client; fi
  artifacts:
    paths:
      - $WEATHER-linux-amd64*
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

build:linux-arm64:
  <<: *go-build
  stage: build
  variables:
    GOOS: linux
    GOARCH: arm64
  script:
    - go build -ldflags "${LDFLAGS}" -o $WEATHER-linux-arm64 ./src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $WEATHER-cli-linux-arm64 ./src/client; fi
  artifacts:
    paths:
      - $WEATHER-linux-arm64*
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

build:darwin-amd64:
  <<: *go-build
  stage: build
  variables:
    GOOS: darwin
    GOARCH: amd64
  script:
    - go build -ldflags "${LDFLAGS}" -o $WEATHER-darwin-amd64 ./src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $WEATHER-cli-darwin-amd64 ./src/client; fi
  artifacts:
    paths:
      - $WEATHER-darwin-amd64*
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

build:darwin-arm64:
  <<: *go-build
  stage: build
  variables:
    GOOS: darwin
    GOARCH: arm64
  script:
    - go build -ldflags "${LDFLAGS}" -o $WEATHER-darwin-arm64 ./src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $WEATHER-cli-darwin-arm64 ./src/client; fi
  artifacts:
    paths:
      - $WEATHER-darwin-arm64*
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

build:windows-amd64:
  <<: *go-build
  stage: build
  variables:
    GOOS: windows
    GOARCH: amd64
  script:
    - go build -ldflags "${LDFLAGS}" -o $WEATHER-windows-amd64.exe ./src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $WEATHER-cli-windows-amd64.exe ./src/client; fi
  artifacts:
    paths:
      - $WEATHER-windows-amd64*.exe
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

build:windows-arm64:
  <<: *go-build
  stage: build
  variables:
    GOOS: windows
    GOARCH: arm64
  script:
    - go build -ldflags "${LDFLAGS}" -o $WEATHER-windows-arm64.exe ./src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $WEATHER-cli-windows-arm64.exe ./src/client; fi
  artifacts:
    paths:
      - $WEATHER-windows-arm64*.exe
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

build:freebsd-amd64:
  <<: *go-build
  stage: build
  variables:
    GOOS: freebsd
    GOARCH: amd64
  script:
    - go build -ldflags "${LDFLAGS}" -o $WEATHER-freebsd-amd64 ./src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $WEATHER-cli-freebsd-amd64 ./src/client; fi
  artifacts:
    paths:
      - $WEATHER-freebsd-amd64*
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

build:freebsd-arm64:
  <<: *go-build
  stage: build
  variables:
    GOOS: freebsd
    GOARCH: arm64
  script:
    - go build -ldflags "${LDFLAGS}" -o $WEATHER-freebsd-arm64 ./src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $WEATHER-cli-freebsd-arm64 ./src/client; fi
  artifacts:
    paths:
      - $WEATHER-freebsd-arm64*
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

# =============================================================================
# TEST
# =============================================================================

test:
  <<: *go-build
  stage: test
  script:
    - go test -v -cover ./...
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/
    - if: $CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "master"
    - if: $CI_COMMIT_BRANCH == "beta"

# =============================================================================
# RELEASE (GitLab Release)
# =============================================================================

release:
  stage: release
  image: registry.gitlab.com/gitlab-org/release-cli:latest
  needs:
    - build:linux-amd64
    - build:linux-arm64
    - build:darwin-amd64
    - build:darwin-arm64
    - build:windows-amd64
    - build:windows-arm64
    - build:freebsd-amd64
    - build:freebsd-arm64
    - test
  script:
    - echo "Creating release ${CI_COMMIT_TAG}"
    - echo "${CI_COMMIT_TAG#v}" > version.txt
  artifacts:
    paths:
      - version.txt
      - $WEATHER-*
  release:
    tag_name: $CI_COMMIT_TAG
    name: "Release $CI_COMMIT_TAG"
    description: "Release created by GitLab CI"
    assets:
      links:
        - name: "$WEATHER-linux-amd64"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$WEATHER-linux-amd64?job=build:linux-amd64"
        - name: "$WEATHER-linux-arm64"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$WEATHER-linux-arm64?job=build:linux-arm64"
        - name: "$WEATHER-darwin-amd64"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$WEATHER-darwin-amd64?job=build:darwin-amd64"
        - name: "$WEATHER-darwin-arm64"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$WEATHER-darwin-arm64?job=build:darwin-arm64"
        - name: "$WEATHER-windows-amd64.exe"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$WEATHER-windows-amd64.exe?job=build:windows-amd64"
        - name: "$WEATHER-windows-arm64.exe"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$WEATHER-windows-arm64.exe?job=build:windows-arm64"
        - name: "$WEATHER-freebsd-amd64"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$WEATHER-freebsd-amd64?job=build:freebsd-amd64"
        - name: "$WEATHER-freebsd-arm64"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$WEATHER-freebsd-arm64?job=build:freebsd-arm64"
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

# =============================================================================
# BETA BUILDS (Push to beta branch)
# =============================================================================

build:beta:linux:
  <<: *go-build
  stage: build
  variables:
    GOOS: linux
    GOARCH: amd64
  before_script:
    - apk add --no-cache git bash
    - export VERSION="$(date +%Y%m%d%H%M%S)-beta"
    - export COMMIT_ID="${CI_COMMIT_SHORT_SHA}"
    - export BUILD_DATE="$(date +"%a %b %d, %Y at %H:%M:%S %Z")"
    - export LDFLAGS="-s -w -X 'main.Version=${VERSION}' -X 'main.CommitID=${COMMIT_ID}' -X 'main.BuildDate=${BUILD_DATE}'"
  script:
    - go build -ldflags "${LDFLAGS}" -o $WEATHER-linux-amd64 ./src
    - go build -ldflags "${LDFLAGS}" -o $WEATHER-linux-arm64 ./src
  artifacts:
    paths:
      - $WEATHER-linux-*
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_BRANCH == "beta"

# =============================================================================
# DAILY BUILDS (Scheduled + main/master push)
# =============================================================================

build:daily:linux:
  <<: *go-build
  stage: build
  variables:
    GOOS: linux
    GOARCH: amd64
  before_script:
    - apk add --no-cache git bash
    - export VERSION="$(date +%Y%m%d%H%M%S)"
    - export COMMIT_ID="${CI_COMMIT_SHORT_SHA}"
    - export BUILD_DATE="$(date +"%a %b %d, %Y at %H:%M:%S %Z")"
    - export LDFLAGS="-s -w -X 'main.Version=${VERSION}' -X 'main.CommitID=${COMMIT_ID}' -X 'main.BuildDate=${BUILD_DATE}'"
  script:
    - go build -ldflags "${LDFLAGS}" -o $WEATHER-linux-amd64 ./src
    - go build -ldflags "${LDFLAGS}" -o $WEATHER-linux-arm64 ./src
  artifacts:
    paths:
      - $WEATHER-linux-*
    expire_in: 1 day
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "master"
      when: manual
      allow_failure: true

# =============================================================================
# DOCKER BUILDS
# =============================================================================

docker:build:
  stage: docker
  image: docker:latest
  services:
    - docker:dind
  variables:
    DOCKER_TLS_CERTDIR: "/certs"
    DOCKER_BUILDKIT: "1"
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker buildx create --name multiarch-builder --use 2>/dev/null || docker buildx use multiarch-builder
  script:
    - |
      # Determine version and tags based on trigger
      if [ -n "$CI_COMMIT_TAG" ]; then
        VERSION="${CI_COMMIT_TAG#v}"
        YYMM=$(date +%y%m)
        TAGS="-t $CI_REGISTRY_IMAGE:$VERSION -t $CI_REGISTRY_IMAGE:latest -t $CI_REGISTRY_IMAGE:$YYMM -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA"
      elif [ "$CI_COMMIT_BRANCH" = "beta" ]; then
        VERSION="beta-$CI_COMMIT_SHORT_SHA"
        TAGS="-t $CI_REGISTRY_IMAGE:beta -t $CI_REGISTRY_IMAGE:devel -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA"
      else
        VERSION="devel-$CI_COMMIT_SHORT_SHA"
        TAGS="-t $CI_REGISTRY_IMAGE:devel -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA"
      fi
      BUILD_DATE="$(date -Iseconds)"
    - |
      # Build multi-arch with OCI labels and manifest annotations
      docker buildx build \
        -f docker/Dockerfile \
        --platform linux/amd64,linux/arm64 \
        --build-arg VERSION="${VERSION}" \
        --build-arg COMMIT_ID="${CI_COMMIT_SHORT_SHA}" \
        --build-arg BUILD_DATE="${BUILD_DATE}" \
        --label "org.opencontainers.image.vendor=${PROJECTORG}" \
        --label "org.opencontainers.image.authors=${PROJECTORG}" \
        --label "org.opencontainers.image.title=$WEATHER" \
        --label "org.opencontainers.image.base.name=$WEATHER" \
        --label "org.opencontainers.image.description=Containerized version of $WEATHER" \
        --label "org.opencontainers.image.licenses=MIT" \
        --label "org.opencontainers.image.version=${VERSION}" \
        --label "org.opencontainers.image.created=${BUILD_DATE}" \
        --label "org.opencontainers.image.revision=${CI_COMMIT_SHORT_SHA}" \
        --label "org.opencontainers.image.url=${CI_PROJECT_URL}" \
        --label "org.opencontainers.image.source=${CI_PROJECT_URL}" \
        --label "org.opencontainers.image.documentation=${CI_PROJECT_URL}" \
        --annotation "manifest:org.opencontainers.image.vendor=${PROJECTORG}" \
        --annotation "manifest:org.opencontainers.image.authors=${PROJECTORG}" \
        --annotation "manifest:org.opencontainers.image.title=$WEATHER" \
        --annotation "manifest:org.opencontainers.image.description=Containerized version of $WEATHER" \
        --annotation "manifest:org.opencontainers.image.licenses=MIT" \
        --annotation "manifest:org.opencontainers.image.version=${VERSION}" \
        --annotation "manifest:org.opencontainers.image.created=${BUILD_DATE}" \
        --annotation "manifest:org.opencontainers.image.revision=${CI_COMMIT_SHORT_SHA}" \
        --annotation "manifest:org.opencontainers.image.url=${CI_PROJECT_URL}" \
        --annotation "manifest:org.opencontainers.image.source=${CI_PROJECT_URL}" \
        --annotation "manifest:org.opencontainers.image.documentation=${CI_PROJECT_URL}" \
        $TAGS \
        --push \
        .
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/
    - if: $CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "master"
    - if: $CI_COMMIT_BRANCH == "beta"

docker:build-aio:
  stage: docker
  image: docker:latest
  services:
    - docker:dind
  variables:
    DOCKER_TLS_CERTDIR: "/certs"
    DOCKER_BUILDKIT: "1"
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker buildx create --name multiarch-builder --use 2>/dev/null || docker buildx use multiarch-builder
  script:
    - |
      # AIO uses separate image name: {repo}-aio:{tag}
      AIO_IMAGE="${CI_REGISTRY_IMAGE}-aio"
      if [ -n "$CI_COMMIT_TAG" ]; then
        VERSION="${CI_COMMIT_TAG#v}"
        YYMM=$(date +%y%m)
        TAGS="-t ${AIO_IMAGE}:${VERSION} -t ${AIO_IMAGE}:latest -t ${AIO_IMAGE}:${YYMM} -t ${AIO_IMAGE}:${CI_COMMIT_SHORT_SHA}"
      elif [ "$CI_COMMIT_BRANCH" = "beta" ]; then
        VERSION="beta-$CI_COMMIT_SHORT_SHA"
        TAGS="-t ${AIO_IMAGE}:beta -t ${AIO_IMAGE}:devel -t ${AIO_IMAGE}:${CI_COMMIT_SHORT_SHA}"
      else
        VERSION="devel-$CI_COMMIT_SHORT_SHA"
        TAGS="-t ${AIO_IMAGE}:devel -t ${AIO_IMAGE}:${CI_COMMIT_SHORT_SHA}"
      fi
      BUILD_DATE="$(date -Iseconds)"
    - |
      # Build multi-arch all-in-one with OCI labels and manifest annotations
      docker buildx build \
        -f docker/Dockerfile.aio \
        --platform linux/amd64,linux/arm64 \
        --build-arg VERSION="${VERSION}" \
        --build-arg COMMIT_ID="${CI_COMMIT_SHORT_SHA}" \
        --build-arg BUILD_DATE="${BUILD_DATE}" \
        --label "org.opencontainers.image.vendor=${PROJECTORG}" \
        --label "org.opencontainers.image.authors=${PROJECTORG}" \
        --label "org.opencontainers.image.title=$WEATHER-aio" \
        --label "org.opencontainers.image.description=$WEATHER - all-in-one (debian + postgresql + valkey + tor)" \
        --label "org.opencontainers.image.licenses=MIT" \
        --label "org.opencontainers.image.version=${VERSION}" \
        --label "org.opencontainers.image.created=${BUILD_DATE}" \
        --label "org.opencontainers.image.revision=${CI_COMMIT_SHORT_SHA}" \
        --label "org.opencontainers.image.url=${CI_PROJECT_URL}" \
        --label "org.opencontainers.image.source=${CI_PROJECT_URL}" \
        --label "org.opencontainers.image.documentation=${CI_PROJECT_URL}" \
        --annotation "manifest:org.opencontainers.image.vendor=${PROJECTORG}" \
        --annotation "manifest:org.opencontainers.image.authors=${PROJECTORG}" \
        --annotation "manifest:org.opencontainers.image.title=$WEATHER-aio" \
        --annotation "manifest:org.opencontainers.image.description=$WEATHER - all-in-one (debian + postgresql + valkey + tor)" \
        --annotation "manifest:org.opencontainers.image.licenses=MIT" \
        --annotation "manifest:org.opencontainers.image.version=${VERSION}" \
        --annotation "manifest:org.opencontainers.image.created=${BUILD_DATE}" \
        --annotation "manifest:org.opencontainers.image.revision=${CI_COMMIT_SHORT_SHA}" \
        --annotation "manifest:org.opencontainers.image.url=${CI_PROJECT_URL}" \
        --annotation "manifest:org.opencontainers.image.source=${CI_PROJECT_URL}" \
        --annotation "manifest:org.opencontainers.image.documentation=${CI_PROJECT_URL}" \
        $TAGS \
        --push \
        .
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/
    - if: $CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "master"
    - if: $CI_COMMIT_BRANCH == "beta"
```

## GitLab CI Variables

Set these in GitLab Project → Settings → CI/CD → Variables:

| Variable | Description | Example |
|----------|-------------|---------|
| `CI_REGISTRY` | GitLab container registry (auto-set) | `registry.gitlab.com` |
| `CI_REGISTRY_USER` | Registry username (auto-set) | `gitlab-ci-token` |
| `CI_REGISTRY_PASSWORD` | Registry password (auto-set) | `$CI_JOB_TOKEN` |
| `CI_REGISTRY_IMAGE` | Full image path (auto-set) | `registry.gitlab.com/org/project` |

## GitLab Scheduled Pipelines (for Daily Builds)

Create in GitLab Project → Build → Pipeline schedules:

| Field | Value |
|-------|-------|
| Description | Daily Build |
| Interval Pattern | `0 3 * * *` (3am UTC daily) |
| Cron Timezone | UTC |
| Target Branch | `main` or `master` |
| Activated | Yes |

## Variable Mapping

| GitHub Actions | GitLab CI | Description |
|----------------|-----------|-------------|
| `${{ github.ref_name }}` | `$CI_COMMIT_REF_NAME` | Branch or tag name |
| `${{ github.sha }}` | `$CI_COMMIT_SHA` | Full commit SHA |
| `${{ github.repository }}` | `$CI_PROJECT_PATH` | Repo path (org/project) |
| `${{ github.server_url }}` | `$CI_SERVER_URL` | Server URL |
| `${{ secrets.NAME }}` | `$NAME` | CI/CD variables |
| `GITHUB_ENV` | `dotenv` artifact | Pass vars between jobs |

**Notes:**
- GitLab CI uses a single `.gitlab-ci.yml` file instead of multiple workflow files
- Use `rules:` (preferred) or `only/except` for conditional job execution
- GitLab has built-in container registry at `$CI_REGISTRY_IMAGE`
- Scheduled pipelines configured in GitLab UI, not in YAML
- Use `needs:` for job dependencies (DAG mode) instead of linear stages

---

# JENKINS

**For projects using Jenkins CI/CD (self-hosted).**

Jenkins provides equivalent functionality to GitHub Actions, Gitea Actions, and GitLab CI for self-hosted environments.

## Configuration

| Setting | Value |
|---------|-------|
| Agents | `arm64`, `amd64` (both required) |
| Build | All 8 platforms in parallel |
| Triggers | Tag push, beta branch, main/master, scheduled daily |

## Triggers (Matching GitHub Actions)

| Trigger | Jenkins Config | Equivalent To |
|---------|----------------|---------------|
| Tag push | `when { buildingTag() }` | `release.yml` |
| Beta branch | `when { branch 'beta' }` | `beta.yml` |
| Main/master | `when { anyOf { branch 'main'; branch 'master' } }` | `daily.yml` |
| Scheduled | `triggers { cron('0 3 * * *') }` | `daily.yml` schedule |
| All branches | Default (no `when`) | `docker.yml` |

## Jenkinsfile

All projects MUST have a `Jenkinsfile` in the repository root.

```groovy
pipeline {
    agent none

    triggers {
        // Daily build at 3am UTC (matches GitHub Actions daily.yml)
        cron('0 3 * * *')
    }

    environment {
        PROJECTNAME = 'weather'
        PROJECTORG = 'apimgr'
        BINDIR = 'binaries'
        RELDIR = 'releases'
        GODIR = "/tmp/${PROJECTORG}/go"
        GOCACHE = "/tmp/${PROJECTORG}/go/build"

        // =========================================================================
        // GIT PROVIDER CONFIGURATION
        // Uncomment ONE block below based on your git hosting platform
        // =========================================================================

        // ----- GITHUB (default) -----
        GIT_FQDN = 'github.com'
        GIT_TOKEN = credentials('github-token')  // Jenkins credentials ID
        REGISTRY = "ghcr.io/${PROJECTORG}/$WEATHER"

        // ----- GITEA / FORGEJO (self-hosted) -----
        // GIT_FQDN = 'git.example.com'  // Your Gitea/Forgejo domain
        // GIT_TOKEN = credentials('gitea-token')  // Jenkins credentials ID
        // REGISTRY = "${GIT_FQDN}/${PROJECTORG}/$WEATHER"

        // ----- GITLAB (gitlab.com or self-hosted) -----
        // GIT_FQDN = 'gitlab.com'  // or your self-hosted GitLab domain
        // GIT_TOKEN = credentials('gitlab-token')  // Jenkins credentials ID
        // REGISTRY = "registry.${GIT_FQDN}/${PROJECTORG}/$WEATHER"

        // ----- DOCKER HUB -----
        // GIT_FQDN = 'github.com'  // Git host (separate from registry)
        // GIT_TOKEN = credentials('github-token')
        // REGISTRY = "docker.io/${PROJECTORG}/$WEATHER"

        // =========================================================================
    }

    stages {
        stage('Setup') {
            agent { label 'amd64' }
            steps {
                script {
                    // Determine build type and version
                    if (env.TAG_NAME) {
                        // Release build (tag push) - matches release.yml
                        env.BUILD_TYPE = 'release'
                        env.VERSION = env.TAG_NAME.replaceFirst('^v', '')
                    } else if (env.BRANCH_NAME == 'beta') {
                        // Beta build - matches beta.yml
                        env.BUILD_TYPE = 'beta'
                        env.VERSION = sh(script: 'date -u +"%Y%m%d%H%M%S"', returnStdout: true).trim() + '-beta'
                    } else if (env.BRANCH_NAME == 'main' || env.BRANCH_NAME == 'master') {
                        // Daily build - matches daily.yml
                        env.BUILD_TYPE = 'daily'
                        env.VERSION = sh(script: 'date -u +"%Y%m%d%H%M%S"', returnStdout: true).trim()
                    } else {
                        // Other branches - dev build
                        env.BUILD_TYPE = 'dev'
                        env.VERSION = sh(script: 'date -u +"%Y%m%d%H%M%S"', returnStdout: true).trim() + '-dev'
                    }
                    env.COMMIT_ID = sh(script: 'git rev-parse --short HEAD', returnStdout: true).trim()
                    env.BUILD_DATE = sh(script: 'date +"%a %b %d, %Y at %H:%M:%S %Z"', returnStdout: true).trim()
                    env.LDFLAGS = "-s -w -X 'main.Version=${env.VERSION}' -X 'main.CommitID=${env.COMMIT_ID}' -X 'main.BuildDate=${env.BUILD_DATE}'"
                    env.HAS_CLI = sh(script: '[ -d src/client ] && echo true || echo false', returnStdout: true).trim()
                }
                sh 'mkdir -p ${BINDIR} ${RELDIR}'
                echo "Build type: ${BUILD_TYPE}, Version: ${VERSION}"
            }
        }

        stage('Build Server') {
            parallel {
                // Linux
                stage('Linux AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=linux \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-linux-amd64 ./src
                        '''
                    }
                }
                stage('Linux ARM64') {
                    agent { label 'arm64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=linux \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-linux-arm64 ./src
                        '''
                    }
                }
                // Darwin (macOS)
                stage('Darwin AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=darwin \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-darwin-amd64 ./src
                        '''
                    }
                }
                stage('Darwin ARM64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=darwin \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-darwin-arm64 ./src
                        '''
                    }
                }
                // Windows
                stage('Windows AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=windows \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-windows-amd64.exe ./src
                        '''
                    }
                }
                stage('Windows ARM64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=windows \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-windows-arm64.exe ./src
                        '''
                    }
                }
                // FreeBSD
                stage('FreeBSD AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=freebsd \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-freebsd-amd64 ./src
                        '''
                    }
                }
                stage('FreeBSD ARM64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=freebsd \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-freebsd-arm64 ./src
                        '''
                    }
                }
            }
        }

        // CLI builds - only if src/client/ exists (matches GitHub Actions)
        stage('Build CLI') {
            when {
                expression { env.HAS_CLI == 'true' }
            }
            parallel {
                stage('CLI Linux AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=linux \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-cli-linux-amd64 ./src/client
                        '''
                    }
                }
                stage('CLI Linux ARM64') {
                    agent { label 'arm64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=linux \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-cli-linux-arm64 ./src/client
                        '''
                    }
                }
                stage('CLI Darwin AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=darwin \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-cli-darwin-amd64 ./src/client
                        '''
                    }
                }
                stage('CLI Darwin ARM64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=darwin \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-cli-darwin-arm64 ./src/client
                        '''
                    }
                }
                stage('CLI Windows AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=windows \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-cli-windows-amd64.exe ./src/client
                        '''
                    }
                }
                stage('CLI Windows ARM64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=windows \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-cli-windows-arm64.exe ./src/client
                        '''
                    }
                }
                stage('CLI FreeBSD AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=freebsd \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-cli-freebsd-amd64 ./src/client
                        '''
                    }
                }
                stage('CLI FreeBSD ARM64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GODIR}:/go \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=freebsd \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$WEATHER-cli-freebsd-arm64 ./src/client
                        '''
                    }
                }
            }
        }

        stage('Test') {
            agent { label 'amd64' }
            steps {
                sh '''
                    docker run --rm \
                        -v ${WORKSPACE}:/build \
                        -v ${GOCACHE}:/root/.cache/go-build \
                        -v ${GODIR}:/go \
                        -w /build \
                        golang:alpine \
                        go test -v -cover ./...
                '''
            }
        }

        // Stable Release - matches release.yml (tag push only)
        stage('Release: Stable') {
            agent { label 'amd64' }
            when {
                expression { env.BUILD_TYPE == 'release' }
            }
            steps {
                sh '''
                    echo "${VERSION}" > ${RELDIR}/version.txt

                    for f in ${BINDIR}/$WEATHER-*; do
                        [ -f "$f" ] || continue
                        cp "$f" ${RELDIR}/
                    done

                    tar --exclude='.git' --exclude='.github' --exclude='.gitea' \
                        --exclude='.forgejo' --exclude='binaries' --exclude='releases' \
                        --exclude='*.tar.gz' \
                        -czf ${RELDIR}/$WEATHER-${VERSION}-source.tar.gz .
                '''
                archiveArtifacts artifacts: 'releases/*', fingerprint: true
            }
        }

        // Beta Release - matches beta.yml (beta branch only)
        stage('Release: Beta') {
            agent { label 'amd64' }
            when {
                expression { env.BUILD_TYPE == 'beta' }
            }
            steps {
                sh '''
                    echo "${VERSION}" > ${RELDIR}/version.txt

                    for f in ${BINDIR}/$WEATHER-*; do
                        [ -f "$f" ] || continue
                        cp "$f" ${RELDIR}/
                    done
                '''
                archiveArtifacts artifacts: 'releases/*', fingerprint: true
            }
        }

        // Daily Release - matches daily.yml (main/master + scheduled)
        stage('Release: Daily') {
            agent { label 'amd64' }
            when {
                expression { env.BUILD_TYPE == 'daily' }
            }
            steps {
                sh '''
                    echo "${VERSION}" > ${RELDIR}/version.txt

                    for f in ${BINDIR}/$WEATHER-*; do
                        [ -f "$f" ] || continue
                        cp "$f" ${RELDIR}/
                    done
                '''
                archiveArtifacts artifacts: 'releases/*', fingerprint: true
            }
        }

        // Docker - matches docker.yml (ALL branches and tags)
        stage('Docker') {
            agent { label 'amd64' }
            steps {
                script {
                    def tags = "-t ${REGISTRY}:${COMMIT_ID}"

                    if (env.BUILD_TYPE == 'release') {
                        // Release tag - version, latest, YYMM
                        def yymm = new Date().format('yyMM')
                        tags += " -t ${REGISTRY}:${VERSION}"
                        tags += " -t ${REGISTRY}:latest"
                        tags += " -t ${REGISTRY}:${yymm}"
                    } else if (env.BUILD_TYPE == 'beta') {
                        // Beta branch - beta, devel
                        tags += " -t ${REGISTRY}:beta"
                        tags += " -t ${REGISTRY}:devel"
                    } else {
                        // All other branches - devel only
                        tags += " -t ${REGISTRY}:devel"
                    }

                    // Login to container registry
                    // Works with: ghcr.io, registry.gitlab.com, gitea/forgejo, docker.io
                    sh """
                        echo "\${GIT_TOKEN}" | docker login ${REGISTRY.split('/')[0]} -u ${PROJECTORG} --password-stdin
                    """

                    // Build multi-arch with OCI labels and manifest annotations
                    sh """
                        docker buildx create --name $WEATHER-builder --use 2>/dev/null || docker buildx use $WEATHER-builder
                        docker buildx build \
                            -f docker/Dockerfile \
                            --platform linux/amd64,linux/arm64 \
                            --build-arg VERSION="${VERSION}" \
                            --build-arg COMMIT_ID="${COMMIT_ID}" \
                            --build-arg BUILD_DATE="${BUILD_DATE}" \
                            --label "org.opencontainers.image.vendor=${PROJECTORG}" \
                            --label "org.opencontainers.image.authors=${PROJECTORG}" \
                            --label "org.opencontainers.image.title=$WEATHER" \
                            --label "org.opencontainers.image.base.name=$WEATHER" \
                            --label "org.opencontainers.image.description=Containerized version of $WEATHER" \
                            --label "org.opencontainers.image.licenses=MIT" \
                            --label "org.opencontainers.image.version=${VERSION}" \
                            --label "org.opencontainers.image.created=${BUILD_DATE}" \
                            --label "org.opencontainers.image.revision=${COMMIT_ID}" \
                            --label "org.opencontainers.image.url=https://${GIT_FQDN}/${PROJECTORG}/$WEATHER" \
                            --label "org.opencontainers.image.source=https://${GIT_FQDN}/${PROJECTORG}/$WEATHER" \
                            --label "org.opencontainers.image.documentation=https://${GIT_FQDN}/${PROJECTORG}/$WEATHER" \
                            --annotation "manifest:org.opencontainers.image.vendor=${PROJECTORG}" \
                            --annotation "manifest:org.opencontainers.image.authors=${PROJECTORG}" \
                            --annotation "manifest:org.opencontainers.image.title=$WEATHER" \
                            --annotation "manifest:org.opencontainers.image.description=Containerized version of $WEATHER" \
                            --annotation "manifest:org.opencontainers.image.licenses=MIT" \
                            --annotation "manifest:org.opencontainers.image.version=${VERSION}" \
                            --annotation "manifest:org.opencontainers.image.created=${BUILD_DATE}" \
                            --annotation "manifest:org.opencontainers.image.revision=${COMMIT_ID}" \
                            --annotation "manifest:org.opencontainers.image.url=https://${GIT_FQDN}/${PROJECTORG}/$WEATHER" \
                            --annotation "manifest:org.opencontainers.image.source=https://${GIT_FQDN}/${PROJECTORG}/$WEATHER" \
                            --annotation "manifest:org.opencontainers.image.documentation=https://${GIT_FQDN}/${PROJECTORG}/$WEATHER" \
                            ${tags} \
                            --push \
                            .
                    """
                }
            }
        }

        // Docker All-in-One - matches docker.yml build-aio (ALL branches and tags)
        // AIO uses separate image name: {repo}-aio:{tag}
        stage('Docker AIO') {
            agent { label 'amd64' }
            steps {
                script {
                    def aioRegistry = "${REGISTRY}-aio"
                    def tags = "-t ${aioRegistry}:${COMMIT_ID}"

                    if (env.BUILD_TYPE == 'release') {
                        // Release tag - version, latest, YYMM
                        def yymm = new Date().format('yyMM')
                        tags += " -t ${aioRegistry}:${VERSION}"
                        tags += " -t ${aioRegistry}:latest"
                        tags += " -t ${aioRegistry}:${yymm}"
                    } else if (env.BUILD_TYPE == 'beta') {
                        // Beta branch - beta, devel
                        tags += " -t ${aioRegistry}:beta"
                        tags += " -t ${aioRegistry}:devel"
                    } else {
                        // All other branches - devel only
                        tags += " -t ${aioRegistry}:devel"
                    }

                    // Login to container registry
                    sh """
                        echo "\${GIT_TOKEN}" | docker login ${REGISTRY.split('/')[0]} -u ${PROJECTORG} --password-stdin
                    """

                    // Build multi-arch all-in-one with OCI labels and manifest annotations
                    sh """
                        docker buildx create --name $WEATHER-builder --use 2>/dev/null || docker buildx use $WEATHER-builder
                        docker buildx build \
                            -f docker/Dockerfile.aio \
                            --platform linux/amd64,linux/arm64 \
                            --build-arg VERSION="${VERSION}" \
                            --build-arg COMMIT_ID="${COMMIT_ID}" \
                            --build-arg BUILD_DATE="${BUILD_DATE}" \
                            --label "org.opencontainers.image.vendor=${PROJECTORG}" \
                            --label "org.opencontainers.image.authors=${PROJECTORG}" \
                            --label "org.opencontainers.image.title=$WEATHER-aio" \
                            --label "org.opencontainers.image.description=$WEATHER - all-in-one (debian + postgresql + valkey + tor)" \
                            --label "org.opencontainers.image.licenses=MIT" \
                            --label "org.opencontainers.image.version=${VERSION}" \
                            --label "org.opencontainers.image.created=${BUILD_DATE}" \
                            --label "org.opencontainers.image.revision=${COMMIT_ID}" \
                            --label "org.opencontainers.image.url=https://${GIT_FQDN}/${PROJECTORG}/$WEATHER" \
                            --label "org.opencontainers.image.source=https://${GIT_FQDN}/${PROJECTORG}/$WEATHER" \
                            --label "org.opencontainers.image.documentation=https://${GIT_FQDN}/${PROJECTORG}/$WEATHER" \
                            --annotation "manifest:org.opencontainers.image.vendor=${PROJECTORG}" \
                            --annotation "manifest:org.opencontainers.image.authors=${PROJECTORG}" \
                            --annotation "manifest:org.opencontainers.image.title=$WEATHER-aio" \
                            --annotation "manifest:org.opencontainers.image.description=$WEATHER - all-in-one (debian + postgresql + valkey + tor)" \
                            --annotation "manifest:org.opencontainers.image.licenses=MIT" \
                            --annotation "manifest:org.opencontainers.image.version=${VERSION}" \
                            --annotation "manifest:org.opencontainers.image.created=${BUILD_DATE}" \
                            --annotation "manifest:org.opencontainers.image.revision=${COMMIT_ID}" \
                            --annotation "manifest:org.opencontainers.image.url=https://${GIT_FQDN}/${PROJECTORG}/$WEATHER" \
                            --annotation "manifest:org.opencontainers.image.source=https://${GIT_FQDN}/${PROJECTORG}/$WEATHER" \
                            --annotation "manifest:org.opencontainers.image.documentation=https://${GIT_FQDN}/${PROJECTORG}/$WEATHER" \
                            ${tags} \
                            --push \
                            .
                    """
                }
            }
        }
    }

    post {
        always {
            cleanWs()
        }
    }
}
```

## Jenkins Configuration

### Required Settings

| Setting | Value |
|---------|-------|
| Agent labels | `amd64` and `arm64` MUST be available |
| Docker | Required on all agents (builds use golang:alpine) |
| Docker buildx | Required on amd64 agent for multi-arch builds |
| Go caches | `/tmp/apimgr/go-cache` and `/tmp/apimgr/go-mod-cache` |

### Credentials Setup (Jenkins → Credentials → Add Credentials)

Create a **Secret text** credential for your git provider's API token:

| Git Provider | Credential ID | Token Source |
|--------------|---------------|--------------|
| GitHub | `github-token` | Settings → Developer settings → Personal access tokens |
| Gitea | `gitea-token` | User Settings → Applications → Access Tokens |
| Forgejo | `forgejo-token` | User Settings → Applications → Access Tokens |
| GitLab | `gitlab-token` | User Settings → Access Tokens |
| Docker Hub | `dockerhub-token` | Account Settings → Security → Access Tokens |

**Required Token Permissions:**

| Provider | Permissions |
|----------|-------------|
| GitHub | `write:packages`, `read:packages`, `delete:packages` |
| Gitea/Forgejo | `package:write` (or `write:package`) |
| GitLab | `write_registry`, `read_registry` |
| Docker Hub | Read/Write access |

### Provider Configuration

In the Jenkinsfile, uncomment the appropriate block:

```groovy
// ----- GITHUB (default) -----
GIT_FQDN = 'github.com'
GIT_TOKEN = credentials('github-token')
REGISTRY = "ghcr.io/${PROJECTORG}/$WEATHER"

// ----- GITEA / FORGEJO (self-hosted) -----
// GIT_FQDN = 'git.example.com'
// GIT_TOKEN = credentials('gitea-token')
// REGISTRY = "${GIT_FQDN}/${PROJECTORG}/$WEATHER"

// ----- GITLAB (gitlab.com or self-hosted) -----
// GIT_FQDN = 'gitlab.com'
// GIT_TOKEN = credentials('gitlab-token')
// REGISTRY = "registry.${GIT_FQDN}/${PROJECTORG}/$WEATHER"
```

### Triggers Comparison

| Release Type | GitHub Actions | Jenkins |
|--------------|----------------|---------|
| Stable | `release.yml` (tag push) | `BUILD_TYPE == 'release'` (tag) |
| Beta | `beta.yml` (beta branch) | `BUILD_TYPE == 'beta'` (beta branch) |
| Daily | `daily.yml` (schedule + main) | `BUILD_TYPE == 'daily'` (cron + main/master) |
| Docker | `docker.yml` (all branches) | Docker stage (always runs) |

---

# CHECKPOINT 5: BUILD & DEPLOYMENT VERIFICATION

Before proceeding, confirm you understand:
- [ ] Docker uses tini as init, Alpine base
- [ ] Makefile has exactly 4 targets: build, release, docker, test
- [ ] Binary naming: NEVER include -musl suffix
- [ ] All 8 platform builds required (4 OS x 2 arch)
- [ ] CLI builds (if src/client/ exists): 8 additional binaries with `-cli` suffix

**CI/CD Equivalence:**

| Feature | GitHub Actions | Gitea/Forgejo | GitLab CI | Jenkins |
|---------|----------------|---------------|-----------|---------|
| Stable release | `release.yml` | `release.yml` | `rules: tag` | `BUILD_TYPE == 'release'` |
| Beta release | `beta.yml` | `beta.yml` | `rules: beta` | `BUILD_TYPE == 'beta'` |
| Daily release | `daily.yml` | `daily.yml` | `rules: schedule` | `BUILD_TYPE == 'daily'` |
| Docker images | `docker.yml` | `docker.yml` | `docker:build` | Docker stage |
| Self-hosted | No | Yes | Yes | Yes |

---

# PART 29: TESTING & DEVELOPMENT (NON-NEGOTIABLE)

## NEVER Use Project Directory for Testing (NON-NEGOTIABLE)

**See Critical Rules: Files & Directories Master Rules for complete forbidden lists.**

**Testing Rule:** ALL runtime/test data MUST use temp directories:

| REQUIRED | Example |
|----------|---------|
| Temp directory | `/tmp/apimgr/weather-XXXXXX/` |
| Volume mounts | `/tmp/apimgr/weather-XXXXXX/rootfs/` |
| Test databases | In temp directory, never project |

**The project directory is for SOURCE CODE ONLY. All runtime/test data goes to the OS temp directory.**

## Config Files: Runtime-Generated Only (NON-NEGOTIABLE)

**See Critical Rules: Files & Directories Master Rules - "NEVER Create These Files"**

Config files are NEVER in the repository. They are generated at RUNTIME:

| File | Location | Created When |
|------|----------|--------------|
| `server.yml` | `{config_dir}/server.yml` (see PART 4) | Server first run |
| `cli.yml` | `~/.config/apimgr/weather/cli.yml` | CLI first run |
| Tor data | `{data_dir}/tor/` (see PART 32) | When Tor enabled |

**Why runtime-generated?**

| Reason | Benefit |
|--------|---------|
| **Always current** | Embedded defaults always in sync with code |
| **No maintenance** | No example files to become outdated |
| **Cleaner repo** | Source code only, no runtime artifacts |

**How configuration works:**

1. **First run** - Binary auto-generates config in OS config directory with sane defaults
2. **Flags/env override** - Command-line flags and environment variables override config
3. **Admin panel** - Web UI for all settings (server)
4. **Manual edit** - Users can edit generated config file if needed

**Configuration precedence (highest to lowest):**
1. Command-line flags
2. Environment variables
3. Config file (in OS config directory)
4. Embedded defaults

## Temporary Directory Structure (NON-NEGOTIABLE)

**CRITICAL: NEVER use `/tmp` root directory directly. ALWAYS use `/tmp/apimgr/weather-XXXXXX` structure.**

**FORBIDDEN:**
- ❌ `/tmp/myfile` - Root tmp directory
- ❌ `/tmp/weather` - Missing org prefix
- ❌ `mktemp -d` - No org/project structure
- ❌ `/tmp/test-data` - Generic paths

**REQUIRED:**
- ✓ `/tmp/apimgr/weather-XXXXXX/` - Full structure
- ✓ `/tmp/cloudops/echoip-aB3xY9/` - Org + project + random
- ✓ `mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}/$WEATHER-XXXXXX"` - Proper command

**See "Inferring Variables from Path" section for how to detect `ORG` and `PROJECT`.**

### Creating Temp Directories

**Always use `apimgr/weather-` structure for identifiable temp dirs:**

| Language | How to Create Prefixed Temp Dir |
|----------|--------------------------------|
| Shell | `mkdir -p "${TMPDIR:-/tmp}/${PROJECTORG}" && mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}/$WEATHER-XXXXXX"` |
| Go | `os.MkdirAll(filepath.Join(os.TempDir(), projectOrg), 0755); os.MkdirTemp(filepath.Join(os.TempDir(), projectOrg), projectName+"-")` |
| Python | `os.makedirs(f"{tempfile.gettempdir()}/{project_org}", exist_ok=True); tempfile.mkdtemp(prefix=f"{project_name}-", dir=f"{tempfile.gettempdir()}/{project_org}")` |

**Result:** `/tmp/cloudops/echoip-aB3xY9` or `/tmp/netutils/pastebin-k9mN2p` (identifiable by org and project)

### Directory Structure

| Purpose | Path Pattern | Example |
|---------|--------------|---------|
| Dev/Test runtime | `{tempdir}/apimgr/weather-XXXXXX/` | `/tmp/apimgr/weather-aB3xY9/` |
| Config volume | `{tempdir}/apimgr/weather-XXXXXX/rootfs/config/` | `/tmp/apimgr/weather-aB3xY9/rootfs/config/` |
| Data volume | `{tempdir}/apimgr/weather-XXXXXX/rootfs/data/` | `/tmp/apimgr/weather-aB3xY9/rootfs/data/` |

### OS Temp Directories

| OS | Default Temp Dir | Env Var |
|----|------------------|---------|
| Linux | `/tmp` | `$TMPDIR` |
| macOS | `/var/folders/.../T/` | `$TMPDIR` |
| Windows | `C:\Users\{user}\AppData\Local\Temp` | `%TEMP%` |
| FreeBSD | `/tmp` | `$TMPDIR` |

### Rules

| Rule | Description |
|------|-------------|
| **NEVER** | Use project directory for test/runtime data |
| **NEVER** | Hardcode `/tmp` - use `os.TempDir()` or `mktemp` |
| **NEVER** | Use bare `mktemp -d` without org prefix |
| **ALWAYS** | Use `apimgr.` prefix for all temp dirs |
| **ALWAYS** | Detect org from git remote or directory path |

### Cleanup

```bash
# Find all temp dirs for this org
ls -la "${TMPDIR:-/tmp}"/${PROJECTORG}.*/

# Clean all temp dirs for this org
rm -rf "${TMPDIR:-/tmp}"/${PROJECTORG}.*/
```

### Correct vs Incorrect

| WRONG | RIGHT | Why |
|-------|-------|-----|
| `/tmp/` | `/tmp/apimgr/weather-XXXXXX/` | NEVER use root tmp |
| `/tmp/myfile` | `/tmp/cloudops/echoip-aB3xY9/myfile` | Always use org/project structure |
| `/tmp/echoip` | `/tmp/cloudops/echoip-kL9mN2/` | Missing org, missing random suffix |
| `/tmp/test-data/` | `/tmp/devtools/quotesvc-Qw5rT1/test-data/` | Generic path not allowed |
| `mktemp -d` | `mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}/$WEATHER-XXXXXX"` | Must include org/project |
| `os.TempDir()` alone | `os.MkdirTemp(filepath.Join(os.TempDir(), projectOrg), projectName+"-")` | Must nest under org |
| Hardcoded org name | Detect from git remote or path | Auto-detect, never hardcode |

**Rule: ALL temp directories MUST be under `/tmp/apimgr/weather-XXXXXX/` - no exceptions.**

### Summary: Temp Directory Rules

**The ONLY acceptable temp directory pattern:**
```
/tmp/apimgr/weather-XXXXXX/
```

**Breaking it down:**
- `/tmp/` or `$TMPDIR` - OS temp directory base
- `apimgr/` - Organization directory (cloudops, acmesoft, etc.)
- `weather-XXXXXX` - Project directory with random suffix

**Examples of CORRECT paths:**
- `/tmp/cloudops/echoip-aB3xY9/` ✓
- `/tmp/netutils/pastebin-k9mN2p/` ✓
- `/tmp/apimgr/jokes-Qw5rT1/` ✓

**Examples of WRONG paths:**
- `/tmp/echoip/` ❌ (missing org)
- `/tmp/myfile` ❌ (no structure at all)
- `/tmp/test-data/` ❌ (generic path)
- `/tmp/cloudops/` ❌ (no project directory)

**Why this structure:**
- Prevents conflicts between projects
- Makes cleanup easy (`rm -rf /tmp/apimgr.*`)
- Identifies which project created temp files
- Prevents pollution of root `/tmp` directory
- Multiple projects can run simultaneously

## Container Usage (NON-NEGOTIABLE)

**⚠️ NEVER RUN BINARIES DIRECTLY ON THE HOST. ALWAYS USE CONTAINERS. ⚠️**

**See also: "Container-Only Development" in Critical Rules section.**

**ALL builds, tests, and binary execution MUST use containers. The host is for orchestration only.**

| Rule | Description |
|------|-------------|
| **Host has NO Go** | Go is NOT installed on the host - don't even try |
| **NEVER run binaries on host** | All binaries run inside containers, never directly |
| **NEVER** | Run `go build` directly on host |
| **NEVER** | Run `go test` directly on host |
| **NEVER** | Run `binaries/weather` on host |
| **NEVER** | Run `$BUILD_DIR/weather` on host |
| **ALWAYS** | Build inside container, run inside container |

### Container Types

| Purpose | Tool | Image | When to Use |
|---------|------|-------|-------------|
| **Building** | Docker | `golang:alpine` | Compiling Go code |
| **Container testing** | Docker | `alpine:latest` | Quick tests, CI/CD |
| **Full OS testing** | Incus | `debian:latest` | Systemd, services, integration |

### Testing Strategy

**Two types of tests are REQUIRED:**

| Test Type | Files | Run With | Tests |
|-----------|-------|----------|-------|
| **Go Unit Tests** | `*_test.go` | `go test` | Function/package logic, no server |
| **Integration Tests** | `tests/*.sh` | Shell scripts | Full server, API endpoints, auth |

**Go Unit Tests (`*_test.go`):**
- Test individual functions and packages
- No server running required
- Fast, run frequently during development
- Run with `make test`

**Integration Tests (`tests/*.sh`):**
- Test complete running server
- Test API endpoints, .txt extension, Accept headers
- Test authentication, admin routes
- Test project-specific functionality (from PART 37)
- Run with `./tests/run_tests.sh`

### Testing Requirements Summary

**BOTH types of tests are REQUIRED for all projects:**

1. **Go Unit Tests** (`*_test.go`) - Test package logic
2. **Integration Tests** (`tests/*.sh`) - Test full running application

**Integration tests MUST be comprehensive:**
- ✓ Test ALL project-specific endpoints (PART 37)
- ✓ If project has CRUD → Test full CRUD (Create, Read, Update, Delete)
- ✓ Test both API endpoints (`/api/v1/*`) AND frontend routes (`/**`)
- ✓ Test API .txt extension (for simplicity)
- ✓ Test Accept headers (application/json, text/plain, text/html)
- ✓ Test frontend smart detection (browser → HTML, CLI → text)
- ✓ Test authentication (admin, user if applicable)

**Example: User management project MUST test:**
```bash
# API CRUD (JSON)
POST   /api/v1/users           # Create user (API JSON)
GET    /api/v1/users/1         # Read user (API JSON)
PUT    /api/v1/users/1         # Update user (API JSON)
DELETE /api/v1/users/1         # Delete user (API)

# API .txt extension (for simplicity)
GET    /api/v1/users/1.txt     # Read user (API plain text)

# Frontend routes (smart detection)
curl /users                    # CLI → plain text (smart detection)
browser /users                 # Browser → HTML page (smart detection)
curl -H "Accept: text/plain" /users/1   # Plain text (Accept header)
curl -H "Accept: text/html" /users/1    # HTML (Accept header)
```

**Example: Jokes API (read-only) MUST test:**
```bash
# API endpoints
GET /api/v1/jokes/random             # Random joke (JSON)
GET /api/v1/jokes/random.txt         # Random joke (text)
GET /api/v1/jokes/programming        # Category filter (JSON)
GET /api/v1/jokes/search?q=bug       # Search (JSON)

# Frontend endpoints (smart detection)
curl /jokes/random                   # CLI auto-detects → text
curl /jokes                          # CLI → text list
curl -H "Accept: text/html" /jokes   # Browser → HTML
```

**Example: Weather API (external integration) MUST test:**
```bash
# API endpoints with location params
GET /api/v1/weather/current/New%20York        # Current weather (JSON)
GET /api/v1/weather/current/New%20York.txt    # Current weather (text)
GET /api/v1/weather/forecast/10001            # ZIP code forecast (JSON)
GET /api/v1/weather/alerts/40.7128,-74.0060   # Lat/long alerts (JSON)

# Test caching behavior
GET /api/v1/weather/current/Chicago           # First call (cache miss)
GET /api/v1/weather/current/Chicago           # Second call (cache hit, faster)

# Frontend (smart detection)
curl /weather/Chicago                # CLI → text
curl /weather/forecast/90210         # CLI → text forecast
```

**Example: Link Shortener (URL mapping) MUST test:**
```bash
# API CRUD for short links
POST   /api/v1/links -d '{"url":"https://example.com/long/url"}'  # Create
GET    /api/v1/links/abc123         # Get link details (JSON)
PUT    /api/v1/links/abc123 -d '{"url":"https://new.com"}'        # Update
DELETE /api/v1/links/abc123         # Delete

# Redirect resolution
GET /abc123                          # Should redirect to destination
GET /abc123/stats                    # Link statistics (JSON or HTML)

# Frontend (smart detection)
curl /links                          # User's links list (text)
curl /links/abc123                   # Link details (text)
```

### Go Unit Test Requirements

**Every package with logic SHOULD have unit tests:**

| Package | Test File | What to Test |
|---------|-----------|--------------|
| `config/` | `config_test.go` | Config loading, validation, defaults |
| `server/` | `server_test.go` | Route registration, middleware |
| `server/handler/` | `*_handler_test.go` | Handler logic (mock requests) |
| `mode/` | `mode_test.go` | Mode detection, behavior |
| `ssl/` | `ssl_test.go` | Certificate loading, validation |
| `paths/` | `paths_test.go` | Path resolution |

**What to test in unit tests:**
- ✓ Function inputs/outputs
- ✓ Edge cases and error handling
- ✓ Validation logic
- ✓ Data transformations
- ✓ Business logic without dependencies

**What NOT to test in unit tests:**
- ✗ Full HTTP requests (use integration tests)
- ✗ Database operations (use integration tests)
- ✗ External services (use integration tests)
- ✗ Authentication flows (use integration tests)

**Running Go tests:**
```bash
# Run all unit tests
make test
```

**Note:** Makefile targets use Docker internally. See PART 26 for underlying commands.

## 100% Test Coverage (NON-NEGOTIABLE)

**ALL code MUST have 100% test coverage. No exceptions.**

### Coverage Requirements

| Coverage Type | Requirement | Verification |
|--------------|-------------|--------------|
| **Go Unit Tests** | 100% code coverage | `go test -cover` must report 100% |
| **Integration Tests** | 100% endpoint coverage | Every endpoint tested |
| **Admin Routes** | 100% route coverage | Every admin route tested |
| **Error Paths** | 100% error handling | All error conditions tested |

### What 100% Coverage Means

**Go Code (Unit Tests):**
```bash
# Run tests with coverage enforcement (fails if below 100%)
make test
```

**Endpoints (Integration Tests):**

| Endpoint Type | Must Test |
|--------------|-----------|
| **Public API** | All `/api/v1/*` endpoints |
| **Public Web** | All frontend routes |
| **Admin API** | All `/api/v1/admin/*` endpoints |
| **Admin Web** | All `/{adminpath}/*` routes |
| **Error cases** | 400, 401, 403, 404, 500 responses |
| **Edge cases** | Empty data, invalid input, rate limits |

### Coverage Enforcement

**In CI/CD Pipeline (REQUIRED):**

```yaml
# .github/workflows/test.yml
test:
  runs-on: ubuntu-latest
  steps:
    - uses: actions/checkout@v4

    - name: Run tests with coverage
      run: |
        docker run --rm -v $(pwd):/build -w /build golang:alpine \
          go test -cover -coverprofile=coverage.out ./...

    - name: Check coverage is 100%
      run: |
        COVERAGE=$(docker run --rm -v $(pwd):/build -w /build golang:alpine \
          go tool cover -func=coverage.out | grep total | awk '{print $3}' | sed 's/%//')
        if [ $(echo "$COVERAGE < 100" | bc -l) -eq 1 ]; then
          echo "ERROR: Coverage is $COVERAGE%, must be 100%"
          exit 1
        fi
        echo "Coverage: $COVERAGE% ✓"
```

### How to Achieve 100% Coverage

**1. Test All Code Paths:**
```go
// Function with multiple paths
func ValidateInput(input string) error {
    if input == "" {
        return ErrEmpty  // Test this path
    }
    if len(input) > 100 {
        return ErrTooLong  // Test this path
    }
    if !isValid(input) {
        return ErrInvalid  // Test this path
    }
    return nil  // Test this path
}

// Tests must cover ALL paths
func TestValidateInput(t *testing.T) {
    tests := []struct {
        name    string
        input   string
        wantErr error
    }{
        {"empty", "", ErrEmpty},
        {"too long", strings.Repeat("a", 101), ErrTooLong},
        {"invalid", "bad@input", ErrInvalid},
        {"valid", "good-input", nil},
    }
    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            err := ValidateInput(tt.input)
            if err != tt.wantErr {
                t.Errorf("got %v, want %v", err, tt.wantErr)
            }
        })
    }
}
```

**2. Test Error Handlers:**
```go
// Error handler must be tested
func handleError(err error) string {
    if errors.Is(err, ErrNotFound) {
        return "Not found"
    }
    if errors.Is(err, ErrForbidden) {
        return "Forbidden"
    }
    return "Internal error"
}

// Test ALL error types
func TestHandleError(t *testing.T) {
    tests := []struct {
        err  error
        want string
    }{
        {ErrNotFound, "Not found"},
        {ErrForbidden, "Forbidden"},
        {errors.New("random"), "Internal error"},
    }
    // ...
}
```

**3. Test All Endpoints:**
```bash
#!/bin/bash
# tests/test_all_endpoints.sh

# Track coverage
declare -A TESTED_ENDPOINTS

# Test each endpoint
test_endpoint() {
    local method=$1
    local path=$2
    TESTED_ENDPOINTS["$method $path"]=1
    # ... test logic
}

# PUBLIC API
test_endpoint GET "/api/v1/jokes/random"
test_endpoint GET "/api/v1/jokes/categories"
test_endpoint GET "/api/v1/jokes/{id}"

# ADMIN API (with auth)
test_endpoint GET "/api/v1/admin/server/settings"
test_endpoint PUT "/api/v1/admin/server/settings"
test_endpoint GET "/api/v1/admin/server/logs"

# At end: verify ALL endpoints were tested
verify_all_endpoints_tested
```

### What Counts as Tested

| ✓ Counts | ✗ Does NOT Count |
|----------|------------------|
| Actual function call in test | Comment saying "tested manually" |
| Assert on return value | Print statement without assert |
| Error path exercised | Only happy path tested |
| All branches covered | Just main branch |
| Integration test hits endpoint | Documentation says it works |

### Coverage Exceptions (NONE)

**There are NO exceptions to 100% coverage:**

| Common Excuse | Response |
|--------------|----------|
| "It's just a simple getter" | Test it anyway |
| "The code is obvious" | Obvious code can still have bugs |
| "It's only used internally" | Internal code needs tests too |
| "I tested it manually" | Manual tests don't count |
| "It's just logging" | Mock the logger and test |
| "It's third-party code" | Test your integration with it |

**When to run which tests:**

| When | Run This | Purpose |
|------|----------|---------|
| **During development** | `make test` (Go unit tests) | Fast feedback, verify logic |
| **Before committing** | `make test` + `./tests/run_tests.sh` | Verify all tests pass |
| **Before release** | `make test` + `./tests/incus.sh` | Full systemd testing |
| **In CI/CD** | Both Go tests and integration tests | Automated verification |

**Test Execution Order:**
```bash
1. make test                    # Go unit tests (fast)
2. ./tests/run_tests.sh         # Integration tests (slower, full coverage)
```

### Integration Testing Strategy

**Preferred: Incus with Debian** (if available)
- Full systemd support
- Complete OS environment
- Service installation testing
- Full integration tests

**Fallback: Docker with golang:alpine**
- When Incus not available
- CI/CD environments
- Quick validation tests

### Incus vs Docker

| Aspect | Incus (Preferred) | Docker (Fallback) |
|--------|-------------------|-------------------|
| **Use for** | Full OS/systemd testing | Container/app testing |
| **Image** | `debian:latest` | `golang:alpine` or `alpine:latest` |
| **Init system** | Full systemd | None (single process) |
| **Best for** | Service install, integration | Quick tests, CI/CD |
| **Startup** | ~5s | Fast (~1s) |
| **Availability** | May not be installed | Always available |

### Testing Workflow

```bash
# 1. Build in Docker (always use Docker for builds)
BUILD_DIR=$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}.XXXXXX")
docker run --rm -v $(pwd):/build -w /build -e CGO_ENABLED=0 \
  golang:alpine go build -o /build/binaries/weather ./src

# 2. Test (prefer Incus, fallback to Docker)
if command -v incus &>/dev/null; then
  # PREFERRED: Full OS test in Incus (debian + systemd)
  # Use latest Debian stable (currently 12/bookworm)
  echo "Testing with Incus (Debian + systemd)..."
  incus launch images:debian/12 test-weather
  incus file push binaries/weather test-weather/usr/local/bin/
  incus exec test-weather -- chmod +x /usr/local/bin/weather
  incus exec test-weather -- weather --help
  incus exec test-weather -- weather --service --install
  incus exec test-weather -- systemctl status weather
  incus delete test-weather --force
else
  # FALLBACK: Quick test in Docker (alpine, no systemd)
  echo "Incus not available, testing with Docker..."
  docker run --rm -v $(pwd)/binaries:/app alpine:latest \
    /app/weather --help
fi
```

### Why Containerized Everything?

| Reason | Description |
|--------|-------------|
| **Clean system** | No Go, no binaries, no artifacts on host |
| **Isolation** | Each test runs in fresh environment |
| **Reproducible** | Same results across all machines |
| **Full OS testing** | Incus provides real systemd for service tests |
| **No pollution** | Host system stays pristine |

### Test Scripts (tests/ directory)

**ALL projects MUST have these test scripts in `tests/` directory:**

| Script | Purpose | Container | Tests |
|--------|---------|-----------|-------|
| `tests/run_tests.sh` | Auto-detect runtime and run tests | Auto-detect | Runs incus.sh or docker.sh |
| `tests/docker.sh` | Beta testing with Docker | `alpine:latest` | Full integration tests |
| `tests/incus.sh` | Beta testing with Incus | `debian:latest` | Full integration + systemd tests |

**docker.sh and incus.sh MUST:**
1. Set up Go cache directories (GODIR/GOCACHE) for faster builds
2. Build all binaries using Docker (golang:alpine) in temp directory:
   - Server (`./src`)
   - CLI client (`./src/client`) if exists
   - Agent (`./src/agent`) if exists
3. Install test tools in container (Docker: `apk add --no-cache curl bash file jq`)
4. Copy binaries to test container
5. Start server and capture logs (for setup token extraction)
6. Run full beta test suite:
   - Version and help checks (server, CLI, agent if built)
   - Binary info verification
   - **Binary rename tests** (copy binary, verify --help shows new name)
   - **Admin setup** (use setup token → create admin → login → generate API token)
   - Test API endpoints (.txt extension, Accept headers)
   - Test frontend smart detection (browser → HTML, CLI → text)
   - Test project-specific endpoints (from PART 37)
   - Test admin authentication (see "Testing Admin Routes")
   - **CLI full functionality** (with API token against running server)
   - **Agent full functionality** (with API token against running server)
7. Clean up on exit

#### tests/docker.sh

**Purpose:** Full integration testing in Docker Alpine container

```bash
#!/usr/bin/env bash
set -euo pipefail

# Detect project info
PROJECTNAME=$(basename "$PWD")
PROJECTORG=$(basename "$(dirname "$PWD")")

# Create temp directory for build
BUILD_DIR=$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}.XXXXXX")
trap "rm -rf $BUILD_DIR" EXIT

# Go cache directories (same as Makefile)
GODIR="${HOME}/.local/share/go"
GOCACHE="${HOME}/.local/share/go/build"
mkdir -p "$GODIR" "$GOCACHE"

# Common docker run for Go builds
GO_DOCKER="docker run --rm \
  -v $(pwd):/build \
  -v ${GOCACHE}:/root/.cache/go-build \
  -v ${GODIR}:/go \
  -w /build \
  -e CGO_ENABLED=0 \
  golang:alpine"

echo "Building server binary in Docker..."
$GO_DOCKER go build -o "$BUILD_DIR/$WEATHER" ./src

# Build CLI client if exists
if [ -d "src/client" ]; then
    echo "Building CLI client in Docker..."
    $GO_DOCKER go build -o "$BUILD_DIR/$WEATHER-cli" ./src/client
fi

# Build agent if exists
if [ -d "src/agent" ]; then
    echo "Building agent in Docker..."
    $GO_DOCKER go build -o "$BUILD_DIR/$WEATHER-agent" ./src/agent
fi

echo "Testing in Docker (Alpine)..."
docker run --rm \
  -v "$BUILD_DIR:/app" \
  alpine:latest sh -c "
    set -e

    # Install required tools for testing
    apk add --no-cache curl bash file jq >/dev/null

    chmod +x /app/$WEATHER
    [ -f /app/$WEATHER-cli ] && chmod +x /app/$WEATHER-cli
    [ -f /app/$WEATHER-agent ] && chmod +x /app/$WEATHER-agent

    echo '=== Version Check ==='
    /app/$WEATHER --version

    echo '=== Help Check ==='
    /app/$WEATHER --help

    echo '=== Binary Info ==='
    ls -lh /app/$WEATHER
    file /app/$WEATHER

    echo '=== Starting Server for API Tests ==='
    /app/$WEATHER --port 64580 > /tmp/server.log 2>&1 &
    SERVER_PID=\$!
    sleep 3
    # Show setup token if present (for debugging)
    grep -i 'setup.*token' /tmp/server.log 2>/dev/null || true

    echo '=== API Endpoint Tests ==='
    # Test JSON response (default)
    curl -f http://localhost:64580/api/v1/healthz || echo 'FAILED: /api/v1/healthz'

    # Test .txt extension (plain text)
    curl -f http://localhost:64580/api/v1/healthz.txt || echo 'FAILED: /api/v1/healthz.txt'

    # Test Accept header: application/json
    curl -f -H 'Accept: application/json' http://localhost:64580/healthz || echo 'FAILED: Accept JSON'

    # Test Accept header: text/plain
    curl -f -H 'Accept: text/plain' http://localhost:64580/healthz || echo 'FAILED: Accept text/plain'

    echo '=== Project-Specific Endpoint Tests ==='
    # MUST test ALL endpoints from PART 37 - both API and frontend
    # Test FULL CRUD if project has CRUD operations
    #
    # Example for jokes API (API routes with .txt extension):
    #   curl -f http://localhost:64580/api/v1/jokes/random || echo 'FAILED: API JSON'
    #   curl -f http://localhost:64580/api/v1/jokes/random.txt || echo 'FAILED: API .txt'
    #   curl -f -H 'Accept: text/plain' http://localhost:64580/api/v1/jokes/random || echo 'FAILED: API Accept text'
    #
    # Example for jokes frontend (smart detection, no .txt - test with text for simplicity):
    #   JOKE=\$(curl -s http://localhost:64580/jokes/random)  # CLI auto-detects text
    #   if echo "\$JOKE" | grep -q "Why"; then echo '✓ Frontend text works'; else echo 'FAILED: Frontend text'; fi
    #   # Optional: verify HTML is served to browsers
    #   curl -f -s -I -H 'Accept: text/html' http://localhost:64580/jokes/random | grep -q 'text/html' || echo 'FAILED: Frontend HTML'
    #
    # Example for user CRUD (full test suite):
    #   # API CRUD
    #   curl -f -X POST -H 'Content-Type: application/json' -d '{\"username\":\"test\"}' http://localhost:64580/api/v1/users || echo 'FAILED: CREATE user API'
    #   curl -f http://localhost:64580/api/v1/users/1 || echo 'FAILED: READ user API JSON'
    #   curl -f http://localhost:64580/api/v1/users/1.txt || echo 'FAILED: READ user API .txt'
    #   curl -f -X PUT -H 'Content-Type: application/json' -d '{\"email\":\"new@test.com\"}' http://localhost:64580/api/v1/users/1 || echo 'FAILED: UPDATE user API'
    #   curl -f -X DELETE http://localhost:64580/api/v1/users/1 || echo 'FAILED: DELETE user API'
    #   # Frontend (smart detection - test with text for simplicity)
    #   USERS=\$(curl -s http://localhost:64580/users)  # CLI auto-detects text
    #   if echo "\$USERS" | grep -q "testuser"; then echo '✓ Frontend user list'; else echo 'FAILED: Frontend user list'; fi
    #   USER=\$(curl -s http://localhost:64580/users/1)  # CLI auto-detects text
    #   if echo "\$USER" | grep -q "testuser"; then echo '✓ Frontend user profile'; else echo 'FAILED: Frontend user'; fi
    #
    # Test ALL project-specific endpoints defined in PART 37

    echo '=== Admin Setup & API Token Creation ==='
    # Get setup token from server output (captured during startup)
    SETUP_TOKEN=\$(cat /tmp/server.log 2>/dev/null | grep -oP 'Setup Token.*:\\s*\\K[a-f0-9]+' | head -1 || echo '')

    if [ -n \"\$SETUP_TOKEN\" ]; then
        echo \"Setup token found: \${SETUP_TOKEN:0:8}...\"

        # Create admin account
        curl -sf -X POST \\
            -H \"X-Setup-Token: \$SETUP_TOKEN\" \\
            -H \"Content-Type: application/json\" \\
            -d '{\"username\":\"testadmin\",\"password\":\"TestPass123!\"}' \\
            http://localhost:64580/api/v1/admin/setup || echo 'Admin setup failed (may already exist)'

        # Login and get session
        SESSION=\$(curl -sf -X POST \\
            -H \"Content-Type: application/json\" \\
            -d '{\"username\":\"testadmin\",\"password\":\"TestPass123!\"}' \\
            http://localhost:64580/api/v1/admin/login | grep -oP '\"session_token\":\\s*\"\\K[^\"]+' || echo '')

        if [ -n \"\$SESSION\" ]; then
            echo '✓ Admin login successful'

            # Generate API token for CLI/Agent testing
            API_TOKEN=\$(curl -sf -X POST \\
                -H \"Authorization: Bearer \$SESSION\" \\
                http://localhost:64580/api/v1/admin/profile/token | grep -oP '\"token\":\\s*\"\\K[^\"]+' || echo '')

            if [ -n \"\$API_TOKEN\" ]; then
                echo \"✓ API token created: \${API_TOKEN:0:12}...\"
            else
                echo 'API token creation failed (continuing without token)'
            fi
        else
            echo 'Admin login failed (continuing without session)'
        fi
    else
        echo 'No setup token found (server may already be configured)'
    fi

    echo '=== Binary Rename Tests ==='
    # Test that binaries show ACTUAL name in --help/--version (not hardcoded)
    cp /app/$WEATHER /app/renamed-server
    chmod +x /app/renamed-server
    if /app/renamed-server --help 2>&1 | grep -q 'renamed-server'; then
        echo '✓ Server binary rename works (--help shows actual name)'
    else
        echo '✗ FAILED: Server --help does not show renamed binary name'
    fi

    echo '=== CLI Client Tests (if exists) ==='
    if [ -f /app/$WEATHER-cli ]; then
        /app/$WEATHER-cli --version || echo 'FAILED: CLI --version'
        /app/$WEATHER-cli --help || echo 'FAILED: CLI --help'

        # Test binary rename
        cp /app/$WEATHER-cli /app/renamed-cli
        chmod +x /app/renamed-cli
        if /app/renamed-cli --help 2>&1 | grep -q 'renamed-cli'; then
            echo '✓ CLI binary rename works'
        else
            echo '✗ FAILED: CLI --help does not show renamed binary name'
        fi

        # Full CLI functionality tests against server
        echo '--- CLI Full Functionality Tests ---'
        if [ -n \"\${API_TOKEN:-}\" ]; then
            # Test with API token
            /app/$WEATHER-cli --server http://localhost:64580 --token \"\$API_TOKEN\" status || echo 'CLI status failed'
            # Project-specific CLI commands go here (PART 37)
            # Example: /app/$WEATHER-cli --server http://localhost:64580 --token \"\$API_TOKEN\" list
        else
            # Test without token (anonymous if allowed)
            /app/$WEATHER-cli --server http://localhost:64580 status || echo 'CLI status (no token) failed or not applicable'
        fi
    else
        echo 'CLI client not built - skipping'
    fi

    echo '=== Agent Tests (if exists) ==='
    if [ -f /app/$WEATHER-agent ]; then
        /app/$WEATHER-agent --version || echo 'FAILED: Agent --version'
        /app/$WEATHER-agent --help || echo 'FAILED: Agent --help'

        # Test binary rename
        cp /app/$WEATHER-agent /app/renamed-agent
        chmod +x /app/renamed-agent
        if /app/renamed-agent --help 2>&1 | grep -q 'renamed-agent'; then
            echo '✓ Agent binary rename works'
        else
            echo '✗ FAILED: Agent --help does not show renamed binary name'
        fi

        # Full Agent functionality tests against server
        echo '--- Agent Full Functionality Tests ---'
        if [ -n \"\${API_TOKEN:-}\" ]; then
            # Test agent registration/status with API token
            /app/$WEATHER-agent --server http://localhost:64580 --token \"\$API_TOKEN\" status || echo 'Agent status failed'
            # Project-specific agent commands go here (PART 37)
        else
            echo 'Agent tests skipped (no API token)'
        fi
    else
        echo 'Agent not built - skipping'
    fi

    echo '=== Stopping Server ==='
    kill \$SERVER_PID
    wait \$SERVER_PID 2>/dev/null || true

    echo '=== All tests passed ==='
"

echo "Docker tests completed successfully"
```

#### tests/incus.sh

**Purpose:** Full integration + systemd testing in Incus Debian container

```bash
#!/usr/bin/env bash
set -euo pipefail

# Check if incus is available
if ! command -v incus &>/dev/null; then
    echo "ERROR: incus not found. Install incus or use tests/docker.sh"
    exit 1
fi

# Detect project info
PROJECTNAME=$(basename "$PWD")
PROJECTORG=$(basename "$(dirname "$PWD")")
CONTAINER_NAME="test-$WEATHER-$$"

# Incus image - use latest Debian stable (update when new stable releases)
INCUS_IMAGE="images:debian/12"

# Create temp directory for build
BUILD_DIR=$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}.XXXXXX")
trap "rm -rf $BUILD_DIR; incus delete $CONTAINER_NAME --force 2>/dev/null || true" EXIT

# Go cache directories (same as Makefile)
GODIR="${HOME}/.local/share/go"
GOCACHE="${HOME}/.local/share/go/build"
mkdir -p "$GODIR" "$GOCACHE"

# Common docker run for Go builds
GO_DOCKER="docker run --rm \
  -v $(pwd):/build \
  -v ${GOCACHE}:/root/.cache/go-build \
  -v ${GODIR}:/go \
  -w /build \
  -e CGO_ENABLED=0 \
  golang:alpine"

echo "Building server binary in Docker..."
$GO_DOCKER go build -o "$BUILD_DIR/$WEATHER" ./src

# Build CLI client if exists
if [ -d "src/client" ]; then
    echo "Building CLI client in Docker..."
    $GO_DOCKER go build -o "$BUILD_DIR/$WEATHER-cli" ./src/client
fi

# Build agent if exists
if [ -d "src/agent" ]; then
    echo "Building agent in Docker..."
    $GO_DOCKER go build -o "$BUILD_DIR/$WEATHER-agent" ./src/agent
fi

echo "Launching Incus container (Debian + systemd)..."
incus launch "$INCUS_IMAGE" "$CONTAINER_NAME"

# Wait for container to be ready
sleep 2

echo "Copying binaries to container..."
incus file push "$BUILD_DIR/$WEATHER" "$CONTAINER_NAME/usr/local/bin/"
incus exec "$CONTAINER_NAME" -- chmod +x "/usr/local/bin/$WEATHER"

# Copy CLI client if built
if [ -f "$BUILD_DIR/$WEATHER-cli" ]; then
    incus file push "$BUILD_DIR/$WEATHER-cli" "$CONTAINER_NAME/usr/local/bin/"
    incus exec "$CONTAINER_NAME" -- chmod +x "/usr/local/bin/$WEATHER-cli"
fi

# Copy agent if built
if [ -f "$BUILD_DIR/$WEATHER-agent" ]; then
    incus file push "$BUILD_DIR/$WEATHER-agent" "$CONTAINER_NAME/usr/local/bin/"
    incus exec "$CONTAINER_NAME" -- chmod +x "/usr/local/bin/$WEATHER-agent"
fi

# Ensure curl is available for testing
incus exec "$CONTAINER_NAME" -- bash -c "command -v curl || apt-get update && apt-get install -y curl" >/dev/null 2>&1

echo "Running tests in Incus..."
incus exec "$CONTAINER_NAME" -- bash -c "
    set -e

    echo '=== Version Check ==='
    $WEATHER --version

    echo '=== Help Check ==='
    $WEATHER --help

    echo '=== Binary Info ==='
    ls -lh /usr/local/bin/$WEATHER
    file /usr/local/bin/$WEATHER

    echo '=== Service Install Test ==='
    $WEATHER --service --install

    echo '=== Service Status ==='
    systemctl status $WEATHER || true

    echo '=== Service Start Test ==='
    systemctl start $WEATHER
    sleep 2
    systemctl status $WEATHER

    echo '=== API Endpoint Tests ==='
    # Test JSON response (default)
    curl -f http://localhost:80/api/v1/healthz || echo 'FAILED: /api/v1/healthz'

    # Test .txt extension (plain text)
    curl -f http://localhost:80/api/v1/healthz.txt || echo 'FAILED: /api/v1/healthz.txt'

    # Test Accept header: application/json
    curl -f -H 'Accept: application/json' http://localhost:80/healthz || echo 'FAILED: Accept JSON'

    # Test Accept header: text/plain
    curl -f -H 'Accept: text/plain' http://localhost:80/healthz || echo 'FAILED: Accept text/plain'

    echo '=== Project-Specific Endpoint Tests ==='
    # MUST test ALL endpoints from PART 37 - both API and frontend
    # Test FULL CRUD if project has CRUD operations
    #
    # Example for jokes API (API routes with .txt extension):
    #   curl -f http://localhost:80/api/v1/jokes/random || echo 'FAILED: API JSON'
    #   curl -f http://localhost:80/api/v1/jokes/random.txt || echo 'FAILED: API .txt'
    #   curl -f -H 'Accept: text/plain' http://localhost:80/api/v1/jokes/random || echo 'FAILED: API Accept text'
    #
    # Example for jokes frontend (smart detection, no .txt - test with text for simplicity):
    #   JOKE=\$(curl -s http://localhost:80/jokes/random)  # CLI auto-detects text
    #   if echo "\$JOKE" | grep -q "Why"; then echo '✓ Frontend text works'; else echo 'FAILED: Frontend text'; fi
    #   # Optional: verify HTML is served to browsers
    #   curl -f -s -I -H 'Accept: text/html' http://localhost:80/jokes/random | grep -q 'text/html' || echo 'FAILED: Frontend HTML'
    #
    # Example for user CRUD (full test suite):
    #   # API CRUD
    #   curl -f -X POST -H 'Content-Type: application/json' -d '{\"username\":\"test\"}' http://localhost:80/api/v1/users || echo 'FAILED: CREATE user API'
    #   curl -f http://localhost:80/api/v1/users/1 || echo 'FAILED: READ user API JSON'
    #   curl -f http://localhost:80/api/v1/users/1.txt || echo 'FAILED: READ user API .txt'
    #   curl -f -X PUT -H 'Content-Type: application/json' -d '{\"email\":\"new@test.com\"}' http://localhost:80/api/v1/users/1 || echo 'FAILED: UPDATE user API'
    #   curl -f -X DELETE http://localhost:80/api/v1/users/1 || echo 'FAILED: DELETE user API'
    #   # Frontend (smart detection - test with text for simplicity)
    #   USERS=\$(curl -s http://localhost:80/users)  # CLI auto-detects text
    #   if echo "\$USERS" | grep -q "testuser"; then echo '✓ Frontend user list'; else echo 'FAILED: Frontend user list'; fi
    #   USER=\$(curl -s http://localhost:80/users/1)  # CLI auto-detects text
    #   if echo "\$USER" | grep -q "testuser"; then echo '✓ Frontend user profile'; else echo 'FAILED: Frontend user'; fi
    #
    # Test ALL project-specific endpoints defined in PART 37

    echo '=== Admin Setup & API Token Creation ==='
    # Get setup token from journal
    SETUP_TOKEN=\$(journalctl -u $WEATHER --no-pager 2>/dev/null | grep -oP 'Setup Token.*:\\s*\\K[a-f0-9]+' | head -1 || echo '')

    if [ -n \"\$SETUP_TOKEN\" ]; then
        echo \"Setup token found: \${SETUP_TOKEN:0:8}...\"

        # Create admin account
        curl -sf -X POST \\
            -H \"X-Setup-Token: \$SETUP_TOKEN\" \\
            -H \"Content-Type: application/json\" \\
            -d '{\"username\":\"testadmin\",\"password\":\"TestPass123!\"}' \\
            http://localhost:80/api/v1/admin/setup || echo 'Admin setup failed (may already exist)'

        # Login and get session
        SESSION=\$(curl -sf -X POST \\
            -H \"Content-Type: application/json\" \\
            -d '{\"username\":\"testadmin\",\"password\":\"TestPass123!\"}' \\
            http://localhost:80/api/v1/admin/login | grep -oP '\"session_token\":\\s*\"\\K[^\"]+' || echo '')

        if [ -n \"\$SESSION\" ]; then
            echo '✓ Admin login successful'

            # Generate API token for CLI/Agent testing
            API_TOKEN=\$(curl -sf -X POST \\
                -H \"Authorization: Bearer \$SESSION\" \\
                http://localhost:80/api/v1/admin/profile/token | grep -oP '\"token\":\\s*\"\\K[^\"]+' || echo '')

            if [ -n \"\$API_TOKEN\" ]; then
                echo \"✓ API token created: \${API_TOKEN:0:12}...\"
            else
                echo 'API token creation failed (continuing without token)'
            fi
        else
            echo 'Admin login failed (continuing without session)'
        fi
    else
        echo 'No setup token found (server may already be configured)'
    fi

    echo '=== Binary Rename Tests ==='
    # Test that binaries show ACTUAL name in --help/--version (not hardcoded)
    cp /usr/local/bin/$WEATHER /tmp/renamed-server
    chmod +x /tmp/renamed-server
    if /tmp/renamed-server --help 2>&1 | grep -q 'renamed-server'; then
        echo '✓ Server binary rename works (--help shows actual name)'
    else
        echo '✗ FAILED: Server --help does not show renamed binary name'
    fi

    echo '=== CLI Client Tests (if exists) ==='
    if [ -f /usr/local/bin/$WEATHER-cli ]; then
        $WEATHER-cli --version || echo 'FAILED: CLI --version'
        $WEATHER-cli --help || echo 'FAILED: CLI --help'

        # Test binary rename
        cp /usr/local/bin/$WEATHER-cli /tmp/renamed-cli
        chmod +x /tmp/renamed-cli
        if /tmp/renamed-cli --help 2>&1 | grep -q 'renamed-cli'; then
            echo '✓ CLI binary rename works'
        else
            echo '✗ FAILED: CLI --help does not show renamed binary name'
        fi

        # Full CLI functionality tests against server
        echo '--- CLI Full Functionality Tests ---'
        if [ -n \"\${API_TOKEN:-}\" ]; then
            # Test with API token
            $WEATHER-cli --server http://localhost:80 --token \"\$API_TOKEN\" status || echo 'CLI status failed'
            # Project-specific CLI commands go here (PART 37)
        else
            # Test without token (anonymous if allowed)
            $WEATHER-cli --server http://localhost:80 status || echo 'CLI status (no token) failed or not applicable'
        fi
    else
        echo 'CLI client not installed - skipping'
    fi

    echo '=== Agent Tests (if exists) ==='
    if [ -f /usr/local/bin/$WEATHER-agent ]; then
        $WEATHER-agent --version || echo 'FAILED: Agent --version'
        $WEATHER-agent --help || echo 'FAILED: Agent --help'

        # Test binary rename
        cp /usr/local/bin/$WEATHER-agent /tmp/renamed-agent
        chmod +x /tmp/renamed-agent
        if /tmp/renamed-agent --help 2>&1 | grep -q 'renamed-agent'; then
            echo '✓ Agent binary rename works'
        else
            echo '✗ FAILED: Agent --help does not show renamed binary name'
        fi

        # Full Agent functionality tests against server
        echo '--- Agent Full Functionality Tests ---'
        if [ -n \"\${API_TOKEN:-}\" ]; then
            # Test agent registration/status with API token
            $WEATHER-agent --server http://localhost:80 --token \"\$API_TOKEN\" status || echo 'Agent status failed'
            # Project-specific agent commands go here (PART 37)
        else
            echo 'Agent tests skipped (no API token)'
        fi
    else
        echo 'Agent not installed - skipping'
    fi

    echo '=== Service Stop Test ==='
    systemctl stop $WEATHER

    echo '=== All tests passed ==='
"

echo "Incus tests completed successfully"
```

#### tests/run_tests.sh

**Purpose:** Automatic test runner - detects available container runtime and runs appropriate test

```bash
#!/usr/bin/env bash
set -euo pipefail

# Detect available container runtime and run appropriate test
if command -v incus &>/dev/null; then
    echo "Incus detected - running full systemd tests..."
    exec "$(dirname "$0")/incus.sh"
elif command -v docker &>/dev/null; then
    echo "Docker detected - running container tests..."
    exec "$(dirname "$0")/docker.sh"
else
    echo "ERROR: Neither incus nor docker found"
    echo "Please install one of the following:"
    echo "  - Incus (preferred): https://linuxcontainers.org/incus/"
    echo "  - Docker (fallback): https://docker.com/"
    exit 1
fi
```

**Test Script Rules:**

| Rule | Requirement |
|------|-------------|
| **Location** | `tests/run_tests.sh`, `tests/docker.sh`, `tests/incus.sh` |
| **Permissions** | Executable (`chmod +x tests/*.sh`) |
| **Build method** | ALWAYS use Docker (golang:alpine) with GODIR/GOCACHE |
| **Go cache** | Use `GODIR="${HOME}/.local/share/go"` and `GOCACHE="${HOME}/.local/share/go/build"` |
| **Build location** | ALWAYS use temp directory |
| **Build all components** | Build server, CLI client (if `src/client/` exists), agent (if `src/agent/` exists) |
| **Test container tools** | Docker alpine MUST install: `apk add --no-cache curl bash file jq` |
| **Test all binaries** | Test `--version` and `--help` for server, CLI client, and agent if built |
| **Binary rename test** | Copy binary with new name, verify `--help` shows renamed name (not hardcoded) |
| **Admin setup** | Use setup token to create admin account, login, generate API token |
| **CLI full functionality** | Test CLI with API token against running server (not just --help) |
| **Agent full functionality** | Test agent with API token against running server (not just --help) |
| **API endpoint testing** | MUST test .txt extension and Accept headers on API routes |
| **Frontend testing** | MUST test smart detection (CLI → text, browser → HTML) |
| **Content negotiation** | Test JSON, text/plain, and text/html responses |
| **Project-specific tests** | MUST test ALL endpoints from PART 37 (CRUD, API, frontend) |
| **Admin authentication** | Test setup token, login, and rejection (no bypass) |
| **Cleanup** | ALWAYS use `trap` for cleanup |
| **Exit codes** | 0 = success, non-zero = failure |
| **Output** | Clear progress messages with `echo` |
| **Error handling** | `set -euo pipefail` at top |

### Shell Completions (Built-in)

**ALL binaries (server, agent, client) support shell completions - built into binary, no separate files.**

See PART 36: "Shell Completions (Built-in)" for full implementation details.

```bash
# Generate and install completions (prints to stdout, user redirects)
weather --shell completions bash > /etc/bash_completion.d/weather
weather-cli --shell completions bash > /etc/bash_completion.d/weather-cli
weather-agent --shell completions bash > /etc/bash_completion.d/weather-agent

# Or use eval in shell rc file
eval "$(weather --shell init)"
eval "$(weather-cli --shell init)"
eval "$(weather-agent --shell init)"
```

| Advantage | Description |
|-----------|-------------|
| **Always current** | Completions match binary version exactly |
| **Rename-friendly** | Works even if user renames binary |
| **No sync issues** | Can't have outdated completion files |

## Testing Admin Routes (NON-NEGOTIABLE)

**Admin routes (`/admin/**`) require authentication. Tests MUST verify authentication works.**

**CRITICAL: Do NOT bypass authentication in tests - TEST that it works!**

### Proper Admin Testing Approach

**Tests should verify the authentication system, not skip it:**

```bash
#!/usr/bin/env bash
set -euo pipefail

echo '=== Admin Authentication Tests ==='

# Start server normally (authentication required)
/app/$WEATHER --port 64580 &
SERVER_PID=$!
sleep 3

# 1. Test that unauthenticated access is REJECTED
echo "Testing unauthenticated access is blocked..."
HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:64580/admin)
if [ "$HTTP_CODE" = "302" ] || [ "$HTTP_CODE" = "401" ]; then
    echo "✓ Unauthenticated access properly rejected"
else
    echo "✗ FAILED: Admin routes not protected (got HTTP $HTTP_CODE)"
    kill $SERVER_PID
    exit 1
fi

# 2. Get setup token from server logs (using proper temp dir structure)
SETUP_TOKEN=$(grep -oP 'Setup Token.*:\s*\K[a-f0-9]+' "${TMPDIR:-/tmp}/${PROJECTORG}/$WEATHER/server.log" | head -1)

if [ -z "$SETUP_TOKEN" ]; then
    echo "✗ FAILED: No setup token found in logs"
    kill $SERVER_PID
    exit 1
fi

echo "✓ Setup token found: ${SETUP_TOKEN:0:8}..."

# 3. Test admin routes WITH authentication (setup token)
echo "Testing admin access with setup token..."
HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" \
    -H "X-Setup-Token: $SETUP_TOKEN" \
    http://localhost:64580/admin)

if [ "$HTTP_CODE" = "200" ]; then
    echo "✓ Admin access works with setup token"
else
    echo "✗ FAILED: Admin access with token returned HTTP $HTTP_CODE"
    kill $SERVER_PID
    exit 1
fi

# 4. Complete setup wizard (create admin account)
echo "Creating admin account via API..."
curl -s -X POST \
    -H "X-Setup-Token: $SETUP_TOKEN" \
    -H "Content-Type: application/json" \
    -d '{"username":"testadmin","password":"TestPass123!"}' \
    http://localhost:64580/api/v1/admin/setup

# 5. Test login with created admin
echo "Testing admin login..."
SESSION=$(curl -s -X POST \
    -H "Content-Type: application/json" \
    -d '{"username":"testadmin","password":"TestPass123!"}' \
    http://localhost:64580/api/v1/admin/login | jq -r '.session_token')

if [ -z "$SESSION" ] || [ "$SESSION" = "null" ]; then
    echo "✗ FAILED: Admin login failed"
    kill $SERVER_PID
    exit 1
fi

echo "✓ Admin login successful"

# 6. Test admin routes with valid session
echo "Testing admin routes with session..."
curl -s -H "Authorization: Bearer $SESSION" \
    http://localhost:64580/api/v1/admin/users > /dev/null

echo "✓ Admin routes work with authentication"

# 7. Test that invalid credentials are rejected
echo "Testing invalid credentials are rejected..."
INVALID=$(curl -s -X POST \
    -H "Content-Type: application/json" \
    -d '{"username":"testadmin","password":"wrongpassword"}' \
    -w "%{http_code}" \
    http://localhost:64580/api/v1/admin/login)

if echo "$INVALID" | grep -q "401\|403"; then
    echo "✓ Invalid credentials properly rejected"
else
    echo "✗ FAILED: Invalid credentials not rejected"
    kill $SERVER_PID
    exit 1
fi

# Cleanup
kill $SERVER_PID
wait $SERVER_PID 2>/dev/null || true

echo '=== All admin authentication tests passed ==='
```

### Debug Mode - ONLY for Manual Development

**Debug mode auth bypass exists ONLY for quick manual testing during development:**

```go
// In admin middleware
func AdminAuthMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // Debug mode: bypass authentication ONLY for manual dev work
        // NEVER use this in automated tests!
        if os.Getenv("DEBUG") == "true" || config.IsDebug() {
            log.Println("[DEBUG] Admin auth bypassed (debug mode - manual dev only)")
            next.ServeHTTP(w, r)
            return
        }

        // Normal: require valid admin session
        session := validateAdminSession(r)
        if session == nil {
            http.Redirect(w, r, cfg.AdminPath+"/login", http.StatusSeeOther)
            return
        }

        next.ServeHTTP(w, r)
    })
}
```

**Debug bypass is for:**
- ✓ Quick manual UI testing during development
- ✓ Exploring admin panel while coding
- ✓ Debugging admin routes interactively

**Debug bypass is NOT for:**
- ✗ Automated test scripts
- ✗ Beta testing
- ✗ CI/CD pipelines
- ✗ Verifying authentication works

### Admin Testing Rules

| Rule | Requirement |
|------|-------------|
| **Test authentication** | Tests MUST verify auth works, not bypass it |
| **Use setup token** | First-run setup token for initial admin access |
| **Create test admin** | Create admin account via setup API |
| **Test login flow** | Verify credentials, sessions, and access control |
| **Test rejection** | Verify unauthenticated and invalid credentials are rejected |
| **Debug mode** | ONLY for manual development, NEVER in automated tests |

### Container Images

| Purpose | Image | Required Packages | Why |
|---------|-------|-------------------|-----|
| Building Go | `golang:alpine` | `git`, `bash` | Latest Go, dependencies need git |
| Container runtime | `alpine:latest` | `git`, `bash`, `curl`, `tini`, `tor` | Minimal, all runtime tools included |
| Full OS runtime | `debian:latest` (Incus) | Full OS | Complete systemd, realistic environment |

### Common Docker Commands

**All Go commands MUST be run through Docker. Here are the patterns:**

```bash
# Set project path to YOUR actual project location (examples shown below)
# Use git top-level if in a git repo: PROJECT_PATH="$(git rev-parse --show-toplevel)"
# Or use absolute path to your project directory
PROJECT_PATH="/root/Projects/github/apimgr/weather"  # Example 1
# PROJECT_PATH="~/Documents/myproject"                     # Example 2
# PROJECT_PATH="~/myproject"                               # Example 3
# PROJECT_PATH="/workspace/dev/myproject"                  # Example 4

# Go cache directories (same as Makefile - speeds up builds significantly)
GODIR="${HOME}/.local/share/go"
GOCACHE="${HOME}/.local/share/go/build"
mkdir -p "$GODIR" "$GOCACHE"

# Common docker run for Go commands
GO_DOCKER="docker run --rm \
  -v $PROJECT_PATH:/build \
  -v $GOCACHE:/root/.cache/go-build \
  -v $GODIR:/go \
  -w /build \
  -e CGO_ENABLED=0"

# Build (outputs to binaries/ which can be mounted into test containers)
$GO_DOCKER golang:alpine go build -o /build/binaries/weather ./src

# Run tests
$GO_DOCKER golang:alpine go test ./...

# Run specific test
$GO_DOCKER golang:alpine go test -v ./src/server/...

# Tidy modules
$GO_DOCKER golang:alpine go mod tidy

# Download dependencies
$GO_DOCKER golang:alpine go mod download

# Check formatting
$GO_DOCKER golang:alpine go fmt ./...

# Run vet
$GO_DOCKER golang:alpine go vet ./...

# Interactive shell (for debugging)
docker run --rm -it \
  -v $PROJECT_PATH:/build \
  -v $GOCACHE:/root/.cache/go-build \
  -v $GODIR:/go \
  -w /build \
  golang:alpine sh
```

## Build and Test (NON-NEGOTIABLE)

**Build outputs to `binaries/`, test by running in container. Always use GODIR/GOCACHE for faster builds.**

```bash
# Go cache directories (same as Makefile)
GODIR="${HOME}/.local/share/go"
GOCACHE="${HOME}/.local/share/go/build"
mkdir -p "$GODIR" "$GOCACHE"

# Build (with caching)
docker run --rm \
  -v $(pwd):/build \
  -v $GOCACHE:/root/.cache/go-build \
  -v $GODIR:/go \
  -w /build -e CGO_ENABLED=0 \
  golang:alpine go build -o /build/binaries/weather ./src

# Test in Docker (quick) - install tools first
docker run --rm -v $(pwd)/binaries:/app alpine:latest sh -c "
  apk add --no-cache curl bash file jq >/dev/null
  /app/weather --help
"

# Test in Incus (full OS with systemd) - PREFERRED
# Use latest Debian stable (currently 12/bookworm)
incus launch images:debian/12 test-weather
incus file push binaries/weather test-weather/usr/local/bin/
incus exec test-weather -- weather --help
incus delete test-weather --force
```

### Testing with Config/Data

```bash
# Go cache directories (same as Makefile)
GODIR="${HOME}/.local/share/go"
GOCACHE="${HOME}/.local/share/go/build"
mkdir -p "$GODIR" "$GOCACHE"

# Create prefixed temp dir for test data
TEST_DIR=$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}.XXXXXX")
mkdir -p $TEST_DIR/{config,data,logs}

# Build to binaries/ (with caching)
docker run --rm \
  -v $(pwd):/build \
  -v $GOCACHE:/root/.cache/go-build \
  -v $GODIR:/go \
  -w /build -e CGO_ENABLED=0 \
  golang:alpine go build -o /build/binaries/weather ./src

# Quick test in Docker (install tools first)
docker run --rm -v $(pwd)/binaries:/app alpine:latest sh -c "
  apk add --no-cache curl bash file jq >/dev/null
  /app/weather --help
  /app/weather --version
"

# Full test with config/data in Docker
docker run --rm \
  -v $(pwd)/binaries:/app \
  -v $TEST_DIR:/test \
  alpine:latest /app/weather \
    --config /test/config \
    --data /test/data \
    --log /test/logs

# Cleanup
rm -rf $TEST_DIR
```

### Full OS Testing with Incus

**For testing systemd services, use Incus with Debian:**

```bash
# Create prefixed temp dir
TEST_DIR=$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}.XXXXXX")
mkdir -p $TEST_DIR/{config,data,logs}

# Build
docker run --rm -v $(pwd):/build -w /build -e CGO_ENABLED=0 \
  golang:alpine go build -o /build/binaries/weather ./src

# Launch Incus container (use latest Debian stable)
incus launch images:debian/12 test-weather

# Push binary and test data
incus file push binaries/weather test-weather/usr/local/bin/
incus exec test-weather -- mkdir -p /etc/apimgr/weather /var/lib/apimgr/weather

# Test
incus exec test-weather -- weather --help
incus exec test-weather -- weather --version
incus exec test-weather -- weather --service --install
incus exec test-weather -- systemctl status weather

# Cleanup
incus delete test-weather --force
rm -rf $TEST_DIR
```

**NEVER run binaries directly on host - always use Docker or Incus containers!**

## Process Management (NON-NEGOTIABLE)

**STRICT RULES: Only kill/remove the EXACT process or container being worked on. NEVER anything else.**

### FORBIDDEN Commands (NEVER Use)

| Command | Reason |
|---------|--------|
| `pkill -f {pattern}` | Too broad, kills unrelated processes |
| `pkill {name}` | Too broad without `-x` flag |
| `killall {name}` | Too broad, may kill unrelated processes |
| `kill -9 {pid}` | Use graceful `kill {pid}` first |
| `docker kill` | Use `docker stop` for graceful shutdown |
| `docker rm $(docker ps -aq)` | Removes ALL containers |
| `docker rm $(docker ps -q)` | Removes ALL running containers |
| `docker rmi $(docker images -q)` | Removes ALL images |
| `docker system prune` | Cleans ALL unused resources |
| `docker container prune` | Removes ALL stopped containers |
| `docker image prune` | Removes ALL dangling images |
| `docker volume prune` | Removes ALL unused volumes |
| `docker network prune` | Removes ALL unused networks |
| `rm -rf /` | Catastrophic |
| `rm -rf /*` | Catastrophic |
| `rm -rf ~` | Destroys home directory |
| `rm -rf .` | Dangerous in wrong directory |
| `rm -rf *` | Dangerous without proper scoping |

### Process Termination Rules

| Rule | Description |
|------|-------------|
| **Identify first** | ALWAYS get exact PID before killing |
| **Graceful first** | Use `kill {pid}` (SIGTERM), wait, then `kill -9 {pid}` only if needed |
| **One at a time** | Kill ONE specific PID, never patterns |
| **Verify PID** | Confirm PID belongs to the project process |
| **Document** | Log what was killed and why |

**Kill Process Flow:**
```
1. pgrep -la weather           # List matching processes
2. Verify the PID is correct          # CHECK before killing
3. kill {pid}                         # Graceful termination (SIGTERM)
4. sleep 5                            # Wait for graceful shutdown
5. pgrep -la weather           # Check if still running
6. kill -9 {pid}                      # Force kill ONLY if still running
```

### Docker Container Rules

| Rule | Description |
|------|-------------|
| **ONLY this project** | Only stop/remove containers named `weather` |
| **NEVER other containers** | Even if they look related or unused |
| **NEVER images not ours** | Only remove `apimgr/weather:*` images |
| **NEVER base images** | Never remove `golang`, `alpine`, `ubuntu`, etc. |
| **NEVER volumes** | Unless explicitly part of this project |

**Docker Cleanup Flow:**
```
1. docker ps -a --filter name=weather     # List ONLY this project's containers
2. Verify output shows ONLY weather       # CHECK before removing
3. docker stop weather                    # Stop gracefully
4. docker rm weather                      # Remove container

# For images:
1. docker images apimgr/weather     # List ONLY this project's images
2. Verify output shows ONLY our images          # CHECK before removing
3. docker rmi apimgr/weather:tag    # Remove SPECIFIC tag
```

### Allowed Commands (Project-Scoped ONLY)

| Command | Description |
|---------|-------------|
| `kill {specific-pid}` | Kill exact PID only (after verification) |
| `pkill -x weather` | Exact binary name match only |
| `docker stop weather` | Stop specific container by name |
| `docker rm weather` | Remove specific container by name |
| `docker rmi apimgr/weather:tag` | Remove specific image:tag |
| `rm -rf $BUILD_DIR` | Remove temp build dir (from mktemp) |
| `rm -rf $TEST_DIR` | Remove temp test dir (from mktemp) |

### Before ANY Kill/Remove Operation

1. **List first**: See exactly what will be affected
2. **Verify**: Confirm it's the correct process/container/file
3. **Be specific**: Use exact names, PIDs, or paths - NEVER patterns
4. **Ask if unsure**: When in doubt, ask the user
5. **Document**: Log what was removed and why

## File Cleanup Rules (NON-NEGOTIABLE)

**Always be explicit and project-scoped when deleting files.**

### Safe Cleanup Commands

| Purpose | Command |
|---------|---------|
| Temp build dir | `rm -rf $BUILD_DIR` (saved from mktemp) |
| Temp test dir | `rm -rf $TEST_DIR` (saved from mktemp) |
| All mktemp dirs | Cleaned automatically on reboot |
| Project binaries | `rm -rf binaries/weather*` |
| Project releases | `rm -rf releases/weather*` |

**Note:** Always use `mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}.XXXXXX"` and save the path to a variable for cleanup. Temp dirs are auto-cleaned on reboot.

### NEVER Delete Without Confirmation

| Item | Why |
|------|-----|
| User data directories | Irreversible data loss |
| Config files | User customizations lost |
| Database files | Data loss |
| SSL certificates | Service disruption |
| Git repositories | Code loss |
| Anything outside project scope | Affects other systems |

### Cleanup Checklist

Before running any `rm -rf`:

1. **Echo first**: `echo "Would delete: /path/to/delete"` - verify the path
2. **Check pwd**: `pwd` - make sure you're in the right directory
3. **List first**: `ls -la /path/to/delete` - see what will be deleted
4. **Be specific**: Use full paths, not relative paths with wildcards
5. **Ask if unsure**: When in doubt, ask the user before deleting

---


# PART 30: READTHEDOCS DOCUMENTATION (NON-NEGOTIABLE)

## Overview

**Every project MUST have documentation hosted on ReadTheDocs.**

**CRITICAL:** The `docs/` directory is **ONLY** for ReadTheDocs files (MkDocs documentation). **NEVER** put other files in `docs/` - use `src/` for source code, `scripts/` for scripts, etc.

Documentation uses MkDocs Material theme with dark/light/auto switching.

**See PART 16: Themes for project-wide theme rules (colors, accessibility, switching behavior).**

| Attribute | Value |
|-----------|-------|
| Documentation engine | MkDocs (Markdown-based) |
| Theme | MkDocs Material (follows PART 16 theme rules) |
| Theme files | `docs/stylesheets/dark.css`, `docs/stylesheets/light.css` |
| Hosting | ReadTheDocs |
| URL format | `https://apimgr-weather.readthedocs.io` |
| Source directory | `docs/` (ONLY ReadTheDocs files) |

## Required Files

### Project Root Files

| File | Purpose |
|------|---------|
| `mkdocs.yml` | MkDocs configuration |
| `.readthedocs.yaml` | ReadTheDocs build configuration |

### Documentation Directory (`docs/`)

| File | Required | Purpose |
|------|:--------:|---------|
| `index.md` | ✓ | Documentation homepage |
| `installation.md` | ✓ | Installation guide (Docker, binary, systemd) |
| `configuration.md` | ✓ | Configuration reference (all settings) |
| `api.md` | ✓ | API documentation (endpoints, formats) |
| `cli.md` | If applicable | CLI reference (flags, commands) |
| `admin.md` | ✓ | Admin panel guide |
| `development.md` | ✓ | Development/contributing guide |
| `stylesheets/dark.css` | Optional | Dark theme customization |
| `stylesheets/light.css` | Optional | Light theme customization |
| `requirements.txt` | ✓ | Python dependencies for MkDocs |

## mkdocs.yml Template (NON-NEGOTIABLE)

```yaml
site_name: WEATHER
site_url: https://apimgr-weather.readthedocs.io
site_description: "{Project description}"
site_author: apimgr

repo_name: apimgr/weather
repo_url: {PLATFORM_REPO_URL}
edit_uri: edit/main/docs/  # Adjust path format for GitLab/Gitea if needed

theme:
  name: material
  palette:
    # Dark/Light/Auto theme toggle - Dark is default
    - scheme: slate
      primary: deep purple
      accent: pink
      toggle:
        icon: material/brightness-4
        name: Switch to light mode
    - scheme: default
      primary: indigo
      accent: indigo
      toggle:
        icon: material/brightness-7
        name: Switch to auto mode
    - media: "(prefers-color-scheme)"
      toggle:
        icon: material/brightness-auto
        name: Switch to dark mode
  features:
    - navigation.instant
    - navigation.tracking
    - navigation.tabs
    - navigation.sections
    - navigation.expand
    - navigation.top
    - search.suggest
    - search.highlight
    - content.code.copy
    - content.action.edit
  font:
    text: Roboto
    code: Roboto Mono
  icon:
    repo: fontawesome/brands/github

extra_css:
  - stylesheets/dark.css
  - stylesheets/light.css

plugins:
  - search
  - minify:
      minify_html: true

markdown_extensions:
  - abbr
  - admonition
  - attr_list
  - def_list
  - footnotes
  - meta
  - md_in_html
  - tables
  - toc:
      permalink: true
      toc_depth: 3
  - pymdownx.arithmatex:
      generic: true
  - pymdownx.betterem:
      smart_enable: all
  - pymdownx.caret
  - pymdownx.details
  - pymdownx.emoji:
      emoji_index: !!python/name:material.extensions.emoji.twemoji
      emoji_generator: !!python/name:material.extensions.emoji.to_svg
  - pymdownx.highlight:
      anchor_linenums: true
      line_spans: __span
      pygments_lang_class: true
  - pymdownx.inlinehilite
  - pymdownx.keys
  - pymdownx.magiclink:
      repo_url_shorthand: true
      user: apimgr
      repo: weather
  - pymdownx.mark
  - pymdownx.smartsymbols
  - pymdownx.superfences:
      custom_fences:
        - name: mermaid
          class: mermaid
          format: !!python/name:pymdownx.superfences.fence_code_format
  - pymdownx.tabbed:
      alternate_style: true
  - pymdownx.tasklist:
      custom_checkbox: true
  - pymdownx.tilde

nav:
  - Home: index.md
  - Getting Started:
    - Installation: installation.md
    - Configuration: configuration.md
  - Usage:
    - API Reference: api.md
    - CLI Reference: cli.md
    - Admin Panel: admin.md
  - Development:
    - Contributing: development.md

extra:
  social:
    - icon: fontawesome/brands/git-alt  # Or github/gitlab/gitea as appropriate
      link: {PLATFORM_REPO_URL}
  generator: false
```

## .readthedocs.yaml Template (NON-NEGOTIABLE)

```yaml
# ReadTheDocs configuration
# https://docs.readthedocs.io/en/stable/config-file/v2.html
# NOTE: Update os/python to latest LTS versions periodically

version: 2

build:
  os: ubuntu-24.04          # Use latest Ubuntu LTS
  tools:
    python: "3.12"          # Use latest stable Python

mkdocs:
  configuration: mkdocs.yml

python:
  install:
    - requirements: docs/requirements.txt
```

## docs/requirements.txt (NON-NEGOTIABLE)

```
mkdocs>=1.5.0
mkdocs-material>=9.5.0
mkdocs-minify-plugin>=0.7.0
pymdown-extensions>=10.0
```

## Theme CSS Files (NON-NEGOTIABLE)

**Theme colors and rules defined in PART 16. These files apply those rules to MkDocs:**

| File | Purpose | Applies To |
|------|---------|------------|
| `docs/stylesheets/dark.css` | Dark theme | `scheme: slate` |
| `docs/stylesheets/light.css` | Light theme | `scheme: default` |

### Dark Theme CSS

**File:** `docs/stylesheets/dark.css`

```css
/* Dark Theme */
/* Applied when scheme: slate is active */

:root {
  /* Dark theme color palette */
  --dark-bg: #282a36;
  --dark-bg-alt: #44475a;
  --dark-text: #f8f8f2;
  --dark-text-muted: #6272a4;
  --dark-accent-cyan: #8be9fd;
  --dark-accent-green: #50fa7b;
  --dark-accent-orange: #ffb86c;
  --dark-accent-pink: #ff79c6;
  --dark-accent-purple: #bd93f9;
  --dark-accent-red: #ff5555;
  --dark-accent-yellow: #f1fa8c;
}

/* Apply dark theme customization */
[data-md-color-scheme="slate"] {
  --md-default-bg-color: var(--dark-bg);
  --md-default-fg-color: var(--dark-text);
  --md-default-fg-color--light: var(--dark-text-muted);
  --md-default-fg-color--lighter: var(--dark-bg-alt);
  --md-default-fg-color--lightest: var(--dark-bg-alt);

  --md-primary-fg-color: var(--dark-accent-purple);
  --md-primary-fg-color--light: var(--dark-accent-pink);
  --md-primary-fg-color--dark: var(--dark-accent-purple);
  --md-primary-bg-color: var(--dark-text);
  --md-primary-bg-color--light: var(--dark-text);

  --md-accent-fg-color: var(--dark-accent-pink);
  --md-accent-fg-color--transparent: rgba(255, 121, 198, 0.1);
  --md-accent-bg-color: var(--dark-accent-pink);

  --md-code-fg-color: var(--dark-text);
  --md-code-bg-color: var(--dark-bg-alt);

  --md-code-hl-color: rgba(255, 184, 108, 0.2);
  --md-code-hl-number-color: var(--dark-accent-purple);
  --md-code-hl-special-color: var(--dark-accent-pink);
  --md-code-hl-function-color: var(--dark-accent-green);
  --md-code-hl-constant-color: var(--dark-accent-purple);
  --md-code-hl-keyword-color: var(--dark-accent-pink);
  --md-code-hl-string-color: var(--dark-accent-yellow);
  --md-code-hl-name-color: var(--dark-text);
  --md-code-hl-operator-color: var(--dark-accent-pink);
  --md-code-hl-punctuation-color: var(--dark-text);
  --md-code-hl-comment-color: var(--dark-text-muted);
  --md-code-hl-generic-color: var(--dark-text);
  --md-code-hl-variable-color: var(--dark-text);

  --md-typeset-color: var(--dark-text);
  --md-typeset-a-color: var(--dark-accent-cyan);

  --md-typeset-kbd-color: var(--dark-text);
  --md-typeset-kbd-accent-color: var(--dark-bg-alt);
  --md-typeset-kbd-border-color: var(--dark-text-muted);

  --md-typeset-mark-color: rgba(241, 250, 140, 0.3);

  --md-typeset-table-color: var(--dark-bg-alt);

  --md-admonition-fg-color: var(--dark-text);
  --md-admonition-bg-color: var(--dark-bg-alt);

  --md-footer-bg-color: var(--dark-bg-alt);
  --md-footer-bg-color--dark: var(--dark-bg);
}

/* Navigation and sidebar */
[data-md-color-scheme="slate"] .md-nav__link {
  color: var(--dark-text);
}

[data-md-color-scheme="slate"] .md-nav__link:hover {
  color: var(--dark-accent-cyan);
}

[data-md-color-scheme="slate"] .md-nav__link--active {
  color: var(--dark-accent-pink);
}

/* Search */
[data-md-color-scheme="slate"] .md-search__input {
  background-color: var(--dark-bg-alt);
  color: var(--dark-text);
}

[data-md-color-scheme="slate"] .md-search__input::placeholder {
  color: var(--dark-text-muted);
}

/* Tables */
[data-md-color-scheme="slate"] .md-typeset table:not([class]) th {
  background-color: var(--dark-bg-alt);
  color: var(--dark-accent-purple);
}

[data-md-color-scheme="slate"] .md-typeset table:not([class]) tr:hover {
  background-color: rgba(68, 71, 90, 0.5);
}

/* Code blocks */
[data-md-color-scheme="slate"] .highlight {
  background-color: var(--dark-bg-alt);
}

[data-md-color-scheme="slate"] code {
  background-color: var(--dark-bg-alt);
  color: var(--dark-text);
}

/* Admonitions */
[data-md-color-scheme="slate"] .md-typeset .admonition,
[data-md-color-scheme="slate"] .md-typeset details {
  border-color: var(--dark-accent-purple);
  background-color: var(--dark-bg-alt);
}

[data-md-color-scheme="slate"] .md-typeset .admonition-title,
[data-md-color-scheme="slate"] .md-typeset summary {
  background-color: rgba(189, 147, 249, 0.1);
}

/* Note admonition */
[data-md-color-scheme="slate"] .md-typeset .admonition.note,
[data-md-color-scheme="slate"] .md-typeset details.note {
  border-color: var(--dark-accent-cyan);
}

[data-md-color-scheme="slate"] .md-typeset .note > .admonition-title,
[data-md-color-scheme="slate"] .md-typeset .note > summary {
  background-color: rgba(139, 233, 253, 0.1);
}

/* Warning admonition */
[data-md-color-scheme="slate"] .md-typeset .admonition.warning,
[data-md-color-scheme="slate"] .md-typeset details.warning {
  border-color: var(--dark-accent-orange);
}

[data-md-color-scheme="slate"] .md-typeset .warning > .admonition-title,
[data-md-color-scheme="slate"] .md-typeset .warning > summary {
  background-color: rgba(255, 184, 108, 0.1);
}

/* Danger/Error admonition */
[data-md-color-scheme="slate"] .md-typeset .admonition.danger,
[data-md-color-scheme="slate"] .md-typeset .admonition.error,
[data-md-color-scheme="slate"] .md-typeset details.danger,
[data-md-color-scheme="slate"] .md-typeset details.error {
  border-color: var(--dark-accent-red);
}

[data-md-color-scheme="slate"] .md-typeset .danger > .admonition-title,
[data-md-color-scheme="slate"] .md-typeset .error > .admonition-title,
[data-md-color-scheme="slate"] .md-typeset .danger > summary,
[data-md-color-scheme="slate"] .md-typeset .error > summary {
  background-color: rgba(255, 85, 85, 0.1);
}

/* Tip/Success admonition */
[data-md-color-scheme="slate"] .md-typeset .admonition.tip,
[data-md-color-scheme="slate"] .md-typeset .admonition.success,
[data-md-color-scheme="slate"] .md-typeset details.tip,
[data-md-color-scheme="slate"] .md-typeset details.success {
  border-color: var(--dark-accent-green);
}

[data-md-color-scheme="slate"] .md-typeset .tip > .admonition-title,
[data-md-color-scheme="slate"] .md-typeset .success > .admonition-title,
[data-md-color-scheme="slate"] .md-typeset .tip > summary,
[data-md-color-scheme="slate"] .md-typeset .success > summary {
  background-color: rgba(80, 250, 123, 0.1);
}
```

### Light Theme CSS

**File:** `docs/stylesheets/light.css`

```css
/* Light Theme - Clean light color scheme */
/* Applied when scheme: default is active */

:root {
  /* Light theme color palette */
  --light-bg: #ffffff;
  --light-bg-alt: #f5f5f5;
  --light-bg-elevated: #e0e0e0;
  --light-text: #1a1a1a;
  --light-text-muted: #666666;
  --light-accent-blue: #0066cc;
  --light-accent-green: #008000;
  --light-accent-orange: #ff8c00;
  --light-accent-red: #cc0000;
  --light-accent-purple: #6600cc;
  --light-accent-teal: #008080;
}

/* Apply light theme customization */
[data-md-color-scheme="default"] {
  --md-default-bg-color: var(--light-bg);
  --md-default-fg-color: var(--light-text);
  --md-default-fg-color--light: var(--light-text-muted);
  --md-default-fg-color--lighter: var(--light-bg-elevated);
  --md-default-fg-color--lightest: var(--light-bg-alt);

  --md-primary-fg-color: var(--light-accent-purple);
  --md-primary-fg-color--light: var(--light-accent-blue);
  --md-primary-fg-color--dark: var(--light-accent-purple);
  --md-primary-bg-color: var(--light-bg);
  --md-primary-bg-color--light: var(--light-bg-alt);

  --md-accent-fg-color: var(--light-accent-blue);
  --md-accent-fg-color--transparent: rgba(0, 102, 204, 0.1);
  --md-accent-bg-color: var(--light-accent-blue);

  --md-code-fg-color: var(--light-text);
  --md-code-bg-color: var(--light-bg-alt);

  --md-typeset-a-color: var(--light-accent-blue);
  --md-typeset-mark-color: rgba(255, 235, 59, 0.5);
}

/* Navigation */
[data-md-color-scheme="default"] .md-nav__link:hover {
  color: var(--light-accent-blue);
}

[data-md-color-scheme="default"] .md-nav__link--active {
  color: var(--light-accent-purple);
}

/* Admonitions */
[data-md-color-scheme="default"] .md-typeset .admonition.note,
[data-md-color-scheme="default"] .md-typeset details.note {
  border-color: var(--light-accent-blue);
}

[data-md-color-scheme="default"] .md-typeset .admonition.warning,
[data-md-color-scheme="default"] .md-typeset details.warning {
  border-color: var(--light-accent-orange);
}

[data-md-color-scheme="default"] .md-typeset .admonition.danger,
[data-md-color-scheme="default"] .md-typeset .admonition.error,
[data-md-color-scheme="default"] .md-typeset details.danger,
[data-md-color-scheme="default"] .md-typeset details.error {
  border-color: var(--light-accent-red);
}

[data-md-color-scheme="default"] .md-typeset .admonition.tip,
[data-md-color-scheme="default"] .md-typeset .admonition.success,
[data-md-color-scheme="default"] .md-typeset details.tip,
[data-md-color-scheme="default"] .md-typeset details.success {
  border-color: var(--light-accent-green);
}
```

## Documentation Templates

### docs/index.md

```markdown
# WEATHER

{Brief project description}

## Quick Start

```bash
# Docker
docker run -p 64580:80 {PLATFORM_CONTAINER_REGISTRY}/apimgr/weather:latest

# Binary
./weather-linux-amd64 --config server.yml
```

## Features

- {Feature 1}
- {Feature 2}
- {Feature 3}

## Documentation

- [Installation](installation.md) - How to install and run
- [Configuration](configuration.md) - All configuration options
- [API Reference](api.md) - REST API, Swagger, GraphQL
- [Admin Panel](admin.md) - Web UI administration
- [Development](development.md) - Contributing guide

## Links

- [Repository]({PLATFORM_REPO_URL})
- [Live Demo](https://weather.apimgr.us) (if applicable)
- [API Documentation](/openapi) (Swagger UI)
- [GraphQL Playground](/graphql)

## License

MIT - See [LICENSE.md]({PLATFORM_REPO_URL}/blob/main/LICENSE.md)
```

### docs/installation.md

```markdown
# Installation

## Docker (Recommended)

```bash
docker run -d \
  --name weather \
  -p 64580:80 \
  -v weather-data:/data \
  {PLATFORM_CONTAINER_REGISTRY}/apimgr/weather:latest
```

## Binary

Download from [releases]({PLATFORM_REPO_URL}/releases):

```bash
# Linux AMD64
wget {PLATFORM_RELEASE_URL}/weather-linux-amd64
chmod +x weather-linux-amd64
./weather-linux-amd64
```

## Systemd Service

```bash
sudo ./weather --service install
sudo systemctl start weather
sudo systemctl enable weather
```

## Configuration

See [Configuration](configuration.md) for all options.
```

### docs/configuration.md

```markdown
# Configuration

## Config File

Default location: `/etc/apimgr/weather/server.yml`

```yaml
server:
  address: 0.0.0.0
  port: 80

database:
  type: sqlite
  path: /data/db/server.db

# ... (all configuration options)
```

## Environment Variables

All settings can be overridden via environment:

```bash
WEATHER_SERVER_PORT=8080
WEATHER_DATABASE_TYPE=postgres
```

## Admin Panel

All settings are configurable via the web UI at `/admin`.
```

### docs/api.md

```markdown
# API Reference

## REST API

Base URL: `/api/v1/`

### Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/healthz` | GET | Health check |
| `/api/v1/{resource}` | GET | List resources |

## Swagger UI

Interactive API documentation: [/openapi](/openapi)

## GraphQL

GraphQL playground: [/graphql](/graphql)

### Schema

```graphql
# ... (GraphQL schema)
```
```

### docs/admin.md

```markdown
# Admin Panel

## Access

- URL: `/admin`
- First-run setup wizard creates admin account
- Session-based authentication

## Features

- Server configuration
- User management
- Database management
- Backup/restore
- SSL/TLS management
- Monitoring & logs

## Admin API

Programmatic access via `/api/v1/admin/` with bearer token authentication.
```

### docs/development.md

```markdown
# Development Guide

## Prerequisites

- Go 1.21+
- Make
- Docker (optional)

## Build

```bash
git clone {PLATFORM_REPO_URL}
cd weather
make build
```

## Run Locally

```bash
./binaries/weather --config server.yml --debug
```

## Testing

```bash
make test
```

## Contributing

1. Fork the repository
2. Create feature branch
3. Make changes
4. Run tests
5. Submit pull request

## Code Style

- Follow Go standard formatting
- Add tests for new features
- Update documentation
```

---

## Project-Specific Customization

**The theme colors defined above are DEFAULT values.** Individual projects MAY customize colors to match their branding, but MUST:

- Maintain WCAG AA contrast ratios (4.5:1 minimum)
- Keep both light and dark themes readable
- Update `docs/stylesheets/dark.css` and `docs/stylesheets/light.css` accordingly
- Document color choices in project's AI.md file

**Example project-specific customization:**
- Change accent colors to match project branding
- Adjust background shades for better contrast
- Add project logo colors to palette
- Ensure all changes work in BOTH themes

---

# PART 31: I18N & A11Y (NON-NEGOTIABLE)

## Internationalization (i18n)

### Core Requirements

| Requirement | Description |
|-------------|-------------|
| **Encoding** | UTF-8 everywhere - files, database, HTTP responses |
| **Accept-Language** | Respect browser header for language selection |
| **Default language** | English (en) when no preference detected |
| **Fallback chain** | `user preference → Accept-Language → default (en)` |

### Translation File Format

**Location:** `locales/{lang}.json`

```json
{
  "meta": {
    "language": "es",
    "name": "Español",
    "native_name": "Español",
    "direction": "ltr",
    "version": "1.0.0"
  },
  "common": {
    "save": "Guardar",
    "cancel": "Cancelar",
    "delete": "Eliminar",
    "edit": "Editar",
    "loading": "Cargando...",
    "error": "Error",
    "success": "Éxito"
  },
  "auth": {
    "login": "Iniciar sesión",
    "logout": "Cerrar sesión",
    "register": "Registrarse",
    "forgot_password": "¿Olvidaste tu contraseña?"
  },
  "errors": {
    "required": "Este campo es obligatorio",
    "invalid_email": "Correo electrónico inválido",
    "too_short": "Debe tener al menos {min} caracteres",
    "too_long": "No puede exceder {max} caracteres"
  },
  "plurals": {
    "items": {
      "zero": "Sin elementos",
      "one": "{count} elemento",
      "other": "{count} elementos"
    }
  }
}
```

### Adding New Languages

1. Create `locales/{lang}.json` with all keys from `locales/en.json`
2. Add language to `config.server.i18n.available_languages`
3. Language automatically appears in language selector

### RTL (Right-to-Left) Support

| Language | Code | Direction |
|----------|------|-----------|
| Arabic | `ar` | `rtl` |
| Hebrew | `he` | `rtl` |
| Persian | `fa` | `rtl` |
| Urdu | `ur` | `rtl` |

**HTML Implementation:**
```html
<html lang="{{.Lang}}" dir="{{.Dir}}">
```

**CSS for RTL:**
```css
/* Use logical properties */
.element {
  margin-inline-start: 1rem;  /* Not margin-left */
  padding-inline-end: 1rem;   /* Not padding-right */
  text-align: start;          /* Not text-align: left */
}

/* RTL-specific overrides */
[dir="rtl"] .icon-arrow {
  transform: scaleX(-1);
}
```

### Date/Time/Number Formatting

**Use Go's `golang.org/x/text` package for locale-aware formatting.**

| Format Type | Example (en-US) | Example (de-DE) | Example (ar-SA) |
|-------------|-----------------|-----------------|-----------------|
| Date | 12/31/2024 | 31.12.2024 | ٣١/١٢/٢٠٢٤ |
| Time | 2:30 PM | 14:30 | ٢:٣٠ م |
| Number | 1,234.56 | 1.234,56 | ١٬٢٣٤٫٥٦ |
| Currency | $1,234.56 | 1.234,56 € | ١٬٢٣٤٫٥٦ ر.س |
| Percentage | 45.5% | 45,5 % | ٤٥٫٥٪ |

**Implementation:**
```go
import "golang.org/x/text/language"
import "golang.org/x/text/message"

func FormatNumber(n float64, lang string) string {
    tag := language.MustParse(lang)
    p := message.NewPrinter(tag)
    return p.Sprintf("%.2f", n)
}
```

### Plural Rules

**Use CLDR plural categories:** `zero`, `one`, `two`, `few`, `many`, `other`

| Language | Categories Used |
|----------|-----------------|
| English | one, other |
| French | one, other (0 is "one") |
| Russian | one, few, many, other |
| Arabic | zero, one, two, few, many, other |
| Japanese | other (no plural forms) |

**Go Implementation:**
```go
import "golang.org/x/text/feature/plural"

func Pluralize(key string, count int, lang string) string {
    tag := language.MustParse(lang)
    // Select plural form based on count and language rules
    form := plural.Cardinal.MatchPlural(tag, count, 0, 0, 0, 0)
    return translations[lang][key][form.String()]
}
```

### Configuration

```yaml
server:
  i18n:
    enabled: true
    default_language: en
    available_languages:
      - en
      - es
      - de
      - fr
      - ar
      - ja
      - zh
    fallback_language: en
    cookie_name: lang
    cookie_max_age: 31536000  # 1 year
```

---

## Accessibility (a11y)

### Core Requirements

| Requirement | Standard | Description |
|-------------|----------|-------------|
| **WCAG 2.1 AA** | Mandatory | Full compliance required |
| **Keyboard navigation** | Mandatory | All functionality via keyboard |
| **Screen readers** | Mandatory | Full support for NVDA, JAWS, VoiceOver |
| **Color contrast** | 4.5:1 minimum | Text against background |
| **Focus indicators** | Visible | Clear focus styles on all interactive elements |
| **Touch targets** | 44x44px minimum | Mobile accessibility |

### Skip Links

**First focusable element on every page:**

```html
<body>
  <a href="#main-content" class="skip-link">Skip to main content</a>
  <a href="#navigation" class="skip-link">Skip to navigation</a>

  <nav id="navigation">...</nav>
  <main id="main-content">...</main>
</body>
```

```css
.skip-link {
  position: absolute;
  top: -40px;
  left: 0;
  background: var(--color-primary);
  color: white;
  padding: 8px 16px;
  z-index: 100;
  transition: top 0.3s;
}

.skip-link:focus {
  top: 0;
}
```

### ARIA Patterns

#### Live Regions (Dynamic Content)

```html
<!-- Status messages -->
<div role="status" aria-live="polite" aria-atomic="true">
  {{.StatusMessage}}
</div>

<!-- Error alerts -->
<div role="alert" aria-live="assertive">
  {{.ErrorMessage}}
</div>

<!-- Loading indicator -->
<div aria-live="polite" aria-busy="true">
  Loading...
</div>
```

#### Modal Dialogs

```html
<div role="dialog"
     aria-modal="true"
     aria-labelledby="dialog-title"
     aria-describedby="dialog-desc">
  <h2 id="dialog-title">Confirm Delete</h2>
  <p id="dialog-desc">Are you sure you want to delete this item?</p>
  <button>Cancel</button>
  <button>Delete</button>
</div>
```

**Focus Management:**
- Trap focus inside modal when open
- Return focus to trigger element when closed
- First focusable element receives focus on open

#### Navigation Landmarks

```html
<header role="banner">...</header>
<nav role="navigation" aria-label="Main">...</nav>
<main role="main">...</main>
<aside role="complementary">...</aside>
<footer role="contentinfo">...</footer>
```

#### Form Accessibility

```html
<form>
  <!-- Required field -->
  <label for="email">
    Email <span aria-hidden="true">*</span>
    <span class="sr-only">(required)</span>
  </label>
  <input type="email" id="email" name="email"
         required
         aria-required="true"
         aria-describedby="email-hint email-error">
  <span id="email-hint" class="hint">We'll never share your email.</span>
  <span id="email-error" class="error" role="alert" aria-live="polite"></span>

  <!-- Password with show/hide -->
  <label for="password">Password</label>
  <div class="password-field">
    <input type="password" id="password" name="password"
           aria-describedby="password-requirements">
    <button type="button"
            aria-pressed="false"
            aria-label="Show password">
      <span aria-hidden="true">👁</span>
    </button>
  </div>
  <ul id="password-requirements">
    <li>At least 8 characters</li>
    <li>Contains uppercase and lowercase</li>
  </ul>

  <!-- Form submission -->
  <button type="submit" aria-busy="false">
    <span class="button-text">Submit</span>
    <span class="loading-spinner" aria-hidden="true"></span>
  </button>
</form>
```

### Focus Management

| Scenario | Focus Behavior |
|----------|----------------|
| Page load | First heading or main content |
| Modal open | First focusable element in modal |
| Modal close | Element that triggered modal |
| Tab panel switch | First focusable in new panel |
| Accordion expand | Stay on trigger button |
| Error on submit | First field with error |
| Toast notification | Do NOT move focus (use aria-live) |
| Route change (SPA) | Main content heading |

### Screen Reader Announcements

**Announce dynamic changes without moving focus:**

```javascript
// Create announcement element once
const announcer = document.createElement('div');
announcer.setAttribute('role', 'status');
announcer.setAttribute('aria-live', 'polite');
announcer.setAttribute('aria-atomic', 'true');
announcer.className = 'sr-only';
document.body.appendChild(announcer);

// Announce messages
function announce(message) {
  announcer.textContent = '';
  setTimeout(() => {
    announcer.textContent = message;
  }, 100);
}

// Usage
announce('Item saved successfully');
announce('3 search results found');
announce('Form has 2 errors');
```

### Color and Contrast

| Element | Minimum Ratio | Requirement |
|---------|---------------|-------------|
| Normal text | 4.5:1 | WCAG AA |
| Large text (18pt+) | 3:1 | WCAG AA |
| UI components | 3:1 | Borders, icons |
| Focus indicators | 3:1 | Against adjacent colors |

**Never convey information by color alone:**
```html
<!-- Bad -->
<span class="red">Error: Invalid email</span>

<!-- Good -->
<span class="error">
  <span aria-hidden="true">⚠</span>
  Error: Invalid email
</span>
```

### Keyboard Shortcuts

| Key | Action |
|-----|--------|
| `Tab` | Move to next focusable element |
| `Shift+Tab` | Move to previous focusable element |
| `Enter` | Activate button/link |
| `Space` | Activate button, toggle checkbox |
| `Escape` | Close modal/dropdown |
| `Arrow keys` | Navigate within component (tabs, menus) |
| `Home/End` | First/last item in list |

### Screen Reader Only Text

```css
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  white-space: nowrap;
  border: 0;
}

/* Allow focus for skip links */
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
  white-space: normal;
}
```

### Testing Requirements

| Tool | Purpose |
|------|---------|
| axe DevTools | Automated accessibility testing |
| WAVE | Visual accessibility checker |
| Lighthouse | Accessibility audit |
| NVDA/VoiceOver | Screen reader testing |
| Keyboard only | Manual keyboard navigation test |

**Automated tests MUST include accessibility checks:**
```go
// In integration tests
func TestAccessibility(t *testing.T) {
    // Verify skip link exists
    // Verify all images have alt text
    // Verify form labels are associated
    // Verify heading hierarchy
    // Verify landmarks exist
}
```

---


# PART 32: TOR HIDDEN SERVICE (NON-NEGOTIABLE)

## Overview

**ALL projects MUST have built-in Tor hidden service support.**

Tor integration uses **external Tor binary** via `github.com/cretz/bine`. This maintains `CGO_ENABLED=0` compatibility for static binaries while providing full Tor hidden service functionality.

## Configuration

```yaml
server:
  tor:
    # Path to Tor binary (auto-detected if empty)
    binary: ""
    # Data directory for this instance's Tor data
    # Default: {data_dir}/tor/
    data_dir: ""
```

**Notes:**
- Uses external Tor binary (not embedded) for CGO_ENABLED=0 compatibility
- **Auto-enabled if tor binary is installed** - no enable flag needed
- Binary manages its OWN Tor instance (not system Tor)
- When binary stops, its Tor instance stops (clean shutdown)
- .onion address derived from keys in `{data_dir}/tor/site/`
- Completely isolated from any system Tor installation
- **App handles EVERYTHING** - directory creation, permissions, torrc generation, process management
- No external scripts needed - all Tor management is built into the server binary

## Tor Process Management (NON-NEGOTIABLE)

**The application MUST start its OWN dedicated Tor process. NEVER use system Tor.**

This prevents conflicts with any existing Tor installation on the system.

```
1. Find Tor binary:
   ├─ Check config `server.tor.binary` path
   ├─ Check PATH for `tor` executable
   ├─ Check common locations:
   │   ├─ Linux: /usr/bin/tor, /usr/local/bin/tor
   │   ├─ macOS: /usr/local/bin/tor, /opt/homebrew/bin/tor
   │   ├─ Windows: C:\Program Files\Tor\tor.exe
   │   └─ BSD: /usr/local/bin/tor
   └─ NOT FOUND: Log INFO, disable Tor features, continue without Tor

2. Start DEDICATED Tor process:
   ├─ Use application's own DataDir: `{data_dir}/tor/`
   ├─ Use random available ControlPort (not 9051)
   ├─ Disable SocksPort (server-only, not browsing)
   ├─ Completely isolated from system Tor
   ├─ Wait for bootstrap completion
   └─ Create hidden service via ADD_ONION

3. On application shutdown:
   └─ Terminate the dedicated Tor process
```

### Why Dedicated Tor Process?

| Reason | Description |
|--------|-------------|
| **No conflicts** | System Tor uses 9050/9051, we use random ports |
| **Isolation** | Our DataDir is separate from system Tor |
| **Clean shutdown** | We control the process lifecycle |
| **No permissions issues** | Don't need access to system Tor control |
| **Predictable behavior** | Always same configuration |

### Tor Logging Levels (NON-NEGOTIABLE)

**Tor is OPTIONAL. Missing Tor is NOT an error.**

| Event | Log Level | Message Example |
|-------|-----------|-----------------|
| Tor binary not found | **INFO** | `Tor binary not found, hidden service disabled` |
| Tor disabled (no binary) | **INFO** | `Tor hidden service: disabled (tor not installed)` |
| Tor starting | **INFO** | `Starting Tor hidden service...` |
| Tor started successfully | **INFO** | `Tor hidden service: xyz123...abc.onion` |
| Tor bootstrap timeout | **WARN** | `Tor bootstrap timeout, hidden service unavailable` |
| Tor process crash | **WARN** | `Tor process crashed, attempting restart` |
| Tor restart failed | **WARN** | `Tor restart failed: <reason>` |
| Tor network unreachable | **WARN** | `Tor network unreachable, will retry` |
| Tor control connection lost | **WARN** | `Tor control connection lost, restarting` |

**Rules:**
- Tor not detected = **INFO** (not an error - Tor is optional)
- Tor startup/runtime errors = **WARN** (server continues without Tor)
- Server NEVER fails to start due to Tor issues
- All Tor operations are best-effort, non-blocking

## Implementation

### Library

Use `github.com/cretz/bine` (pure Go, CGO_ENABLED=0 compatible):

```go
import (
    "github.com/cretz/bine/tor"
)

func startDedicatedTor(ctx context.Context, localPort int) (*tor.Tor, *tor.OnionService, error) {
    // Start OUR OWN Tor process - completely separate from system Tor
    t, err := tor.Start(ctx, &tor.StartConf{
        // Our own data directory - isolated from system Tor
        DataDir: paths.GetDataDir() + "/tor",

        // Let bine pick available ports (avoids conflict with system Tor 9050/9051)
        // These are set automatically to available ports
        NoAutoSocksPort: false,

        // Optional: specify path if not in PATH
        // ExePath: "/usr/bin/tor",

        // Debug output (development only)
        // DebugWriter: os.Stderr,
    })
    if err != nil {
        return nil, nil, fmt.Errorf("failed to start dedicated tor: %w", err)
    }

    // Wait for Tor to bootstrap
    dialCtx, cancel := context.WithTimeout(ctx, 3*time.Minute)
    defer cancel()
    if err := t.EnableNetwork(dialCtx, true); err != nil {
        t.Close()
        return nil, nil, fmt.Errorf("failed to enable tor network: %w", err)
    }

    // Create hidden service
    onion, err := t.Listen(ctx, &tor.ListenConf{
        RemotePorts: []int{80},
        LocalPort:   localPort,
    })
    if err != nil {
        t.Close()
        return nil, nil, fmt.Errorf("failed to create onion service: %w", err)
    }

    // onion.ID contains the .onion address (without .onion suffix)
    log.Printf("Tor hidden service started: %s.onion", onion.ID)
    return t, onion, nil
}

// Shutdown cleanly terminates our dedicated Tor process
func shutdownTor(t *tor.Tor) error {
    if t != nil {
        return t.Close()
    }
    return nil
}
```

### Port Allocation

| Port | System Tor | Our Tor |
|------|------------|---------|
| SocksPort | 9050 | 0 (disabled - server only) |
| ControlPort | 9051 | Random available |
| DataDir | `/var/lib/tor` | `{data_dir}/tor/` |

**bine automatically selects available ControlPort**, ensuring no conflict with system Tor. SocksPort is disabled since we're running as a hidden service server, not browsing through Tor.

### Tor Configuration Optimizations (NON-NEGOTIABLE)

**Tor is used ONLY for hidden services. Optimize accordingly.**

```go
// Optimized torrc settings for hidden-service-only mode
func getTorConfig() string {
    return `
# Hidden service only - not a relay or exit
SocksPort 0
# No SOCKS proxy needed - we're server only

# Disable unused features
ExitRelay 0
ExitPolicy reject *:*
# Never act as exit node

# Don't relay traffic for others
ORPort 0
DirPort 0

# Reduce circuit building (we only need service circuits)
MaxCircuitDirtiness 600
# Keep circuits longer

# Reduce bandwidth for Tor overhead
BandwidthRate 1 MB
BandwidthBurst 2 MB

# Hidden service optimizations
HiddenServiceSingleHopMode 0
# Keep full anonymity (3 hops)

# Faster startup
FetchDirInfoEarly 1
FetchDirInfoExtraEarly 1

# Reduce memory usage
DisableDebuggerAttachment 1
`
}
```

| Setting | Value | Reason |
|---------|-------|--------|
| `SocksPort 0` | Disabled | Not browsing, server only |
| `ExitRelay 0` | Disabled | Not an exit node |
| `ORPort 0` | Disabled | Not relaying traffic |
| `DirPort 0` | Disabled | Not a directory server |
| `ExitPolicy reject *:*` | Block all | Extra safety |
| `MaxCircuitDirtiness 600` | 10 minutes | Keep circuits longer |

### Tor Process Lifecycle (NON-NEGOTIABLE)

**The application MUST fully manage the Tor process lifecycle.**

| Event | Action |
|-------|--------|
| **App Start** | Find Tor binary → Start dedicated Tor process → Wait for bootstrap → Create hidden service |
| **App Running** | Monitor Tor process, restart if crashed |
| **App Shutdown** | Terminate Tor process gracefully (SIGTERM) |
| **App Crash** | Tor process should terminate (child process dies with parent) |
| **SIGTERM/SIGINT** | Graceful shutdown: stop Tor, then exit |
| **SIGHUP** | Reload config, restart Tor if settings changed |

### Tor Restart Triggers (NON-NEGOTIABLE)

**Tor MUST be restarted when these events occur:**

| Trigger | Action | Notes |
|---------|--------|-------|
| **Regenerate .onion address** | Stop Tor → Delete keys → Start Tor | New random address |
| **Apply vanity address** | Stop Tor → Replace keys → Start Tor | Use generated vanity keys |
| **Import external keys** | Stop Tor → Replace keys → Start Tor | Use imported keys |
| **Start Tor** | Start Tor | Manual start (auto-starts on boot if installed) |
| **Stop Tor** | Stop Tor | Manual stop (temporary, restarts on reboot) |
| **Tor process crash** | Restart Tor | Auto-recovery |
| **Tor unresponsive** | Stop Tor → Start Tor | Health check failed |
| **Config change** | Stop Tor → Start Tor | Settings changed |

### Restart Implementation

```go
// TorManager handles all Tor lifecycle operations
type TorManager struct {
    mu        sync.Mutex
    tor       *tor.Tor
    onion     *tor.OnionService
    dataDir   string
    localPort int
    ctx       context.Context
    cancel    context.CancelFunc
}

// Restart stops and starts Tor (used for config changes, recovery)
func (tm *TorManager) Restart() error {
    tm.mu.Lock()
    defer tm.mu.Unlock()

    // Stop existing
    if tm.tor != nil {
        tm.tor.Close()
        tm.tor = nil
        tm.onion = nil
    }

    // Start fresh
    return tm.startLocked()
}

// RegenerateAddress creates a new random .onion address
func (tm *TorManager) RegenerateAddress() (string, error) {
    tm.mu.Lock()
    defer tm.mu.Unlock()

    // Stop Tor
    if tm.tor != nil {
        tm.tor.Close()
        tm.tor = nil
        tm.onion = nil
    }

    // Delete existing keys
    keysDir := filepath.Join(tm.dataDir, "site")
    if err := os.RemoveAll(keysDir); err != nil {
        return "", fmt.Errorf("failed to remove old keys: %w", err)
    }

    // Start Tor - new keys will be generated
    if err := tm.startLocked(); err != nil {
        return "", err
    }

    return tm.onion.ID + ".onion", nil
}

// ApplyKeys stops Tor, replaces keys, and restarts
func (tm *TorManager) ApplyKeys(privateKey []byte) (string, error) {
    tm.mu.Lock()
    defer tm.mu.Unlock()

    // Stop Tor
    if tm.tor != nil {
        tm.tor.Close()
        tm.tor = nil
        tm.onion = nil
    }

    // Write new keys
    keysDir := filepath.Join(tm.dataDir, "site")
    os.MkdirAll(keysDir, 0700)
    keyPath := filepath.Join(keysDir, "hs_ed25519_secret_key")
    if err := os.WriteFile(keyPath, privateKey, 0600); err != nil {
        return "", fmt.Errorf("failed to write key: %w", err)
    }

    // Start Tor with new keys
    if err := tm.startLocked(); err != nil {
        return "", err
    }

    return tm.onion.ID + ".onion", nil
}

// SetEnabled enables or disables Tor
func (tm *TorManager) SetEnabled(enabled bool) error {
    tm.mu.Lock()
    defer tm.mu.Unlock()

    if enabled {
        if tm.tor == nil {
            return tm.startLocked()
        }
    } else {
        if tm.tor != nil {
            tm.tor.Close()
            tm.tor = nil
            tm.onion = nil
        }
    }
    return nil
}
```

### Signal Handling with Tor

```go
func main() {
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()

    // Start Tor
    torProcess, onion, err := startDedicatedTor(ctx, localPort)
    if err != nil {
        log.Printf("Warning: Tor disabled - %v", err)
        // Continue without Tor
    }

    // Handle shutdown signals
    // NOTE: Use signal package's setupSignalHandler() for proper cross-platform support
    // This is simplified - actual implementation uses platform-specific signal_*.go files
    sigChan := make(chan os.Signal, 1)
    // See signal/signal_unix.go and signal_windows.go
    registerShutdownSignals(sigChan)

    go func() {
        <-sigChan
        log.Println("Shutting down...")

        // Stop Tor FIRST
        if torProcess != nil {
            log.Println("Stopping Tor process...")
            torProcess.Close()
        }

        // Then cancel context for other goroutines
        cancel()
    }()

    // Run server...
}
```

### Tor Process Monitoring

```go
// Monitor Tor and restart if it crashes
func monitorTor(ctx context.Context, torProcess *tor.Tor, restartFunc func() (*tor.Tor, error)) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            // Check if Tor is still responsive
            if torProcess != nil {
                // Ping control connection
                if _, err := torProcess.Control.GetInfo("version"); err != nil {
                    log.Println("Tor process unresponsive, restarting...")
                    torProcess.Close()
                    newTor, err := restartFunc()
                    if err != nil {
                        log.Printf("Failed to restart Tor: %v", err)
                    } else {
                        torProcess = newTor
                    }
                }
            }
        }
    }
}
```

### Binary Size

No impact on binary size - Tor is external. Application binary remains small and static.

### Storage Locations

**Tor dirs are ALWAYS under the app's dirs (binary owns Tor):**

| Data | Location |
|------|----------|
| Tor config directory | `{config_dir}/tor/` |
| Tor config file | `{config_dir}/tor/torrc` |
| Tor data directory | `{data_dir}/tor/` |
| Hidden service keys | `{data_dir}/tor/site/` |
| Tor process PID | `{data_dir}/tor/tor.pid` |
| Tor log file | `{log_dir}/tor.log` |

**This applies to ALL environments:**

| Environment | Tor Config | Tor Data | Tor Log |
|-------------|------------|----------|---------|
| Docker | `/config/weather/tor/` | `/data/weather/tor/` | `/data/log/weather/tor.log` |
| Linux root | `/etc/apimgr/weather/tor/` | `/var/lib/apimgr/weather/tor/` | `/var/log/apimgr/weather/tor.log` |
| Linux user | `~/.config/apimgr/weather/tor/` | `~/.local/share/apimgr/weather/tor/` | `~/.local/log/apimgr/weather/tor.log` |
| macOS | `~/Library/Application Support/.../tor/` | Same | `~/Library/Logs/apimgr/weather/tor.log` |
| Windows | `%AppData%\...\tor\` | Same | `%AppData%\...\log\tor.log` |

### Runtime Directory Handling (NON-NEGOTIABLE)

**Binary MUST ensure directories exist with correct permissions BEFORE creating any files.**

```go
// Called during Tor startup, before writing torrc or starting tor process
func ensureTorDirs() error {
    configDir := paths.GetConfigDir()
    dataDir := paths.GetDataDir()

    // Tor directories (all under app's dirs, binary owns Tor)
    dirs := []string{
        filepath.Join(configDir, "tor"),           // torrc location
        filepath.Join(dataDir, "tor"),             // Tor data
        filepath.Join(dataDir, "tor", "site"),     // Hidden service keys
    }

    for _, dir := range dirs {
        // Create directory
        if err := os.MkdirAll(dir, 0700); err != nil {
            return fmt.Errorf("create tor dir %s: %w", dir, err)
        }
        // Enforce permissions even if dir already existed
        if err := os.Chmod(dir, 0700); err != nil {
            return fmt.Errorf("chmod tor dir %s: %w", dir, err)
        }
        // Enforce ownership (current user)
        uid := os.Getuid()
        gid := os.Getgid()
        if err := os.Chown(dir, uid, gid); err != nil {
            // Non-fatal on Windows (no chown)
            if runtime.GOOS != "windows" {
                return fmt.Errorf("chown tor dir %s: %w", dir, err)
            }
        }
    }

    return nil
}

// ensureTorFile creates/updates a file with correct permissions
func ensureTorFile(path string, content []byte) error {
    // Ensure parent dir exists
    if err := os.MkdirAll(filepath.Dir(path), 0700); err != nil {
        return fmt.Errorf("create parent dir: %w", err)
    }

    // Write file with restricted permissions
    if err := os.WriteFile(path, content, 0600); err != nil {
        return fmt.Errorf("write file: %w", err)
    }

    // Enforce permissions (in case file existed with wrong perms)
    if err := os.Chmod(path, 0600); err != nil {
        return fmt.Errorf("chmod file: %w", err)
    }

    // Enforce ownership
    uid := os.Getuid()
    gid := os.Getgid()
    if runtime.GOOS != "windows" {
        if err := os.Chown(path, uid, gid); err != nil {
            return fmt.Errorf("chown file: %w", err)
        }
    }

    return nil
}
```

| Rule | Description |
|------|-------------|
| **Create before write** | Dirs must exist before creating torrc or keys |
| **Permissions: 0700** | Tor directories are private (owner only, `rwx------`) |
| **Permissions: 0600** | Tor files are private (owner only, `rw-------`) |
| **Ownership** | Current user/group (NOT tor user, app owns everything) |
| **Enforce on exist** | Always chmod/chown even if dir/file already exists |
| **Idempotent** | Safe to call multiple times |

**Tor File Permissions:**

| File/Dir | Path | Permissions | Owner |
|----------|------|-------------|-------|
| Config dir | `{config_dir}/tor/` | `0700` | app user |
| torrc | `{config_dir}/tor/torrc` | `0600` | app user |
| Data dir | `{data_dir}/tor/` | `0700` | app user |
| Site dir | `{data_dir}/tor/site/` | `0700` | app user |
| Private key | `{data_dir}/tor/site/hs_ed25519_secret_key` | `0600` | app user |
| Public key | `{data_dir}/tor/site/hs_ed25519_public_key` | `0600` | app user |
| Hostname | `{data_dir}/tor/site/hostname` | `0600` | app user |
| PID file | `{data_dir}/tor/tor.pid` | `0600` | app user |
| Log file | `{log_dir}/tor.log` | `0600` | app user |

## Admin Panel

### /{adminpath}/server/tor (Web UI)

| Element | Type | Description |
|---------|------|-------------|
| Tor Service | Toggle switch | Start/Stop hidden service (auto-starts on boot) |
| Status | Indicator | ● Connected / ○ Disconnected / ⚠ Error |
| .onion Address | Read-only text | Full address with copy button |
| Regenerate Address | Button | Creates new random .onion (requires confirmation modal) |
| Vanity Prefix | Text input | Desired prefix (max 6 characters) |
| Generate Vanity | Button | Starts background generation |
| Vanity Status | Progress indicator | Shows when generating in background |
| Import Keys | File upload | Import externally generated keys |

**Status Card Example:**
```
┌─────────────────────────────────────────────────────────┐
│ Tor Hidden Service                                      │
│                                                         │
│ Status: ● Connected                                     │
│ Address: abcd1234...wxyz.onion                  [Copy]  │
│                                                         │
│ [Regenerate Address]                                    │
├─────────────────────────────────────────────────────────┤
│ Vanity Address                                          │
│                                                         │
│ Prefix: [______] (max 6 chars)  [Generate]              │
│                                                         │
│ ⏳ Generating: "jokes" - 2h 15m elapsed...              │
│    [Cancel]                                             │
├─────────────────────────────────────────────────────────┤
│ Import External Keys                      [Import Keys] │
│ ⓘ Help: How to generate longer vanity addresses        │
└─────────────────────────────────────────────────────────┘
```

### Vanity Address Generation

**Built-in generation (max 6 characters):**

| Prefix Length | Approximate Time |
|---------------|------------------|
| 1-4 chars | Seconds to minutes |
| 5 chars | Minutes to hours |
| 6 chars | Hours to days |

**Behavior:**
- Generation runs in background
- Current .onion address remains active while generating
- Notification sent when vanity address is ready
- User clicks notification or "Apply" button to activate
- Old keys deleted, new vanity keys activated
- Tor restarts with new address

### External Vanity Generation (7+ characters)

For prefixes longer than 6 characters, use external tools with GPU acceleration. The admin panel includes documentation (expandable help section):

**Using mkp224o (CPU):**
```bash
# Install
git clone https://github.com/cathugger/mkp224o
cd mkp224o && ./autogen.sh && ./configure && make

# Generate (example: 7-char prefix "myapp12")
./mkp224o -d ./keys myapp12

# Output: ./keys/myapp12xxxxx.onion/
#   ├── hostname        # Your .onion address
#   ├── hs_ed25519_public_key
#   └── hs_ed25519_secret_key
```

**Using mkp224o (GPU - much faster):**
```bash
# With CUDA support
./configure --enable-cuda
make

# Generate
./mkp224o -d ./keys myapp12
```

**Importing keys:**
1. Generate keys using mkp224o or similar tool
2. In admin panel, click "Import Keys"
3. Upload `hs_ed25519_secret_key` file (or zip containing both key files)
4. Confirm to replace current address
5. Tor restarts with imported keys

**Time estimates for longer prefixes:**

| Prefix Length | CPU Time | GPU Time |
|---------------|----------|----------|
| 7 chars | Days to weeks | Hours to days |
| 8 chars | Weeks to months | Days to weeks |
| 9+ chars | Months to years | Weeks to months |

**Security Notes:**
- .onion address shown only after admin authentication
- "Regenerate Address" requires confirmation modal (destructive - old address stops working)
- Address regeneration logged to audit log
- Imported keys should be generated on a trusted machine
- Delete source key files after successful import

### API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/tor` | GET | Get Tor status and .onion address |
| `/api/v1/admin/server/tor` | PATCH | Update Tor settings |
| `/api/v1/admin/server/tor/regenerate` | POST | Regenerate .onion address |
| `/api/v1/admin/server/tor/vanity` | GET | Get vanity generation status |
| `/api/v1/admin/server/tor/vanity` | POST | Start vanity generation |
| `/api/v1/admin/server/tor/vanity` | DELETE | Cancel vanity generation |
| `/api/v1/admin/server/tor/vanity/apply` | POST | Apply vanity address |
| `/api/v1/admin/server/tor/import` | POST | Import external keys |

### Response Format

```json
{
  "enabled": true,
  "status": "connected",
  "onion_address": "abcd1234efgh5678ijkl9012mnop3456qrst7890uvwx.onion",
  "uptime": "2d 5h 30m"
}
```

## Behavior

| Scenario | Behavior |
|----------|----------|
| First run | Tor starts, generates .onion address, saves to config |
| Subsequent runs | Tor starts, uses existing .onion address |
| Disabled in config | Tor does not start, no .onion available |
| Regenerate address | Old keys deleted, new .onion generated, config updated |
| Network issues | Tor retries connection automatically |

## CLI

The `--status` command includes Tor and cluster status:

### Single Instance

```
$ myapp --status

Server Status: Running
  Port: 8080
  Mode: production
  Uptime: 2d 5h 30m

Node: standalone
Cluster: disabled

Tor Hidden Service: Connected
  Address: abcd1234...wxyz.onion
```

### Cluster Mode

```
$ myapp --status

Server Status: Running
  Port: 8080
  Mode: production
  Uptime: 2d 5h 30m

Node: node-abc123
  Hostname: server-1.example.com

Cluster: connected
  Status: healthy
  Nodes: 3
  Database: postgres://db.example.com/myapp

Tor Hidden Service: Connected
  Address: abcd1234...wxyz.onion
```

### Status Fields

| Field | Description |
|-------|-------------|
| Node | Node ID (standalone or unique ID) |
| Hostname | Server hostname |
| Cluster | disabled, connected, degraded, disconnected |
| Nodes | Number of nodes in cluster |
| Database | Database connection info (driver://host/db) |

---



# PART 33: MULTI-USER (OPTIONAL - NON-NEGOTIABLE WHEN IMPLEMENTED)


## Overview

**This PART covers regular user accounts (end-users). Server Admin accounts are covered in PART 17: ADMIN PANEL.**

**Projects can operate in two modes: admin-only or multi-user.**

| Mode | Use Case | Default |
|------|----------|---------|
| **Admin-only** | Simple APIs (jokes, quotes, etc.) - just server admin account | YES |
| **Multi-user** | Apps needing end-user accounts, registration, profiles, API tokens | NO |

**Key Distinction:**
- **Server Admin** (PART 17): Administrative accounts for managing the app - **always required**
- **Regular Users** (this PART): End-user accounts for using the app - **optional**

| Aspect | Server Admin (PART 17) | Regular User (this PART) |
|--------|------------------------|--------------------------|
| **Purpose** | Manage server, configuration | Use application features |
| **Storage** | `admins` table | `users` table |
| **Required** | **YES - all projects** | **NO - optional** |
| **Access** | `/admin/*` only | `/users/*` routes |
| **Created by** | Setup wizard, admin invite | Registration, admin invitation |

**See PART 17: ADMIN PANEL for Server Admin authentication, setup wizard, MFA, and admin management.**

## Registration Modes

**Multi-user apps use a SINGLE setting to control registration behavior.**

**Config setting:**
```yaml
users:
  # Enable multi-user mode
  enabled: true

  registration:
    # Registration mode: disabled, public, private, approval
    mode: disabled
```

### Registration Mode Definitions

| Mode | Who Can Register | Use Case | Admin Action Required |
|------|------------------|----------|----------------------|
| **disabled** | No one | Admin-created accounts only | Admin creates all users |
| **public** | Anyone | Open community, public service | None (auto-active after email verify) |
| **private** | Invite code holders only | Controlled growth, beta testing | Users generate invite codes |
| **approval** | Anyone (pending approval) | Moderated community | Admin approves each registration |

### Mode: disabled

**No registration allowed. Admin creates all user accounts.**

- `/auth/register` → 404 or redirect to `/auth/login`
- Registration form not shown anywhere
- Only admins can create users via `/admin/server/users/create`
- Use for: Internal tools, admin-only services

### Mode: public

**Anyone can register with valid email. Immediate access after email verification.**

- `/auth/register` → Registration form
- User submits username, email, password
- Email verification sent (if `require_email_verification: true`)
- After verification → account immediately active
- No admin approval needed
- Use for: Public services, open communities

### Mode: private

**Invite-only registration. Users need an invite code.**

- Existing users generate invite codes at `/users/invites/create`
- Invite code has expiration (`invite_expiration_days` config)
- New user visits `/auth/register?invite={code}`
- Invite code validated, user submits registration form
- Email verification sent (if `require_email_verification: true`)
- After verification → account active
- Invite code consumed (one-time use)
- Use for: Controlled growth, beta testing, exclusive communities

**Invite code management:**
- Users can create up to `max_invites_per_user` codes
- Invite codes expire after `invite_expiration_days`
- Track who invited whom (referral tracking)
- Admin can see all invites at `/admin/server/users/invites`

### Mode: approval

**Anyone can register, but admin must approve before account is active.**

- `/auth/register` → Registration form
- User submits registration form
- Email verification sent (if `require_email_verification: true`)
- After verification → account created as **pending**
- Admin notified of pending user
- Admin reviews at `/admin/server/users/pending`
- Admin approves/rejects
- If approved → account active, user notified
- If rejected → account deleted, user notified
- Use for: Moderated communities, quality control

## Regular User Behavior

| Route | Regular User Access |
|-------|---------------------|
| `/admin/*` | NO - 403 Forbidden (unless user has admin role) |
| `/users/*` | Full access to own profile, settings, tokens |
| `/auth/login` | Login page |
| `/auth/logout` | Logout |
| Public routes | Authenticated view (may show user-specific content) |

**Regular User Accounts:**
- Stored in database (users table)
- Managed via `/users/{id}`, `/users/settings`
- Can have roles (admin, user, custom)
- Multiple accounts supported

## User Account Security (NON-NEGOTIABLE)

**Regular users have access to the same account security features as server admins.**

### Passkeys/WebAuthn

| Feature | Description |
|---------|-------------|
| **Registration** | User can register multiple passkeys at `/users/settings/security` |
| **Login** | Passkey can be used as primary login or as 2FA |
| **Device-bound** | Each passkey tied to specific device/authenticator |
| **Naming** | User names each passkey for identification |
| **Revocation** | User can revoke individual passkeys |
| **Backup** | Recovery keys provided when first passkey registered |

### TOTP Two-Factor Authentication

| Feature | Description |
|---------|-------------|
| **Setup** | QR code + manual entry key at `/users/settings/security` |
| **Apps supported** | Any TOTP app (Google Authenticator, Authy, 1Password, etc.) |
| **Backup codes** | 10 one-time recovery codes generated on setup |
| **Regenerate** | Can regenerate backup codes (invalidates old ones) |
| **Disable** | Requires current TOTP code or recovery key to disable |

### Account Email vs Notification Email (NON-NEGOTIABLE)

**Users can configure separate email addresses for security vs general notifications.**

| Email Type | Purpose | Required | Examples |
|------------|---------|----------|----------|
| **Account Email** | Security-critical communications | YES | Password reset, 2FA recovery, security alerts, login from new device |
| **Notification Email** | General notifications (non-security) | NO (defaults to account email) | Activity updates, mentions, newsletter, product updates |

**Rules:**
- Account email is set during registration (required)
- Notification email is optional (defaults to account email if not set)
- Both emails must be verified before use
- Account email changes require current password + 2FA (if enabled)
- Notification email changes only require current session
- **All email features require working SMTP** - if SMTP unavailable, no emails sent

**User Settings Email UI (`/users/settings/email`):**
```
┌─────────────────────────────────────────────────────────────┐
│  Email Settings                                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Account Email (security notifications):                    │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ user@example.com                      ✓ Verified    │    │
│  └─────────────────────────────────────────────────────┘    │
│  [Change Account Email]                                     │
│  Used for: password reset, 2FA recovery, security alerts    │
│                                                             │
│  Notification Email (general notifications):                │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ notifications@example.com             ✓ Verified    │    │
│  └─────────────────────────────────────────────────────┘    │
│  [Change] [Remove]                                          │
│  Used for: activity updates, mentions, newsletters          │
│  [ ] Use account email for all notifications                │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### Scoped Notification Preferences (NON-NEGOTIABLE)

**Users can enable/disable specific notification categories.**

| Category | Default | Description |
|----------|---------|-------------|
| **Security Alerts** | ON (locked) | Cannot disable - login from new device, password changed, 2FA changed |
| **Session Notifications** | ON | Session started from new location |
| **Activity** | ON | Mentions, replies, follows (if applicable) |
| **Product Updates** | OFF | New features, announcements |
| **Newsletter** | OFF | Marketing emails, tips |

**Notification Preferences UI (`/users/settings/notifications`):**
```
┌─────────────────────────────────────────────────────────────┐
│  Notification Preferences                                   │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Security (cannot be disabled):                             │
│  [✓] Security alerts (login, password, 2FA changes)        │
│                                                             │
│  Account:                                                   │
│  [✓] Session notifications                                  │
│                                                             │
│  Activity:                                                  │
│  [✓] Mentions and replies                                   │
│  [✓] New followers                                          │
│                                                             │
│  Marketing:                                                 │
│  [ ] Product updates and announcements                      │
│  [ ] Newsletter and tips                                    │
│                                                             │
│  Delivery: [Email ▼]  (requires SMTP)                       │
│                                                             │
│  [Save Preferences]                                         │
└─────────────────────────────────────────────────────────────┘
```

**SMTP Requirement:**
- All email notifications require working SMTP configuration
- If SMTP unavailable, in-app notifications only (no email delivery)
- See PART 18: EMAIL & NOTIFICATIONS for SMTP configuration

### Username Validation (NON-NEGOTIABLE)

**Username Rules:**
| Rule | Value |
|------|-------|
| Min length | 3 characters |
| Max length | 32 characters |
| Allowed chars | `a-z`, `0-9`, `_`, `-` (lowercase only) |
| Must start with | Letter (`a-z`) |
| Cannot end with | `_` or `-` |
| No consecutive | `__`, `--`, `_-`, `-_` |

**Username Blocklist (case-insensitive):**

```go
var UsernameBlocklist = []string{
    // System & Administrative
    "admin", "administrator", "root", "system", "sysadmin", "superuser",
    "master", "owner", "operator", "manager", "moderator", "mod",
    "staff", "support", "helpdesk", "help", "service", "daemon",

    // Server & Technical
    "server", "host", "node", "cluster", "api", "www", "web", "mail",
    "email", "smtp", "ftp", "ssh", "dns", "proxy", "gateway", "router",
    "firewall", "localhost", "local", "internal", "external", "public",
    "private", "network", "database", "db", "cache", "redis", "mysql",
    "postgres", "mongodb", "elastic", "nginx", "apache", "docker",

    // Application & Service Names
    "app", "application", "bot", "robot", "crawler", "spider", "scraper",
    "webhook", "callback", "cron", "scheduler", "worker", "queue", "job",
    "task", "process", "service", "microservice", "lambda", "function",

    // Authentication & Security
    "auth", "authentication", "login", "logout", "signin", "signout",
    "signup", "register", "password", "passwd", "token", "oauth", "sso",
    "saml", "ldap", "kerberos", "security", "secure", "ssl", "tls",
    "certificate", "cert", "key", "secret", "credential", "session",

    // Roles & Permissions
    "guest", "anonymous", "anon", "user", "users", "member", "members",
    "subscriber", "editor", "author", "contributor", "reviewer", "auditor",
    "analyst", "developer", "dev", "devops", "engineer", "architect",
    "designer", "tester", "qa", "billing", "finance", "legal", "hr",
    "sales", "marketing", "ceo", "cto", "cfo", "coo", "founder", "cofounder",

    // Common Reserved
    "account", "accounts", "profile", "profiles", "settings", "config",
    "configuration", "dashboard", "panel", "console", "portal", "home",
    "index", "main", "default", "null", "nil", "undefined", "void",
    "true", "false", "test", "testing", "debug", "demo", "example",
    "sample", "temp", "temporary", "tmp", "backup", "archive", "log",
    "logs", "audit", "report", "reports", "analytics", "stats", "status",

    // API & Endpoints
    "api", "rest", "graphql", "grpc", "websocket", "ws", "wss", "http",
    "https", "endpoint", "endpoints", "route", "routes", "path", "url",
    "uri", "callback", "hook", "hooks", "event", "events", "stream",

    // Content & Media
    "blog", "news", "article", "articles", "post", "posts", "page", "pages",
    "feed", "rss", "atom", "sitemap", "robots", "favicon", "static",
    "assets", "images", "image", "img", "media", "upload", "uploads",
    "download", "downloads", "file", "files", "document", "documents",

    // Communication
    "contact", "message", "messages", "chat", "notification", "notifications",
    "alert", "alerts", "inbox", "outbox", "sent", "draft", "drafts",
    "spam", "abuse", "report", "flag", "block", "mute", "ban",

    // Commerce & Billing
    "shop", "store", "cart", "checkout", "order", "orders", "invoice",
    "invoices", "payment", "payments", "subscription", "subscriptions",
    "plan", "plans", "pricing", "billing", "refund", "coupon", "discount",

    // Social Features
    "follow", "follower", "followers", "following", "friend", "friends",
    "like", "likes", "share", "shares", "comment", "comments", "reply",
    "mention", "mentions", "tag", "tags", "group", "groups", "team", "teams",
    "community", "communities", "forum", "forums", "channel", "channels",

    // Brand & Legal
    "official", "verified", "trusted", "partner", "affiliate", "sponsor",
    "brand", "trademark", "copyright", "legal", "terms", "privacy",
    "policy", "policies", "tos", "eula", "gdpr", "dmca", "abuse",

    // Offensive / Impersonation Prevention
    "fuck", "shit", "ass", "bitch", "bastard", "damn", "cunt", "dick",
    "penis", "vagina", "sex", "porn", "xxx", "nude", "naked", "nsfw",
    "kill", "murder", "death", "die", "suicide", "hate", "nazi", "hitler",
    "racist", "racism", "terrorist", "terrorism", "isis", "alqaeda",

    // Numbers & Special
    "0", "1", "123", "1234", "12345", "000", "111", "666", "911", "420", "69",

    // Common Spam Patterns
    "info", "noreply", "no-reply", "donotreply", "mailer", "postmaster",
    "webmaster", "hostmaster", "abuse", "spam", "junk", "trash",

    // Project-specific (dynamic)
    "weather", "apimgr",
}
```

**Blocklist Notes:**
- Server admin account is exempt from this blocklist
- Blocklist is checked case-insensitively
- Also blocks usernames that contain blocklisted words as substrings for critical terms (admin, root, system, mod, official, verified)
- Custom blocklist entries can be added via config

### Username & Email Rules (NON-NEGOTIABLE)

**Case Insensitivity:**
- Usernames are case-insensitive: `admin` = `Admin` = `aDmIn`
- Emails are case-insensitive: `me@example.com` = `Me@Example.COM`
- Stored in lowercase, compared in lowercase

**Login Identifier (NON-NEGOTIABLE):**

Users can log in with ANY of these three identifiers:

| Identifier | Format | Example | Detection |
|------------|--------|---------|-----------|
| **User ID** | Numeric only | `12345` | All digits |
| **Username** | Text (no @) | `johndoe` | Letters/numbers, no `@` |
| **Email** | Contains @ | `john@example.com` | Contains `@` |

**Detection Logic:**
```go
func DetectIdentifierType(input string) string {
    // Numeric only = User ID
    if regexp.MustCompile(`^\d+$`).MatchString(input) {
        return "user_id"
    }
    // Contains @ = Email
    if strings.Contains(input, "@") {
        return "email"
    }
    // Otherwise = Username
    return "username"
}
```

**API Request:**

`POST /api/v1/auth/login`

Identifier can be: username, user_id, or email.

```json
{
  "identifier": "johndoe",
  "password": "secretpassword"
}
```

**All identifiers must be unique across all users.**

**Email Addresses:**
| SMTP Configured | Max Emails | Verification |
|-----------------|------------|--------------|
| No | 1 (primary only) | Not possible |
| Yes | Unlimited | Additional emails must be verified |

**Email Types:**
| Type | Purpose | Used For |
|------|---------|----------|
| **Account Email** | Security & account recovery | Password reset, 2FA recovery, security alerts, login notifications |
| **Notification Email** | Non-security communications | Newsletters, updates, marketing, general notifications |

**Email Validation Rules (NON-NEGOTIABLE):**

| Rule | Value | Example |
|------|-------|---------|
| **Format** | RFC 5322 compliant | `user@example.com` |
| **Min local part** | 1 character | `a@example.com` ✓ |
| **Max local part** | 64 characters | Per RFC 5321 |
| **Max domain** | 255 characters | Per RFC 5321 |
| **Max total length** | 254 characters | Per RFC 5321 |
| **Allowed local chars** | `a-z`, `0-9`, `.`, `+`, `_`, `-` | `user.name+tag@example.com` ✓ |
| **Cannot start/end with** | `.` in local part | `.user@example.com` ✗ |
| **No consecutive dots** | In local part | `user..name@example.com` ✗ |
| **Domain validation** | Must have valid TLD | `user@localhost` ✗ |
| **Case handling** | Case-insensitive, stored lowercase | `User@Example.COM` → `user@example.com` |

**Email Validation Code:**
```go
func ValidateEmail(email string) error {
    email = strings.TrimSpace(strings.ToLower(email))

    // Length checks
    if len(email) > 254 {
        return errors.New("email too long (max 254 characters)")
    }

    parts := strings.Split(email, "@")
    if len(parts) != 2 {
        return errors.New("invalid email format")
    }

    local, domain := parts[0], parts[1]

    // Local part checks
    if len(local) == 0 || len(local) > 64 {
        return errors.New("invalid local part length")
    }
    if strings.HasPrefix(local, ".") || strings.HasSuffix(local, ".") {
        return errors.New("local part cannot start or end with dot")
    }
    if strings.Contains(local, "..") {
        return errors.New("local part cannot have consecutive dots")
    }

    // Domain checks
    if len(domain) == 0 || len(domain) > 255 {
        return errors.New("invalid domain length")
    }
    if !strings.Contains(domain, ".") {
        return errors.New("domain must have valid TLD")
    }

    // Regex for allowed characters
    localRegex := regexp.MustCompile(`^[a-z0-9.+_-]+$`)
    if !localRegex.MatchString(local) {
        return errors.New("invalid characters in local part")
    }

    domainRegex := regexp.MustCompile(`^[a-z0-9][a-z0-9.-]*[a-z0-9]\.[a-z]{2,}$`)
    if !domainRegex.MatchString(domain) {
        return errors.New("invalid domain format")
    }

    return nil
}
```

**Email Blocklist (Optional):**
```go
var EmailDomainBlocklist = []string{
    // Disposable email domains (add as needed)
    "tempmail.com", "throwaway.email", "guerrillamail.com",
    "mailinator.com", "10minutemail.com", "trashmail.com",
}
```

**Email Behavior Rules:**
- Primary email set at registration (becomes account email by default)
- User can designate a different verified email as account email
- Additional emails require verification (SMTP required)
- All emails must be unique across all users
- Unverified emails cannot be used for login
- Account email receives security-sensitive communications ONLY
- Notification email receives everything else (if set, otherwise account email)

### Profile Privacy Settings (NON-NEGOTIABLE)

**Users and organizations can set their profile visibility.**

**Visibility Options:**

| Visibility | Default | Description |
|------------|---------|-------------|
| **Public** | ✓ Yes | Profile visible to everyone, appears in search, listings, public pages |
| **Private** | No | Profile hidden from public, search, listings, other user contexts |

**What Private Means:**

| Context | Public Profile | Private Profile |
|---------|----------------|-----------------|
| **Public search** | ✓ Appears | ✗ Hidden |
| **Public listings** | ✓ Appears | ✗ Hidden |
| **User directories** | ✓ Appears | ✗ Hidden |
| **Profile URL** | ✓ Accessible | 404 Not Found |
| **API queries** | ✓ Returned | ✗ Excluded |
| **Activity feeds** | ✓ Visible | ✗ Hidden |
| **Organization members list** (if in org) | Username only | Username only |
| **Direct mentions/links** | ✓ Works | Redirect to 404 |

**Private Profile Exceptions (always visible to):**
- The user themselves
- Server admins (via admin panel, not public routes)
- Other org members (if user is in same org - username only, minimal info)

**Database Fields:**
```sql
-- Users
visibility TEXT NOT NULL DEFAULT 'public'  -- public, private

-- Organizations
visibility TEXT NOT NULL DEFAULT 'public'  -- public, private
```

**API Behavior:**
```go
// Public endpoints automatically filter private profiles
func GetPublicUsers() []User {
    return db.Where("visibility = ?", "public").Find(&users)
}

// User's own profile always accessible
func GetUserProfile(requestingUserID, targetUserID int) (*User, error) {
    user := db.Find(targetUserID)
    if user.Visibility == "private" && requestingUserID != targetUserID {
        return nil, ErrNotFound  // 404, not 403 (don't leak existence)
    }
    return user, nil
}
```

### Avatar Settings (NON-NEGOTIABLE)

**Users and organizations can set their avatar using three methods.**

**Avatar Types:**

| Type | Description | Storage |
|------|-------------|---------|
| **Gravatar** | Default. Uses email hash to fetch from gravatar.com | No storage needed |
| **Upload** | User uploads image file | Stored locally or S3 |
| **URL** | External image URL | URL stored in database |

**Avatar Validation Rules:**

| Rule | Value |
|------|-------|
| **Allowed formats** | PNG, JPG, JPEG, GIF, BMP, WEBP, SVG, ICO |
| **Max file size** | 2 MB (upload) |
| **Min dimensions** | 64x64 pixels |
| **Max dimensions** | 1024x1024 pixels (resized if larger) |
| **Aspect ratio** | Square preferred (auto-cropped if not) |
| **Storage sizes** | Original, 256x256, 128x128, 64x64, 32x32 |

**Avatar Validation Code:**
```go
var AllowedImageTypes = map[string]bool{
    "image/png":     true,
    "image/jpeg":    true,
    "image/gif":     true,
    "image/bmp":     true,
    "image/webp":    true,
    "image/svg+xml": true,
    "image/x-icon":  true,
    "image/vnd.microsoft.icon": true,
}

func ValidateAvatar(file io.Reader, filename string) error {
    // Read first 512 bytes for MIME detection
    header := make([]byte, 512)
    n, err := file.Read(header)
    if err != nil {
        return errors.New("cannot read file")
    }

    // Detect actual MIME type (not from extension)
    mimeType := http.DetectContentType(header[:n])
    if !AllowedImageTypes[mimeType] {
        return fmt.Errorf("invalid image type: %s", mimeType)
    }

    // For external URLs, fetch and validate
    return nil
}

func ValidateAvatarURL(url string) error {
    // Must be HTTPS
    if !strings.HasPrefix(url, "https://") {
        return errors.New("avatar URL must use HTTPS")
    }

    // Fetch with timeout
    client := &http.Client{Timeout: 10 * time.Second}
    resp, err := client.Head(url)
    if err != nil {
        return errors.New("cannot reach avatar URL")
    }
    defer resp.Body.Close()

    // Check Content-Type
    contentType := resp.Header.Get("Content-Type")
    if !AllowedImageTypes[contentType] {
        return fmt.Errorf("URL does not point to valid image: %s", contentType)
    }

    // Check Content-Length (max 2MB)
    if resp.ContentLength > 2*1024*1024 {
        return errors.New("avatar too large (max 2MB)")
    }

    return nil
}
```

**Gravatar Integration:**
```go
import "crypto/md5"

func GetGravatarURL(email string, size int) string {
    email = strings.TrimSpace(strings.ToLower(email))
    hash := md5.Sum([]byte(email))
    return fmt.Sprintf("https://www.gravatar.com/avatar/%x?s=%d&d=identicon", hash, size)
}
```

**Avatar API Endpoints:**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `GET /api/v1/users/avatar` | GET | Get current user's avatar URL |
| `POST /api/v1/users/avatar` | POST | Upload new avatar |
| `PATCH /api/v1/users/avatar` | PATCH | Update avatar settings (type, URL) |
| `DELETE /api/v1/users/avatar` | DELETE | Reset to Gravatar |
| `GET /api/v1/orgs/{slug}/avatar` | GET | Get org's avatar URL |
| `POST /api/v1/orgs/{slug}/avatar` | POST | Upload org avatar |
| `PATCH /api/v1/orgs/{slug}/avatar` | PATCH | Update org avatar settings |
| `DELETE /api/v1/orgs/{slug}/avatar` | DELETE | Reset org to Gravatar |

**Avatar Upload Request:**
```
POST /api/v1/users/avatar
Content-Type: multipart/form-data

file: <binary image data>
```

**Avatar URL Request:**
```json
PATCH /api/v1/users/avatar
{
    "type": "url",
    "url": "https://example.com/my-avatar.png"
}
```

**Avatar Response:**
```json
{
    "type": "upload",
    "urls": {
        "original": "/uploads/avatars/user_123_original.png",
        "256": "/uploads/avatars/user_123_256.png",
        "128": "/uploads/avatars/user_123_128.png",
        "64": "/uploads/avatars/user_123_64.png",
        "32": "/uploads/avatars/user_123_32.png"
    }
}
```

### Server Admin Limitations (NON-NEGOTIABLE)

**What Server Admin CAN do:**
| Action | Description |
|--------|-------------|
| Send password reset link | Triggers email to user's account email |
| Disable user's 2FA | After manual identity verification (out-of-band) |
| Disable/suspend account | Block user from logging in |
| Enable/unsuspend account | Restore access |
| View masked email | `j***n@e***.com` (for support identification) |
| View username | For support identification |
| View account status | Active, suspended, 2FA enabled, etc. |
| View last login | Timestamp only |

**What Server Admin CANNOT do:**
| Action | Reason |
|--------|--------|
| View full email addresses | Privacy - only masked version visible |
| View passwords | Passwords are hashed, not stored |
| Set/change user passwords | Only user can set via reset link |
| View recovery keys | Keys are hashed, not stored |
| View 2FA secrets | Secrets are encrypted with user's password |
| Read user's private data | Privacy by design |
| Impersonate without logging | All admin actions are audited |

**Admin Password Reset Flow:**
```
Admin Panel (/admin/server/moderation/users/{id})
┌─────────────────────────────────────────────────────────────┐
│  User: johndoe                                              │
│  Email: j***n@e***.com (masked)                             │
│  Status: Active                                             │
│  2FA: Enabled                                               │
│  Last Login: 2025-01-15 09:00:00                            │
├─────────────────────────────────────────────────────────────┤
│  Actions:                                                   │
│  [Send Password Reset]  [Disable 2FA]  [Suspend Account]    │
└─────────────────────────────────────────────────────────────┘

Admin clicks "Send Password Reset"
         ↓
┌─────────────────────────────────────────────────────────────┐
│  Confirm Action                                             │
├─────────────────────────────────────────────────────────────┤
│  This will send a password reset link to the user's         │
│  account email (j***n@e***.com).                            │
│                                                             │
│  You will NOT see the reset link or new password.           │
│                                                             │
│  Reason (required for audit log):                           │
│  [User requested via support ticket #1234    ]              │
│                                                             │
│  [Cancel]  [Send Reset Link]                                │
└─────────────────────────────────────────────────────────────┘

         ↓ (email sent to user)

User receives: "Password reset requested by administrator.
               Click here to set a new password."
```

**Why These Limitations?**
- **Zero-knowledge design**: Admin cannot access what they don't need
- **Privacy by default**: User data is user's data
- **Audit trail**: All admin actions logged with reason
- **Trust minimization**: Even compromised admin account has limited damage potential

### Error Messages (NON-NEGOTIABLE)

**Specific Errors (OK to reveal - validation only):**
| Scenario | Error Message |
|----------|---------------|
| Blocklisted username | `Username contains blocked word: {word}` |
| Username too short | `Username must be at least 3 characters` |
| Username too long | `Username cannot exceed 32 characters` |
| Invalid characters | `Username can only contain lowercase letters, numbers, underscore, and hyphen` |
| Invalid email format | `Please enter a valid email address` |
| Password too weak | `Password must be at least 8 characters` |

**Generic Errors (NEVER reveal existence):**
| Scenario | Error Message |
|----------|---------------|
| Username/email taken | `Unable to complete registration. [Forgot credentials?](/auth/password/forgot)` |
| Login failed (any reason) | `Invalid credentials. [Forgot password?](/auth/password/forgot)` |
| Reset request | `If an account exists, instructions have been sent.` |

**Why Generic Errors?**
- Prevents username/email enumeration attacks
- Attacker cannot determine if account exists
- Same response time for both cases (prevent timing attacks)
- Links to recovery flow instead of revealing information

### 2FA, Passkeys & OIDC (NON-NEGOTIABLE)

**Supported Authentication Methods:**
| Method | Description |
|--------|-------------|
| Password | Standard username/email + password |
| TOTP (2FA) | Time-based one-time passwords (Google Authenticator, Authy, etc.) |
| Passkeys | WebAuthn/FIDO2 passwordless authentication |
| OIDC | External identity providers |

**OIDC Providers (Examples):**
- Self-hosted: Authentik, Authelia, Keycloak, Dex, Zitadel
- Cloud: Auth0, Okta, Azure AD, Google, GitHub, GitLab

**Recovery Keys (CRITICAL):**
| Rule | Description |
|------|-------------|
| **Format** | `{8-hex-chars}-{4-hex-chars}` (e.g., `a1b2c3d4-e5f6`) |
| **Count** | 10 recovery keys generated |
| **Generated once** | Recovery keys generated when 2FA/passkey enabled |
| **User must copy** | Displayed ONCE, user MUST save them |
| **Hashed storage** | Keys are hashed (SHA-256), NOT stored in plain text |
| **NOT recoverable** | If lost, cannot be retrieved - account recovery required |
| **Single use** | Each recovery key can only be used once |
| **Case insensitive** | Keys are validated case-insensitively |

**Recovery Key Flow:**
```
┌─────────────────────────────────────────────────────────────┐
│  🔑 SAVE YOUR RECOVERY KEYS                                 │
├─────────────────────────────────────────────────────────────┤
│  These keys can be used to access your account if you       │
│  lose access to your 2FA device. Each key can only be       │
│  used once.                                                 │
│                                                             │
│  ⚠️  SAVE THESE NOW - THEY WILL NOT BE SHOWN AGAIN          │
│                                                             │
│  1. a1b2c3d4-e5f6    6. k5l6m7n8-o9p0                       │
│  2. g7h8i9j0-k1l2    7. q1r2s3t4-u5v6                       │
│  3. m3n4o5p6-q7r8    8. w7x8y9z0-a1b2                       │
│  4. s9t0u1v2-w3x4    9. c3d4e5f6-g7h8                       │
│  5. y5z6a7b8-c9d0   10. i9j0k1l2-m3n4                       │
│                                                             │
│  [Download as TXT]  [Copy All]                              │
│                                                             │
│  ☑️ I have saved my recovery keys                            │
│                                                             │
│  [Continue]                                                 │
└─────────────────────────────────────────────────────────────┘
```

**Admin Panel MFA Setup (`/admin/account/security`):**

```
┌─────────────────────────────────────────────────────────────┐
│  🔐 Account Security                                        │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Two-Factor Authentication                                  │
│  ─────────────────────────────────────────────────────────  │
│  Add an extra layer of security to your admin account.      │
│                                                             │
│  TOTP (Authenticator App)              [Not Enabled]        │
│  Use Google Authenticator, Authy,      [Set Up →]           │
│  or any TOTP-compatible app                                 │
│                                                             │
│  Passkey (Biometric/Security Key)      [Not Enabled]        │
│  Use fingerprint, Face ID, or a        [Set Up →]           │
│  hardware security key                                      │
│                                                             │
│  Recovery Keys                         [Not Generated]      │
│  Generated when you enable MFA         [──────────]         │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**TOTP Setup Flow (`/admin/account/security/totp/setup`):**

```
┌─────────────────────────────────────────────────────────────┐
│  📱 Set Up Authenticator App                                │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Step 1: Confirm your password                              │
│  Password: [••••••••••••            ]  [Continue]           │
│                                                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Step 2: Scan QR code with your authenticator app           │
│                                                             │
│         ┌─────────────────┐                                 │
│         │  █▀▀▀▀▀▀▀▀▀█   │                                 │
│         │  █ QR CODE █   │   Can't scan?                   │
│         │  █▄▄▄▄▄▄▄▄▄█   │   Manual key: JBSWY3DPEHPK3PXP  │
│         └─────────────────┘   [Copy Key]                    │
│                                                             │
│  Step 3: Enter the 6-digit code from your app               │
│  Verification Code: [      ]  [Verify]                      │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**Passkey Setup Flow (`/admin/account/security/passkey/setup`):**

```
┌─────────────────────────────────────────────────────────────┐
│  🔑 Set Up Passkey                                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Step 1: Confirm your password                              │
│  Password: [••••••••••••            ]  [Continue]           │
│                                                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Step 2: Register your passkey                              │
│                                                             │
│  Your browser will prompt you to use:                       │
│  • Fingerprint (Touch ID)                                   │
│  • Face recognition (Face ID)                               │
│  • Hardware security key (YubiKey, etc.)                    │
│  • Device PIN                                               │
│                                                             │
│  Passkey Name: [MacBook Pro Touch ID    ]                   │
│                                                             │
│  [Register Passkey]                                         │
│                                                             │
│  ℹ️  You can register multiple passkeys for backup          │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**After MFA Enabled - Recovery Keys Shown:**
(See Recovery Key Flow above)

**2FA/Passkey Setup Requirements:**
1. User/admin must be logged in
2. User/admin must re-enter password to confirm identity
3. For TOTP: scan QR code and verify with 6-digit code
4. For Passkey: complete WebAuthn registration flow
5. Recovery keys generated and displayed (MUST save)
6. User/admin must confirm they saved recovery keys (checkbox)
7. Only then is 2FA/passkey activated

### Account Recovery Matrix (NON-NEGOTIABLE)

**What CAN be recovered:**
| User Knows | User Forgot | Recovery Method |
|------------|-------------|-----------------|
| Email | Password | `/auth/password/forgot` → email link → set new password |
| Username | Password | `/auth/password/forgot` → email link → set new password |
| Email + Password | 2FA code | `/auth/login` → `/auth/recovery/use` → disable/reset 2FA |
| Username + Password | 2FA code | `/auth/login` → `/auth/recovery/use` → disable/reset 2FA |

**What CANNOT be recovered:**
| Scenario | Result |
|----------|--------|
| Forgot username AND email | ❌ No recovery - account lost |
| Forgot password + no email access | ❌ No recovery - account lost |
| Lost 2FA + no recovery keys | ❌ Contact admin (manual identity verification) |
| Lost everything | ❌ No recovery - account lost |

**Why no recovery without username/email?**
- We cannot store data that identifies users without credentials
- This is a security feature, not a limitation
- Users MUST remember at least one identifier (username or email)

### Server Admin Recovery (NON-NEGOTIABLE)

The server admin (administrator with access to the server/binary) has ONE recovery method:

| Scenario | Recovery Method |
|----------|-----------------|
| Admin forgot password | `weather --maintenance setup` |
| Admin lost API token | `weather --maintenance setup` |
| Admin lost recovery keys | `weather --maintenance setup` |
| Admin lost 2FA + no recovery keys | `weather --maintenance setup` |
| Admin lost everything | `weather --maintenance setup` |

**This requires:**
- Console/SSH access to the server to run the binary
- Console access to see the new setup token
- The service should be stopped first

**This does NOT require:**
- Previous password
- Previous API token
- Previous recovery keys
- Email access

See **PART 22: BACKUP & RESTORE → Admin Recovery Command** for full details.

### Recovery Key Usage Flow

**When Recovery Keys Are Used:**
- User has 2FA/passkey enabled
- User lost access to 2FA device (phone lost, authenticator wiped, etc.)
- User still knows username/email AND password

**Flow:**
```
┌─────────────────────────────────────────────────────────────┐
│  /auth/login                                                │
├─────────────────────────────────────────────────────────────┤
│  Username/Email: [john@example.com        ]                 │
│  Password:       [••••••••••••            ]                 │
│                                                             │
│  [Login]                                                    │
└─────────────────────────────────────────────────────────────┘
                            ↓
                    (2FA is enabled)
                            ↓
┌─────────────────────────────────────────────────────────────┐
│  Two-Factor Authentication                                  │
├─────────────────────────────────────────────────────────────┤
│  Enter the 6-digit code from your authenticator app:        │
│                                                             │
│  [      ]                                                   │
│                                                             │
│  [Verify]                                                   │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│  Lost access to your authenticator?                         │
│  [Use Recovery Key]                                         │
└─────────────────────────────────────────────────────────────┘
                            ↓
                (User clicks "Use Recovery Key")
                            ↓
┌─────────────────────────────────────────────────────────────┐
│  Use Recovery Key                                           │
├─────────────────────────────────────────────────────────────┤
│  Enter one of your recovery keys:                           │
│                                                             │
│  [a1b2c3d4-e5f6                          ]                  │
│                                                             │
│  ⚠️  This key will be invalidated after use.                 │
│                                                             │
│  [Submit]                                                   │
└─────────────────────────────────────────────────────────────┘
                            ↓
                (Valid recovery key entered)
                            ↓
┌─────────────────────────────────────────────────────────────┐
│  Recovery Key Accepted                                      │
├─────────────────────────────────────────────────────────────┤
│  ✅ Recovery key accepted and invalidated.                   │
│  You have X recovery keys remaining.                        │
│                                                             │
│  What would you like to do?                                 │
│                                                             │
│  ○ Disable 2FA temporarily (login with password only)       │
│  ○ Set up new 2FA device now                                │
│                                                             │
│  [Continue]                                                 │
└─────────────────────────────────────────────────────────────┘
                            ↓
        (If "Set up new 2FA" → new recovery keys generated)
                            ↓
┌─────────────────────────────────────────────────────────────┐
│  🔑 NEW RECOVERY KEYS                                        │
├─────────────────────────────────────────────────────────────┤
│  Your old recovery keys have been invalidated.              │
│  Save these new recovery keys:                              │
│                                                             │
│  1. x1y2z3a4-b5c6    6. p5q6r7s8-t9u0                       │
│  2. d7e8f9g0-h1i2    7. v1w2x3y4-z5a6                       │
│  3. j3k4l5m6-n7o8    8. b7c8d9e0-f1g2                       │
│  4. q9r0s1t2-u3v4    9. h3i4j5k6-l7m8                       │
│  5. w5x6y7z8-a9b0   10. n9o0p1q2-r3s4                       │
│                                                             │
│  [Download as TXT]  [Copy All]                              │
│                                                             │
│  ☑️ I have saved my recovery keys                            │
│                                                             │
│  [Complete Setup]                                           │
└─────────────────────────────────────────────────────────────┘
```

**Recovery Key API Flow:**
```
POST /api/v1/auth/login
  → { "identifier": "john@example.com", "password": "secretpassword" }
  ← { "ok": true, "data": { "requires_2fa": true, "session_token": "temp_xxx" } }

POST /api/v1/auth/recovery/use
  → { "session_token": "temp_xxx", "recovery_key": "a1b2c3d4-e5f6" }
  ← { "ok": true, "data": { "token": "auth_xxx", "remaining_keys": 9 } }

# Now authenticated - can manage 2FA via /users/security/
POST /api/v1/users/security/2fa/disable
  ← { "ok": true, "data": {} }
     OR (setup new device)
POST /api/v1/users/security/2fa/enable
  ← { "ok": true, "data": { "qr_code": "base64", "secret": "JBSWY3DPEHPK3PXP", "recovery_keys": [] } }
```

**Recovery Key Rules:**
| Rule | Description |
|------|-------------|
| Single use | Each key invalidated after one use |
| Hashed storage | Keys stored as hashes, cannot be retrieved |
| Regeneration | New 2FA setup = new recovery keys |
| Old keys invalidated | All old keys invalidated when new keys generated |
| Remaining count | Show user how many keys remain |
| Last key warning | ⚠️ Warning when only 1-2 keys remaining |
| Zero keys + lost 2FA | Must contact admin for manual verification |

**OIDC/LDAP Configuration:**
```yaml
server:
  auth:
    oidc:
      enabled: false
      providers:
        - name: authentik
          display_name: "Login with Authentik"
          issuer: "https://auth.example.com/application/o/myapp/"
          client_id: "{client_id}"
          client_secret: "{client_secret}"
          scopes: ["openid", "profile", "email", "groups"]
          # Auto-create user on first login
          auto_register: true
          # Map OIDC claims to user fields
          claims_mapping:
            username: "preferred_username"
            email: "email"
            name: "name"
            # Claim containing group memberships
            groups: "groups"
          # Map external groups to server admin role
          # Users in these groups become server admins
          admin_groups:
            - "admins"
            - "server-admins"
            - "app-administrators"
          # Map external groups to user roles (if multi-user enabled)
          role_mapping:
            admin: ["admins", "app-administrators"]
            moderator: ["moderators", "support-staff"]
            user: ["users", "members"]

    ldap:
      enabled: false
      server: "ldap://ldap.example.com:389"
      bind_dn: "cn=readonly,dc=example,dc=com"
      bind_password: "{ldap_password}"
      base_dn: "dc=example,dc=com"
      user_filter: "(uid={username})"
      # Map LDAP attributes to user fields
      attributes:
        username: "uid"
        email: "mail"
        name: "cn"
        groups: "memberOf"
      # Map LDAP groups to server admin role
      admin_groups:
        - "cn=admins,ou=groups,dc=example,dc=com"
        - "cn=server-admins,ou=groups,dc=example,dc=com"
      # Map LDAP groups to user roles (if multi-user enabled)
      role_mapping:
        admin: ["cn=admins,ou=groups,dc=example,dc=com"]
        moderator: ["cn=moderators,ou=groups,dc=example,dc=com"]
        user: ["cn=users,ou=groups,dc=example,dc=com"]
```

### Server Admin Group Mapping (NON-NEGOTIABLE)

**Server admins can map external identity provider groups to the server admin role.**

| Provider | Configuration | Description |
|----------|---------------|-------------|
| **OIDC** | `admin_groups` list | Group names from the `groups` claim |
| **LDAP** | `admin_groups` list | Full DN of groups (e.g., `cn=admins,ou=groups,dc=example,dc=com`) |

**How Group Mapping Works:**

1. User authenticates via OIDC/LDAP
2. Server retrieves user's group memberships from identity provider
3. If user belongs to ANY group in `admin_groups` → grant server admin access
4. Admin access persists for session duration
5. On next login, group membership is re-evaluated
6. If user is removed from all `admin_groups` → admin access revoked

**Admin Panel (`/admin/server/security/auth`):**

| Element | Type | Description |
|---------|------|-------------|
| OIDC Providers | Section | List of configured OIDC providers |
| LDAP Configuration | Section | LDAP server settings |
| Admin Groups | Tag input | Groups that grant server admin access |
| Role Mapping | Table | Map external groups to application roles |
| Test Connection | Button | Test OIDC/LDAP connectivity |
| Test Group Mapping | Button | Test user's groups and resulting role |

**Sane Defaults:**
- `admin_groups`: Empty (no external groups granted admin by default)
- `role_mapping`: Empty (users get default role unless mapped)
- `auto_register`: `false` (users must be pre-created unless enabled)
- Group membership checked on every login (not cached)

### Why This Separation?

| Reason | Description |
|--------|-------------|
| **Security** | Server admin has server-level access, not app-level |
| **Simplicity** | Admin-only mode doesn't need user management |
| **Isolation** | Server admin credentials separate from user data |
| **Recovery** | Can access admin even if database is corrupted |

## Configuration

```yaml
server:
  users:
    # Enable multi-user mode (default: disabled = admin-only)
    enabled: false

    registration:
      # Registration mode: disabled, public, private, approval
      # - disabled: No registration allowed (admin creates users only)
      # - public: Anyone can register (open registration)
      # - private: Invite-only (requires invite code)
      # - approval: Anyone can register, admin must approve
      mode: disabled

      # Email verification (applies to all modes except disabled)
      require_email_verification: true

      # Email domain restrictions (applies to public/approval modes)
      allowed_domains: []      # Empty = all domains allowed
      blocked_domains: []      # Block specific domains

      # Invite settings (for private mode)
      invite_expiration_days: 7     # How long invite codes are valid
      max_invites_per_user: 10      # How many invites each user can create

    roles:
      # Available roles
      available:
        - admin
        - user
      # Default role for new users
      default: user

    tokens:
      # Allow users to generate API tokens
      enabled: true
      # Maximum tokens per user
      max_per_user: 5
      # Token expiration (0 = never)
      expiration_days: 0

    profile:
      # Allow users to upload avatars
      allow_avatar: true
      # Allow users to set display name
      allow_display_name: true
      # Allow users to set bio
      allow_bio: true

    auth:
      # Session duration
      session_duration: 30d
      # Require 2FA for all users
      require_2fa: false
      # Allow 2FA (user choice)
      allow_2fa: true
      # Password requirements
      password_min_length: 8
      password_require_uppercase: false
      password_require_number: false
      password_require_special: false

    limits:
      # Rate limits per user (0 = use global)
      requests_per_minute: 0
      requests_per_day: 0
```

## User Roles & Permissions

| Role | Description | Default Permissions |
|------|-------------|---------------------|
| `admin` | Full access | All permissions |
| `user` | Standard user | Read, own profile, own API tokens |

### Custom Roles

Projects can define custom roles with specific permissions:

```yaml
server:
  users:
    roles:
      available:
        - admin
        - moderator
        - user
        - readonly
      default: user
      permissions:
        moderator:
          - read
          - write
          - moderate
        readonly:
          - read
```

## User Features

### Registration Modes (NON-NEGOTIABLE)

**Single setting controls all registration behavior:**

| Mode | Description | Who Can Register | Workflow |
|------|-------------|------------------|----------|
| **disabled** | No registration | No one (admin creates users only) | Registration form hidden |
| **public** | Open registration | Anyone with valid email | Submit form → verify email → active |
| **private** | Invite-only | Users with invite code only | Enter code → submit form → verify email → active |
| **approval** | Admin approval required | Anyone, but admin must approve | Submit form → verify email → admin approves → active |

### Registration Flow by Mode

**Mode: disabled**
```
/auth/register → 404 or redirect to login
No registration allowed, admin creates users manually
```

**Mode: public**
```
1. User visits /auth/register
2. Submits registration form (username, email, password)
3. Email verification sent (if require_email_verification: true)
4. User clicks verification link
5. Account active → user can log in
```

**Mode: private**
```
1. Existing user generates invite code (/users/invites/create)
2. New user visits /auth/register?invite={code}
3. Submits registration form
4. Email verification sent (if require_email_verification: true)
5. User clicks verification link
6. Account active → user can log in
```

**Mode: approval**
```
1. User visits /auth/register
2. Submits registration form
3. Email verification sent (if require_email_verification: true)
4. User clicks verification link
5. Admin notified of pending user
6. Admin approves user at /{adminpath}/server/users/pending
7. Account active → user can log in
```

### Authentication Methods

| Method | Use For |
|--------|---------|
| Session (cookie) | Web interface |
| API token | API access (passed as Bearer token in Authorization header) |

### Password Reset Flow

```
1. User requests password reset
2. Email sent with reset link (expires in 1 hour)
3. User clicks link, sets new password
4. All existing sessions invalidated
5. User must log in with new password
```

### Two-Factor Authentication (2FA)

| Feature | Description |
|---------|-------------|
| TOTP | Time-based one-time passwords (Google Authenticator, etc.) |
| Passkeys/WebAuthn | FIDO2 passwordless authentication (biometric, security keys) |
| Recovery keys | 10 one-time use keys (format: `a1b2c3d4-e5f6`) |
| Remember device | Optional "trust this device" for 30 days |

## User Profile (NON-NEGOTIABLE)

### Profile Fields

| Field | Type | Required | Editable | Public | Description |
|-------|------|----------|----------|--------|-------------|
| `id` | Integer | Auto | No | No | Unique user ID |
| `username` | String | Yes | No* | Yes | Unique username (3-32 chars, lowercase) |
| `email` | String | Yes | Yes | No | Primary email (private by default) |
| `display_name` | String | No | Yes | Yes | Public display name |
| `avatar_type` | Enum | Yes | Yes | Yes | `gravatar`, `upload`, `url` |
| `avatar_url` | String | No | Yes | Yes | Avatar URL (if type is upload/url) |
| `bio` | String | No | Yes | Yes | Short biography (max 500 chars) |
| `location` | String | No | Yes | Yes | Location (free text) |
| `website` | String | No | Yes | Yes | Personal website URL |
| `visibility` | Enum | Yes | Yes | N/A | `public` (default), `private` |
| `timezone` | String | No | Yes | No | IANA timezone (e.g., `America/New_York`) |
| `language` | String | No | Yes | No | Preferred language (e.g., `en`, `es`) |
| `role` | String | Yes | No | No | User role (set by admin) |
| `verified` | Boolean | Auto | No | Yes | Email verified badge |
| `created_at` | Timestamp | Auto | No | Yes | Account creation date |
| `last_login` | Timestamp | Auto | No | No | Last login (private) |

*Username can only be changed by admin or via special request flow.

**Profile Example (API Response):**
```json
GET /api/v1/users
{
    "id": 12345,
    "username": "johndoe",
    "display_name": "John Doe",
    "avatar": {
        "type": "gravatar",
        "urls": {
            "256": "https://www.gravatar.com/avatar/abc123?s=256&d=identicon",
            "128": "https://www.gravatar.com/avatar/abc123?s=128&d=identicon",
            "64": "https://www.gravatar.com/avatar/abc123?s=64&d=identicon",
            "32": "https://www.gravatar.com/avatar/abc123?s=32&d=identicon"
        }
    },
    "bio": "Software developer and coffee enthusiast",
    "location": "San Francisco, CA",
    "website": "https://johndoe.dev",
    "visibility": "public",
    "timezone": "America/Los_Angeles",
    "language": "en",
    "verified": true,
    "created_at": "2024-01-15T10:30:00Z"
}
```

**Public Profile Example (what others see):**
```json
GET /api/v1/public/users/johndoe
{
    "username": "johndoe",
    "display_name": "John Doe",
    "avatar": {
        "256": "https://www.gravatar.com/avatar/abc123?s=256&d=identicon"
    },
    "bio": "Software developer and coffee enthusiast",
    "location": "San Francisco, CA",
    "website": "https://johndoe.dev",
    "verified": true,
    "created_at": "2024-01-15T10:30:00Z"
}
```

### User Settings

Settings are organized into categories. Each setting has a default value and can be modified by the user.

**Settings Categories:**

| Category | Route | Description |
|----------|-------|-------------|
| **Account** | `/users/settings` | Basic account settings |
| **Privacy** | `/users/settings/privacy` | Visibility and data sharing |
| **Notifications** | `/users/settings/notifications` | Email and push preferences |
| **Appearance** | `/users/settings/appearance` | Theme and display options |
| **Security** | `/users/security` | Password, 2FA, sessions |

#### Account Settings (`/users/settings`)

| Setting | Type | Default | Description |
|---------|------|---------|-------------|
| `display_name` | String | null | Public display name |
| `bio` | String | null | Short biography |
| `location` | String | null | Location |
| `website` | URL | null | Personal website |
| `timezone` | Select | Auto-detect | Timezone for dates/times |
| `language` | Select | `en` | Interface language |
| `date_format` | Select | `YYYY-MM-DD` | Date display format |
| `time_format` | Select | `24h` | 12h or 24h time |

**Account Settings Form Example:**
```
Account Settings (/users/settings)
┌─────────────────────────────────────────────────────────────┐
│  Display Name                                               │
│  [John Doe                                    ]             │
│                                                             │
│  Bio                                                        │
│  [Software developer and coffee enthusiast   ]             │
│  Characters: 42/500                                         │
│                                                             │
│  Location                                                   │
│  [San Francisco, CA                          ]             │
│                                                             │
│  Website                                                    │
│  [https://johndoe.dev                        ]             │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  Timezone                                                   │
│  [America/Los_Angeles (UTC-8)            ▼]                │
│                                                             │
│  Language                                                   │
│  [English                                ▼]                │
│                                                             │
│  Date Format                                                │
│  ○ YYYY-MM-DD (2025-01-15)                                 │
│  ● MM/DD/YYYY (01/15/2025)                                 │
│  ○ DD/MM/YYYY (15/01/2025)                                 │
│                                                             │
│  Time Format                                                │
│  ● 24-hour (14:30)                                         │
│  ○ 12-hour (2:30 PM)                                       │
│                                                             │
│  [Save Changes]                                             │
└─────────────────────────────────────────────────────────────┘
```

#### Privacy Settings (`/users/settings/privacy`)

| Setting | Type | Default | Description |
|---------|------|---------|-------------|
| `visibility` | Select | `public` | Profile visibility (public/private) |
| `show_email` | Toggle | Off | Show email on public profile |
| `show_activity` | Toggle | On | Show activity on public profile |
| `show_orgs` | Toggle | On | Show org memberships on profile |
| `searchable` | Toggle | On | Appear in user search results |
| `org_visibility` | Toggle | On | Show basic info in orgs (even if private) |

**Privacy Settings Form Example:**
```
Privacy Settings (/users/settings/privacy)
┌─────────────────────────────────────────────────────────────┐
│  Profile Visibility                                         │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ ○ Public                                             │   │
│  │   Anyone can view your profile and find you in      │   │
│  │   search results.                                    │   │
│  │                                                      │   │
│  │ ● Private                                            │   │
│  │   Your profile is hidden from public view and       │   │
│  │   search results. Only you can see your profile.    │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│  When Profile is Public:                                    │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  [OFF] Show email address on profile                        │
│        Your email will be visible to anyone viewing your    │
│        profile.                                             │
│                                                             │
│  [ON ] Show activity on profile                             │
│        Recent activity will appear on your public profile.  │
│                                                             │
│  [ON ] Show organization memberships                        │
│        Organizations you belong to will be listed on your   │
│        profile.                                             │
│                                                             │
│  [ON ] Appear in search results                             │
│        Others can find you when searching for users.        │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│  When Profile is Private:                                   │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  [ON ] Show basic info in organizations                     │
│        Members of organizations you belong to can see       │
│        your username, name, and avatar. Your full profile   │
│        remains private.                                     │
│                                                             │
│  [Save Changes]                                             │
└─────────────────────────────────────────────────────────────┘
```

#### Notification Settings (`/users/settings/notifications`)

| Setting | Type | Default | Description |
|---------|------|---------|-------------|
| `email_security` | Toggle | On | Security alerts via email (cannot disable) |
| `email_mentions` | Toggle | On | Email when mentioned |
| `email_updates` | Toggle | On | Product updates and news |
| `email_digest` | Select | `weekly` | Digest frequency (never/daily/weekly) |
| `push_enabled` | Toggle | Off | Browser push notifications |
| `push_mentions` | Toggle | On | Push when mentioned |

**Notification Settings Form Example:**
```
Notification Settings (/users/settings/notifications)
┌─────────────────────────────────────────────────────────────┐
│  Email Notifications                                        │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  [ON ] Security alerts (required)                    🔒     │
│        Password changes, new logins, 2FA changes.           │
│        This setting cannot be disabled for your security.   │
│                                                             │
│  [ON ] Mentions and replies                                 │
│        When someone mentions you or replies to you.         │
│                                                             │
│  [OFF] Product updates                                      │
│        News about new features and improvements.            │
│                                                             │
│  Activity Digest                                            │
│  [Weekly                                         ▼]        │
│  Options: Never, Daily, Weekly                              │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│  Push Notifications                                         │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  [OFF] Enable push notifications                            │
│        Receive notifications in your browser even when      │
│        you're not on this site.                             │
│                                                             │
│        (Requires browser permission)                        │
│                                                             │
│  [Save Changes]                                             │
└─────────────────────────────────────────────────────────────┘
```

#### Appearance Settings (`/users/settings/appearance`)

| Setting | Type | Default | Description |
|---------|------|---------|-------------|
| `theme` | Select | `dark` | Theme (dark/light/auto) |
| `font_size` | Select | `medium` | Font size (small/medium/large) |
| `reduce_motion` | Toggle | Off | Reduce animations |

**Appearance Settings Form Example:**
```
Appearance Settings (/users/settings/appearance)
┌─────────────────────────────────────────────────────────────┐
│  Theme                                                      │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐                       │
│  │  🌙     │ │  ☀️     │ │  💻     │                       │
│  │ Dark    │ │ Light   │ │ Auto    │                       │
│  └─────────┘ └─────────┘ └─────────┘ ↑ Default: Dark       │
│                                                             │
│  Font Size                                                  │
│  ○ Small                                                    │
│  ● Medium (default)                                         │
│  ○ Large                                                    │
│                                                             │
│  Accessibility                                              │
│  [OFF] Reduce motion                                        │
│        Minimize animations and transitions.                 │
│                                                             │
│  [Save Changes]                                             │
└─────────────────────────────────────────────────────────────┘
```

### User Settings API

**Database Storage:**

| Setting Category | Storage Location |
|------------------|------------------|
| **Account** (display_name, bio, location, website, timezone, language) | `users` table |
| **Privacy** (visibility, org_visibility) | `users` table |
| **Privacy** (show_email, show_activity, show_orgs, searchable) | `user_preferences` table |
| **Notifications** (email_*, push_*) | `user_preferences` table |
| **Appearance** (theme, font_size, reduce_motion, date_format, time_format) | `user_preferences` table |

**Preferences are created on first access (lazy initialization):**
```go
func GetOrCreatePreferences(userID int) (*UserPreferences, error) {
    prefs := &UserPreferences{}
    err := db.Where("user_id = ?", userID).First(prefs).Error
    if err == gorm.ErrRecordNotFound {
        prefs = &UserPreferences{UserID: userID}  // Uses DB defaults
        db.Create(prefs)
    }
    return prefs, nil
}
```

**Get All Settings:**
```json
GET /api/v1/users/settings
{
    "account": {
        "display_name": "John Doe",
        "bio": "Software developer",
        "location": "San Francisco, CA",
        "website": "https://johndoe.dev",
        "timezone": "America/Los_Angeles",
        "language": "en",
        "date_format": "MM/DD/YYYY",
        "time_format": "24h"
    },
    "privacy": {
        "visibility": "private",
        "show_email": false,
        "show_activity": true,
        "show_orgs": true,
        "searchable": false,
        "org_visibility": true
    },
    "notifications": {
        "email_security": true,
        "email_mentions": true,
        "email_updates": false,
        "email_digest": "weekly",
        "push_enabled": false,
        "push_mentions": true
    },
    "appearance": {
        "theme": "dark",
        "font_size": "medium",
        "reduce_motion": false
    }
}
```

**Update Settings (partial update):**
```json
PATCH /api/v1/users/settings
{
    "privacy": {
        "visibility": "public",
        "org_visibility": true
    }
}
```

## User API Tokens

**See PART 11: API Token Security for token format, storage, and validation rules.**

| Feature | Description |
|---------|-------------|
| Generate | User can create API tokens from `/users/settings/tokens` |
| Name/Label | User can name tokens for identification |
| Permissions | Optional: limit token to specific scopes |
| Expiration | Optional: set expiry date |
| Last used | Track when token was last used |
| Revoke | User can delete tokens anytime |

**User Token Prefix:** `usr_` (e.g., `usr_x9y8z7w6v5u4t3s2r1q0p9o8n7m6l5k4`)

**User Tokens UI (`/users/settings/tokens`):**
```
┌─────────────────────────────────────────────────────────────┐
│  API Tokens                                    [+ New Token] │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ My CLI Token           usr_a1b2...      Last: 2h ago│    │
│  │ Scopes: read, write    Expires: Never       [Revoke]│    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ CI Pipeline            usr_x9y8...      Last: 1d ago│    │
│  │ Scopes: read           Expires: 2025-12-31  [Revoke]│    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

## Admin Panel

### /{adminpath}/server/moderation/users (User Moderation)

| Element | Type | Description |
|---------|------|-------------|
| User list | Table | All users with search/filter |
| Delete user | Button | Remove user (confirmation required) |
| Impersonate | Button | Log in as user (admin only) |
| Disable/Enable | Toggle | Temporarily disable account |
| Revoke sessions | Button | Log user out everywhere |

### /{adminpath}/server/moderation/users/{id} (User Detail)

| Section | Contents |
|---------|----------|
| Profile | Email, name, avatar, bio, role (read-only) |
| Security | 2FA status, sessions |
| Activity | Login history, API usage |
| Actions | Disable, delete, impersonate |

### /{adminpath}/server/roles (Role Management)

| Element | Type | Description |
|---------|------|-------------|
| Role list | Table | All roles |
| Create role | Button | Define new role |
| Edit permissions | Checkboxes | Set role permissions |
| Delete role | Button | Remove role (reassign users first) |

### /{adminpath}/server/users/invites (User Invitation Codes)

| Element | Type | Description |
|---------|------|-------------|
| Generate invite | Button | Create invitation code/link |
| Invite list | Table | All invites with status |
| Expiration | Date picker | When invite expires |
| Max uses | Number | How many times invite can be used |
| Role | Dropdown | What role invited users get |
| Revoke | Button | Disable invite |

## Route Standards (NON-NEGOTIABLE)

**All routes MUST follow these standards:**

| Rule | Description |
|------|-------------|
| **Scoped** | Routes grouped by scope: `/auth`, `/user`, `/org`, `/admin` |
| **Mirrored** | Web (`/`) and API (`/api/v1/`) use same structure |
| **Intuitive** | Simple, predictable paths |
| **Params over queries** | Use path params, limit query params to defined cases |
| **Duplicated when needed** | Same resource may exist in multiple scopes |
| **Auth under /auth/** | NEVER `/login`, `/register`, `/password/*` at root - ALWAYS `/auth/login`, `/auth/register`, `/auth/password/*`, etc. |
| **Admin scoped** | `/admin/**` requires authenticated admin - unauthenticated flows (invites) go through `/auth/` |

### Response Formats

| Route | Default | Options |
|-------|---------|---------|
| `/` (web) | HTML | - |
| `/api/v1/` | JSON (`application/json`) | JSON, Text |
| `/api/v1/**/*.txt` | Text (`text/plain`) | - |

### Scopes

| Scope | Web | API | Description |
|-------|-----|-----|-------------|
| Public | `/` | `/api/v1/` | Public resources, unauthenticated |
| Server | `/server/` | `/api/v1/server/` | Server info pages (about, privacy, etc.) |
| Auth | `/auth/` | `/api/v1/auth/` | Authentication flows |
| Users | `/users/` | `/api/v1/users/` | User resources (requires ID) |
| Orgs | `/orgs/` | `/api/v1/orgs/` | Organization resources (requires slug) |
| Admin | `/{admin_path}/` | `/api/v1/{admin_path}/` | Admin/server management |

### Authentication Requirements

| Scope | Web Auth | API Auth | Notes |
|-------|----------|----------|-------|
| Public | None | None | Unauthenticated access |
| Server | None | None | Static info pages |
| Auth | None | None | Used to obtain authentication |
| Users | Session cookie | `Authorization: Bearer {token}` | User must be logged in |
| Orgs | Session cookie | `Authorization: Bearer {token}` | User + org membership |
| Admin | Session cookie | `Authorization: Bearer {admin_token}` | Admin-only access |

**API Token Types:**

| Token Type | Prefix | Use For | Stored In |
|------------|--------|---------|-----------|
| Admin token | `adm_` | Admin operations, CLI | `tokens` table |
| User token | `usr_` | User operations | `tokens` table |
| Org token | `org_` | Org operations | `tokens` table |
| Admin agent | `adm_agt_` | Admin infrastructure agent | `tokens` table |
| User agent | `usr_agt_` | User's personal agent | `tokens` table |
| Org agent | `org_agt_` | Organization agent | `tokens` table |

**Unified Tokens Table (`tokens`):**
- All token types stored in single table with `owner_type` (admin/user/org)
- Each token has: name, scope (`global`/`read-write`/`read`), expiration
- `token_prefix` stores first 8 chars for display: `"adm_abc1..."`
- Multiple tokens per owner allowed

**Web Session Cookies:**

| Cookie | Scope | Max Age | Notes |
|--------|-------|---------|-------|
| `admin_session` | `/admin/` | 30 days | Admin web sessions |
| `user_session` | `/users/`, `/orgs/` | 7 days | User web sessions |

## Web Routes

### Public (`/`)

| Path | Description |
|------|-------------|
| `/` | Home page |
| `/healthz` | Health check |
| `/openapi` | Swagger UI |
| `/graphql` | GraphiQL interface |

### Server (`/server/`)

| Path | Description |
|------|-------------|
| `/server/about` | About the application |
| `/server/privacy` | Privacy policy |
| `/server/contact` | Contact form |
| `/server/help` | Help / documentation |

### Auth (`/auth/`)

| Path | Description |
|------|-------------|
| `/auth/login` | Login form (username/email + password) |
| `/auth/logout` | Logout |
| `/auth/register` | Registration form |
| `/auth/2fa` | 2FA verification step (after password, before session) |
| `/auth/passkey` | Passkey authentication (WebAuthn) |
| `/auth/password/forgot` | Request password reset (sends email) |
| `/auth/password/reset/{token}` | Set new password (from email link) |
| `/auth/username/forgot` | Request username reminder (sends email) |
| `/auth/recovery/use` | Use recovery key (2FA bypass) |
| `/auth/verify/{token}` | Email verification |
| `/auth/invite/user/{token}` | User invite acceptance (set username, password) |
| `/auth/invite/server/{token}` | Server admin invite acceptance (set username, password) |
| `/auth/oidc/{provider}` | OIDC login initiation (redirect to provider) |
| `/auth/oidc/{provider}/callback` | OIDC callback (provider redirects back) |
| `/auth/ldap` | LDAP login form (if separate from main login) |

### Users (`/users/`)

**No ID required - app knows current user from session.**

| Path | Description |
|------|-------------|
| `/users` | Current user's profile |
| `/users/settings` | Account settings |
| `/users/tokens` | Manage API tokens |
| `/users/security` | Password, 2FA, sessions, recovery |
| `/users/security/password` | Change password |
| `/users/security/sessions` | Active sessions |
| `/users/security/2fa` | Two-factor settings |
| `/users/security/recovery` | View/regenerate recovery keys |
| `/users/security/passkeys` | Manage passkeys (WebAuthn) |

### Orgs (`/orgs/`)

Organizations - only for projects with multi-user collaboration.

| Path | Description |
|------|-------------|
| `/orgs` | List user's organizations |
| `/orgs/new` | Create new organization |
| `/orgs/{slug}` | Organization dashboard |
| `/orgs/{slug}/settings` | Organization settings |
| `/orgs/{slug}/tokens` | Organization API tokens |
| `/orgs/{slug}/members` | Member management |
| `/orgs/{slug}/members/invite` | Invite new members |
| `/orgs/{slug}/roles` | Organization roles |
| `/orgs/{slug}/security` | Security settings |
| `/orgs/{slug}/security/audit` | Audit log |
| `/orgs/{slug}/security/audit/export` | Export audit log (compliance) |
| `/orgs/{slug}/security/sessions` | Active sessions (org-wide) |
| `/orgs/{slug}/billing` | Billing & subscription (if applicable) |

### Admin (`/admin/`)

| Path | Description |
|------|-------------|
| `/admin` | Dashboard |
| `/admin/profile` | Your admin account (password, API token, 2FA) |
| `/admin/profile/preferences` | Admin preferences (theme, notifications) |

### Admin - Server (`/admin/server/`)

| Path | Description |
|------|-------------|
| `/admin/server/setup` | Initial setup wizard |
| `/admin/server/settings` | Server settings |
| `/admin/server/branding` | Branding & SEO |
| `/admin/server/ssl` | SSL/TLS settings |
| `/admin/server/tor` | Tor hidden service |
| `/admin/server/web` | Web settings (robots.txt, security.txt) |
| `/admin/server/pages` | Standard pages (about, privacy, contact) |
| `/admin/server/email` | Email/SMTP settings |
| `/admin/server/email/templates` | Email templates |
| `/admin/server/notifications` | Notification settings |
| `/admin/server/scheduler` | Scheduled tasks |
| `/admin/server/backup` | Backup & restore |
| `/admin/server/logs` | Log viewer |
| `/admin/server/roles` | Role definitions |
| `/admin/server/users/invites` | User registration invite codes (multi-user apps) |

### Admin - Server Admins (`/admin/server/admins/`)

| Path | Description |
|------|-------------|
| `/admin/server/admins` | Server admin accounts |
| `/admin/server/admins/invite` | Invite new server admin (generates link) |
| `/admin/server/admins/{id}` | Admin detail |

### Admin - Moderation (`/admin/server/moderation/`)

| Path | Description |
|------|-------------|
| `/admin/server/moderation/users` | User moderation |
| `/admin/server/moderation/users/{id}` | User detail |
| `/admin/server/moderation/orgs` | Org moderation |
| `/admin/server/moderation/orgs/{slug}` | Org detail |

## API Routes

### Public (`/api/v1/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/healthz` | GET | Health check |

**Note:** `/openapi.json` is a root-level endpoint (not `/api/v1/openapi.json`). See PART 14.

### Server (`/api/v1/server/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/server/about` | GET | About information |
| `/api/v1/server/privacy` | GET | Privacy policy |
| `/api/v1/server/contact` | POST | Submit contact form |
| `/api/v1/server/help` | GET | Help content |

### Auth (`/api/v1/auth/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/auth/register` | POST | Register new user |
| `/api/v1/auth/login` | POST | User login (returns session or 2FA challenge) |
| `/api/v1/auth/logout` | POST | User logout |
| `/api/v1/auth/2fa` | POST | Complete 2FA verification |
| `/api/v1/auth/passkey/challenge` | POST | Get WebAuthn challenge |
| `/api/v1/auth/passkey/verify` | POST | Verify WebAuthn response |
| `/api/v1/auth/password/forgot` | POST | Request password reset (sends email) |
| `/api/v1/auth/password/reset` | POST | Set new password (with token from email) |
| `/api/v1/auth/username/forgot` | POST | Request username reminder (sends email) |
| `/api/v1/auth/recovery/use` | POST | Use recovery key (2FA bypass) |
| `/api/v1/auth/verify` | POST | Verify email address |
| `/api/v1/auth/refresh` | POST | Refresh session/token |
| `/api/v1/auth/invite/user/{token}` | GET | Validate user invite token |
| `/api/v1/auth/invite/user/{token}` | POST | Complete user invite (set username, password) |
| `/api/v1/auth/invite/server/{token}` | GET | Validate server admin invite token |
| `/api/v1/auth/invite/server/{token}` | POST | Complete admin invite (set username, password) |
| `/api/v1/auth/oidc/{provider}` | GET | Get OIDC authorization URL |
| `/api/v1/auth/oidc/{provider}/callback` | POST | Exchange OIDC code for session |
| `/api/v1/auth/ldap` | POST | LDAP authentication |

### Users (`/api/v1/users/`)

**No ID required - app knows current user from session/token.**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/users` | GET | Current user's profile |
| `/api/v1/users` | PATCH | Update current user's profile |
| `/api/v1/users/tokens` | GET | List user's API tokens |
| `/api/v1/users/tokens` | POST | Create API token |
| `/api/v1/users/tokens/{token_id}` | GET | Get token details |
| `/api/v1/users/tokens/{token_id}` | DELETE | Revoke API token |
| `/api/v1/users/settings` | GET | Get user preferences |
| `/api/v1/users/settings` | PATCH | Update user preferences |
| `/api/v1/users/security/password` | POST | Change password |
| `/api/v1/users/security/sessions` | GET | List active sessions |
| `/api/v1/users/security/sessions/{session_id}` | DELETE | Revoke session |
| `/api/v1/users/security/2fa` | GET | Get 2FA status |
| `/api/v1/users/security/2fa/enable` | POST | Enable 2FA |
| `/api/v1/users/security/2fa/disable` | POST | Disable 2FA |
| `/api/v1/users/security/recovery` | GET | Get recovery keys status |
| `/api/v1/users/security/recovery/regenerate` | POST | Regenerate recovery keys |
| `/api/v1/users/security/passkeys` | GET | List passkeys |
| `/api/v1/users/security/passkeys` | POST | Register new passkey |
| `/api/v1/users/security/passkeys/{passkey_id}` | DELETE | Remove passkey |

### Orgs (`/api/v1/orgs/`)

Organizations - only for projects with multi-user collaboration.

**Route scoping:** All routes use org slug. Client gets own orgs from `GET /api/v1/orgs`.

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/orgs` | GET | Own orgs (user) or list all (admin) |
| `/api/v1/orgs` | POST | Create organization |
| `/api/v1/orgs/{slug}` | GET | Get organization details |
| `/api/v1/orgs/{slug}` | PATCH | Update organization |
| `/api/v1/orgs/{slug}` | DELETE | Delete organization |
| `/api/v1/orgs/{slug}/settings` | GET | Get org settings |
| `/api/v1/orgs/{slug}/settings` | PATCH | Update org settings |
| `/api/v1/orgs/{slug}/tokens` | GET | List org API tokens |
| `/api/v1/orgs/{slug}/tokens` | POST | Create org API token |
| `/api/v1/orgs/{slug}/tokens/{token_id}` | GET | Get token details |
| `/api/v1/orgs/{slug}/tokens/{token_id}` | DELETE | Revoke token |
| `/api/v1/orgs/{slug}/members` | GET | List members |
| `/api/v1/orgs/{slug}/members` | POST | Add member |
| `/api/v1/orgs/{slug}/members/{member_id}` | GET | Get member details |
| `/api/v1/orgs/{slug}/members/{member_id}` | PATCH | Update member role |
| `/api/v1/orgs/{slug}/members/{member_id}` | DELETE | Remove member |
| `/api/v1/orgs/{slug}/invites` | GET | List pending invites |
| `/api/v1/orgs/{slug}/invites` | POST | Create invite |
| `/api/v1/orgs/{slug}/invites/{invite_id}` | DELETE | Revoke invite |
| `/api/v1/orgs/{slug}/roles` | GET | List organization roles |
| `/api/v1/orgs/{slug}/roles` | POST | Create custom role |
| `/api/v1/orgs/{slug}/roles/{role_id}` | PATCH | Update role |
| `/api/v1/orgs/{slug}/roles/{role_id}` | DELETE | Delete role |
| `/api/v1/orgs/{slug}/security/audit` | GET | List audit events (paginated) |
| `/api/v1/orgs/{slug}/security/audit/export` | POST | Request audit export |
| `/api/v1/orgs/{slug}/security/audit/export/{export_id}` | GET | Download audit export |
| `/api/v1/orgs/{slug}/security/audit/retention` | GET | Get retention settings |
| `/api/v1/orgs/{slug}/security/audit/retention` | PATCH | Update retention (org owner only) |
| `/api/v1/orgs/{slug}/security/sessions` | GET | List org-wide sessions |

### Admin - Server (`/api/v1/admin/server/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/setup` | GET | Get setup status (is_complete, current_step) |
| `/api/v1/admin/server/setup/verify` | POST | Verify setup token |
| `/api/v1/admin/server/setup/account` | POST | Create admin account (Step 1) |
| `/api/v1/admin/server/setup/token` | POST | Generate API token (Step 2) |
| `/api/v1/admin/server/setup/config` | POST | Save server config (Step 3) |
| `/api/v1/admin/server/setup/security` | POST | Security settings - backup password, 2FA (Step 4) |
| `/api/v1/admin/server/setup/services` | POST | Configure services (Step 5) |
| `/api/v1/admin/server/setup/complete` | POST | Complete setup wizard (Step 6) |
| `/api/v1/admin/server/settings` | GET | Get server settings |
| `/api/v1/admin/server/settings` | PATCH | Update server settings |
| `/api/v1/admin/server/status` | GET | Server status (detailed, admin-only) |
| `/api/v1/admin/server/stats` | GET | Statistics |
| `/api/v1/admin/server/restart` | POST | Restart server |

### Admin - Server Roles (`/api/v1/admin/server/roles/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/roles` | GET | List roles |
| `/api/v1/admin/server/roles` | POST | Create role |
| `/api/v1/admin/server/roles/{id}` | GET | Get role details |
| `/api/v1/admin/server/roles/{id}` | PATCH | Update role |
| `/api/v1/admin/server/roles/{id}` | DELETE | Delete role |

### Admin - User Invites (`/api/v1/admin/server/users/invites/`)

User registration invite codes (multi-user apps only).

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/users/invites` | GET | List user invite codes |
| `/api/v1/admin/server/users/invites` | POST | Create user invite code |
| `/api/v1/admin/server/users/invites/{id}` | GET | Get invite details |
| `/api/v1/admin/server/users/invites/{id}` | DELETE | Revoke invite |

### Admin - Server Admins (`/api/v1/admin/server/admins/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/admins` | GET | List server admins |
| `/api/v1/admin/server/admins/{id}` | GET | Get admin details |
| `/api/v1/admin/server/admins/{id}` | DELETE | Delete admin |
| `/api/v1/admin/server/admins/{id}/disable` | POST | Disable admin |
| `/api/v1/admin/server/admins/{id}/enable` | POST | Enable admin |
| `/api/v1/admin/server/admins/invite` | POST | Generate admin invite link |

### Admin - Moderation Users (`/api/v1/admin/server/moderation/users/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/moderation/users` | GET | List all users |
| `/api/v1/admin/server/moderation/users/{id}` | GET | Get user details |
| `/api/v1/admin/server/moderation/users/{id}` | DELETE | Delete user |
| `/api/v1/admin/server/moderation/users/disable` | POST | Disable user |
| `/api/v1/admin/server/moderation/users/enable` | POST | Enable user |
| `/api/v1/admin/server/moderation/users/impersonate` | POST | Get impersonation token |

### Admin - Moderation Orgs (`/api/v1/admin/server/moderation/orgs/`)

Moderation only - server admin does not manage org members/roles.

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/moderation/orgs` | GET | List all organizations |
| `/api/v1/admin/server/moderation/orgs/{slug}` | GET | Get organization details |
| `/api/v1/admin/server/moderation/orgs/{slug}` | DELETE | Delete organization |
| `/api/v1/admin/server/moderation/orgs/{slug}/disable` | POST | Disable organization |
| `/api/v1/admin/server/moderation/orgs/{slug}/enable` | POST | Enable organization |

### Admin - Profile (`/api/v1/admin/profile/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/profile` | GET | Get admin profile |
| `/api/v1/admin/profile` | PATCH | Update admin profile (username, icon) |
| `/api/v1/admin/profile/password` | POST | Change admin password |
| `/api/v1/admin/profile/token` | GET | Get current API token (masked) |
| `/api/v1/admin/profile/token` | POST | Regenerate API token (returns new token ONCE) |
| `/api/v1/admin/profile/preferences` | GET | Get admin preferences (theme, notifications) |
| `/api/v1/admin/profile/preferences` | PATCH | Update admin preferences |

### Admin - Branding (`/api/v1/admin/server/branding/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/branding` | GET | Get branding settings |
| `/api/v1/admin/server/branding` | PATCH | Update branding |

### Admin - SSL (`/api/v1/admin/server/ssl/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/ssl` | GET | Get SSL settings |
| `/api/v1/admin/server/ssl` | PATCH | Update SSL settings |
| `/api/v1/admin/server/ssl/renew` | POST | Force certificate renewal |

### Admin - Tor (`/api/v1/admin/server/tor/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/tor` | GET | Get Tor status |
| `/api/v1/admin/server/tor` | PATCH | Update Tor settings |
| `/api/v1/admin/server/tor/regenerate` | POST | Regenerate .onion address |
| `/api/v1/admin/server/tor/vanity` | GET | Get vanity generation status |
| `/api/v1/admin/server/tor/vanity` | POST | Start vanity generation |
| `/api/v1/admin/server/tor/vanity` | DELETE | Cancel vanity generation |
| `/api/v1/admin/server/tor/vanity/apply` | POST | Apply vanity address |
| `/api/v1/admin/server/tor/import` | POST | Import external keys |

### Admin - Web (robots.txt, security.txt) (`/api/v1/admin/server/web/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/web` | GET | Get web settings |
| `/api/v1/admin/server/web` | PATCH | Update web settings |
| `/api/v1/admin/server/web/robots` | GET | Get robots.txt config |
| `/api/v1/admin/server/web/robots` | PATCH | Update robots.txt |
| `/api/v1/admin/server/web/robots/preview` | GET | Preview robots.txt |
| `/api/v1/admin/server/web/security` | GET | Get security.txt config |
| `/api/v1/admin/server/web/security` | PATCH | Update security.txt |
| `/api/v1/admin/server/web/security/preview` | GET | Preview security.txt |

### Admin - Pages (`/api/v1/admin/server/pages/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/pages` | GET | Get all page settings |
| `/api/v1/admin/server/pages/about` | GET | Get about page content |
| `/api/v1/admin/server/pages/about` | PATCH | Update about page content |
| `/api/v1/admin/server/pages/privacy` | GET | Get privacy policy content |
| `/api/v1/admin/server/pages/privacy` | PATCH | Update privacy policy content |
| `/api/v1/admin/server/pages/contact` | GET | Get contact page settings |
| `/api/v1/admin/server/pages/contact` | PATCH | Update contact page settings |
| `/api/v1/admin/server/pages/help` | GET | Get help page content |
| `/api/v1/admin/server/pages/help` | PATCH | Update help page content |

### Admin - Email (`/api/v1/admin/server/email/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/email` | GET | Get email settings |
| `/api/v1/admin/server/email` | PATCH | Update email settings |
| `/api/v1/admin/server/email/test` | POST | Send test email |
| `/api/v1/admin/server/email/templates` | GET | List email templates |
| `/api/v1/admin/server/email/templates/{name}` | GET | Get template |
| `/api/v1/admin/server/email/templates/{name}` | PUT | Update template |
| `/api/v1/admin/server/email/templates/{name}/reset` | POST | Reset to default |
| `/api/v1/admin/server/email/templates/{name}/preview` | POST | Preview template |

### Admin - Scheduler (`/api/v1/admin/server/scheduler/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/scheduler` | GET | List scheduled tasks |
| `/api/v1/admin/server/scheduler/{id}` | GET | Get task details |
| `/api/v1/admin/server/scheduler/{id}` | PATCH | Update task |
| `/api/v1/admin/server/scheduler/{id}/run` | POST | Run task now |
| `/api/v1/admin/server/scheduler/{id}/enable` | POST | Enable task |
| `/api/v1/admin/server/scheduler/{id}/disable` | POST | Disable task |

### Admin - Backup (`/api/v1/admin/server/backup/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/backup` | GET | List backups |
| `/api/v1/admin/server/backup` | POST | Create backup |
| `/api/v1/admin/server/backup/{id}` | GET | Get backup details |
| `/api/v1/admin/server/backup/{id}` | DELETE | Delete backup |
| `/api/v1/admin/server/backup/{id}/download` | GET | Download backup file |
| `/api/v1/admin/server/backup/restore` | POST | Restore from backup |

### Admin - Logs (`/api/v1/admin/server/logs/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/logs` | GET | List log files |
| `/api/v1/admin/server/logs/{type}` | GET | Get log entries |
| `/api/v1/admin/server/logs/{type}/download` | GET | Download log file |

## Email Templates (User-Related)

| Template | Purpose |
|----------|---------|
| `user_welcome` | Welcome email after registration |
| `user_verify_email` | Email verification link |
| `user_password_reset` | Password reset link |
| `user_password_changed` | Confirmation of password change |
| `user_2fa_enabled` | Confirmation of 2FA enabled |
| `user_new_login` | Alert for login from new device/location |
| `user_invite` | Invitation email |
| `user_account_disabled` | Account has been disabled |

## Database Architecture (NON-NEGOTIABLE)

**Applications use TWO separate SQLite databases by default.**

### Database Files

| Database | File | Purpose |
|----------|------|---------|
| **Server DB** | `{data_dir}/db/server.db` | Admin credentials, server state, scheduler |
| **Users DB** | `{data_dir}/db/users.db` | User accounts, tokens, sessions (multi-user mode) |

### Why Two Databases?

| Reason | Description |
|--------|-------------|
| **Isolation** | Admin credentials separate from user data |
| **Security** | Compromised user DB doesn't expose admin |
| **Backup** | Can backup/restore independently |
| **Logical separation** | Server config vs user data |

### Database Modes

| Mode | Server DB | Users DB | Use Case |
|------|-----------|----------|----------|
| **Single Instance** | Local SQLite | Local SQLite | Default, simple deployment |
| **Cluster** | Remote (shared) | Remote (shared) | Multi-node, load distribution |
| **Mixed Mode** | Any supported | Any supported | Heterogeneous backend infrastructure |

#### Clustering vs High Availability (IMPORTANT TERMINOLOGY)

**These are NOT interchangeable terms.**

| Term | Meaning |
|------|---------|
| **Clustering** | Multiple application nodes sharing state via a common database and Valkey/Redis. Enables horizontal scaling and load distribution. All nodes are equal peers. |
| **High Availability (HA)** | Fault tolerance for the database backend itself (e.g., PostgreSQL replication, Galera for MariaDB). This is OUTSIDE the application's scope. |

**The application provides clustering (multi-node). Database HA is your infrastructure's responsibility.**

```
┌─────────────────────────────────────────────────────────────────┐
│                      APPLICATION LAYER                          │
│                                                                 │
│   ┌─────────┐     ┌─────────┐     ┌─────────┐                 │
│   │ Node 1  │     │ Node 2  │     │ Node 3  │  ← Clustering   │
│   └────┬────┘     └────┬────┘     └────┬────┘                 │
│        │               │               │                       │
│        └───────────────┼───────────────┘                       │
│                        │                                        │
│              ┌─────────▼─────────┐                             │
│              │  Valkey/Redis     │  ← Cluster coordination     │
│              └─────────┬─────────┘                             │
│                        │                                        │
└────────────────────────┼────────────────────────────────────────┘
                         │
┌────────────────────────┼────────────────────────────────────────┐
│                        ▼              INFRASTRUCTURE LAYER      │
│              ┌───────────────────┐                              │
│              │ Database Backend  │  ← HA is YOUR responsibility│
│              │ (PostgreSQL/MySQL)│                              │
│              └───────────────────┘                              │
│                                                                 │
│   Examples of HA (not our concern):                            │
│   - PostgreSQL: Patroni, pgpool, streaming replication          │
│   - MySQL/MariaDB: Galera Cluster, Group Replication           │
│   - Managed: AWS RDS Multi-AZ, CloudSQL HA                     │
└─────────────────────────────────────────────────────────────────┘
```

### Single Instance (Default)

Both databases are local SQLite files:

```yaml
server:
  database:
    driver: sqlite
    # Both databases stored locally
    # {data_dir}/db/server.db
    # {data_dir}/db/users.db
```

### Cluster Mode (Remote Database)

**When clustering, BOTH databases MUST use the same remote database.**

All nodes need shared access to:
- Admin credentials (same login works on any node)
- Server settings (consistent configuration)
- User accounts (users can access any node)
- Sessions (no re-login when switching nodes)
- API tokens (tokens work on any node)

**Two ways to configure connection (pick one):**

| Method | When to Use |
|--------|-------------|
| `url` | Simple, single connection string, environment-friendly |
| `host`/`port`/etc | More explicit, when fields come from different sources |

**Using connection URL:**
```yaml
server:
  database:
    driver: postgres
    url: ${DATABASE_URL}  # postgres://user:pass@host:5432/dbname?sslmode=require
```

**Using individual fields:**
```yaml
server:
  database:
    driver: postgres
    host: db.example.com
    port: 5432
    name: myapp
    username: myapp
    password: ${DB_PASSWORD}
    sslmode: require

    # Connection pool
    max_open: 25
    max_idle: 5
    max_lifetime: 5m
```

**URL Format:**
```
postgres://[username[:password]@]host[:port]/database[?sslmode=mode]
mysql://[username[:password]@]host[:port]/database[?params]
```

**Note:** `url` takes precedence if both url and individual fields are specified.

```yaml
# All tables go in same database with prefixes:
# - srv_* tables (config, admin_sessions, rate_limits, audit_log, scheduler_*, backups)
# - usr_* tables (admins, users, api_keys, password_resets, email_verifications, totp_secrets, passkeys, trusted_devices, user_sessions)
```

### Table Prefixes in Shared Database

| Prefix | Tables |
|--------|--------|
| `srv_` | `srv_config`, `srv_config_meta`, `srv_admin_sessions`, `srv_rate_limits`, `srv_audit_log`, `srv_scheduler_tasks`, `srv_scheduler_history`, `srv_backups` |
| `usr_` | `usr_admins`, `usr_users`, `usr_api_keys`, `usr_password_resets`, `usr_email_verifications`, `usr_totp_secrets`, `usr_passkeys`, `usr_trusted_devices`, `usr_user_sessions` |

### Cluster Requirements

| Requirement | Description |
|-------------|-------------|
| **Shared database** | All nodes connect to same PostgreSQL/MySQL |
| **Same credentials** | Admin can log into any node |
| **Session sharing** | User sessions valid across all nodes |
| **Token validation** | API tokens work on any node |
| **Config sync** | Settings changes propagate to all nodes |

### Cluster Initialization (NON-NEGOTIABLE)

**The FIRST node is the source of truth. Subsequent nodes inherit from the remote database.**

#### First Node (Primary Setup)

```
1. Deploy first node
         │
         ▼
2. First run creates local SQLite databases
   - Admin credentials auto-generated
   - Server settings initialized
         │
         ▼
3. Configure application via admin panel
   - Set branding, SSL, etc.
   - Create users (if multi-user mode)
         │
         ▼
4. Ready to migrate to cluster?
         │
         ▼
5. Setup remote database (PostgreSQL/MySQL)
         │
         ▼
6. Update config: driver: postgres (or use Web UI)
         │
         ▼
7. Restart - app auto-migrates local data to remote
         │
         ▼
8. Now using remote DB
   (First node is source of truth)
```

#### Additional Nodes (Inherit from Remote)

```
1. Deploy new node
         │
         ▼
2. Configure with SAME remote database connection
   driver: postgres
   host: db.example.com (same as first node)
         │
         ▼
3. First run detects existing data in remote DB
         │
         ▼
4. SKIP initialization - inherit everything:
   - Admin credentials (same login)
   - Server settings (same config)
   - Users (same accounts)
   - Sessions (shared)
         │
         ▼
5. Node joins cluster automatically
```

#### Node Behavior

| Scenario | Behavior |
|----------|----------|
| **First node + SQLite** | Create admin, init settings |
| **First node + empty remote DB** | Create admin, init settings (becomes source of truth) |
| **New node + remote DB with data** | Skip init, inherit everything from DB |
| **Any node + settings change** | Write to DB, all nodes see change |

#### Migration Methods

**Migration to remote database is done via config file OR admin web UI - NO CLI commands.**

**Method 1: Config File**

```yaml
# server.yml - change driver and add connection details
server:
  database:
    driver: postgres
    host: db.example.com
    port: 5432
    name: myapp
    username: myapp
    password: ${DB_PASSWORD}
    sslmode: require
```

On restart, the application:
1. Detects driver change from `sqlite` to `postgres`
2. Connects to remote database
3. If empty: migrates local SQLite data automatically
4. If has data: uses existing data (node joins cluster)

**Method 2: Admin Web UI**

`/admin/server/database`

| Element | Type | Description |
|---------|------|-------------|
| Current Driver | Read-only | Shows current database driver |
| Driver | Dropdown | sqlite, postgres, mysql |
| Host | Text input | Database host (shown when not sqlite) |
| Port | Number input | Database port |
| Database Name | Text input | Database name |
| Username | Text input | Database username |
| Password | Password input | Database password |
| SSL Mode | Dropdown | disable, require, verify-full |
| Test Connection | Button | Verify connection before saving |
| Migrate & Switch | Button | Migrate data and switch to remote |

**Migration Process (automatic on driver change):**

```
1. Test connection to remote database
         │
         ▼
2. If remote DB empty:
   - Create tables
   - Export local SQLite data
   - Import to remote
         │
         ▼
3. If remote DB has data:
   - Verify schema compatibility
   - Skip migration (join existing cluster)
         │
         ▼
4. Switch to remote driver
         │
         ▼
5. Local SQLite files preserved as backup
```

### Storage Backend Sync (Bidirectional)

**This section covers ALL storage transitions, not just the initial SQLite → Remote migration.**

The Migration Methods above describe the **initial migration** to cluster mode. This section describes:
- Migrating back from Remote → SQLite (leaving cluster)
- YAML config import/export for backup or migration
- All possible storage transitions

**Data always syncs TOWARD the new storage backend before switching.**

| From | To | Method | Sync Action |
|------|-----|--------|-------------|
| **SQLite → Remote** | Config file or Web UI | Export SQLite data → Import to remote DB → Switch to remote |
| **Remote → SQLite** | Web UI only | Export remote data → Import to SQLite files → Disconnect → Switch to SQLite |
| **SQLite → YAML** | CLI: `--maintenance backup` | Export `server.db` settings → Write to backup file |
| **YAML → SQLite** | CLI: `--maintenance restore` | Read backup → Import settings to `server.db` |
| **YAML → Remote** | CLI: `--maintenance restore` | Read backup → Import settings to remote DB |

#### Remote → SQLite (Downgrade to Local)

When switching from remote database back to local SQLite:

```
1. User selects "Switch to SQLite" in Web UI
         │
         ▼
2. Export ALL data from remote database
         │
         ▼
3. Create/update local SQLite files:
   - {data_dir}/db/server.db
   - {data_dir}/db/users.db
         │
         ▼
4. Import remote data to SQLite
         │
         ▼
5. Verify data integrity (row counts match)
         │
         ▼
6. Disconnect from remote database
         │
         ▼
7. Update config: driver: sqlite
         │
         ▼
8. Now using local SQLite (standalone mode)
```

**Use case:** Converting cluster node back to standalone instance.

#### SQLite ↔ YAML Sync

Settings can be stored in database OR config file. Sync between them:

**SQLite → YAML (Export settings to file):**

```
Admin Web UI: /{adminpath}/server/settings → "Export to YAML"
         │
         ▼
Read all settings from server.db
         │
         ▼
Write to server.yml (preserves comments, formatting)
         │
         ▼
Settings now in both DB and YAML (DB is source of truth)
```

**YAML → SQLite (Import settings from file):**

```
On startup: YAML file detected with changes
         │
         ▼
Read settings from server.yml
         │
         ▼
Import to server.db (overwrites DB values)
         │
         ▼
DB is now source of truth
```

#### Sync Priority (Source of Truth)

| Mode | Source of Truth | Behavior |
|------|-----------------|----------|
| **Running** | Database | DB values used, YAML ignored |
| **Startup (YAML changed)** | YAML | YAML imported to DB, then DB is source |
| **Startup (YAML unchanged)** | Database | DB values used |
| **Cluster** | Remote Database | All nodes read from shared DB |

### Mixed Mode (Heterogeneous Database Backends)

**Mixed Mode allows different nodes in a cluster to connect to different database backends.**

This is useful when:
- Migrating from one database to another (e.g., MySQL → PostgreSQL)
- Geographic distribution with local database preferences
- Testing new database backend before full migration

#### Mixed Mode Configuration

Each node specifies its own database connection:

**Node 1 (PostgreSQL):**
```yaml
server:
  database:
    driver: postgres
    host: pg.us-east.example.com
    port: 5432
    name: myapp
    username: myapp
    password: ${DB_PASSWORD}
```

**Node 2 (MariaDB):**
```yaml
server:
  database:
    driver: mysql
    host: maria.eu-west.example.com
    port: 3306
    name: myapp
    username: myapp
    password: ${DB_PASSWORD}
```

**Node 3 (PostgreSQL - different server):**
```yaml
server:
  database:
    driver: postgres
    host: pg.ap-south.example.com
    port: 5432
    name: myapp
    username: myapp
    password: ${DB_PASSWORD}
```

#### Mixed Mode Requirements

| Requirement | Description |
|-------------|-------------|
| **Valkey/Redis REQUIRED** | State synchronization between heterogeneous backends |
| **Schema compatibility** | All databases MUST have identical schema |
| **Data sync** | Application handles cross-database replication via Valkey |
| **Same schema version** | All nodes must run same application version |

#### Mixed Mode Diagram

```
┌─────────────────────────────────────────────────────────────────────┐
│                        CLUSTER NODES                                │
│                                                                     │
│  ┌──────────┐        ┌──────────┐        ┌──────────┐             │
│  │  Node 1  │        │  Node 2  │        │  Node 3  │             │
│  │ (US-East)│        │ (EU-West)│        │(AP-South)│             │
│  └────┬─────┘        └────┬─────┘        └────┬─────┘             │
│       │                   │                   │                    │
│       └───────────────────┼───────────────────┘                    │
│                           │                                         │
│                  ┌────────▼────────┐                               │
│                  │  Valkey/Redis   │  ← Sync layer (REQUIRED)      │
│                  │    Cluster      │                               │
│                  └────────┬────────┘                               │
│                           │                                         │
└───────────────────────────┼─────────────────────────────────────────┘
                            │
        ┌───────────────────┼───────────────────┐
        │                   │                   │
        ▼                   ▼                   ▼
┌──────────────┐   ┌──────────────┐   ┌──────────────┐
│  PostgreSQL  │   │   MariaDB    │   │  PostgreSQL  │
│  (US-East)   │   │  (EU-West)   │   │  (AP-South)  │
└──────────────┘   └──────────────┘   └──────────────┘
```

#### Mixed Mode Sync via Valkey

**All state changes are broadcast through Valkey/Redis:**

```
Node 1 writes user record
         │
         ▼
Local PostgreSQL INSERT
         │
         ▼
Publish to Valkey: "user.created" + payload
         │
         ├──────────────────────────────────────┐
         │                                      │
         ▼                                      ▼
Node 2 receives                          Node 3 receives
         │                                      │
         ▼                                      ▼
Local MariaDB INSERT                     Local PostgreSQL INSERT
```

**The application handles:**
- Publishing changes to Valkey after local writes
- Subscribing to changes from other nodes
- Applying remote changes to local database
- Conflict resolution (last-write-wins by timestamp)

### Node Management (NON-NEGOTIABLE)

**Simple node management via admin web UI. No CLI commands, no manual config.**

#### Adding a Node

**On existing node:**

1. Go to `/admin/server/nodes/add`
2. Click "Generate Token" button
3. Server generates:
   - Token: `node_{random_32_chars}`
   - URL: `{proto}://{fqdn}` (of this node)
4. Display token and URL to admin (copy buttons)

**On new server:**

1. Go to `/admin/server/nodes/add`
2. Enter:
   - URL from existing node
   - Token from existing node
3. Click "Join Cluster"
4. New node automatically:
   - Connects to existing node
   - Gets database connection details
   - Gets all configuration
   - Joins cluster

```
Existing Node                          New Node
     │                                      │
     ▼                                      │
/{adminpath}/server/nodes/add               │
     │                                      │
     ▼                                      │
Generate Token                              │
  → node_abc123...                          │
  → https://node1.example.com               │
     │                                      │
     └──────── Share token + URL ──────────►│
                                            │
                                            ▼
                                   /{adminpath}/server/nodes/add
                                            │
                                            ▼
                                   Enter URL + Token
                                            │
                                            ▼
                                   Click "Join Cluster"
                                            │
                                            ▼
                                   Auto-configured!
```

#### Join Cluster Flow (Technical)

**Step-by-step process when new node joins cluster:**

```
NEW NODE                                    EXISTING NODE
    │                                            │
    │  1. POST /api/v1/cluster/join              │
    │     Body: { "token": "node_xxx" }          │
    │─────────────────────────────────────────►  │
    │                                            │
    │                                            ▼
    │                                   2. Validate token:
    │                                      - Token exists?
    │                                      - Not expired (15 min)?
    │                                      - Not already used?
    │                                      - Not in 90-day lockout?
    │                                            │
    │                                            ▼
    │                                   3. Mark token as used
    │                                            │
    │  4. Response: cluster bootstrap data       │
    │  ◄─────────────────────────────────────────│
    │                                            │
    ▼                                            │
5. Receive bootstrap data:                       │
   - Database connection (encrypted)             │
   - Encryption key for secrets                  │
   - Cluster ID                                  │
    │                                            │
    ▼                                            │
6. Connect to remote database                    │
    │                                            │
    ▼                                            │
7. Read all configuration from database          │
   - Server settings                             │
   - Branding/SEO                                │
   - SSL settings                                │
   - All other config                            │
    │                                            │
    ▼                                            │
8. Register self in nodes table                  │
   - node_id: {hostname}                         │
   - status: online                              │
   - joined_at: now()                            │
    │                                            │
    ▼                                            │
9. Write minimal server.yml                      │
   - Database connection only                    │
    │                                            │
    ▼                                            │
10. Start heartbeat                              │
    │                                            │
    ▼                                            │
11. Node is now part of cluster                  │
```

#### Bootstrap Data Structure

**Response from existing node (`POST /api/v1/cluster/join`):**

```json
{
  "ok": true,
  "data": {
    "cluster": {
      "id": "cluster_abc123",
      "name": "MyApp Cluster"
    },
    "database": {
      "driver": "postgres",
      "host": "db.example.com",
      "port": 5432,
      "name": "myapp",
      "username": "myapp",
      "password_encrypted": "base64_encrypted_password",
      "sslmode": "require"
    },
    "encryption": {
      "key_encrypted": "base64_encrypted_key"
    },
    "node": {
      "suggested_id": "server-2"
    }
  }
}
```

#### Security: Encrypted Transfer

**Sensitive data is encrypted during transfer using token-derived key:**

```go
// Token is used to derive encryption key for bootstrap data
func deriveKeyFromToken(token string) []byte {
    // Use Argon2id to derive encryption key from token
    salt := sha256.Sum256([]byte("cluster_join_" + token))
    return argon2.IDKey([]byte(token), salt[:16], 3, 64*1024, 4, 32)
}

// Existing node encrypts sensitive data
func encryptBootstrapData(data []byte, token string) []byte {
    key := deriveKeyFromToken(token)
    // AES-256-GCM encryption
    return aesGcmEncrypt(data, key)
}

// New node decrypts using same token
func decryptBootstrapData(encrypted []byte, token string) []byte {
    key := deriveKeyFromToken(token)
    return aesGcmDecrypt(encrypted, key)
}
```

**What's encrypted:**
- Database password
- Encryption key for secrets (TOTP secrets, etc.)

**What's NOT encrypted (not sensitive):**
- Database host/port/name
- Cluster ID
- Node suggestions

#### Database Tables for Clustering

**Nodes Table (in remote database):**

| Column | Type | Description |
|--------|------|-------------|
| `id` | String | Node ID (default: hostname) |
| `hostname` | String | Server hostname |
| `ip_address` | String | Node IP address |
| `version` | String | Application version |
| `status` | String | online, offline, degraded |
| `last_heartbeat` | Timestamp | Last heartbeat time |
| `joined_at` | Timestamp | When node joined cluster |
| `system_info` | JSON | CPU, memory, disk stats |

**Join Tokens Table (in remote database):**

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID | Primary key |
| `token_hash` | String | SHA-256 hash of token |
| `created_by` | String | Node ID that created token |
| `created_at` | Timestamp | Creation time |
| `expires_at` | Timestamp | Expiration (created_at + 15 min) |
| `used_at` | Timestamp | When token was used (NULL if unused) |
| `used_by` | String | Node ID that used token |
| `lockout_until` | Timestamp | Cannot reuse until (used_at + 90 days) |

#### Heartbeat

**Nodes send heartbeat every 30 seconds:**

```go
func startHeartbeat(ctx context.Context, db *sql.DB, nodeID string) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            updateHeartbeat(db, nodeID)
        }
    }
}

func updateHeartbeat(db *sql.DB, nodeID string) {
    db.Exec(`
        UPDATE nodes
        SET last_heartbeat = NOW(),
            status = 'online',
            system_info = $1
        WHERE id = $2
    `, getSystemInfo(), nodeID)
}
```

**Node status determination:**

| Last Heartbeat | Status |
|----------------|--------|
| < 1 minute ago | online |
| 1-5 minutes ago | degraded |
| > 5 minutes ago | offline |

#### Error Handling

| Error | Response | Action |
|-------|----------|--------|
| Invalid token | 401 Unauthorized | Show error, ask to retry |
| Token expired | 401 Token Expired | Generate new token on existing node |
| Token already used | 401 Token Already Used | Generate new token |
| Token in lockout | 401 Token Locked | Wait 90 days or generate new token |
| Database connection failed | 500 Database Error | Show error, check DB settings |
| Network error | Connection Failed | Retry with backoff |

#### Token Rules

| Rule | Value |
|------|-------|
| Format | `node_{random_32_chars}` |
| Valid for | 15 minutes |
| Usage | One-time only |
| Reuse lockout | 90 days (prevents replay attacks) |

#### Removing a Node

**A node can only remove ITSELF from the cluster.**

1. Go to `/admin/server/nodes/remove` (on the node to remove)
2. Click "Remove from Cluster"
3. Confirmation modal: "Are you sure you want to remove {nodename} from the cluster?"
   - [Yes, Remove] [Cancel]
4. On confirmation:
   - Node disconnects from cluster
   - Node reverts to standalone mode (local SQLite)
   - Node creates fresh local databases
   - Other nodes see removal, adjust node count

**Cannot remove other nodes** - prevents accidental/malicious removal.

#### Viewing Nodes

**`/admin/server/nodes`** - Node list

| Column | Description |
|--------|-------------|
| Node Name | Hostname (clickable link) |
| Status | online, offline, degraded |
| Uptime | Time since last restart |
| Version | Application version |
| Last Seen | Last heartbeat time |

**`/admin/server/nodes/{node}`** - Node detail

| Section | Contents |
|---------|----------|
| **Info** | Node name, hostname, IP, version, uptime |
| **Status** | Connection status, last heartbeat |
| **System** | CPU usage, memory usage, disk usage |
| **Database** | Connection status, query latency |
| **Tor** | Hidden service status, .onion address |

#### Node Identity

| Setting | Default | Changeable |
|---------|---------|------------|
| Node ID | `{hostname}` | Yes, via `/admin/server/nodes/settings` |
| Display Name | `{hostname}` | Yes |

#### First Node Behavior

**Generating the first token automatically converts to cluster mode.**

```
Single Instance (SQLite)
         │
         ▼
Admin goes to /{adminpath}/server/nodes/add
         │
         ▼
Clicks "Generate Token"
         │
         ▼
Wizard prompts: "Enable cluster mode?"
  - Requires remote database connection
  - Enter PostgreSQL/MySQL details
         │
         ▼
On confirm:
  - Migrates local data to remote DB
  - Generates join token
  - Node is now cluster-ready
```

#### Admin Panel Routes

| Route | Description |
|-------|-------------|
| `/admin/server/nodes` | List all nodes |
| `/admin/server/nodes/add` | Add node (generate token OR join) |
| `/admin/server/nodes/remove` | Remove THIS node from cluster |
| `/admin/server/nodes/settings` | Node identity settings |
| `/admin/server/nodes/{node}` | View specific node details |

#### API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/nodes` | GET | List all nodes |
| `/api/v1/admin/server/nodes/token` | POST | Generate join token |
| `/api/v1/admin/server/nodes/join` | POST | Join cluster with token |
| `/api/v1/admin/server/nodes/leave` | POST | Remove this node from cluster |
| `/api/v1/admin/server/nodes/{node}` | GET | Get node details |
| `/api/v1/admin/server/nodes/settings` | GET | Get node identity settings |
| `/api/v1/admin/server/nodes/settings` | PATCH | Update node identity |

### Supported Remote Databases

| Database | Driver | Pure Go | Notes |
|----------|--------|---------|-------|
| PostgreSQL | `github.com/jackc/pgx/v5` | YES | Recommended for production |
| MySQL/MariaDB | `github.com/go-sql-driver/mysql` | YES | Widely supported |
| SQLite | `modernc.org/sqlite` | YES | Single instance only |

### Schema Migration

When using remote database, the same tables are created but with appropriate types:

| SQLite Type | PostgreSQL Type | MySQL Type |
|-------------|-----------------|------------|
| TEXT | TEXT | VARCHAR(255) / TEXT |
| INTEGER | INTEGER / BIGINT | INT / BIGINT |
| BOOLEAN | BOOLEAN | TINYINT(1) |
| TIMESTAMP | TIMESTAMPTZ | DATETIME |
| UUID | UUID | CHAR(36) |
| JSON | JSONB | JSON |

## Database Schema

### Server Database Tables (server.db)

#### Admin Credentials Table

**Stores server admin credentials - NEVER in config file.**

| Column | Type | Description |
|--------|------|-------------|
| `id` | INTEGER | Primary key (always 1 - single admin) |
| `username` | String | Admin username |
| `email` | String | Admin email |
| `password_hash` | String | Argon2id hash (PHC format) |
| `token_hash` | String | SHA-256 hash of API token |
| `token_prefix` | String | First 8 chars of token (for identification) |
| `totp_secret` | String | 2FA secret (encrypted, optional) |
| `totp_enabled` | Boolean | 2FA enabled |
| `created_at` | Timestamp | Account creation |
| `updated_at` | Timestamp | Last update |
| `last_login_at` | Timestamp | Last login |

**Notes:**
- Only ONE row ever exists (id=1)
- Created via setup wizard on first run
- Setup token displayed in console ONCE, used to access `/admin/server/setup`
- Admin password and API token created during setup wizard (user must copy)

#### Admin Sessions Table

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID | Primary key |
| `token_hash` | String | SHA-256 hash of session token |
| `ip_address` | String | Client IP |
| `user_agent` | String | Browser/client info |
| `location` | String | GeoIP location |
| `expires_at` | Timestamp | Session expiry |
| `created_at` | Timestamp | Session start |

#### Scheduler State Table

| Column | Type | Description |
|--------|------|-------------|
| `task_id` | String | Unique task identifier |
| `last_run` | Timestamp | Last execution time |
| `next_run` | Timestamp | Next scheduled time |
| `last_result` | String | success/failure |
| `last_error` | Text | Error message if failed |
| `run_count` | Integer | Total runs |
| `enabled` | Boolean | Task enabled |

### Users Database Tables (users.db)

#### Users Table

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID | Primary key |
| `email` | String | Unique, required |
| `password_hash` | String | Argon2id hash (PHC format) |
| `display_name` | String | Optional |
| `avatar_url` | String | Optional |
| `bio` | Text | Optional |
| `role` | String | User role |
| `email_verified` | Boolean | Email verified status |
| `approved` | Boolean | Admin approved (if required) |
| `disabled` | Boolean | Account disabled |
| `totp_secret` | String | 2FA secret (encrypted) |
| `totp_enabled` | Boolean | 2FA enabled |
| `timezone` | String | User timezone |
| `language` | String | User language |
| `created_at` | Timestamp | Account creation |
| `updated_at` | Timestamp | Last update |
| `last_login_at` | Timestamp | Last login |

#### User Tokens Table

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID | Primary key |
| `user_id` | UUID | Foreign key to users |
| `name` | String | User-defined label |
| `token_hash` | String | SHA-256 hash of API token |
| `token_prefix` | String | First 8 chars (for identification) |
| `scopes` | JSON | Optional permission scopes |
| `expires_at` | Timestamp | Optional expiration |
| `last_used_at` | Timestamp | Last usage |
| `created_at` | Timestamp | Creation time |

#### User Sessions Table

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID | Primary key |
| `user_id` | UUID | Foreign key to users |
| `token_hash` | String | SHA-256 hash of session token |
| `ip_address` | String | Client IP |
| `user_agent` | String | Browser/client info |
| `location` | String | GeoIP location |
| `expires_at` | Timestamp | Session expiry |
| `created_at` | Timestamp | Session start |

#### Invites Table

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID | Primary key |
| `code` | String | Unique invite code |
| `role` | String | Role for invited users |
| `max_uses` | Integer | Maximum uses (0 = unlimited) |
| `use_count` | Integer | Current use count |
| `expires_at` | Timestamp | Expiration |
| `created_by` | UUID | Admin who created |
| `created_at` | Timestamp | Creation time |

## Public User Profiles & Vanity URLs (OPTIONAL)

**For apps with public user profiles, support vanity URLs at root level.**

This is OPTIONAL and only applies when user profiles should be publicly accessible (social platforms, code hosting, link aggregators, portfolios, etc.).

### Vanity URL Routing

| URL Pattern | Maps To | API Endpoint |
|-------------|---------|--------------|
| `/{username}` | User public profile | `GET /api/v1/users/{username}` |
| `/{username}/{resource}` | User's resource | `GET /api/v1/users/{username}/{resource}` |
| `/{username}/{resource}/{item}` | Specific item | `GET /api/v1/users/{username}/{resource}/{item}` |

**Examples by App Type:**

| App Type | `/{username}` Shows | Sub-routes |
|----------|---------------------|------------|
| **Linktree clone** | User's link page | `/{user}/analytics` |
| **GitHub clone** | User profile + repos | `/{user}/{repo}`, `/{user}/{repo}/issues` |
| **Twitter clone** | User timeline | `/{user}/status/{id}`, `/{user}/followers` |
| **Portfolio** | User portfolio | `/{user}/projects/{project}` |

### Public User API Endpoints

| Endpoint | Method | Auth | Description |
|----------|--------|------|-------------|
| `GET /api/v1/users/{username}` | GET | None | Public profile (filtered fields) |
| `GET /api/v1/users/{username}/repos` | GET | None | User's public repositories |
| `GET /api/v1/users/{username}/followers` | GET | None | User's followers |
| `GET /api/v1/users/{username}/following` | GET | None | Users they follow |

### Public vs Private Profile Fields

| Field | Public | Private (self only) |
|-------|--------|---------------------|
| `username` | ✓ | ✓ |
| `display_name` | ✓ | ✓ |
| `bio` | ✓ | ✓ |
| `avatar_url` | ✓ | ✓ |
| `website` | ✓ | ✓ |
| `location` | ✓ (if enabled) | ✓ |
| `created_at` | ✓ | ✓ |
| `email` | ✗ | ✓ |
| `email_verified` | ✗ | ✓ |
| `2fa_enabled` | ✗ | ✓ |
| `last_login` | ✗ | ✓ |

### Username Validation (NON-NEGOTIABLE)

```go
// Username rules:
// - 2-39 characters
// - Lowercase alphanumeric and hyphens only
// - Must start and end with alphanumeric
// - No consecutive hyphens
// - Not in reserved names list

var usernameRegex = regexp.MustCompile(`^[a-z0-9]([a-z0-9-]*[a-z0-9])?$`)

func ValidateUsername(username string) error {
    if len(username) < 2 || len(username) > 39 {
        return errors.New("username must be 2-39 characters")
    }
    if !usernameRegex.MatchString(username) {
        return errors.New("username must be lowercase alphanumeric with hyphens")
    }
    if strings.Contains(username, "--") {
        return errors.New("username cannot contain consecutive hyphens")
    }
    if isReservedName(username) {
        return errors.New("username is reserved")
    }
    return nil
}
```

### Reserved Names

See PART 16 (Web Frontend) for the complete reserved names list. Users and orgs share the same namespace and cannot register reserved names.

---



# PART 34: ORGANIZATIONS (OPTIONAL - NON-NEGOTIABLE WHEN IMPLEMENTED)

**Requires PART 33: MULTI-USER to be implemented first.**

## When Organizations Are Needed vs Not Needed

**Key Question: Do users need to collaborate as teams/groups with shared resources?**

### Organization Decision Matrix

| Scenario | Orgs Needed? | Why |
|----------|--------------|-----|
| Teams share repositories/projects | ✅ YES | GitHub, GitLab model - org owns repos |
| Company departments with shared resources | ✅ YES | Marketing team, Engineering team |
| Agencies managing client accounts | ✅ YES | Agency creates org per client |
| Multi-tenant SaaS with team billing | ✅ YES | Billing at org level, not user |
| Personal note-taking app | ❌ NO | Individual use, no sharing |
| Simple blog platform | ❌ NO | Authors work independently |
| Dating/social matching | ❌ NO | Individual profiles, not teams |
| Single-user self-hosted apps | ❌ NO | One user, no collaboration |

### Project Examples: Organizations vs No Organizations

**Projects that DO need organizations:**

| Project Type | Example Names | Org Use Case |
|--------------|---------------|--------------|
| **Git Hosting** | GitHub, GitLab, Gitea, Forgejo | Orgs own repositories, teams have access |
| **Project Management** | Jira, Linear, Plane | Teams collaborate on projects |
| **Document Collaboration** | Notion, Confluence, Outline | Teams share docs/wikis |
| **Cloud Storage** | Nextcloud, Seafile | Shared folders for teams |
| **Communication** | Slack, Mattermost, Discord | Workspaces/servers for groups |
| **Design Tools** | Figma, Penpot | Teams share design files |
| **CI/CD Platforms** | Jenkins, Drone, Woodpecker | Orgs have pipelines and secrets |
| **Container Registry** | Harbor, Docker Hub | Orgs own image repositories |
| **Monitoring/Observability** | Grafana, Sentry | Teams share dashboards/projects |
| **API Management** | Kong, Tyk | Orgs manage API keys and quotas |

**Projects that do NOT need organizations:**

| Project Type | Example Names | Why No Orgs |
|--------------|---------------|-------------|
| **Personal Tools** | Standard Notes, Joplin | Individual note-taking |
| **Single-User Hosting** | Personal blogs, portfolios | One author per site |
| **Consumer Social** | Instagram, TikTok | Individual accounts (followers ≠ org) |
| **Dating Apps** | Tinder, Bumble | Individual matching |
| **Media Consumption** | Netflix, Spotify | Personal accounts (family ≠ org) |
| **Personal Finance** | Budget trackers | Individual budgets |
| **Fitness/Health** | Strava, MyFitnessPal | Personal tracking |
| **Gaming** | Most games | Players, not organizations |
| **Simple APIs** | Jokes, Quotes, Weather | No user accounts at all |
| **Pastebin** | Hastebin, PrivateBin | Anonymous/individual pastes |

### Organization Decision Tree

```
Does your app have multiple users?
│
├─► NO → Skip organizations (and skip multi-user too)
│
└─► YES
    │
    ├─► Do users need to share resources (repos, projects, files)?
    │   └─► YES → Organizations beneficial
    │
    ├─► Do users work in teams with shared permissions?
    │   └─► YES → Organizations beneficial
    │
    ├─► Is billing/subscription at team level, not individual?
    │   └─► YES → Organizations beneficial
    │
    └─► Are users independent with no collaboration needs?
        └─► Skip organizations - just user accounts
```

### Organization vs Just Groups/Teams

**When full Organizations are needed:**

| Feature | Simple Groups | Full Organizations |
|---------|---------------|-------------------|
| Shared ownership | ❌ User owns, shares access | ✅ Org owns resources |
| Billing entity | ❌ Per-user billing | ✅ Org-level billing |
| Transfer ownership | ❌ Complex | ✅ Add/remove members |
| Public profile | ❌ No org identity | ✅ /orgs/acme public page |
| Vanity URL | ❌ No | ✅ /acme-corp/project |
| Member roles | ❌ Simple share | ✅ Owner, Admin, Member |
| Audit trail | ❌ Per-user | ✅ Org-level audit |

### Quick Decision

| If your users... | Orgs? |
|-----------------|-------|
| Work alone, never share | ❌ No |
| Share occasionally (like Google Docs link) | ❌ No (just sharing) |
| Regularly collaborate as teams | ✅ Yes |
| Need team billing | ✅ Yes |
| Are companies/agencies with multiple staff | ✅ Yes |

---

## Organization Profile (NON-NEGOTIABLE)

### Org Profile Fields

| Field | Type | Required | Editable | Public | Description |
|-------|------|----------|----------|--------|-------------|
| `id` | Integer | Auto | No | No | Unique org ID |
| `slug` | String | Yes | No* | Yes | URL-safe identifier (3-32 chars) |
| `name` | String | Yes | Yes | Yes | Display name |
| `description` | String | No | Yes | Yes | Short description (max 500 chars) |
| `avatar_type` | Enum | Yes | Yes | Yes | `gravatar`, `upload`, `url` |
| `avatar_url` | String | No | Yes | Yes | Avatar URL |
| `website` | String | No | Yes | Yes | Organization website |
| `location` | String | No | Yes | Yes | Location |
| `visibility` | Enum | Yes | Yes | N/A | `public` (default), `private` |
| `owner_id` | Integer | Yes | Yes** | No | Owner user ID |
| `member_count` | Integer | Auto | No | Yes | Number of members |
| `created_at` | Timestamp | Auto | No | Yes | Creation date |

*Slug change requires confirmation and redirect setup.
**Ownership can be transferred to another member.

**Org Profile Example (API Response):**
```json
GET /api/v1/orgs/acme-corp
{
    "id": 42,
    "slug": "acme-corp",
    "name": "Acme Corporation",
    "description": "Building the future, one anvil at a time",
    "avatar": {
        "type": "upload",
        "urls": {
            "256": "/uploads/orgs/acme-corp_256.png",
            "128": "/uploads/orgs/acme-corp_128.png",
            "64": "/uploads/orgs/acme-corp_64.png",
            "32": "/uploads/orgs/acme-corp_32.png"
        }
    },
    "website": "https://acme.example.com",
    "location": "Phoenix, AZ",
    "visibility": "public",
    "member_count": 15,
    "created_at": "2024-06-01T08:00:00Z",
    "your_role": "admin"
}
```

### Org Member Roles

| Role | Permissions |
|------|-------------|
| **Owner** | Full control, can delete org, transfer ownership |
| **Admin** | Manage members, settings, tokens (cannot delete org) |
| **Member** | View org, access org resources |

### Org Settings

**Settings Categories:**

| Category | Route | Who Can Edit |
|----------|-------|--------------|
| **General** | `/orgs/{slug}/settings` | Owner, Admin |
| **Members** | `/orgs/{slug}/members` | Owner, Admin |
| **Roles** | `/orgs/{slug}/roles` | Owner, Admin |
| **Security** | `/orgs/{slug}/security` | Owner, Admin |
| **Email** | `/orgs/{slug}/email` | Owner, Admin |
| **Tokens** | `/orgs/{slug}/tokens` | Owner, Admin |
| **Billing** | `/orgs/{slug}/billing` | Owner only |
| **Danger Zone** | `/orgs/{slug}/settings#danger` | Owner only |

#### General Settings (`/orgs/{slug}/settings`)

| Setting | Type | Default | Description |
|---------|------|---------|-------------|
| `name` | String | Required | Organization display name |
| `description` | String | null | Short description |
| `website` | URL | null | Organization website |
| `location` | String | null | Location |
| `visibility` | Select | `public` | Public or private org |
| `default_member_role` | Select | `member` | Role for new members |
| `require_2fa` | Toggle | Off | Require 2FA for all members |

**General Settings Form Example:**
```
Organization Settings (/orgs/acme-corp/settings)
┌─────────────────────────────────────────────────────────────┐
│  Organization Profile                                       │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  Name                                                       │
│  [Acme Corporation                           ]             │
│                                                             │
│  URL Slug                                                   │
│  [acme-corp                                  ] 🔒           │
│  https://example.com/orgs/acme-corp                        │
│  (Contact support to change)                                │
│                                                             │
│  Description                                                │
│  [Building the future, one anvil at a time   ]             │
│  Characters: 42/500                                         │
│                                                             │
│  Website                                                    │
│  [https://acme.example.com                   ]             │
│                                                             │
│  Location                                                   │
│  [Phoenix, AZ                                ]             │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│  Visibility                                                 │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  ● Public                                                   │
│    Anyone can see this organization and its public         │
│    members.                                                 │
│                                                             │
│  ○ Private                                                  │
│    Only members can see this organization. It won't        │
│    appear in search or public listings.                    │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│  Member Settings                                            │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  Default role for new members                               │
│  [Member                                     ▼]            │
│                                                             │
│  [OFF] Require two-factor authentication                    │
│        All members must enable 2FA to access org resources. │
│                                                             │
│  [Save Changes]                                             │
└─────────────────────────────────────────────────────────────┘
```

#### Members Management (`/orgs/{slug}/members`)

**Members List Example:**
```
Organization Members (/orgs/acme-corp/members)
┌─────────────────────────────────────────────────────────────┐
│  Members (15)                              [+ Invite Member]│
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ 👤 johndoe          John Doe           Owner    ⋮  │   │
│  │ 👤 janedoe          Jane Doe           Admin    ⋮  │   │
│  │ 👤 bobsmith         Bob Smith          Member   ⋮  │   │
│  │ 👤 private_user     Private User       Member   ⋮  │   │
│  │    (Profile hidden - org visibility enabled)        │   │
│  │ ...                                                 │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  ⋮ Menu: Change role, Remove from org                      │
└─────────────────────────────────────────────────────────────┘
```

#### Danger Zone (`/orgs/{slug}/settings#danger`)

**Owner-only actions:**

| Action | Confirmation | Description |
|--------|--------------|-------------|
| Transfer ownership | Password + confirmation | Transfer to another admin |
| Delete organization | Password + type org name | Permanently delete |

**Danger Zone Form Example:**
```
Danger Zone (/orgs/acme-corp/settings#danger)
┌─────────────────────────────────────────────────────────────┐
│  ⚠️ Danger Zone                                              │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  Transfer Ownership                                         │
│  Transfer this organization to another admin. You will     │
│  become an admin after transfer.                           │
│                                                     [Transfer]│
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  Delete Organization                                        │
│  Once deleted, all data will be permanently removed.       │
│  This action cannot be undone.                             │
│                                                     [Delete] │
└─────────────────────────────────────────────────────────────┘
```

#### Organization Email Settings (`/orgs/{slug}/email`) (NON-NEGOTIABLE)

**Organizations can configure a separate email address for org-specific notifications.**

| Email Type | Purpose | Required | Examples |
|------------|---------|----------|----------|
| **Organization Email** | Org-specific notifications | NO (defaults to owner's email) | Member joined/left, role changes, security alerts for org, billing notices |

**Rules:**
- Organization email is optional (defaults to owner's account email)
- Organization email must be verified before use
- Only Owner and Admins can change organization email
- Email changes logged to org audit log
- **All email features require working SMTP** - if SMTP unavailable, no emails sent

**Organization Email Settings Form:**
```
Organization Email Settings (/orgs/acme-corp/email)
┌─────────────────────────────────────────────────────────────┐
│  Email Settings                                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Organization Email:                                        │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ org-admin@acme.example.com            ✓ Verified    │    │
│  └─────────────────────────────────────────────────────┘    │
│  [Change] [Remove]                                          │
│  Used for: member changes, security alerts, billing        │
│  [ ] Use owner's email for all notifications                │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│  Notification Preferences                                   │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  Security (cannot be disabled):                             │
│  [✓] Security alerts (suspicious activity, settings changes)│
│                                                             │
│  Members:                                                   │
│  [✓] Member joined organization                             │
│  [✓] Member left organization                               │
│  [✓] Member role changed                                    │
│                                                             │
│  Administrative:                                            │
│  [✓] API token created/revoked                              │
│  [ ] Weekly activity summary                                │
│                                                             │
│  Billing (if applicable):                                   │
│  [✓] Payment received                                       │
│  [✓] Payment failed                                         │
│  [✓] Subscription changes                                   │
│                                                             │
│  [Save Preferences]                                         │
└─────────────────────────────────────────────────────────────┘
```

**Scoped Organization Notification Categories:**

| Category | Default | Description |
|----------|---------|-------------|
| **Security Alerts** | ON (locked) | Cannot disable - suspicious activity, security setting changes |
| **Member Joined** | ON | New member added to organization |
| **Member Left** | ON | Member removed or left organization |
| **Role Changes** | ON | Member role upgraded/downgraded |
| **API Token Activity** | ON | Token created or revoked |
| **Activity Summary** | OFF | Weekly digest of org activity |
| **Billing** | ON | Payment and subscription notifications |

**SMTP Requirement:**
- All email notifications require working SMTP configuration
- If SMTP unavailable, notifications shown in org dashboard only (no email)
- See PART 18: EMAIL & NOTIFICATIONS for SMTP configuration

### Org Settings API

**Database Storage:**

| Setting Category | Storage Location |
|------------------|------------------|
| **General** (name, slug, description, website, location, visibility) | `orgs` table |
| **Members** (default_role, require_2fa, allow_invites) | `org_preferences` table |
| **Visibility** (show_members, show_activity) | `org_preferences` table |
| **Notifications** (notify_new_member, notify_member_leave) | `org_preferences` table |

**Preferences are created on first access (lazy initialization):**
```go
func GetOrCreateOrgPreferences(orgID int) (*OrgPreferences, error) {
    prefs := &OrgPreferences{}
    err := db.Where("org_id = ?", orgID).First(prefs).Error
    if err == gorm.ErrRecordNotFound {
        prefs = &OrgPreferences{OrgID: orgID}  // Uses DB defaults
        db.Create(prefs)
    }
    return prefs, nil
}
```

**Get Org Settings:**
```json
GET /api/v1/orgs/acme-corp/settings
{
    "general": {
        "name": "Acme Corporation",
        "slug": "acme-corp",
        "description": "Building the future, one anvil at a time",
        "website": "https://acme.example.com",
        "location": "Phoenix, AZ",
        "visibility": "public"
    },
    "members": {
        "default_role": "member",
        "require_2fa": false,
        "member_count": 15
    },
    "your_permissions": {
        "can_edit_settings": true,
        "can_manage_members": true,
        "can_manage_billing": false,
        "can_delete_org": false
    }
}
```

## Org-Scoped User Visibility (NON-NEGOTIABLE)

**Users with private profiles can choose to show basic info within organizations they belong to.**

### How It Works

| User Setting | Org Context | Public Context |
|--------------|-------------|----------------|
| `visibility: public` | Full profile visible | Full profile visible |
| `visibility: private`, `org_visibility: true` | Basic info visible | 404 Not Found |
| `visibility: private`, `org_visibility: false` | Username only | 404 Not Found |

### What "Basic Info" Means

When a private user has `org_visibility: true`, org members can see:

| Field | Visible in Org | Visible Publicly |
|-------|----------------|------------------|
| `username` | ✓ Yes | ✗ No |
| `display_name` | ✓ Yes | ✗ No |
| `avatar` | ✓ Yes | ✗ No |
| `bio` | ✗ No | ✗ No |
| `location` | ✗ No | ✗ No |
| `website` | ✗ No | ✗ No |
| `email` | ✗ No | ✗ No |
| `activity` | ✗ No | ✗ No |

### API Responses

**Private user with org_visibility=true, viewed by org member:**
```json
GET /api/v1/orgs/acme-corp/members/private_user
{
    "username": "private_user",
    "display_name": "Private User",
    "avatar": {
        "64": "https://www.gravatar.com/avatar/xyz?s=64&d=identicon"
    },
    "role": "member",
    "joined_at": "2024-08-01T10:00:00Z",
    "profile_visibility": "org_only"  // Indicates limited visibility
}
```

**Private user with org_visibility=true, viewed publicly:**
```json
GET /api/v1/public/users/private_user
{
    "error": "not_found",
    "message": "User not found"
}
// Returns 404, not 403 (don't leak existence)
```

**Private user with org_visibility=false, viewed by org member:**
```json
GET /api/v1/orgs/acme-corp/members/very_private_user
{
    "username": "very_private_user",
    "role": "member",
    "joined_at": "2024-08-01T10:00:00Z",
    "profile_visibility": "hidden"  // Indicates minimal visibility
}
// Only username and role shown - no avatar, no display name
```

### Database Schema Update

```sql
-- Add org_visibility to users table
ALTER TABLE users ADD COLUMN org_visibility INTEGER NOT NULL DEFAULT 1;
-- 1 = show basic info in orgs, 0 = username only

-- Index for efficient org member queries
CREATE INDEX IF NOT EXISTS idx_users_org_visibility ON users(visibility, org_visibility);
```

### Implementation Logic

```go
// Get user info for org context
func GetOrgMemberProfile(orgID, targetUserID, requestingUserID int) (*MemberProfile, error) {
    // Verify requester is in the org
    if !IsOrgMember(orgID, requestingUserID) {
        return nil, ErrForbidden
    }

    // Verify target is in the org
    member := GetOrgMember(orgID, targetUserID)
    if member == nil {
        return nil, ErrNotFound
    }

    user := GetUser(targetUserID)

    // Build response based on visibility settings
    profile := &MemberProfile{
        Username:  user.Username,
        Role:      member.Role,
        JoinedAt:  member.CreatedAt,
    }

    // If public or org_visibility enabled, include basic info
    if user.Visibility == "public" || user.OrgVisibility {
        profile.DisplayName = user.DisplayName
        profile.Avatar = GetAvatarURLs(user)
        profile.ProfileVisibility = "org_only"
    } else {
        profile.ProfileVisibility = "hidden"
    }

    return profile, nil
}
```

### UI Indicators

**In org member lists, show visibility status:**

```
┌─────────────────────────────────────────────────────────────┐
│ 👤 johndoe          John Doe           Owner              │
│ 👤 janedoe          Jane Doe           Admin              │
│ 👤 private_user     Private User       Member   🔒        │
│                     (Profile visible to org only)          │
│ 👤 very_private     -                  Member   🔒🔒      │
│                     (Minimal info - username only)         │
└─────────────────────────────────────────────────────────────┘

🔒 = Private profile, basic info visible in org
🔒🔒 = Private profile, username only
```

## Public Org Profiles & Vanity URLs (OPTIONAL)

**For apps with public organization profiles, support vanity URLs at root level.**

This is OPTIONAL and only applies when org profiles should be publicly accessible (code hosting, team pages, company profiles, etc.).

### Vanity URL Routing

| URL Pattern | Maps To | API Endpoint |
|-------------|---------|--------------|
| `/{orgslug}` | Org public profile | `GET /api/v1/orgs/{slug}` |
| `/{orgslug}/{resource}` | Org's resource | `GET /api/v1/orgs/{slug}/{resource}` |
| `/{orgslug}/{resource}/{item}` | Specific item | `GET /api/v1/orgs/{slug}/{resource}/{item}` |

**Examples by App Type:**

| App Type | `/{orgslug}` Shows | Sub-routes |
|----------|---------------------|------------|
| **GitHub clone** | Org profile + repos | `/{org}/{repo}`, `/{org}/teams` |
| **GitLab clone** | Group page | `/{org}/{project}`, `/{org}/-/members` |
| **Slack clone** | Workspace info | `/{org}/channels`, `/{org}/members` |
| **Company directory** | Company page | `/{org}/about`, `/{org}/jobs` |

### Public Org API Endpoints

| Endpoint | Method | Auth | Description |
|----------|--------|------|-------------|
| `GET /api/v1/orgs/{slug}` | GET | None* | Public org profile |
| `GET /api/v1/orgs/{slug}/repos` | GET | None* | Org's public repositories |
| `GET /api/v1/orgs/{slug}/members` | GET | None* | Public member list |
| `GET /api/v1/orgs/{slug}/teams` | GET | Member | Team list (members only) |

*Public orgs only. Private orgs require membership.

### Public vs Private Org Fields

| Field | Public Org | Private Org (members only) |
|-------|------------|---------------------------|
| `slug` | ✓ | ✓ |
| `name` | ✓ | ✓ |
| `description` | ✓ | ✓ |
| `avatar_url` | ✓ | ✓ |
| `website` | ✓ | ✓ |
| `location` | ✓ | ✓ |
| `created_at` | ✓ | ✓ |
| `member_count` | ✓ (if enabled) | ✓ |
| `members` | Public members only | All members |
| `teams` | ✗ | ✓ |
| `settings` | ✗ | Owner/admin only |

### Org Slug Validation (NON-NEGOTIABLE)

```go
// Org slug rules (same as username):
// - 2-39 characters
// - Lowercase alphanumeric and hyphens only
// - Must start and end with alphanumeric
// - No consecutive hyphens
// - Not in reserved names list
// - Not already taken by a user or org

var slugRegex = regexp.MustCompile(`^[a-z0-9]([a-z0-9-]*[a-z0-9])?$`)

func ValidateOrgSlug(slug string) error {
    if len(slug) < 2 || len(slug) > 39 {
        return errors.New("slug must be 2-39 characters")
    }
    if !slugRegex.MatchString(slug) {
        return errors.New("slug must be lowercase alphanumeric with hyphens")
    }
    if strings.Contains(slug, "--") {
        return errors.New("slug cannot contain consecutive hyphens")
    }
    if isReservedName(slug) {
        return errors.New("slug is reserved")
    }
    // Check namespace collision with users
    if userExists(slug) {
        return errors.New("slug already taken")
    }
    return nil
}
```

### Shared Namespace (NON-NEGOTIABLE)

**Users and orgs share the same namespace.** A username `acme` blocks org slug `acme` and vice versa.

| Slug | User Exists | Org Exists | Result |
|------|-------------|------------|--------|
| `acme` | No | No | Available |
| `acme` | Yes | No | `/{acme}` → User profile |
| `acme` | No | Yes | `/{acme}` → Org profile |
| `acme` | Yes | Yes | **IMPOSSIBLE** - blocked at creation |

### Reserved Names

See PART 16 (Web Frontend) for the complete reserved names list. Users and orgs share the same namespace and cannot register reserved names.

---


# PART 35: CUSTOM DOMAINS (OPTIONAL - NON-NEGOTIABLE WHEN IMPLEMENTED)

## Overview

**Custom domains is an OPTIONAL feature that allows users or organizations to use their own domains with the application.** Not all projects need this feature.

**IMPORTANT: Once a project implements custom domains, this entire PART becomes NON-NEGOTIABLE.** The implementation must follow all standards defined here exactly.

| Attribute | Description |
|-----------|-------------|
| Feature type | Optional, per-project |
| Scope | User-owned or Org-owned domains |
| SSL | Automatic via Let's Encrypt DNS-01 |
| Verification | TXT record ownership verification |

## When Custom Domains Are Needed vs Not Needed

**Key Question: Do users need to present YOUR service under THEIR brand/domain?**

### Custom Domains Decision Matrix

| Scenario | Custom Domains? | Why |
|----------|-----------------|-----|
| Users publish public content | ✅ YES | They want `myblog.com` not `platform.com/username` |
| White-label SaaS for businesses | ✅ YES | Customers need `app.theircompany.com` |
| Link-in-bio/landing pages | ✅ YES | Users share their domain, not yours |
| E-commerce/storefronts | ✅ YES | Merchants want branded stores |
| Internal API service | ❌ NO | No public-facing user content |
| Simple data APIs | ❌ NO | API is your service, not theirs |
| Personal self-hosted apps | ❌ NO | Single tenant, admin sets domain |
| Anonymous/ephemeral content | ❌ NO | No identity to brand |

### Project Examples: Custom Domains vs No Custom Domains

**Projects that DO need custom domains:**

| Project Type | Example Names | Custom Domain Use Case |
|--------------|---------------|------------------------|
| **Blogging Platforms** | Ghost, Wordpress.com, Medium | `myblog.com` for each author |
| **Link-in-Bio** | Linktree, Bento, Carrd | `links.myname.com` |
| **E-commerce** | Shopify, WooCommerce, Saleor | `store.mybrand.com` |
| **Website Builders** | Squarespace, Wix, Webflow | `mysite.com` for each customer |
| **Email Marketing** | Mailchimp, Buttondown | `mail.mybrand.com` |
| **Help Desk/Docs** | Zendesk, GitBook, ReadMe | `docs.company.com` |
| **URL Shorteners** | Bitly, Short.io, YOURLS | `short.mybrand.com` |
| **Status Pages** | Statuspage, Instatus | `status.company.com` |
| **Landing Pages** | Leadpages, Unbounce | `campaign.mybrand.com` |
| **Scheduling** | Calendly, Cal.com | `book.consultant.com` |

**Projects that do NOT need custom domains:**

| Project Type | Example Names | Why No Custom Domains |
|--------------|---------------|----------------------|
| **Data APIs** | Weather, GeoIP, Jokes, Quotes | Users consume API, don't rebrand it |
| **Dev Tools (APIs)** | Stripe, Twilio, SendGrid | API is under your brand |
| **Git Hosting** | GitHub, GitLab, Gitea | Repos live on platform (subdomain sufficient) |
| **Chat/Communication** | Slack, Discord, Mattermost | Workspace is internal, not public |
| **Personal Notes** | Standard Notes, Joplin | Private content, not published |
| **Password Managers** | Bitwarden, Vaultwarden | Private vaults, no public presence |
| **Media Libraries** | Jellyfin, Plex, Navidrome | Personal media, not shared publicly |
| **Monitoring/Internal** | Grafana, Prometheus | Internal dashboards |
| **Pastebin (anonymous)** | PrivateBin, Hastebin | Anonymous pastes, no branding |
| **File Sync** | Syncthing, Seafile | Private sync, not public sharing |

### Custom Domains Decision Tree

```
Does your app serve public-facing content for users?
│
├─► NO (internal tool, private data, API-only)
│   └─► Skip custom domains
│
└─► YES (blogs, stores, public pages)
    │
    ├─► Do users want to present content under THEIR brand?
    │   └─► YES → Custom domains beneficial
    │
    ├─► Would "yoursite.yourplatform.com" hurt their brand?
    │   └─► YES → Custom domains beneficial
    │
    ├─► Do users share links publicly that represent them?
    │   └─► YES → Custom domains beneficial
    │
    └─► Is subdomain sufficient (user.platform.com)?
        └─► For many projects, subdomain is enough (simpler)
```

### Custom Domains vs Subdomains

**When full custom domains are worth the complexity:**

| Feature | Subdomain (user.platform.com) | Custom Domain (user.com) |
|---------|------------------------------|-------------------------|
| Setup complexity | ✅ Zero config | ❌ DNS + verification |
| SSL | ✅ Wildcard cert | ❌ Per-domain certs |
| User branding | ⚠️ Platform in URL | ✅ Fully branded |
| SEO | ⚠️ Authority split | ✅ User controls SEO |
| Portability | ❌ Locked to platform | ✅ User owns domain |
| Enterprise demand | ⚠️ Some care | ✅ Often required |

**Start with subdomains, add custom domains if users request it.**

### Quick Decision

| If your users... | Custom Domains? |
|-----------------|-----------------|
| Publish content publicly under their name | ✅ Yes |
| Need white-label for their clients | ✅ Yes |
| Share links that represent their brand | ✅ Yes |
| Run businesses through your platform | ✅ Yes |
| Use your platform internally/privately | ❌ No |
| Just consume your API | ❌ No |
| Are fine with `user.yourplatform.com` | ❌ Maybe (subdomain first) |

### Use Cases (When Implemented)

- **Blog platform**: `myblog.example.com` → user's blog
- **API service**: `api.acme-corp.com` → org's API endpoint
- **SaaS**: `app.customer.com` → customer's branded instance
- **Linktree**: `links.myname.com` → user's link page
- **E-commerce**: `shop.mybrand.com` → merchant's storefront
- **Status page**: `status.company.com` → company's status page

## Feature Configuration

**Enable custom domains in `server.yml`:**

```yaml
server:
  features:
    custom_domains:
      # Enable custom domain support
      enabled: false

      # Limit per user (0 = unlimited)
      max_domains_per_user: 5

      # Limit per org (0 = unlimited)
      max_domains_per_org: 20

      # Require SSL for all custom domains
      require_ssl: true

      # Allow apex domains (example.com)
      allow_apex: true

      # Allow subdomains (sub.example.com)
      allow_subdomain: true

      # Allow wildcard domains (*.example.com)
      allow_wildcard: false

      # Verification token TTL (24 hours)
      verification_ttl: 86400

      # Renew SSL certs N days before expiry
      ssl_renewal_days: 7

      # Reserved domains that cannot be used
      reserved:
        - "localhost"
        - "*.local"
        - "*.test"
        - "*.example"
        - "*.invalid"

      # Blocked patterns (regex)
      # Government/military/education TLDs
      blocked_patterns:
        - ".*\\.(gov|mil|edu)$"
```

**Environment variable override:**

```bash
CUSTOM_DOMAINS_ENABLED=true
CUSTOM_DOMAINS_MAX_PER_USER=5
CUSTOM_DOMAINS_MAX_PER_ORG=20
```

## Database Schema

**Tables in users.db:**

```sql
-- ----------------------------------------------------------------------------
-- Custom Domains
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS custom_domains (
    id                  INTEGER PRIMARY KEY AUTOINCREMENT,

    -- Ownership
    owner_type          TEXT NOT NULL,                      -- user, org
    owner_id            INTEGER NOT NULL,                   -- FK to users or orgs

    -- Domain info
    domain              TEXT NOT NULL UNIQUE,               -- The custom domain
    is_apex             INTEGER NOT NULL DEFAULT 0,         -- Is apex domain (no subdomain)
    is_wildcard         INTEGER NOT NULL DEFAULT 0,         -- Is wildcard (*.example.com)

    -- Verification (domain must resolve to server IP)
    verification_status TEXT NOT NULL DEFAULT 'pending',    -- pending, verified, failed
    verified_at         INTEGER,                            -- When domain was verified
    verified_ip         TEXT,                               -- IP that domain resolved to
    last_check_at       INTEGER,                            -- Last verification check
    check_count         INTEGER NOT NULL DEFAULT 0,         -- Number of verification attempts

    -- SSL Configuration
    ssl_enabled         INTEGER NOT NULL DEFAULT 0,
    ssl_status          TEXT NOT NULL DEFAULT 'none',       -- none, pending, active, expired, error
    ssl_challenge       TEXT,                               -- http-01, tls-alpn-01, dns-01
    ssl_provider        TEXT,                               -- DNS provider (only for dns-01)
    ssl_credentials     TEXT,                               -- Encrypted provider credentials (only for dns-01)
    ssl_cert_pem        TEXT,                               -- Encrypted certificate (PEM)
    ssl_key_pem         TEXT,                               -- Encrypted private key (PEM)
    ssl_issued_at       INTEGER,
    ssl_expires_at      INTEGER,
    ssl_last_error      TEXT,                               -- Last SSL error message

    -- Status
    status              TEXT NOT NULL DEFAULT 'pending',    -- pending, active, suspended, error
    suspended_reason    TEXT,                               -- Why domain was suspended

    -- Timestamps
    created_at          INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    updated_at          INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

CREATE UNIQUE INDEX IF NOT EXISTS idx_custom_domains_domain ON custom_domains(domain);
CREATE INDEX IF NOT EXISTS idx_custom_domains_owner ON custom_domains(owner_type, owner_id);
CREATE INDEX IF NOT EXISTS idx_custom_domains_status ON custom_domains(status);
CREATE INDEX IF NOT EXISTS idx_custom_domains_ssl_expires ON custom_domains(ssl_expires_at);

-- ----------------------------------------------------------------------------
-- Custom Domain Audit Log
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS custom_domain_audit (
    id              INTEGER PRIMARY KEY AUTOINCREMENT,
    domain_id       INTEGER NOT NULL REFERENCES custom_domains(id) ON DELETE CASCADE,
    action          TEXT NOT NULL,                          -- created, verified, ssl_issued, suspended, deleted
    actor_type      TEXT NOT NULL,                          -- user, org, admin, system
    actor_id        INTEGER,
    details         TEXT,                                   -- JSON details
    created_at      INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

CREATE INDEX IF NOT EXISTS idx_domain_audit_domain ON custom_domain_audit(domain_id);
```

## Domain Resolution Flow

**How incoming requests are routed to custom domains:**

```
Incoming Request: https://api.customer.com/path
   │
   ├─► Extract Host header: api.customer.com
   │
   ├─► Check custom_domains table for matching domain
   │   │
   │   ├─► Not found → 404 or redirect to main domain
   │   │
   │   ├─► Found but status != 'active' → Show domain status page
   │   │
   │   └─► Found and active → Continue
   │
   ├─► Check SSL certificate valid
   │   │
   │   ├─► Expired/missing → Attempt renewal or show error
   │   │
   │   └─► Valid → Serve with custom domain's cert
   │
   └─► Route request to owner's resources
       │
       ├─► User-owned: Route to user's content/namespace
       │
       └─► Org-owned: Route to org's resources/namespace
```

**Go Implementation:**

```go
// DomainResolver handles custom domain routing
type DomainResolver struct {
    db       *sql.DB
    // Cache domain lookups
    cache    *cache.Cache
    cacheTTL time.Duration
}

// Resolve looks up a custom domain and returns routing info
func (r *DomainResolver) Resolve(host string) (*CustomDomain, error) {
    // Check cache first
    if cached, ok := r.cache.Get(host); ok {
        return cached.(*CustomDomain), nil
    }

    // Query database
    var domain CustomDomain
    err := r.db.QueryRow(`
        SELECT id, owner_type, owner_id, domain, status, ssl_enabled,
               ssl_cert_pem, ssl_key_pem, ssl_expires_at
        FROM custom_domains
        WHERE domain = ? AND status = 'active'
    `, host).Scan(
        &domain.ID, &domain.OwnerType, &domain.OwnerID, &domain.Domain,
        &domain.Status, &domain.SSLEnabled, &domain.SSLCertPEM,
        &domain.SSLKeyPEM, &domain.SSLExpiresAt,
    )

    if err == sql.ErrNoRows {
        return nil, ErrDomainNotFound
    }
    if err != nil {
        return nil, err
    }

    // Cache result
    r.cache.Set(host, &domain, r.cacheTTL)

    return &domain, nil
}

// Middleware for custom domain handling
func CustomDomainMiddleware(resolver *DomainResolver) func(http.Handler) http.Handler {
    return func(next http.Handler) http.Handler {
        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
            host := r.Host

            // Skip if it's the main application domain
            if host == config.MainDomain {
                next.ServeHTTP(w, r)
                return
            }

            // Resolve custom domain
            domain, err := resolver.Resolve(host)
            if err == ErrDomainNotFound {
                http.Error(w, "Domain not found", http.StatusNotFound)
                return
            }
            if err != nil {
                http.Error(w, "Internal error", http.StatusInternalServerError)
                return
            }

            // Add domain context
            ctx := context.WithValue(r.Context(), CustomDomainKey, domain)
            next.ServeHTTP(w, r.WithContext(ctx))
        })
    }
}
```

## Web Routes

### User Domain Management (`/users/domains/`)

| Path | Description |
|------|-------------|
| `/users/domains` | List user's custom domains |
| `/users/domains/add` | Add new custom domain form |
| `/users/domains/{domain}` | Domain details and management |
| `/users/domains/{domain}/dns` | DNS configuration instructions |
| `/users/domains/{domain}/ssl` | SSL configuration |
| `/users/domains/{domain}/verify` | Trigger verification |
| `/users/domains/{domain}/delete` | Delete confirmation |

### Org Domain Management (`/orgs/{slug}/domains/`)

| Path | Description |
|------|-------------|
| `/orgs/{slug}/domains` | List org's custom domains |
| `/orgs/{slug}/domains/add` | Add new custom domain form |
| `/orgs/{slug}/domains/{domain}` | Domain details and management |
| `/orgs/{slug}/domains/{domain}/dns` | DNS configuration instructions |
| `/orgs/{slug}/domains/{domain}/ssl` | SSL configuration |
| `/orgs/{slug}/domains/{domain}/verify` | Trigger verification |
| `/orgs/{slug}/domains/{domain}/delete` | Delete confirmation |

### Admin Domain Management (`/admin/server/domains/`)

| Path | Description |
|------|-------------|
| `/admin/server/domains` | List all custom domains |
| `/admin/server/domains/{domain}` | View/manage any domain |
| `/admin/server/domains/{domain}/suspend` | Suspend domain |
| `/admin/server/domains/{domain}/unsuspend` | Unsuspend domain |
| `/admin/server/domains/{domain}/delete` | Force delete domain |

## API Routes

### User Domain API (`/api/v1/users/domains/`)

| Route | Method | Description |
|-------|--------|-------------|
| `/api/v1/users/domains` | GET | List user's domains |
| `/api/v1/users/domains` | POST | Add new domain |
| `/api/v1/users/domains/{domain}` | GET | Get domain details |
| `/api/v1/users/domains/{domain}` | DELETE | Remove domain |
| `/api/v1/users/domains/{domain}/verify` | POST | Trigger verification |
| `/api/v1/users/domains/{domain}/dns` | GET | Get DNS records to configure |
| `/api/v1/users/domains/{domain}/ssl` | GET | Get SSL status |
| `/api/v1/users/domains/{domain}/ssl` | POST | Configure SSL (provider + credentials) |
| `/api/v1/users/domains/{domain}/ssl/renew` | POST | Force SSL renewal |

### Org Domain API (`/api/v1/orgs/{slug}/domains/`)

Same routes as user, scoped to organization.

### Admin Domain API (`/api/v1/admin/server/domains/`)

| Route | Method | Description |
|-------|--------|-------------|
| `/api/v1/admin/server/domains` | GET | List all domains (paginated) |
| `/api/v1/admin/server/domains/{domain}` | GET | Get any domain details |
| `/api/v1/admin/server/domains/{domain}` | DELETE | Force delete any domain |
| `/api/v1/admin/server/domains/{domain}/suspend` | POST | Suspend domain |
| `/api/v1/admin/server/domains/{domain}/unsuspend` | POST | Unsuspend domain |
| `/api/v1/admin/server/domains/{domain}/ssl/renew` | POST | Force SSL renewal |

## Verification Flow

**Verification is simple: the custom domain must resolve to the server's public IP or FQDN.**

### Step 1: User Adds Domain

```
POST /api/v1/users/domains
{
  "domain": "api.mycompany.com"
}

Response:
{
  "ok": true,
  "data": {
    "id": 123,
    "domain": "api.mycompany.com",
    "status": "pending",
    "verification_status": "pending",
    "dns_instructions": {
      "target": "custom.yourapp.com",
      "target_ips": ["203.0.113.50", "2001:db8::1"],
      "instructions": "Add a CNAME record pointing to custom.yourapp.com, or A/AAAA records pointing to the IPs above."
    }
  }
}
```

### Step 2: User Configures DNS

User adds ONE of these at their DNS provider:

```
; Option 1: CNAME (recommended for subdomains)
api.mycompany.com.          300  IN  CNAME  custom.yourapp.com.

; Option 2: A/AAAA records (required for apex domains)
mycompany.com.              300  IN  A      203.0.113.50
mycompany.com.              300  IN  AAAA   2001:db8::1
```

### Step 3: User Triggers Verification

```
POST /api/v1/users/domains/api.mycompany.com/verify

Response (success):
{
  "ok": true,
  "data": {
    "domain": "api.mycompany.com",
    "verification_status": "verified",
    "verified_at": "2025-01-15T10:30:00Z",
    "status": "active",
    "resolved_to": "203.0.113.50"
  }
}

Response (failed - wrong IP):
{
  "ok": false,
  "error": "DNS_MISMATCH",
  "message": "Domain does not resolve to this server. DNS propagation can take up to 48 hours."
}
```

### Verification Logic

```go
func (s *DomainService) Verify(domainID int64) (*VerifyResult, error) {
    domain, err := s.GetByID(domainID)
    if err != nil {
        return nil, err
    }

    // Get server's public IPs
    serverIPs := s.getServerPublicIPs()

    // Resolve the custom domain
    ips, err := net.LookupIP(domain.Domain)
    if err != nil {
        return &VerifyResult{
            OK:      false,
            Error:   "DNS_LOOKUP_FAILED",
            Message: "DNS lookup failed",
        }, nil
    }

    // Check if any resolved IP matches server IP
    matched := false
    var resolvedIPs []string
    for _, ip := range ips {
        resolvedIPs = append(resolvedIPs, ip.String())
        for _, serverIP := range serverIPs {
            if ip.Equal(serverIP) {
                matched = true
                break
            }
        }
    }

    if !matched {
        return &VerifyResult{
            OK:      false,
            Error:   "DNS_MISMATCH",
            Message: fmt.Sprintf("Domain resolves to %v, expected %v", resolvedIPs, serverIPs),
        }, nil
    }

    // Mark as verified
    domain.VerificationStatus = "verified"
    domain.VerifiedAt = time.Now().Unix()
    domain.Status = "active"

    if err := s.Update(domain); err != nil {
        return nil, err
    }

    // Log audit event
    s.audit.Log(domain.ID, "verified", domain.OwnerType, domain.OwnerID, nil)

    return &VerifyResult{Success: true, ResolvedTo: resolvedIPs[0]}, nil
}

// getServerPublicIPs returns all public IPs the server is reachable on
// Uses cached external IP discovery (refreshed every 12 hours)
func (s *DomainService) getServerPublicIPs() []net.IP {
    var ips []net.IP

    // From DOMAIN env var / configured FQDN
    if fqdn := config.GetFQDN(); fqdn != "" {
        if resolved, err := net.LookupIP(fqdn); err == nil {
            ips = append(ips, resolved...)
        }
    }

    // From external IP discovery (works in containers)
    // This is cached and refreshed every 12 hours by scheduler
    if cached := s.cache.Get("server_public_ips"); cached != nil {
        ips = append(ips, cached.([]net.IP)...)
    }

    return ips
}

// discoverPublicIPs discovers our public IP addresses
// Called on startup and every 12 hours (hardcoded, sensible interval)
// Safe to expose in /healthz - same info available via `dig`
func discoverPublicIPs() ([]net.IP, error) {
    var ips []net.IP

    // IPv4: Always use external lookup (containers/NAT hide real IP)
    ipv4Services := []string{
        "https://api.ipify.org",
        "https://ifconfig.me/ip",
        "https://icanhazip.com",
        "https://checkip.amazonaws.com",
    }

    for _, url := range ipv4Services {
        if ip := fetchIP(url); ip != nil && ip.To4() != nil {
            ips = append(ips, ip)
            break
        }
    }

    // IPv6: Check local interfaces first for global addresses
    if globalIPv6 := getLocalGlobalIPv6(); globalIPv6 != nil {
        ips = append(ips, globalIPv6)
    }

    if len(ips) == 0 {
        return nil, errors.New("failed to discover public IP")
    }

    return ips, nil
}

// getLocalGlobalIPv6 returns the first global unicast IPv6 address from local interfaces
func getLocalGlobalIPv6() net.IP {
    ifaces, err := net.Interfaces()
    if err != nil {
        return nil
    }

    for _, iface := range ifaces {
        // Skip loopback and down interfaces
        if iface.Flags&net.FlagLoopback != 0 || iface.Flags&net.FlagUp == 0 {
            continue
        }

        addrs, err := iface.Addrs()
        if err != nil {
            continue
        }

        for _, addr := range addrs {
            var ip net.IP
            switch v := addr.(type) {
            case *net.IPNet:
                ip = v.IP
            case *net.IPAddr:
                ip = v.IP
            }

            // Must be IPv6 (not IPv4) and global unicast (not link-local, not ULA)
            if ip != nil && ip.To4() == nil && ip.IsGlobalUnicast() && !isULA(ip) {
                return ip
            }
        }
    }
    return nil
}

// isULA checks if IP is a Unique Local Address (fc00::/7)
func isULA(ip net.IP) bool {
    return len(ip) == net.IPv6len && (ip[0]&0xfe) == 0xfc
}

func fetchIP(url string) net.IP {
    client := &http.Client{Timeout: 5 * time.Second}
    resp, err := client.Get(url)
    if err != nil {
        return nil
    }
    defer resp.Body.Close()

    body, err := io.ReadAll(io.LimitReader(resp.Body, 64))
    if err != nil {
        return nil
    }

    return net.ParseIP(strings.TrimSpace(string(body)))
}
```

## SSL Challenge Types

**Three ACME challenge types are supported for custom domain SSL:**

| Challenge | Requirements | Best For |
|-----------|--------------|----------|
| **HTTP-01** | Port 80 accessible | Direct server access |
| **TLS-ALPN-01** | Port 443 accessible | Behind reverse proxy (recommended) |
| **DNS-01** | DNS API credentials | Wildcard certs, firewalled servers |

### Challenge Selection Logic

```go
func (s *DomainService) selectChallengeType(domain *CustomDomain) string {
    // If user explicitly configured DNS provider, use DNS-01
    if domain.SSLProvider != "" {
        return "dns-01"
    }

    // If domain is wildcard, must use DNS-01
    if domain.IsWildcard {
        return "dns-01"
    }

    // Try TLS-ALPN-01 first (works behind reverse proxy)
    // This is preferred because it uses port 443 which is usually available
    if s.canUseTLSALPN() {
        return "tls-alpn-01"
    }

    // Fall back to HTTP-01
    if s.canUseHTTP() {
        return "http-01"
    }

    // Must configure DNS provider
    return "dns-01"
}
```

## SSL Configuration Flow

### Automatic SSL (HTTP-01 / TLS-ALPN-01)

**For verified domains, SSL can be issued automatically without user configuration:**

Challenge options: `auto`, `http-01`, `tls-alpn-01`

```
POST /api/v1/users/domains/api.mycompany.com/ssl
{
  "challenge": "auto"
}

Response:
{
  "ok": true,
  "data": {
    "domain": "api.mycompany.com",
    "ssl_status": "active",
    "ssl_challenge": "tls-alpn-01",
    "ssl_issued_at": "2025-01-15T10:30:00Z",
    "ssl_expires_at": "2025-04-15T10:30:00Z"
  }
}
```

**TLS-ALPN-01 behind reverse proxy:**

The server handles the ACME TLS-ALPN-01 challenge on port 443. This works behind a reverse proxy as long as the proxy forwards TLS connections for the custom domain to the backend.

### DNS-01 (Manual Configuration)

**For wildcards or when HTTP/TLS challenges aren't available:**

```
POST /api/v1/users/domains/api.mycompany.com/ssl
{
  "challenge": "dns-01",
  "provider": "cloudflare",
  "credentials": {
    "api_token": "cf_xxx..."
  }
}
```

The system validates credentials, encrypts them, and stores for reuse.

### Certificate Issuance

```go
func (s *DomainService) issueCertificate(domain *CustomDomain) error {
    // Create ACME client
    acmeClient := acme.NewClient(acme.Config{
        Email:   s.config.LetsEncryptEmail,
        Staging: s.config.LetsEncryptStaging,
    })

    var cert, key []byte
    var err error

    switch domain.SSLChallenge {
    case "http-01":
        // HTTP-01: Serve challenge on /.well-known/acme-challenge/
        cert, key, err = acmeClient.ObtainCertificateHTTP(domain.Domain)

    case "tls-alpn-01":
        // TLS-ALPN-01: Handle ALPN challenge on port 443
        cert, key, err = acmeClient.ObtainCertificateTLSALPN(domain.Domain)

    case "dns-01":
        // DNS-01: Use configured DNS provider
        creds, err := s.decryptCredentials(domain.SSLCredentials)
        if err != nil {
            return s.setSSLError(domain, err)
        }
        dnsProvider, err := dns.NewProvider(domain.SSLProvider, creds)
        if err != nil {
            return s.setSSLError(domain, err)
        }
        cert, key, err = acmeClient.ObtainCertificateDNS(domain.Domain, dnsProvider)
    }

    if err != nil {
        return s.setSSLError(domain, err)
    }

    // Encrypt and store certificate
    domain.SSLCertPEM = s.encrypt(cert)
    domain.SSLKeyPEM = s.encrypt(key)
    domain.SSLIssuedAt = time.Now().Unix()
    domain.SSLExpiresAt = extractExpiry(cert)
    domain.SSLStatus = "active"
    domain.SSLEnabled = true

    // Clear cache to pick up new cert
    s.cache.Delete(domain.Domain)

    return s.Update(domain)
}
```

### Challenge Endpoints

**HTTP-01 Challenge Handler:**

```go
// Serves ACME HTTP-01 challenges for all custom domains
// Route: GET /.well-known/acme-challenge/{token}
func (s *Server) handleACMEChallenge(w http.ResponseWriter, r *http.Request) {
    token := chi.URLParam(r, "token")
    host := r.Host

    // Look up challenge response for this domain + token
    response, err := s.acmeStore.GetChallenge(host, token)
    if err != nil {
        http.NotFound(w, r)
        return
    }

    w.Header().Set("Content-Type", "text/plain")
    w.Write([]byte(response))
}
```

**TLS-ALPN-01 requires TLS config that handles the ACME-TLS/1 protocol.**

## Scheduled Tasks

**Add to scheduler configuration:**

**System task (hardcoded, not configurable):**
- `public_ip_refresh` - Runs on startup and every 12 hours
- IPv4: External lookup (containers/NAT hide real IP)
- IPv6: Check local interfaces for global unicast address

```yaml
server:
  scheduler:
    tasks:
      custom_domain_verification:
        enabled: true
        schedule: "*/15 * * * *"        # Every 15 minutes
        description: "Retry pending domain verifications"

      custom_domain_ssl_renewal:
        enabled: true
        schedule: "0 4 * * *"           # Daily at 4:00 AM
        description: "Renew expiring custom domain SSL certs"
        renew_before: 7d

      custom_domain_cleanup:
        enabled: true
        schedule: "0 5 * * *"           # Daily at 5:00 AM
        description: "Remove unverified domains after TTL"
```

**Public IP in /healthz:**

The discovered public IPs are safe to include in `/healthz` - same info anyone can get with `dig {fqdn}`.
- IPv4: From external lookup (needed for containers/NAT)
- IPv6: From local interface if global unicast address exists

```json
{
  "status": "healthy",
  "version": "1.0.0",
  "public_ips": {
    "ipv4": "203.0.113.50",
    "ipv6": "2001:db8::1",
    "last_checked": "2025-01-15T10:00:00Z"
  }
}
```

## Error Handling

**Uses standard error format (see PART 16). Domain-specific error codes:**

| Error Code | HTTP | Description |
|------------|------|-------------|
| `DOMAIN_EXISTS` | 409 | Domain already registered |
| `DOMAIN_RESERVED` | 400 | Domain is reserved/blocked |
| `DOMAIN_LIMIT` | 400 | Max domains limit reached |
| `DOMAIN_INVALID` | 400 | Invalid domain format |
| `DOMAIN_NOT_FOUND` | 404 | Domain not found |
| `DOMAIN_NOT_VERIFIED` | 400 | Domain not yet verified |
| `DOMAIN_SUSPENDED` | 403 | Domain is suspended |
| `DNS_LOOKUP_FAILED` | 400 | DNS lookup failed |
| `DNS_MISMATCH` | 400 | Domain does not resolve to server IP |
| `SSL_PROVIDER_INVALID` | 400 | Invalid DNS provider for SSL |
| `SSL_CREDENTIALS_INVALID` | 400 | DNS credentials validation failed |
| `SSL_CHALLENGE_FAILED` | 400 | ACME challenge failed |
| `SSL_ISSUANCE_FAILED` | 500 | Certificate issuance failed |

## Admin Controls

**Server admins can:**

| Action | Description |
|--------|-------------|
| View all domains | List all custom domains across users/orgs |
| Suspend domain | Disable a domain (shows suspension page) |
| Unsuspend domain | Re-enable a suspended domain |
| Force delete | Remove any domain immediately |
| Force SSL renewal | Trigger certificate renewal |
| View audit log | See all domain actions |

**Suspension reasons:**

| Reason | Description |
|--------|-------------|
| `abuse` | Domain used for abuse/spam |
| `tos_violation` | Terms of service violation |
| `billing` | Payment issue (if applicable) |
| `security` | Security concern |
| `admin_request` | Manual admin action |

## WebUI Components

### Domain List Page

```
┌─────────────────────────────────────────────────────────────────┐
│ Custom Domains                                    [+ Add Domain] │
├─────────────────────────────────────────────────────────────────┤
│ Domain                    │ Status   │ SSL      │ Actions       │
├───────────────────────────┼──────────┼──────────┼───────────────┤
│ api.mycompany.com        │ ✅ Active │ 🔒 Valid │ [Manage]      │
│ blog.example.org         │ ⏳ Pending│ ⚠️ None  │ [Verify][DNS] │
│ old.domain.com           │ ❌ Error  │ ❌ Error │ [Fix][Delete] │
└─────────────────────────────────────────────────────────────────┘
```

### DNS Configuration Page

```
┌─────────────────────────────────────────────────────────────────┐
│ DNS Configuration for api.mycompany.com                         │
├─────────────────────────────────────────────────────────────────┤
│ Add these records at your DNS provider:                         │
│                                                                 │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ Type: TXT                                                   │ │
│ │ Name: _verify.api.mycompany.com                            │ │
│ │ Value: verify_abc123def456                       [Copy]    │ │
│ │ Status: ✅ Verified                                         │ │
│ └─────────────────────────────────────────────────────────────┘ │
│                                                                 │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ Type: CNAME                                                 │ │
│ │ Name: api.mycompany.com                                    │ │
│ │ Value: custom.yourapp.com                        [Copy]    │ │
│ │ Status: ⏳ Pending                                          │ │
│ └─────────────────────────────────────────────────────────────┘ │
│                                                                 │
│ [Check DNS Records]                                             │
│                                                                 │
│ ℹ️ DNS changes can take up to 48 hours to propagate.            │
└─────────────────────────────────────────────────────────────────┘
```

### SSL Configuration Page

```
┌─────────────────────────────────────────────────────────────────┐
│ SSL Configuration for api.mycompany.com                         │
├─────────────────────────────────────────────────────────────────┤
│ SSL Status: 🔒 Active                                           │
│ Certificate: Let's Encrypt                                      │
│ Expires: 2025-04-15 (in 90 days)                               │
│                                                                 │
│ DNS Provider: Cloudflare                                        │
│ Credentials: ✅ Valid (last checked: 2 hours ago)               │
│                                                                 │
│ [Renew Now] [Change Provider]                                   │
└─────────────────────────────────────────────────────────────────┘

OR (if not configured):

┌─────────────────────────────────────────────────────────────────┐
│ SSL Configuration for api.mycompany.com                         │
├─────────────────────────────────────────────────────────────────┤
│ SSL Status: ⚠️ Not Configured                                   │
│                                                                 │
│ To enable SSL, we need access to your DNS provider to complete │
│ the ACME DNS-01 challenge.                                      │
│                                                                 │
│ DNS Provider: [Cloudflare          ▼]                           │
│                                                                 │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ API Token: [________________________________]               │ │
│ │                                                             │ │
│ │ ℹ️ Create a token with Zone:DNS:Edit permission             │ │
│ └─────────────────────────────────────────────────────────────┘ │
│                                                                 │
│ [Validate & Enable SSL]                                         │
│                                                                 │
│ 🔒 Credentials are encrypted and stored securely.               │
└─────────────────────────────────────────────────────────────────┘
```

## Implementation Checklist

When implementing custom domains for a project:

- [ ] Add feature flag to configuration
- [ ] Create database tables (custom_domains, custom_domain_records, custom_domain_audit)
- [ ] Implement domain resolver middleware
- [ ] Create user web routes (/users/domains/*)
- [ ] Create user API routes (/api/v1/users/domains/*)
- [ ] Create org web/API routes (if orgs supported)
- [ ] Create admin management routes
- [ ] Implement DNS verification
- [ ] Implement SSL issuance via ACME DNS-01
- [ ] Add scheduled tasks (verification retry, SSL renewal, cleanup)
- [ ] Add domain caching
- [ ] Add rate limiting for domain operations
- [ ] Create WebUI pages
- [ ] Update README.md if project uses custom domains

---



# PART 36: CLI CLIENT & AGENT (OPTIONAL - NON-NEGOTIABLE WHEN IMPLEMENTED)

## Overview

**CLI client and Agent are PER-PROJECT determinations.** Not all projects require a CLI client or agent.

**IMPORTANT: Once a project implements a CLI client, this entire PART becomes NON-NEGOTIABLE.** The CLI must follow all standards defined here exactly.

When a project includes a CLI client, it provides a terminal-based interface for interacting with the server. The CLI supports both standard command-line usage and an interactive TUI (Terminal User Interface) mode.

| Attribute | Value |
|-----------|-------|
| Default binary name | `weather-cli` |
| Versioning | Same as main application |
| Build | Part of same Makefile (`make build` produces both binaries) |
| Config location | `~/.config/apimgr/weather/cli.yml` |

## Binary Naming Rules (NON-NEGOTIABLE)

**Same rules apply to ALL binaries (server, agent, client). See PART 8 for full details.**

| Rule | Display | Internal |
|------|---------|----------|
| Binary name | ACTUAL name (`filepath.Base(os.Args[0])`) | Hardcoded `weather` |
| `--help` output | Shows actual binary name | - |
| `--version` output | Shows actual binary name | - |
| User-Agent | - | `weather-cli/{version}` (hardcoded) |
| Config paths | - | `/etc/apimgr/weather/` (hardcoded) |

```go
// Display: use actual binary name
binaryName := filepath.Base(os.Args[0])

// Internal: hardcoded project name (compiled via -ldflags)
const projectName = "weather"
userAgent := fmt.Sprintf("%s-cli/%s", projectName, version)
```

## API Token Authentication (Multi-User Mode)

**If project uses PART 33 (Multi-User) or PART 34 (Organizations), client MUST support `--token` for API authentication.**

| Flag | Description |
|------|-------------|
| `--token TOKEN` | API token for authentication |
| `--token-file FILE` | Read token from file |

**Token sources (priority order):**
1. `--token` flag (explicit)
2. `--token-file` flag (file path)
3. Environment variable: `WEATHER_TOKEN`
4. Config file: `cli.yml` → `token: xxx`
5. Token file: `~/.config/apimgr/weather/token`

**Token format:** See PART 11 "API Token Security" for token format and validation.

```go
func getToken(flags *Flags) (string, error) {
    // 1. Explicit flag
    if flags.Token != "" {
        return flags.Token, nil
    }
    // 2. Token file flag
    if flags.TokenFile != "" {
        return readTokenFile(flags.TokenFile)
    }
    // 3. Environment variable
    if token := os.Getenv(strings.ToUpper(projectName) + "_TOKEN"); token != "" {
        return token, nil
    }
    // 4. Config file
    if cfg.Token != "" {
        return cfg.Token, nil
    }
    // 5. Default token file
    tokenPath := filepath.Join(configDir, "token")
    if data, err := os.ReadFile(tokenPath); err == nil {
        return strings.TrimSpace(string(data)), nil
    }
    return "", nil  // No token (anonymous access if allowed)
}
```

**Usage:**
```bash
# Explicit token
weather-cli --token "usr_abc123..." list

# From environment
export WEATHER_TOKEN="usr_abc123..."
weather-cli list

# Store token (interactive login)
weather-cli login
# Saves to ~/.config/apimgr/weather/token
```

## User/Org Context (Smart Detection, NON-NEGOTIABLE)

**If project uses PART 33/34, client MUST support `--user` flag for user/org context. Server auto-detects type.**

### --user Flag

| Flag | Description |
|------|-------------|
| `--user NAME` | Target user OR org (server auto-detects) |
| `--user @NAME` | Force user context (explicit) |
| `--user +NAME` | Force org context (explicit) |

**Smart detection priority:**
1. If prefixed with `@` → user
2. If prefixed with `+` → org
3. Otherwise → server auto-detects from name

### Global Token (Works Across User + Orgs)

**A user's token grants access to:**
- Their own user account
- All orgs where they have permissions
- Resources based on their role in each org

```
Token: usr_abc123... (user: alice)
├── User context: alice's personal resources
├── Org context: acme-corp (alice is admin)
├── Org context: dev-team (alice is member)
└── Org context: open-source-proj (alice is owner)
```

**One token, multiple contexts - no need for separate org tokens.**

### Server-Side Smart Detection (NON-NEGOTIABLE)

**Server MUST auto-detect if target is user or org:**

```go
// DetectTargetType determines if name is user or org
func DetectTargetType(ctx context.Context, name string) (TargetType, error) {
    // 1. Check explicit prefix
    if strings.HasPrefix(name, "@") {
        return TargetUser, nil
    }
    if strings.HasPrefix(name, "+") {
        return TargetOrg, nil
    }

    // 2. Strip prefix for lookup
    cleanName := strings.TrimLeft(name, "@+")

    // 3. Check user table first (users are more common)
    if userExists(ctx, cleanName) {
        return TargetUser, nil
    }

    // 4. Check org table
    if orgExists(ctx, cleanName) {
        return TargetOrg, nil
    }

    // 5. Not found
    return TargetUnknown, ErrNotFound
}

// ValidateAccess checks if token has access to target
func ValidateAccess(ctx context.Context, token *Token, target string, action string) error {
    targetType, err := DetectTargetType(ctx, target)
    if err != nil {
        return err
    }

    cleanName := strings.TrimLeft(target, "@+")

    switch targetType {
    case TargetUser:
        // Token owner must BE this user
        if token.UserID != getUserID(ctx, cleanName) {
            return ErrForbidden
        }
        return nil

    case TargetOrg:
        // Token owner must have permission in this org
        org := getOrg(ctx, cleanName)
        role := getOrgRole(ctx, token.UserID, org.ID)
        if !role.Can(action) {
            return ErrForbidden
        }
        return nil
    }

    return ErrNotFound
}
```

### CLI Usage Examples

```bash
# Auto-detect: server figures out if "alice" is user or org
weather-cli --user alice list

# Explicit user context
weather-cli --user @alice list

# Explicit org context
weather-cli --user +acme-corp list

# Default: use token owner's context (no --user flag)
weather-cli list                    # Uses alice's personal context

# Org operations with user's global token
weather-cli --user acme-corp create --name "project"
weather-cli --user dev-team list
```

### API Request Headers

**Client sends context in request:**

| Header | Value | Description |
|--------|-------|-------------|
| `Authorization` | `Bearer usr_abc123...` | User's global token |
| `X-Target-Context` | `alice` or `acme-corp` | Target user/org (optional) |
| `X-Target-Type` | `user` or `org` | Explicit type hint (optional) |

```bash
# CLI translates --user to headers
weather-cli --user acme-corp list

# Becomes:
GET /api/v1/items
Authorization: Bearer usr_abc123...
X-Target-Context: acme-corp
```

### Detection Flow

```
Request arrives with token + optional context
│
├─► No --user / X-Target-Context
│   └─► Use token owner's personal context
│
├─► --user NAME provided
│   ├─► Prefix @? → Force user lookup
│   ├─► Prefix +? → Force org lookup
│   └─► No prefix → Auto-detect:
│       ├─► Check users table → Found? User context
│       ├─► Check orgs table → Found? Org context
│       └─► Neither → 404 Not Found
│
└─► Validate token has access to resolved context
    ├─► User context: token.user_id must match
    ├─► Org context: token.user must have org role
    └─► No access → 403 Forbidden
```

### Smart Context Detection (Based on Token Scope)

**`--user` flag only needed when token has multiple contexts. Server auto-detects when possible.**

| Token Scope | `--user` Needed? | Default Context |
|-------------|------------------|-----------------|
| User only (no orgs) | No | User |
| Single org only | No | That org |
| User + 1 org | Optional | User (use `--user {org}` for org) |
| User + multiple orgs | Yes (for orgs) | User (must specify which org) |

**Examples by token scope:**

```bash
# Token: alice (no org access)
weather-cli list                    # Uses alice's context (only option)
weather-cli --user alice list       # Same (redundant but valid)
weather-cli --user acme-corp list   # ERROR: no access to acme-corp

# Token: scoped to acme-corp only (org-specific token)
weather-cli list                    # Uses acme-corp context (only option)
weather-cli --user acme-corp list   # Same (redundant but valid)
weather-cli --user @me list         # ERROR: token not scoped to user

# Token: alice + acme-corp (user has one org)
weather-cli list                    # Uses alice's context (default = user)
weather-cli --user acme-corp list   # Uses acme-corp context

# Token: alice + acme-corp + dev-team (user has multiple orgs)
weather-cli list                    # Uses alice's context (default = user)
weather-cli --user acme-corp list   # Uses acme-corp context
weather-cli --user dev-team list    # Uses dev-team context
```

**Server-side scope detection:**

```go
// GetDefaultContext returns the default context for a token
func GetDefaultContext(token *Token) (string, TargetType) {
    scopes := token.GetScopes()

    // Single scope - use it directly, no --user needed
    if len(scopes) == 1 {
        return scopes[0].Name, scopes[0].Type
    }

    // Multiple scopes - default to user if available
    for _, scope := range scopes {
        if scope.Type == TargetUser {
            return scope.Name, TargetUser
        }
    }

    // No user scope, multiple orgs - require --user flag
    return "", TargetUnknown
}

// Token scope types
type TokenScope struct {
    Name string      // "alice" or "acme-corp"
    Type TargetType  // TargetUser or TargetOrg
}
```

**Why this design?**
- Zero friction for simple cases (single scope = no flag needed)
- Explicit only when ambiguous (multiple orgs)
- Token scope determines what's possible, `--user` selects which

### Flag-to-Config Save Rules (NON-NEGOTIABLE)

**Flags only update config if current value is empty or invalid:**

```go
// SaveIfEmptyOrInvalid updates config only when appropriate
func SaveIfEmptyOrInvalid(current, flagValue string, validate func(string) bool) string {
    // Flag not provided - keep current
    if flagValue == "" {
        return current
    }

    // Validate flag value
    if !validate(flagValue) {
        // Invalid flag value - keep current, log warning
        log.Warn("invalid flag value, keeping current config")
        return current
    }

    // Current is empty - save new value
    if current == "" {
        return flagValue  // Save to config
    }

    // Current is invalid - replace with valid flag value
    if !validate(current) {
        return flagValue  // Save to config
    }

    // Current is valid - use flag for session only, don't save
    return flagValue  // Use but don't persist
}
```

| Current Config | Flag Value | Result |
|----------------|------------|--------|
| Empty | Valid | **Save to config** |
| Empty | Invalid | Keep empty, warn |
| Valid | Valid | Use flag (don't save) |
| Valid | Invalid | Keep current, warn |
| Invalid | Valid | **Save to config** |
| Invalid | Invalid | Keep current, warn |

**Example:**
```bash
# First run: no server configured
weather-cli --server https://api.example.com list
# → Saves to cli.yml (was empty)

# Second run: server already configured
weather-cli --server https://staging.example.com list
# → Uses staging for THIS command, but cli.yml still has api.example.com

# To permanently change: edit cli.yml directly
```

### Reserved Names

**These names are reserved and cannot be users OR orgs:**

| Name | Reason |
|------|--------|
| `me` | Alias for current token owner |
| `self` | Alias for current token owner |
| `@me` | Explicit user self-reference |
| `admin` | Reserved for system |
| `system` | Reserved for system |
| `api` | Reserved for routes |
| `www` | Reserved for routes |

```bash
# @me always means token owner
weather-cli --user @me list    # Always personal context
```

## Modes

### Automatic Mode Detection (NON-NEGOTIABLE)

**Smart TUI detection. No `--tui` flag or `tui` command needed.**

| Condition | Result |
|-----------|--------|
| `-h`, `--help` | Print help, exit (CLI only, never TUI) |
| `-v`, `--version` | Print version, exit (CLI only, never TUI) |
| Interactive terminal + no command | TUI mode |
| Interactive terminal + config flags only | TUI mode |
| Interactive terminal + command/args | CLI mode |
| Piped/redirected output | Plain output (no TUI) |
| Non-interactive (cron, scripts) | Plain output |

**Exit-immediately flags (NEVER launch TUI):**
```bash
weather-cli -h                    # Print help, exit
weather-cli --help                # Print help, exit
weather-cli -v                    # Print version, exit
weather-cli --version             # Print version, exit
```

**Config flags (still launch TUI):**
```bash
weather-cli                                    # TUI mode
weather-cli --config dev                       # TUI mode (with dev.yml)
weather-cli --server https://example.com       # TUI mode (with server)
weather-cli --token abc123                     # TUI mode (with token)
```

**Command/args (CLI mode):**
```bash
weather-cli list                               # CLI mode
weather-cli golang tutorials                   # CLI mode (search)
weather-cli notes.txt                          # CLI mode (paste file)
```

```go
func detectMode(args []string) string {
    // Exit-immediately flags - never TUI
    for _, arg := range args[1:] {
        switch arg {
        case "-h", "--help", "-v", "--version":
            return "cli"  // Handle and exit
        }
    }

    // Not a terminal = plain output
    if !term.IsTerminal(int(os.Stdout.Fd())) {
        return "plain"
    }

    // Config-only flags don't prevent TUI
    configFlags := map[string]bool{
        "--config": true, "--server": true, "--token": true, "--debug": true,
    }

    for _, arg := range args[1:] {
        if !strings.HasPrefix(arg, "-") {
            return "cli"  // Command/arg provided
        }
        flag := strings.Split(arg, "=")[0]
        if !configFlags[flag] {
            return "cli"  // Action flag
        }
    }

    return "tui"  // No args or config-only = TUI
}
```

## Display Environment Detection (CLI-Specific)

**See PART 7 for core display detection shared by all binaries.**

**CLI binary extends the base detection with GUI support and mode selection:**

### CLI Display Mode Hierarchy

| Mode | Priority | When Used | CLI Binary Behavior |
|------|----------|-----------|---------------------|
| **GUI** | 1 | Native display, no remote | Launch native GUI (GTK/Cocoa/Win32) |
| **TUI** | 2 | Interactive terminal | Launch bubbletea TUI |
| **CLI** | 3 | Command provided or piped | Text output with colors |
| **Headless** | 4 | No display, no TTY | Error (CLI requires interaction) |

### Extended Platform Display Detection

```go
// src/common/display/detect.go
package display

import (
    "os"
    "os/exec"
    "runtime"
    "strings"

    "golang.org/x/term"
)

type DisplayMode int

const (
    ModeHeadless DisplayMode = iota // No display, no TTY
    ModeCLI                         // Command-line only (piped or command provided)
    ModeTUI                         // Terminal UI (interactive terminal)
    ModeGUI                         // Native graphical UI
)

type DisplayEnv struct {
    Mode          DisplayMode
    HasDisplay    bool     // X11, Wayland, Windows, macOS display
    DisplayType   string   // "x11", "wayland", "windows", "macos", "none"
    IsTerminal    bool     // stdout is a TTY
    IsSSH         bool     // Running over SSH
    IsMosh        bool     // Running over mosh
    IsScreen      bool     // Running in screen/tmux
    TerminalType  string   // TERM value
    Cols          int      // Terminal columns (0 if no terminal)
    Rows          int      // Terminal rows (0 if no terminal)
}

func Detect() DisplayEnv {
    env := DisplayEnv{}

    // Check terminal
    env.IsTerminal = term.IsTerminal(int(os.Stdout.Fd()))
    if env.IsTerminal {
        env.Cols, env.Rows, _ = term.GetSize(int(os.Stdout.Fd()))
    }
    env.TerminalType = os.Getenv("TERM")

    // Check remote session
    env.IsSSH = os.Getenv("SSH_CLIENT") != "" || os.Getenv("SSH_TTY") != ""
    env.IsMosh = os.Getenv("MOSH") != "" || strings.Contains(os.Getenv("TERM"), "mosh")
    env.IsScreen = os.Getenv("STY") != "" || os.Getenv("TMUX") != ""

    // Detect display environment
    env.detectDisplay()

    // Determine mode
    env.Mode = env.determineMode()

    return env
}

func (e *DisplayEnv) detectDisplay() {
    switch runtime.GOOS {
    case "linux", "freebsd", "openbsd", "netbsd":
        e.detectUnixDisplay()
    case "darwin":
        e.detectMacOSDisplay()
    case "windows":
        e.detectWindowsDisplay()
    default:
        e.DisplayType = "none"
        e.HasDisplay = false
    }
}

func (e *DisplayEnv) detectUnixDisplay() {
    // Check Wayland first (preferred on modern Linux)
    if os.Getenv("WAYLAND_DISPLAY") != "" {
        e.DisplayType = "wayland"
        e.HasDisplay = true
        return
    }

    // Check X11
    display := os.Getenv("DISPLAY")
    if display != "" {
        // Verify X server is actually accessible
        cmd := exec.Command("xset", "q")
        if err := cmd.Run(); err == nil {
            e.DisplayType = "x11"
            e.HasDisplay = true
            return
        }
    }

    e.DisplayType = "none"
    e.HasDisplay = false
}

func (e *DisplayEnv) detectMacOSDisplay() {
    // macOS always has a display unless running headless
    // Check if we're in a graphical session
    if os.Getenv("TERM_PROGRAM") != "" || os.Getenv("Apple_PubSub_Socket_Render") != "" {
        e.DisplayType = "macos"
        e.HasDisplay = true
        return
    }

    // SSH session to macOS - no local display access
    if e.IsSSH {
        e.DisplayType = "none"
        e.HasDisplay = false
        return
    }

    // Assume display available on macOS
    e.DisplayType = "macos"
    e.HasDisplay = true
}

func (e *DisplayEnv) detectWindowsDisplay() {
    // Windows: check for console vs GUI session
    // GetConsoleWindow returns 0 if no console
    e.DisplayType = "windows"
    e.HasDisplay = true // Windows desktop always available unless service

    // Detect Windows service mode (no display)
    if os.Getenv("USERPROFILE") == "" {
        e.DisplayType = "none"
        e.HasDisplay = false
    }
}

func (e *DisplayEnv) determineMode() DisplayMode {
    // No TTY and no display = headless
    if !e.IsTerminal && !e.HasDisplay {
        return ModeHeadless
    }

    // Has native display = GUI possible
    if e.HasDisplay && !e.IsSSH && !e.IsMosh {
        return ModeGUI
    }

    // Has terminal = TUI possible
    if e.IsTerminal {
        return ModeTUI
    }

    // Fallback to CLI
    return ModeCLI
}

func (e DisplayEnv) String() string {
    modes := []string{"headless", "cli", "tui", "gui"}
    return modes[e.Mode]
}

func (e DisplayEnv) SupportsColors() bool {
    if !e.IsTerminal {
        return false
    }
    // Most modern terminals support colors
    term := strings.ToLower(e.TerminalType)
    return strings.Contains(term, "color") ||
           strings.Contains(term, "256") ||
           strings.Contains(term, "xterm") ||
           strings.Contains(term, "screen") ||
           strings.Contains(term, "tmux") ||
           term == "linux"
}

func (e DisplayEnv) SupportsUnicode() bool {
    // Check locale for UTF-8 support
    lang := os.Getenv("LANG")
    lcAll := os.Getenv("LC_ALL")
    return strings.Contains(strings.ToUpper(lang), "UTF") ||
           strings.Contains(strings.ToUpper(lcAll), "UTF")
}
```

### Mode Selection by Binary (NON-NEGOTIABLE)

| Binary | GUI | TUI | CLI | Headless |
|--------|-----|-----|-----|----------|
| **Server** | ❌ No | Status only | Commands | Default (daemon) |
| **CLI** | ✅ Yes | ✅ Yes (default) | ✅ Yes | ❌ No |
| **Agent** | ❌ No | Status only | Commands | Default (service) |

**Server and Agent are primarily headless services. GUI is CLI-only.**

### GUI Mode Requirements (NON-NEGOTIABLE)

**When GUI mode is available, use NATIVE platform toolkit. No Electron, no web views.**

| Platform | Toolkit | Notes |
|----------|---------|-------|
| **Linux** | GTK4 or Qt6 | GTK4 preferred for GNOME, Qt6 for KDE |
| **macOS** | Cocoa (AppKit) | Native macOS UI via cgo |
| **Windows** | Win32/WinUI | Native Windows UI |
| **BSD** | GTK4 or Qt6 | Same as Linux |

```go
// src/client/gui/gui.go
//go:build gui

package gui

import (
    "runtime"
)

// GUI is conditionally compiled
// Build with: go build -tags gui

func Available() bool {
    env := display.Detect()
    return env.HasDisplay && !env.IsSSH && !env.IsMosh
}

func Launch(config *Config) error {
    switch runtime.GOOS {
    case "linux", "freebsd", "openbsd", "netbsd":
        return launchGTK(config)
    case "darwin":
        return launchCocoa(config)
    case "windows":
        return launchWin32(config)
    default:
        return ErrGUIUnsupported
    }
}
```

### SSH/Mosh Detection (NON-NEGOTIABLE)

**Remote sessions ALWAYS use TUI or CLI. Never attempt GUI over SSH/mosh.**

```go
func IsRemoteSession() bool {
    // SSH detection
    if os.Getenv("SSH_CLIENT") != "" || os.Getenv("SSH_TTY") != "" {
        return true
    }

    // Mosh detection
    if os.Getenv("MOSH") != "" {
        return true
    }

    // Check for SSH connection string
    if os.Getenv("SSH_CONNECTION") != "" {
        return true
    }

    return false
}
```

### Mode Override Flags

**Users can force specific modes when needed:**

```bash
# Force CLI mode (no TUI, no GUI)
weather-cli --mode cli list
weather-cli --cli list          # Short form

# Force TUI mode (skip GUI even if available)
weather-cli --mode tui
weather-cli --tui               # Short form

# Force GUI mode (error if unavailable)
weather-cli --mode gui
weather-cli --gui               # Short form

# Let auto-detection decide (default)
weather-cli                     # Auto-detect best mode
```

```go
// Mode override handling
func selectMode(flagMode string, env DisplayEnv) DisplayMode {
    switch flagMode {
    case "cli":
        return ModeCLI
    case "tui":
        if !env.IsTerminal {
            log.Fatal("TUI mode requires interactive terminal")
        }
        return ModeTUI
    case "gui":
        if !env.HasDisplay || env.IsSSH || env.IsMosh {
            log.Fatal("GUI mode requires local display (not available over SSH/mosh)")
        }
        return ModeGUI
    default:
        return env.Mode // Auto-detect
    }
}
```

## CLI/TUI/GUI Theming

**See PART 16 "Themes (NON-NEGOTIABLE - PROJECT-WIDE)" for the unified color palette.**

**CLI/TUI/GUI use the same `theme.Palette` from `src/common/theme/colors.go`.**

### CLI Theme Configuration

```yaml
# cli.yml - theme section (same format as server.yml)
theme:
  mode: auto          # dark (default), light, auto
```

### TUI Styles from Palette

```go
// src/client/tui/styles.go
package tui

import (
    "github.com/charmbracelet/lipgloss"
    "project/common/theme"
)

func StylesFromPalette(p theme.Palette) Styles {
    return Styles{
        Base: lipgloss.NewStyle().
            Foreground(lipgloss.Color(p.Foreground)).
            Background(lipgloss.Color(p.Background)),
        Title: lipgloss.NewStyle().
            Foreground(lipgloss.Color(p.Primary)).Bold(true),
        Selected: lipgloss.NewStyle().
            Foreground(lipgloss.Color(p.Background)).
            Background(lipgloss.Color(p.Primary)),
        Error: lipgloss.NewStyle().Foreground(lipgloss.Color(p.Error)),
        Success: lipgloss.NewStyle().Foreground(lipgloss.Color(p.Success)),
        Warning: lipgloss.NewStyle().Foreground(lipgloss.Color(p.Warning)),
        Muted: lipgloss.NewStyle().Foreground(lipgloss.Color(p.Muted)),
        Border: lipgloss.NewStyle().BorderForeground(lipgloss.Color(p.Border)),
    }
}
```

### CLI Colored Output

```go
// src/client/cli/output.go
package cli

import (
    "fmt"
    "project/common/theme"
)

// Apply palette colors to CLI text output
func (o *Output) PrintSuccess(msg string) {
    if o.colors {
        fmt.Printf("\033[38;2;%sм%s\033[0m\n", hexToRGB(o.palette.Success), msg)
    } else {
        fmt.Println(msg)
    }
}

func (o *Output) PrintError(msg string) {
    if o.colors {
        fmt.Printf("\033[38;2;%sм%s\033[0m\n", hexToRGB(o.palette.Error), msg)
    } else {
        fmt.Println(msg)
    }
}
```

## Responsive Layout (NON-NEGOTIABLE)

**ALL interfaces MUST look professional from mobile (40x10) to 16K displays (400+ columns).**

### Screen Size Categories

| Category | Columns | Rows | Examples | Layout |
|----------|---------|------|----------|--------|
| **Micro** | <40 | <10 | Phone portrait SSH | Vertical stack, no chrome |
| **Minimal** | 40-59 | 10-15 | Phone landscape SSH | Single column, minimal borders |
| **Compact** | 60-79 | 16-23 | Tablet SSH, small terminal | Compact layout, abbreviated |
| **Standard** | 80-119 | 24-39 | Standard terminal | Normal layout |
| **Wide** | 120-199 | 40-59 | Wide terminal | Sidebars, multi-column |
| **Ultrawide** | 200-399 | 60+ | Ultrawide monitor | Three-column, dashboards |
| **Massive** | 400+ | 80+ | 4K/8K/16K displays | Multi-pane, tile layout |

### GUI Responsive Layout

```go
// GUI window scaling for high-DPI and large displays
func calculateGUILayout(width, height int, dpi float64) Layout {
    // Scale based on DPI
    scale := dpi / 96.0 // 96 DPI is baseline

    // Base sizes (at 96 DPI)
    baseMinWidth := 800
    baseMinHeight := 600

    // Calculate scaled sizes
    minWidth := int(float64(baseMinWidth) * scale)
    minHeight := int(float64(baseMinHeight) * scale)

    // Determine layout mode
    switch {
    case width >= 3840: // 4K+
        return Layout{
            Mode:       "dashboard",
            Columns:    4,
            Sidebar:    true,
            SidebarW:   int(300 * scale),
            FontScale:  scale,
        }
    case width >= 2560: // 1440p/QHD
        return Layout{
            Mode:       "wide",
            Columns:    3,
            Sidebar:    true,
            SidebarW:   int(280 * scale),
            FontScale:  scale,
        }
    case width >= 1920: // 1080p
        return Layout{
            Mode:       "standard",
            Columns:    2,
            Sidebar:    true,
            SidebarW:   int(250 * scale),
            FontScale:  scale,
        }
    case width >= 1280: // 720p
        return Layout{
            Mode:       "compact",
            Columns:    1,
            Sidebar:    true,
            SidebarW:   int(200 * scale),
            FontScale:  scale,
        }
    default:
        return Layout{
            Mode:       "mobile",
            Columns:    1,
            Sidebar:    false,
            FontScale:  scale,
        }
    }
}
```

### TUI Responsive Layout

```go
// src/client/tui/layout.go
package tui

type LayoutMode int

const (
    LayoutMicro     LayoutMode = iota // <40 cols
    LayoutMinimal                      // 40-59 cols
    LayoutCompact                      // 60-79 cols
    LayoutStandard                     // 80-119 cols
    LayoutWide                         // 120-199 cols
    LayoutUltrawide                    // 200-399 cols
    LayoutMassive                      // 400+ cols
)

func GetLayoutMode(cols, rows int) LayoutMode {
    // Use the more constraining dimension
    switch {
    case cols < 40 || rows < 10:
        return LayoutMicro
    case cols < 60 || rows < 16:
        return LayoutMinimal
    case cols < 80 || rows < 24:
        return LayoutCompact
    case cols < 120 || rows < 40:
        return LayoutStandard
    case cols < 200 || rows < 60:
        return LayoutWide
    case cols < 400 || rows < 80:
        return LayoutUltrawide
    default:
        return LayoutMassive
    }
}

// Layout configuration per mode
func (m LayoutMode) Config() LayoutConfig {
    configs := map[LayoutMode]LayoutConfig{
        LayoutMicro: {
            ShowBorders:    false,
            ShowHeader:     false,
            ShowFooter:     false,
            ShowSidebar:    false,
            MaxColumns:     2,
            TruncateAt:     30,
            UseAbbrev:      true,
            VerticalScroll: true,
        },
        LayoutMinimal: {
            ShowBorders:    false,
            ShowHeader:     true,
            ShowFooter:     true,
            ShowSidebar:    false,
            MaxColumns:     3,
            TruncateAt:     40,
            UseAbbrev:      true,
            VerticalScroll: true,
        },
        LayoutCompact: {
            ShowBorders:    true,
            ShowHeader:     true,
            ShowFooter:     true,
            ShowSidebar:    false,
            MaxColumns:     4,
            TruncateAt:     60,
            UseAbbrev:      false,
            VerticalScroll: true,
        },
        LayoutStandard: {
            ShowBorders:    true,
            ShowHeader:     true,
            ShowFooter:     true,
            ShowSidebar:    false,
            MaxColumns:     6,
            TruncateAt:     80,
            UseAbbrev:      false,
            VerticalScroll: true,
        },
        LayoutWide: {
            ShowBorders:    true,
            ShowHeader:     true,
            ShowFooter:     true,
            ShowSidebar:    true,
            SidebarWidth:   30,
            MaxColumns:     8,
            TruncateAt:     120,
            UseAbbrev:      false,
            VerticalScroll: true,
        },
        LayoutUltrawide: {
            ShowBorders:    true,
            ShowHeader:     true,
            ShowFooter:     true,
            ShowSidebar:    true,
            SidebarWidth:   40,
            MaxColumns:     12,
            TruncateAt:     200,
            UseAbbrev:      false,
            VerticalScroll: false, // Full content visible
            MultiPane:      true,
        },
        LayoutMassive: {
            ShowBorders:    true,
            ShowHeader:     true,
            ShowFooter:     true,
            ShowSidebar:    true,
            SidebarWidth:   50,
            MaxColumns:     20,
            TruncateAt:     0, // No truncation
            UseAbbrev:      false,
            VerticalScroll: false,
            MultiPane:      true,
            TileLayout:     true,
        },
    }
    return configs[m]
}
```

### Window Resize Handling (NON-NEGOTIABLE)

**ALL modes MUST handle window resize smoothly.**

```go
// TUI resize handling with bubbletea
func (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {
    switch msg := msg.(type) {
    case tea.WindowSizeMsg:
        m.width = msg.Width
        m.height = msg.Height
        m.layoutMode = GetLayoutMode(msg.Width, msg.Height)
        m.layout = m.layoutMode.Config()

        // Recalculate all component sizes
        m.recalculateViewport()
        m.recalculateTables()
        m.recalculateSidebar()

        // Log resize in debug mode
        if m.debug {
            log.Printf("Window resize: %dx%d, mode: %s",
                msg.Width, msg.Height, m.layoutMode)
        }
    }
    return m, nil
}

// Server/Agent: Handle SIGWINCH for console output
func watchWindowSize(ctx context.Context, callback func(w, h int)) {
    sigCh := make(chan os.Signal, 1)
    signal.Notify(sigCh, syscall.SIGWINCH)

    for {
        select {
        case <-ctx.Done():
            return
        case <-sigCh:
            w, h, _ := term.GetSize(int(os.Stdout.Fd()))
            callback(w, h)
        }
    }
}
```

## Professional UI/UX Standards (NON-NEGOTIABLE)

**Every interface MUST look professional. No amateur hour.**

### Visual Hierarchy

| Element | Priority | Styling |
|---------|----------|---------|
| **Primary Actions** | High | Primary color, prominent placement |
| **Data/Content** | High | Clear contrast, readable fonts |
| **Navigation** | Medium | Consistent position, clear labels |
| **Secondary Actions** | Medium | Muted styling, discoverable |
| **Status/Meta** | Low | Muted color, smaller text |
| **Decorative** | Lowest | Subtle, never distracting |

### Spacing and Alignment

```go
// Consistent spacing units (TUI)
const (
    SpaceXS = 1  // Micro spacing
    SpaceS  = 2  // Small spacing
    SpaceM  = 4  // Medium spacing
    SpaceL  = 6  // Large spacing
    SpaceXL = 8  // Extra large spacing
)

// Apply based on layout mode
func (m LayoutMode) Spacing() int {
    switch m {
    case LayoutMicro, LayoutMinimal:
        return SpaceXS
    case LayoutCompact:
        return SpaceS
    case LayoutStandard:
        return SpaceM
    case LayoutWide:
        return SpaceL
    default:
        return SpaceXL
    }
}
```

### Consistent Icons and Symbols

```go
// Unicode symbols that work across terminals
var Symbols = struct {
    Success  string
    Error    string
    Warning  string
    Info     string
    Arrow    string
    Check    string
    Cross    string
    Bullet   string
    Spinner  []string
}{
    Success:  "✓",
    Error:    "✗",
    Warning:  "⚠",
    Info:     "ℹ",
    Arrow:    "→",
    Check:    "☑",
    Cross:    "☒",
    Bullet:   "•",
    Spinner:  []string{"⠋", "⠙", "⠹", "⠸", "⠼", "⠴", "⠦", "⠧", "⠇", "⠏"},
}

// Fallback for non-Unicode terminals
var SymbolsASCII = struct {
    Success  string
    Error    string
    Warning  string
    Info     string
    Arrow    string
    Check    string
    Cross    string
    Bullet   string
    Spinner  []string
}{
    Success:  "[OK]",
    Error:    "[ERR]",
    Warning:  "[WARN]",
    Info:     "[INFO]",
    Arrow:    "->",
    Check:    "[x]",
    Cross:    "[ ]",
    Bullet:   "*",
    Spinner:  []string{"|", "/", "-", "\\"},
}

func GetSymbols(env DisplayEnv) interface{} {
    if env.SupportsUnicode() {
        return Symbols
    }
    return SymbolsASCII
}
```

### Standard CLI Mode

When command arguments are provided:

```bash
# Standard CLI output (your project)
weather-cli create --file notes.txt --expire 24h
weather-cli get abc123 --output json
weather-cli list --limit 10
weather-cli search --query "keyword"
```

### TUI Mode (Automatic)

When launched with no arguments in an interactive terminal:

```bash
# Launch TUI (no arguments needed)
weather-cli              # Opens TUI automatically

# TUI provides:
# - Interactive menus
# - Search with live results
# - Keyboard shortcuts
# - Visual data display
# - Professional, polished interface
```

**TUI Library:** Use `github.com/charmbracelet/bubbletea` for TUI implementation.

## Configuration

### Directory Structure (NON-NEGOTIABLE)

**CLI client ALWAYS runs as user. NEVER as root/administrator. NEVER uses system directories.**

The CLI binary:
- Runs as current user only (no privilege escalation)
- Uses user home directories exclusively
- Creates all directories and files itself (no external scripts/installers)
- Sets permissions and ownership before creating any files
- Works identically across all platforms (Linux, macOS, Windows)

The CLI client uses the same user directory structure as the server in user mode. This allows the CLI to share configuration with a locally running server when appropriate.

#### Linux / macOS

| Directory | Path | Purpose |
|-----------|------|---------|
| Config | `~/.config/apimgr/weather/` | Configuration files |
| Config File | `~/.config/apimgr/weather/cli.yml` | CLI configuration |
| Data | `~/.local/share/apimgr/weather/` | Persistent data |
| Cache | `~/.cache/apimgr/weather/` | Temporary/cached data |
| Logs | `~/.local/log/apimgr/weather/` | Log files |
| Log File | `~/.local/log/apimgr/weather/cli.log` | CLI log output |

#### Windows

| Directory | Path | Purpose |
|-----------|------|---------|
| Config | `%APPDATA%\apimgr\weather\` | Configuration files |
| Config File | `%APPDATA%\apimgr\weather\cli.yml` | CLI configuration |
| Data | `%LOCALAPPDATA%\apimgr\weather\data\` | Persistent data |
| Cache | `%LOCALAPPDATA%\apimgr\weather\cache\` | Temporary/cached data |
| Logs | `%LOCALAPPDATA%\apimgr\weather\log\` | Log files |
| Log File | `%LOCALAPPDATA%\apimgr\weather\log\cli.log` | CLI log output |

#### Directory Usage

| Directory | Contents | Backup? |
|-----------|----------|---------|
| Config | `cli.yml`, connection profiles, preferences | Yes |
| Data | Downloaded data, local databases, saved items | Yes |
| Cache | API response cache, temp files, thumbnails | No (recreatable) |
| Logs | `cli.log`, debug logs | Optional |

**NEVER use OS system directories:**
- `/etc/apimgr/weather/` (Linux system config)
- `/var/lib/apimgr/weather/` (Linux system data)
- `/var/log/apimgr/weather/` (Linux system logs)
- `C:\ProgramData\` (Windows system data)
- Any directory requiring elevated privileges

#### CLI Startup Sequence (NON-NEGOTIABLE)

**The CLI binary handles ALL initialization. No external scripts, no installers, no manual setup.**

On every startup, the CLI MUST:

1. **Ensure directories exist** (create if missing):
   ```
   ├─ {config_dir}/           (~/.config/apimgr/weather/)
   ├─ {data_dir}/             (~/.local/share/apimgr/weather/)
   ├─ {cache_dir}/            (~/.cache/apimgr/weather/)
   └─ {log_dir}/              (~/.local/log/apimgr/weather/)
   ```

2. **Set correct permissions** (user-only access):
   - Directories: `0700` (rwx------)
   - Config files: `0600` (rw-------)
   - Log files: `0600` (rw-------)

3. **Verify ownership** (current user):
   - All directories and files owned by running user
   - No root/admin ownership ever

```go
// src/client/init.go
package cli

import (
	"fmt"
	"os"
	"path/filepath"
)

// EnsureDirs creates all CLI directories with correct permissions.
// Called on every startup before any file operations.
func EnsureDirs() error {
	dirs := []string{
		paths.ConfigDir(),
		paths.DataDir(),
		paths.CacheDir(),
		paths.LogDir(),
	}

	for _, dir := range dirs {
		if err := os.MkdirAll(dir, 0700); err != nil {
			return fmt.Errorf("create dir %s: %w", dir, err)
		}
		// Ensure permissions even if dir existed
		if err := os.Chmod(dir, 0700); err != nil {
			return fmt.Errorf("chmod dir %s: %w", dir, err)
		}
	}
	return nil
}

// EnsureFile creates parent dirs and sets permissions before writing.
// MUST be called before any file creation.
func EnsureFile(path string, perm os.FileMode) error {
	dir := filepath.Dir(path)
	if err := os.MkdirAll(dir, 0700); err != nil {
		return fmt.Errorf("create parent dir: %w", err)
	}
	return nil
}
```

**CLI initialization order:**
1. Parse CLI flags
2. Call `EnsureDirs()` - create all directories
3. Load/create config file (`cli.yml`)
4. Initialize logging (`cli.log`)
5. Execute command

#### Path Resolution (Go)

```go
// src/client/paths/paths.go
package paths

import (
	"os"
	"path/filepath"
	"runtime"
)

const (
	projectOrg  = "apimgr"
	projectName = "weather"
)

// ConfigDir returns the CLI config directory
func ConfigDir() string {
	if runtime.GOOS == "windows" {
		return filepath.Join(os.Getenv("APPDATA"), projectOrg, projectName)
	}
	home, _ := os.UserHomeDir()
	return filepath.Join(home, ".config", projectOrg, projectName)
}

// DataDir returns the CLI data directory
func DataDir() string {
	if runtime.GOOS == "windows" {
		return filepath.Join(os.Getenv("LOCALAPPDATA"), projectOrg, projectName, "data")
	}
	home, _ := os.UserHomeDir()
	return filepath.Join(home, ".local", "share", projectOrg, projectName)
}

// CacheDir returns the CLI cache directory
func CacheDir() string {
	if runtime.GOOS == "windows" {
		return filepath.Join(os.Getenv("LOCALAPPDATA"), projectOrg, projectName, "cache")
	}
	home, _ := os.UserHomeDir()
	return filepath.Join(home, ".cache", projectOrg, projectName)
}

// LogDir returns the CLI log directory
func LogDir() string {
	if runtime.GOOS == "windows" {
		return filepath.Join(os.Getenv("LOCALAPPDATA"), projectOrg, projectName, "log")
	}
	home, _ := os.UserHomeDir()
	return filepath.Join(home, ".local", "log", projectOrg, projectName)
}

// ConfigFile returns the CLI config file path
func ConfigFile() string {
	return filepath.Join(ConfigDir(), "cli.yml")
}

// LogFile returns the CLI log file path
func LogFile() string {
	return filepath.Join(LogDir(), "cli.log")
}
```

### --config Flag (Config File Selection)

**The `--config` flag loads a specific config file instead of the default `cli.yml`.**

| Input | Resolution |
|-------|------------|
| `--config test` | `{config_dir}/test.yml` |
| `--config dev.yml` | `{config_dir}/dev.yml` |
| `--config test.yaml` | `{config_dir}/test.yaml` |
| `--config ~/testing/app.yml` | Absolute path: `~/testing/app.yml` |
| `--config /etc/myapp/prod.yml` | Absolute path: `/etc/myapp/prod.yml` |
| (not specified) | Default: `{config_dir}/cli.yml` |

**Resolution rules:**
1. If path is absolute (starts with `/` or `~`) → expand, then check extension
2. If path is relative → resolve relative to `{config_dir}`
3. If extension is `.yml` or `.yaml` → use as-is
4. If no extension → auto-detect: check `.yml` first, then `.yaml`, default to `.yml`
5. File must exist or error (except for new configs which default to `.yml`)

```go
// resolveConfigPath resolves --config flag to absolute path
func resolveConfigPath(configFlag string) (string, error) {
    if configFlag == "" {
        return ConfigFile(), nil  // Default: cli.yml
    }

    // Expand ~ to home directory
    if strings.HasPrefix(configFlag, "~/") {
        home, _ := os.UserHomeDir()
        configFlag = filepath.Join(home, configFlag[2:])
    }

    // Absolute path - check extension detection
    if filepath.IsAbs(configFlag) {
        return resolveYamlExtension(configFlag), nil
    }

    // Relative path - resolve to configdir
    path := filepath.Join(ConfigDir(), configFlag)

    return resolveYamlExtension(path), nil
}

// resolveYamlExtension auto-detects .yml or .yaml extension
// If no extension provided, checks for existing .yml then .yaml
// Defaults to .yml if neither exists (for new configs)
func resolveYamlExtension(path string) string {
    ext := filepath.Ext(path)

    // Already has yaml extension - use as-is
    if ext == ".yml" || ext == ".yaml" {
        return path
    }

    // No extension - auto-detect
    if ext == "" {
        // Check .yml first
        if fileExists(path + ".yml") {
            return path + ".yml"
        }
        // Check .yaml second
        if fileExists(path + ".yaml") {
            return path + ".yaml"
        }
        // Default to .yml for new configs
        return path + ".yml"
    }

    // Non-yaml extension - use as-is (user knows what they're doing)
    return path
}
```

**Example usage:**
```bash
# Use different configs for different environments
weather-cli --config dev list              # Uses ~/.config/.../dev.yml
weather-cli --config staging list          # Uses ~/.config/.../staging.yml
weather-cli --config ~/work/prod.yml list  # Uses absolute path

# Config profiles allow different servers/tokens without flags
# dev.yml:   server: https://dev.example.com, token: dev-token
# staging.yml: server: https://staging.example.com, token: staging-token
```

### cli.yml Configuration (NON-NEGOTIABLE)

**EVERYTHING must be configurable via cli.yml. Sane defaults match server where applicable.**

```yaml
# ~/.config/apimgr/weather/cli.yml
# CLI client configuration - ALL options with defaults

# Server connection
server:
  primary: ""                      # Server URL (empty = use {officialsite} or prompt)
  cluster: []                      # Auto-discovered cluster nodes
  timeout: 30                      # Request timeout in seconds (match server default)
  retry: 3                         # Retry attempts on failure
  retry_delay: 1                   # Seconds between retries

# Authentication (required for multi-user, see PART 33/34)
auth:
  token: ""                        # API token (usr_xxx, see PART 11)
  token_file: ""                   # Read token from file instead
  # No default_context - default is ALWAYS token owner (user)
  # Use --user {org} to switch to org context

# Output preferences
output:
  format: table                    # Default: table, json, yaml, plain, csv
  color: auto                      # auto, always, never (match terminal detection)
  pager: auto                      # auto, always, never (use less/more for long output)
  quiet: false                     # Suppress non-essential output
  verbose: false                   # Extra output (same as --verbose)

# TUI preferences (if TUI supported)
tui:
  enabled: true                    # Allow TUI mode (false = CLI-only)
  theme: dark                      # dark, light, system (match server theme options)
  mouse: true                      # Enable mouse support
  unicode: true                    # Use unicode characters (false = ASCII only)

# Logging
logging:
  level: warn                      # debug, info, warn, error (match server default)
  file: ""                         # Log file path (empty = {log_dir}/cli.log)
  max_size: 10                     # Max log file size in MB (match server default)
  max_files: 5                     # Max log files to keep (match server default)

# Cache
cache:
  enabled: true                    # Enable response caching
  ttl: 300                         # Cache TTL in seconds (5 minutes)
  max_size: 100                    # Max cache size in MB

# Debug
debug: false                       # Enable debug mode (same as --debug)

# Project-specific defaults (flag defaults)
defaults:
  # These become defaults for project-specific flags
  # Example for pastebin:
  # public: unlisted               # --public default
  # expire: 24h                    # --expire default
  # syntax: auto                   # --syntax default
```

**Config precedence (highest to lowest):**

| Priority | Source | Example |
|----------|--------|---------|
| 1 | CLI flag | `--format json` |
| 2 | Environment variable | `WEATHER_FORMAT=json` |
| 3 | Config file | `output.format: json` |
| 4 | Compiled default | `table` |

**Environment variable mapping:**
```bash
# Pattern: WEATHER_{SECTION}_{KEY} or WEATHER_{KEY}
WEATHER_SERVER_PRIMARY="https://example.com"
WEATHER_SERVER_TIMEOUT=60
WEATHER_TOKEN="usr_abc123..."
WEATHER_OUTPUT_FORMAT="json"
WEATHER_DEBUG=true
```

### CLI Cluster Failover (NON-NEGOTIABLE)

**CLI client MUST support automatic cluster failover. Background node discovery keeps config current.**

| Feature | Behavior |
|---------|----------|
| **Background discovery** | CLI calls `/api/v1/healthz` in background |
| **Auto-update** | `server.cluster` updated from `cluster.nodes` in response |
| **Failover** | If primary fails, try cluster nodes transparently |
| **No user action** | Completely automatic, user sees no difference |

**CLI Cluster Behavior:**
```
On every CLI command:
1. Load cli.yml
2. Try server.primary
3. If fails → try server.cluster nodes (silent failover)
4. Execute command on first available node
5. Background: GET /api/v1/healthz
6. Read cluster.primary and cluster.nodes from response
7. Update server.primary and server.cluster in cli.yml (async, non-blocking)
```

**User Experience:**
- User runs `mycli list` - just works
- If primary is down, CLI silently uses cluster node
- No error unless ALL nodes are unreachable
- Config stays current automatically

### Server Address Resolution (NON-NEGOTIABLE)

**Priority order (highest to lowest):**

1. `--server` flag (if provided)
2. `server.primary` in `cli.yml` (if set)
3. `server.cluster` nodes (if primary fails)
4. `{officialsite}` compiled default (if project has official site)
5. Error with setup instructions

**Behavior:**

| Scenario | Result |
|----------|--------|
| `--server` flag used | Use that server, **save to `server.primary` in cli.yml** |
| `server.primary` in cli.yml | Use configured primary server |
| Primary fails, cluster exists | Silently try cluster nodes |
| Project has `{officialsite}` | Use official site as default |
| No server available | Error with setup instructions |

**Config save rule: Validate everything, only save valid, never clear valid.**

```go
// saveIfEmpty saves value to config only if current is empty and new is valid
func saveIfEmpty(current, newValue string, validate func(string) bool) (string, error) {
    if newValue == "" {
        return current, nil
    }
    if !validate(newValue) {
        return "", fmt.Errorf("invalid value: %s", newValue)
    }
    if current == "" {
        return newValue, nil  // Save to config
    }
    return newValue, nil  // Use for session, don't save (current preserved)
}
```

| Principle | Rule |
|-----------|------|
| **Validate everything** | Always validate before use or save |
| **Only save valid** | Never save invalid values to config |
| **Never clear valid** | Don't overwrite existing valid config |

**Error when no server configured (projects without official site):**

```bash
$ weather-cli list
Error: no server configured

To configure a server, run:
  weather-cli --server https://your-server.example.com list

This will save the server address for future commands.
Or edit ~/.config/apimgr/weather/cli.yml directly.
```

**Projects with official site show default in help:**

```bash
$ weather-cli --help
...
Flags:
      --server string    Server address (default: https://weather.example.com)
...
```

**Official site (`{officialsite}`) is defined in the project's AI.md or README.md and compiled into the binary.**

Sources for official site (check in order):
1. AI.md: `Official Site: https://...` or `{officialsite}: https://...`
2. README.md: `Official site is: https://...` or `Site: https://...`
3. AI asks user (if not found in docs)
4. If user selects "none", project has no default server

**AI should ask if not defined:**
```
Official site not found in AI.md or README.md.
What is the official site for this project?

1) https://projectname.example.com
2) https://api.example.com/projectname
3) None (users must configure with --server)
4) Other (specify URL)

Enter choice [1-4]:
```

## Standard Flags (NON-NEGOTIABLE)

### Universal Flags (ALL CLIs)

| Flag | Short | Description |
|------|-------|-------------|
| `--help` | `-h` | Show help |
| `--version` | `-v` | Show version |

**Only `-h` and `-v` have short forms. Everything else is long-form only.**

### Boolean/Truthy-Falsey Handling (CLI & Agent)

**CLI and Agent binaries use the SAME truthy/falsey parsing as the server.**

See PART 5: Boolean Handling for the complete implementation.

| Truthy | Falsey |
|--------|--------|
| `true`, `yes`, `on`, `1`, `enable`, `enabled` | `false`, `no`, `off`, `0`, `disable`, `disabled`, `none` |

**Usage in flags:**
```bash
weather-cli --public                    # Boolean flag (true)
weather-cli --public=yes                # Explicit truthy
weather-cli --public=no                 # Explicit falsey
weather-cli --expire=0                  # Falsey = no expiration
weather-cli --expire=disabled           # Falsey = no expiration
```

**Config file (cli.yml):**
```yaml
server:
  verify_ssl: yes        # Truthy
  auto_update: false     # Falsey
  notifications: enabled # Truthy
```

**ALL boolean inputs MUST use `config.ParseBool()` or `config.IsTruthy()` - NEVER `strconv.ParseBool()`.**

### Common Optional Flags (if needed)

| Flag | When to Include |
|------|-----------------|
| `--server` | Multi-server support (skip if single official site) |
| `--token` | Authenticated operations |
| `--config` | Multiple config profiles |
| `--output` | Multiple output formats (json/table/plain) |
| `--debug` | Debug mode |

### Flag Argument Syntax (ALL Binaries)

**All binaries accept BOTH `=` and space for flag values:**
```
--{flag}={value}    # Equals syntax
--{flag} {value}    # Space syntax
```

**Examples:**
```bash
--public=yes   OR  --public yes
--expire=24h   OR  --expire 24h
--limit=10     OR  --limit 10
--output=json  OR  --output json
```

### Project-Specific Flags (by service type)

**Search/Query CLI (minimal flags):**
```bash
# Args ARE the search - no flags needed for basic use
weather-cli golang tutorials           # Search
weather-cli --limit 10 golang          # With limit
weather-cli --output json golang       # JSON output
```

**Pastebin/Content CLI:**
```bash
# Smart detection handles input, flags for metadata
weather-cli notes.txt                          # File (detected), uses defaults
weather-cli notes.txt --public yes             # Public paste
weather-cli notes.txt --public no              # Private (requires auth)
weather-cli notes.txt --public unlisted        # Unlisted (default)
weather-cli notes.txt --expire 24h             # Expiration
weather-cli notes.txt --syntax python          # Syntax highlight
weather-cli notes.txt --author "John"          # Author name
```

**API/Data CLI:**
```bash
# Resource-specific flags
weather-cli get abc123                         # Get by ID
weather-cli list --limit 20 --offset 0         # Pagination
weather-cli delete abc123 --force              # Dangerous ops need confirm
```

### Flag Defaults from Config (NON-NEGOTIABLE)

**Every flag MUST have a corresponding config setting to change its default.**

```yaml
# cli.yml - defaults for flags
defaults:
  public: unlisted      # --public default (yes, no, unlisted)
  expire: 24h           # --expire default
  syntax: auto          # --syntax default
  output: table         # --output default (json, table, plain)
  limit: 20             # --limit default
```

**Precedence (highest to lowest):**
1. Command-line flag (`--public yes`)
2. Environment variable (`WEATHER_PUBLIC=yes`)
3. Config file (`defaults.public: yes`)
4. Hardcoded default

### Flag Guidelines

| Rule | Description |
|------|-------------|
| **Minimize flags** | Smart detection > explicit flags |
| **Config defaults** | Every flag has config equivalent |
| **No redundant flags** | If detectable, don't require flag |
| **Value flags** | `--public unlisted` not `--unlisted` |
| **Confirmation** | Destructive ops: `--force` or interactive confirm |

### Shell Completions (Built-in, NON-NEGOTIABLE)

**ALL binaries (server, agent, client) MUST support shell completions. Built into binary - no separate files.**

| Flag | Description |
|------|-------------|
| `--shell completions [SHELL]` | Print completion script to stdout |
| `--shell init [SHELL]` | Alias: prints eval-wrapped completions command |

**`[SHELL]` is OPTIONAL - both commands auto-detect from `$SHELL` env var if omitted.**

**`--shell init` is just a convenience wrapper:**
```bash
# These are equivalent:
eval "$(weather --shell init)"
eval "$(weather --shell init bash)"      # if $SHELL=/bin/bash

# init outputs the eval command, completions outputs the script:
weather --shell init        # → source <(weather --shell completions bash)
weather --shell completions # → (actual completion script)
```

**Supported shells:**

| Shell | Completion Support | Init Support |
|-------|-------------------|--------------|
| `bash` | Full | `source <(...)` |
| `zsh` | Full | `source <(...)` |
| `fish` | Full | `... \| source` |
| `sh` | Basic (POSIX) | `eval $(...)` |
| `dash` | Basic (POSIX) | `eval $(...)` |
| `ksh` | Basic | `eval $(...)` |
| `powershell` | Full | `Invoke-Expression` |
| `pwsh` | Full (PowerShell Core) | `Invoke-Expression` |

**Behavior:**
- `--shell completions` prints to stdout - user redirects with `> {file}`
- `--shell init` prints eval-ready command for shell rc file
- Auto-detect extracts shell name from `$SHELL` path (e.g., `/bin/bash` → `bash`)

**Usage examples:**
```bash
# Explicit shell specification
weather --shell completions bash > ~/.local/share/bash-completion/completions/weather
weather-cli --shell completions zsh > ~/.zsh/completions/_weather-cli
weather-agent --shell completions fish > ~/.config/fish/completions/weather-agent.fish
weather --shell completions powershell > ~/Documents/PowerShell/completions/weather.ps1

# Auto-detect shell (omit SHELL argument)
weather --shell completions > ~/completions/weather
weather-cli --shell init                    # auto-detect, print init
eval "$(weather --shell init)"              # auto-detect in eval

# Specific shell init
eval "$(weather-cli --shell init bash)"
eval "$(weather-agent --shell init zsh)"
weather --shell init fish | source
```

**Add to shell rc file:**
```bash
# ~/.bashrc, ~/.zshrc, ~/.config/fish/config.fish, etc.
eval "$(weather --shell init)"        # server (auto-detect)
eval "$(weather-cli --shell init)"    # client (auto-detect)
eval "$(weather-agent --shell init)"  # agent (auto-detect)
```

**Why built-in (not separate files):**

| Advantage | Description |
|-----------|-------------|
| **Always current** | Completions match binary version exactly |
| **Rename-friendly** | Works even if user renames binary |
| **No sync issues** | Can't have outdated completion files |
| **Self-contained** | No extra files to distribute/install |

**Implementation:**
```go
func handleShellCommand(args []string) {
    if len(args) < 1 {
        fmt.Fprintln(os.Stderr, "Usage: --shell [completions|init] [SHELL]")
        os.Exit(1)
    }

    cmd := args[0]
    shell := ""
    if len(args) > 1 {
        shell = args[1]
    } else {
        shell = detectShell()  // auto-detect from $SHELL
    }

    binaryName := filepath.Base(os.Args[0])

    switch cmd {
    case "completions":
        printCompletions(shell, binaryName)
    case "init":
        printInit(shell, binaryName)
    }
}

func detectShell() string {
    shellPath := os.Getenv("SHELL")
    if shellPath == "" {
        return "bash"  // default fallback
    }
    return filepath.Base(shellPath)  // /bin/zsh → zsh
}

func printCompletions(shell, binaryName string) {
    switch shell {
    case "bash":
        fmt.Print(generateBashCompletions(binaryName))
    case "zsh":
        fmt.Print(generateZshCompletions(binaryName))
    case "fish":
        fmt.Print(generateFishCompletions(binaryName))
    case "sh", "dash", "ksh":
        fmt.Print(generatePosixCompletions(binaryName))
    case "powershell", "pwsh":
        fmt.Print(generatePowershellCompletions(binaryName))
    default:
        fmt.Fprintf(os.Stderr, "Unsupported shell: %s\n", shell)
        os.Exit(1)
    }
}

func printInit(shell, binaryName string) {
    switch shell {
    case "bash":
        fmt.Printf("source <(%s --shell completions bash)\n", binaryName)
    case "zsh":
        fmt.Printf("source <(%s --shell completions zsh)\n", binaryName)
    case "fish":
        fmt.Printf("%s --shell completions fish | source\n", binaryName)
    case "sh", "dash", "ksh":
        fmt.Printf("eval \"$(%s --shell completions %s)\"\n", binaryName, shell)
    case "powershell", "pwsh":
        fmt.Printf("Invoke-Expression (& %s --shell completions powershell)\n", binaryName)
    default:
        fmt.Fprintf(os.Stderr, "Unsupported shell: %s\n", shell)
        os.Exit(1)
    }
}
```

### --help Output

```bash
$ weather-cli --help
weather-cli {projectversion} - CLI for weather

Usage:
  weather-cli [args] [flags]
  weather-cli                    # TUI mode (no args)

Flags:
  -h, --help                        Show help
  -v, --version                     Show version
      --shell completions [SHELL]   Print shell completions (auto-detect if SHELL omitted)
      --shell init [SHELL]          Print shell init command (auto-detect if SHELL omitted)

      --server URL                  Server URL (default: from config)
      --token TOKEN                 API token for authentication
      --token-file FILE             Read token from file
      --user NAME                   Target user or org (auto-detect, @user, +org)
      --config NAME                 Config profile name (default: cli.yml)
      --debug                       Debug output

  {project-specific flags listed here}

Shells: bash, zsh, fish, sh, dash, ksh, powershell, pwsh

Run without arguments for interactive TUI mode.
```

**If user renames binary:**
```bash
$ mypaste --help
mypaste {projectversion} - CLI client for weather API   # Shows actual binary name

Usage:
  mypaste [command] [flags]                     # Shows actual binary name
...
```

### --version Output

**MUST match server `--version` format. Shows ACTUAL binary name:**

```bash
$ weather-cli --version
weather-cli {projectversion} ({COMMIT_SHA}) built {BUILD_DATE}

# If renamed:
$ mypaste --version
mypaste {projectversion} ({COMMIT_SHA}) built {BUILD_DATE}   # Shows actual name
```

Same format as server:
```bash
$ pastebin --version
pastebin {projectversion} ({COMMIT_SHA}) built {BUILD_DATE}
```

## Commands

**CLI clients have project-specific commands only.** No standard commands required.

Example commands (project-dependent):
- `create`, `get`, `list`, `delete` (pastebin)
- `lookup`, `search`, `nearby` (airports)
- `random`, `search` (quotes)

**Notes:**
- Version and help are FLAGS (`--version`/`-v`, `--help`/`-h`), NOT commands
- No `config` command - edit `cli.yml` directly or use `--server`/`--token` flags
- No `tui` command - TUI launches automatically when no arguments provided
- Config file (`cli.yml`) is auto-created on first run with sane defaults

## Authentication

**Authentication requirements are PROJECT-DEPENDENT and ROUTE-DEPENDENT.**

| Auth Type | When Used |
|-----------|-----------|
| None | Public endpoints (e.g., `GET /api/v1/pastes/{id}`) |
| API Token | Protected endpoints, user-specific data |
| Session | Admin operations (if CLI supports admin features) |

**Token Storage:**
- Stored in `cli.yml` under `server.token`
- `--token` flag saves to cli.yml only if not already set (same as `--server`)
- Environment variable: `WEATHER_CLI_TOKEN` (does NOT save to config)

**Priority (highest to lowest):**
1. `--token` flag (saves only if config empty/invalid)
2. `WEATHER_CLI_TOKEN` environment variable
3. `server.token` in cli.yml

## HTTP Client Identity (NON-NEGOTIABLE)

### User-Agent Rule

**The CLI binary can be renamed by users, but the User-Agent MUST always use the original project name.**

| Aspect | Uses Filename | Uses Original Name |
|--------|---------------|-------------------|
| Display in `--help` | ✓ | |
| Display in `--version` | ✓ | |
| Error messages | ✓ | |
| **Config file path** | | ✓ |
| **User-Agent header** | | ✓ |

**Why?** The server uses User-Agent to identify client types for:
- Client-specific rate limits
- Client-specific settings/features
- Analytics and usage tracking
- Version compatibility checks

### User-Agent Format

```
weather-cli/{version}
```

**Examples (User-Agent uses compiled project name, not binary name):**

| Binary Name | User-Agent Header |
|-------------|-------------------|
| `weather-cli` | `weather-cli/1.2.3` |
| `mypaste` (renamed by user) | `weather-cli/1.2.3` |
| `pb` (renamed by user) | `weather-cli/1.2.3` |

### Implementation

The project name is compiled into the binary at build time:

```go
// Set at build time via -ldflags
var (
    // Original project name (compiled in)
    ProjectName = "pastebin"
    Version     = "1.2.3"
)

// GetUserAgent returns the fixed User-Agent regardless of binary name
func GetUserAgent() string {
    return fmt.Sprintf("%s-cli/%s", ProjectName, Version)
}

// GetBinaryName returns the actual executable name (for display)
func GetBinaryName() string {
    return filepath.Base(os.Args[0])
}
```

**Build command (CI/CD injects version from git tag):**
```bash
# VERSION comes from git tag (see PART 26/28 for version handling)
go build -ldflags "-X main.ProjectName=weather -X main.Version=${VERSION}" -o weather-cli ./src/client
```

### Server-Side Client Detection

The server can use the User-Agent to apply client-specific behavior:

```go
func getClientType(r *http.Request) string {
    ua := r.Header.Get("User-Agent")
    if strings.HasPrefix(ua, ProjectName+"-cli/") {
        return "cli"
    }
    if strings.Contains(ua, "Mozilla") || strings.Contains(ua, "Chrome") {
        return "browser"
    }
    return "api"
}
```

## Output Formats

### JSON

```bash
$ weather-cli get abc123 --output json
{
  "id": "abc123",
  "content": "Hello world example code snippet",
  "language": "go",
  "expires": "2025-01-20T12:00:00Z"
}
```

### Table

```bash
$ weather-cli list --output table
┌──────────┬─────────────────────────────────────────────┬──────────┬─────────────┐
│ ID       │ Content                                     │ Language │ Expires     │
├──────────┼─────────────────────────────────────────────┼──────────┼─────────────┤
│ abc123   │ Hello world example code snippet            │ go       │ 2025-01-20  │
│ def456   │ Python decorator pattern example            │ python   │ 2025-01-21  │
│ ghi789   │ Bash script for deployment                  │ bash     │ 2025-01-22  │
└──────────┴─────────────────────────────────────────────┴──────────┴─────────────┘
```

### Plain

```bash
$ weather-cli get abc123 --output plain
Hello world example code snippet
```

## Project-Specific Commands

Each project defines its own commands based on its API.

### Smart Argument Detection (NON-NEGOTIABLE)

**Minimize flags. Detect intent from arguments.**

**Search/Query Services:**
```bash
# Bare args = search term (no --query flag needed)
weather-cli golang tutorials        # Search for "golang tutorials"
weather-cli "exact phrase"          # Quoted = exact match
weather-cli --limit 5 golang        # Flags before search term OK
```

**Content/Paste Services:**
```bash
# Detection order: stdin → file → directory → text
echo "hello" | weather-cli          # stdin detected → paste stdin
weather-cli notes.txt               # File exists → paste file content
weather-cli /path/to/dir            # Directory → error or list
weather-cli "some text here"        # Not file → paste as text
```

**Detection Logic:**
```go
func detectInput(args []string) (content string, source string) {
    // 1. Check stdin (pipe or redirect)
    if !term.IsTerminal(int(os.Stdin.Fd())) {
        data, _ := io.ReadAll(os.Stdin)
        return string(data), "stdin"
    }

    // 2. If arg provided, check what it is
    if len(args) > 0 {
        arg := args[0]

        // Is it a file?
        if info, err := os.Stat(arg); err == nil {
            if info.IsDir() {
                return "", "error:directory"  // or list files
            }
            data, _ := os.ReadFile(arg)
            return string(data), "file:" + arg
        }

        // Not a file = treat as text
        return strings.Join(args, " "), "text"
    }

    return "", "error:no-input"
}
```

**Result: Cleaner commands:**

| Instead of | Use |
|------------|-----|
| `cli create --file notes.txt` | `cli notes.txt` |
| `cli create --text "hello"` | `cli "hello"` |
| `cat file \| cli create --stdin` | `cat file \| cli` |
| `cli search --query "golang"` | `cli golang` |

**Explicit flags still work (override detection):**
```bash
weather-cli --file notes.txt        # Force file mode
weather-cli --text "notes.txt"      # Force text mode (not file)
```

## Build Integration

**CLI builds follow the same container-only development rules as the server. See PART 26: MAKEFILE for complete targets.**

### Local Development (Makefile + Docker)

```bash
# Quick dev build (server + CLI + agent if exist)
make dev
# Output: ${TMPDIR}/${PROJECTORG}.XXXXXX/weather, weather-cli, weather-agent

# Production test build
make host
# Output: binaries/weather, binaries/weather-cli (with version)

# Full release (all 8 platforms)
make build
# Output: binaries/weather-{os}-{arch}, binaries/weather-cli-{os}-{arch}
```

### CI/CD (Direct go build - NOT Makefile)

```bash
# CI/CD uses actions/setup-go@v5, NOT Docker containers
# See PART 28: CI/CD WORKFLOWS for complete examples
go build -ldflags "${LDFLAGS}" -o $WEATHER-cli ./src/client
```

### Directory Structure

```
weather/
├── src/                    # Server application
│   ├── main.go
│   ├── config/
│   ├── server/
│   ├── ...
│   └── client/             # CLI client (if project has CLI)
│       ├── main.go         # Entry point, mode detection
│       ├── cmd/            # Command implementations
│       │   ├── root.go     # Root command, --help, --version flags
│       │   └── {project-specific}.go  # e.g., create.go, get.go, list.go
│       ├── tui/            # TUI implementation (auto-launched)
│       │   ├── app.go      # Main TUI application
│       │   ├── theme.go    # Theme colors (dark default)
│       │   ├── view/       # View components
│       │   └── component/  # Reusable components
│       └── api/            # API client library
│           └── client.go
├── go.mod
├── Makefile
└── ...
```

## TUI Requirements (NON-NEGOTIABLE)

### Window Awareness

**CLI MUST be window-aware - detect and respond to terminal dimensions.**

```go
// Get terminal dimensions
func getTerminalSize() (width, height int) {
    width, height, _ = term.GetSize(int(os.Stdout.Fd()))
    return
}

// Handle window resize (bubbletea)
func (m Model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {
    switch msg := msg.(type) {
    case tea.WindowSizeMsg:
        m.width = msg.Width
        m.height = msg.Height
        // Reflow content to fit new dimensions
        m.recalculateLayout()
    }
    return m, nil
}
```

| Requirement | Description |
|-------------|-------------|
| **Detect dimensions** | Get terminal columns/rows on startup |
| **Handle resize** | Respond to SIGWINCH, reflow content |
| **Minimum size** | Graceful degradation below 80x24 |
| **Responsive layout** | Adapt UI to available space |
| **Compact mode** | Auto-enable for small screens |

### Terminal Size Breakpoints (NON-NEGOTIABLE)

**Phone SSH and small terminal support is required. Many users work remotely via phone.**

| Breakpoint | Columns | Rows | Mode | Behavior |
|------------|---------|------|------|----------|
| **Large** | ≥120 | ≥40 | Full | All features, full ASCII art, sidebars |
| **Standard** | 80-119 | 24-39 | Normal | Standard layout, simplified art |
| **Compact** | 60-79 | 16-23 | Compact | No ASCII art, abbreviated headers |
| **Minimal** | 40-59 | 10-15 | Minimal | Single column, no borders, text only |
| **Micro** | <40 | <10 | Micro | Critical info only, scrollable |

```go
// src/common/terminal/size.go
package terminal

import (
    "os"
    "golang.org/x/term"
)

type SizeMode int

const (
    SizeModeMicro   SizeMode = iota // <40 cols or <10 rows
    SizeModeMinimal                  // 40-59 cols or 10-15 rows
    SizeModeCompact                  // 60-79 cols or 16-23 rows
    SizeModeNormal                   // 80-119 cols and 24-39 rows
    SizeModeLarge                    // ≥120 cols and ≥40 rows
)

func GetTerminalSize() (width, height int, mode SizeMode) {
    width, height, _ = term.GetSize(int(os.Stdout.Fd()))

    // Default if detection fails
    if width == 0 {
        width = 80
    }
    if height == 0 {
        height = 24
    }

    // Determine mode based on SMALLEST dimension constraint
    switch {
    case width < 40 || height < 10:
        mode = SizeModeMicro
    case width < 60 || height < 16:
        mode = SizeModeMinimal
    case width < 80 || height < 24:
        mode = SizeModeCompact
    case width < 120 || height < 40:
        mode = SizeModeNormal
    default:
        mode = SizeModeLarge
    }

    return
}

func (m SizeMode) String() string {
    return [...]string{"micro", "minimal", "compact", "normal", "large"}[m]
}

func (m SizeMode) ShowASCIIArt() bool {
    return m >= SizeModeNormal
}

func (m SizeMode) ShowBorders() bool {
    return m >= SizeModeCompact
}

func (m SizeMode) ShowSidebar() bool {
    return m >= SizeModeLarge
}

func (m SizeMode) MaxTableColumns() int {
    switch m {
    case SizeModeMicro:
        return 2
    case SizeModeMinimal:
        return 3
    case SizeModeCompact:
        return 4
    case SizeModeNormal:
        return 6
    default:
        return 10
    }
}
```

### Responsive UI Patterns

**Tables:**
```go
// Truncate columns based on terminal width
func (m Model) renderTable() string {
    cols := m.sizeMode.MaxTableColumns()

    // Always show: ID, Name (or primary identifier)
    // Conditionally show: other columns based on space

    switch m.sizeMode {
    case terminal.SizeModeMicro:
        // ID only, vertically scrollable
        return m.renderVerticalList()
    case terminal.SizeModeMinimal:
        // ID + Name, no borders
        return m.renderSimpleTable(2)
    case terminal.SizeModeCompact:
        // ID + Name + Status, light borders
        return m.renderCompactTable(3)
    default:
        // Full table with all columns
        return m.renderFullTable()
    }
}
```

**Help Text:**
```go
func (m Model) renderHelp() string {
    switch m.sizeMode {
    case terminal.SizeModeMicro, terminal.SizeModeMinimal:
        return "?:help q:quit"
    case terminal.SizeModeCompact:
        return "↑↓:nav │ enter:select │ ?:help │ q:quit"
    default:
        return "↑/↓: Navigate │ Enter: Select │ /: Search │ ?: Help │ q: Quit"
    }
}
```

### Minimum Features

| Feature | Required |
|---------|----------|
| Keyboard navigation | ✓ |
| Search/filter | ✓ |
| Help screen (?) | ✓ |
| Quit (q/Ctrl+C) | ✓ |
| Window resize handling | ✓ |
| Responsive layout | ✓ |
| Error display | ✓ |
| Professional appearance | ✓ |

### Required Libraries

| Library | Purpose |
|---------|---------|
| `github.com/charmbracelet/bubbletea` | TUI framework |
| `github.com/charmbracelet/bubbles` | TUI components |
| `github.com/charmbracelet/lipgloss` | TUI styling |
| `golang.org/x/term` | Terminal detection/dimensions |

### Theme Support

**TUI MUST support themes per PART 16 theme rules. Uses same colors as server frontend.**

```go
// src/client/tui/theme.go
package tui

import "github.com/charmbracelet/lipgloss"

type Theme struct {
    Name       string
    Background lipgloss.Color
    Foreground lipgloss.Color
    Primary    lipgloss.Color
    Secondary  lipgloss.Color
    Accent     lipgloss.Color
    Error      lipgloss.Color
    Success    lipgloss.Color
    Warning    lipgloss.Color
    Muted      lipgloss.Color
}

// Dark theme (default) - matches server frontend
var DarkTheme = Theme{
    Name:       "dark",
    Background: lipgloss.Color("#282a36"),
    Foreground: lipgloss.Color("#f8f8f2"),
    Primary:    lipgloss.Color("#bd93f9"),
    Secondary:  lipgloss.Color("#6272a4"),
    Accent:     lipgloss.Color("#8be9fd"),
    Error:      lipgloss.Color("#ff5555"),
    Success:    lipgloss.Color("#50fa7b"),
    Warning:    lipgloss.Color("#f1fa8c"),
    Muted:      lipgloss.Color("#44475a"),
}

// Light theme (optional)
var LightTheme = Theme{
    Name:       "light",
    Background: lipgloss.Color("#ffffff"),
    Foreground: lipgloss.Color("#282a36"),
    Primary:    lipgloss.Color("#6c5ce7"),
    Secondary:  lipgloss.Color("#636e72"),
    Accent:     lipgloss.Color("#0984e3"),
    Error:      lipgloss.Color("#d63031"),
    Success:    lipgloss.Color("#00b894"),
    Warning:    lipgloss.Color("#fdcb6e"),
    Muted:      lipgloss.Color("#dfe6e9"),
}

// Current theme (set from config)
var CurrentTheme = DarkTheme
```

**Theme is set in cli.yml:**
```yaml
tui:
  theme: dark    # dark (default) or light
```

### TUI Implementation Guidance (NON-NEGOTIABLE)

**Small terminal support is NOT optional. Phone SSH is a primary use case.**

**Viewport Management:**
```go
// Always calculate usable space
func (m Model) calculateLayout() {
    // Reserve space for chrome
    headerHeight := 1
    footerHeight := 1
    borderHeight := 0

    if m.sizeMode >= terminal.SizeModeCompact {
        borderHeight = 2 // top + bottom
    }

    m.viewportHeight = m.height - headerHeight - footerHeight - borderHeight
    m.viewportWidth = m.width

    if m.sizeMode >= terminal.SizeModeLarge && m.showSidebar {
        m.viewportWidth = m.width - m.sidebarWidth
    }

    // Ensure minimum usable space
    if m.viewportHeight < 3 {
        m.viewportHeight = 3
    }
    if m.viewportWidth < 20 {
        m.viewportWidth = 20
    }
}
```

**Content Truncation:**
```go
// Truncate text to fit terminal width
func truncate(s string, maxWidth int) string {
    if len(s) <= maxWidth {
        return s
    }
    if maxWidth <= 3 {
        return s[:maxWidth]
    }
    return s[:maxWidth-3] + "..."
}

// Truncate with ellipsis in middle (for paths/URLs)
func truncateMiddle(s string, maxWidth int) string {
    if len(s) <= maxWidth {
        return s
    }
    if maxWidth <= 5 {
        return s[:maxWidth]
    }
    half := (maxWidth - 3) / 2
    return s[:half] + "..." + s[len(s)-half:]
}
```

**Scrolling for Small Screens:**
```go
// Ensure scrolling works on tiny terminals
func (m Model) ensureVisible(index int) {
    if index < m.scrollOffset {
        m.scrollOffset = index
    }
    if index >= m.scrollOffset + m.viewportHeight {
        m.scrollOffset = index - m.viewportHeight + 1
    }
}

// Page size based on viewport
func (m Model) pageSize() int {
    ps := m.viewportHeight - 2
    if ps < 1 {
        ps = 1
    }
    return ps
}
```

**Phone-Friendly Key Bindings:**
```go
// Single-key bindings work better on mobile keyboards
var keyBindings = map[string]string{
    "up":     "k",    // vim-style, single key
    "down":   "j",
    "left":   "h",
    "right":  "l",
    "select": "enter",
    "back":   "escape",  // Also 'b' as alternative
    "quit":   "q",
    "help":   "?",
    "search": "/",
    "top":    "g",       // Go to top
    "bottom": "G",       // Go to bottom
}
```

**Testing Small Terminals:**
```bash
# Test with different terminal sizes
resize -s 10 40   # Phone portrait (micro)
resize -s 16 60   # Phone landscape (minimal)
resize -s 24 80   # Standard terminal
resize -s 40 120  # Large monitor

# Or use stty
stty rows 10 cols 40
```

## Error Handling

### Exit Codes

| Code | Meaning |
|------|---------|
| 0 | Success |
| 1 | General error |
| 2 | Configuration error |
| 3 | Connection error |
| 4 | Authentication error |
| 5 | Not found |
| 64 | Usage error (bad arguments) |

### Error Messages

```bash
# Connection error
$ weather-cli list
Error: cannot connect to server at https://weather.example.com
  Check your network connection and server address.
  Use --server to specify a different server.

# Auth error
$ weather-cli admin users --token invalid
Error: authentication failed
  Your API token is invalid or expired.
  Update server.token in cli.yml or use --token flag.

# Not found
$ weather-cli get abc123
Error: resource not found: abc123
```

## --version Extended Output

When server is reachable, `--version` can show extended info:

```bash
$ weather-cli --version
weather-cli {projectversion} ({COMMIT_SHA}) built {BUILD_DATE}

Server: https://weather.example.com
Server Version: {projectversion} (compatible)

Build Info:
  Go: {GO_VERSION}
  OS/Arch: {GOOS}/{GOARCH}
```

**Version compatibility check:** CLI queries server `/api/v1/version` and warns if versions differ significantly.

## Determining If Project Needs CLI

**Key Question: Would users benefit from terminal-based access to your service?**

### When CLI is Needed vs Not Needed

| Scenario | CLI Needed? | Why |
|----------|-------------|-----|
| Developers querying API data | ✅ YES | `mycli search term` faster than browser |
| Sysadmins managing servers | ✅ YES | Terminal is their native environment |
| CI/CD pipeline integration | ✅ YES | Scripts need programmatic access |
| Bulk data operations | ✅ YES | `mycli import file.csv` beats web forms |
| Simple consumer web app | ❌ NO | Users expect browser, not terminal |
| Photo sharing for families | ❌ NO | Grandma won't use CLI |
| Single-purpose widget | ❌ NO | Too simple, just use curl |
| Mobile-first application | ❌ NO | No terminal on phones |

### Project Examples: CLI vs No CLI

**Projects that DO benefit from CLI:**

| Project Type | Example Names | CLI Use Case |
|--------------|---------------|--------------|
| **Data Lookup APIs** | IP geolocation, airport codes, country data | `mycli lookup JFK` quick terminal queries |
| **Developer Tools** | GitHub CLI, Vercel CLI, Netlify CLI | Developers live in terminal |
| **DevOps/Infra** | kubectl, docker, terraform | Automation and scripting |
| **Pastebin/Snippet** | GitHub Gist, ix.io, termbin | `cat file \| mycli paste` |
| **Git Hosting** | Gitea, Forgejo (via gh/glab) | PR/issue management from terminal |
| **Password Manager** | Bitwarden CLI, 1Password CLI | Secure scripted access |
| **Note Taking** | Standard Notes CLI, Joplin CLI | Quick capture from terminal |
| **URL Shortener** | YOURLS, Shlink | `mycli shorten https://...` |
| **Bookmark Manager** | Linkding, Shaarli | Batch import/export |
| **Time Tracking** | Toggl CLI, Clockify CLI | `mycli start "task"` without context switch |

**Projects that do NOT need CLI:**

| Project Type | Example Names | Why No CLI |
|--------------|---------------|------------|
| **Photo Sharing** | Immich, Photoprism, Google Photos | Visual content needs visual interface |
| **Social Media** | Mastodon, Pixelfed | Social experience is visual |
| **E-commerce** | WooCommerce, Shopify | Shopping is visual/browsing |
| **Video Streaming** | Jellyfin, Plex | Watching video requires GUI |
| **Dating/Social Apps** | Any social app | Human interaction, not automation |
| **Games** | Any game | Games need GUI |
| **CMS/Blogs** | WordPress, Ghost | Content creation is visual |
| **Forum/Community** | Discourse, Flarum | Discussion is web-based |
| **Calendar/Scheduling** | Calendly, Cal.com | Visual scheduling |
| **Survey/Forms** | Typeform, Google Forms | Form filling is web-native |

### CLI Decision Tree

```
Is your target user comfortable in a terminal?
│
├─► YES (developers, sysadmins, power users)
│   │
│   ├─► Would terminal access save them time?
│   │   └─► YES → CLI beneficial
│   │
│   ├─► Would scripting/automation be valuable?
│   │   └─► YES → CLI beneficial
│   │
│   └─► Is data lookup/search a common use case?
│       └─► YES → CLI beneficial
│
└─► NO (general consumers, non-technical users)
    └─► Skip CLI - focus on web/mobile UI
```

### CLI vs Just Using curl

**When CLI adds value over raw curl:**

| Feature | curl | Dedicated CLI |
|---------|------|---------------|
| Authentication | Manual header management | `mycli login` saves token |
| Output formatting | Raw JSON | Pretty tables, colors |
| Pagination | Manual URL building | `mycli list --page 2` |
| Complex operations | Multi-step scripts | Single commands |
| Offline caching | Not possible | Local cache support |
| Tab completion | None | Command/arg completion |
| Interactive mode | None | TUI for browsing |

**If users would just use curl anyway, CLI is worthwhile.**
**If users would never touch terminal, skip CLI.**

### Quick Decision

| If your users are... | CLI? |
|---------------------|------|
| Developers | ✅ Yes |
| Sysadmins/DevOps | ✅ Yes |
| Technical power users | ✅ Yes |
| General consumers | ❌ No |
| Non-technical business users | ❌ No |
| Mobile-only users | ❌ No |

---

## Agent Binary (OPTIONAL - NON-NEGOTIABLE WHEN IMPLEMENTED)

**Agent is OPTIONAL and only needed for very specific project types.** Most projects do NOT need an agent.

### When Agent is Needed vs Not Needed

**Key Question: Does the server need to reach INTO remote hosts to collect data or execute commands?**

| Scenario | Agent Needed? | Why |
|----------|---------------|-----|
| Server collects CPU/RAM/disk from 50 hosts | ✅ YES | Agent runs on each host, pushes metrics |
| Users upload files via web form | ❌ NO | User initiates, server receives |
| API serves random quotes | ❌ NO | Server has all data locally |
| Execute shell commands on remote servers | ✅ YES | Agent receives commands, executes locally |
| CI/CD pipeline runner on build machines | ✅ YES | Agent pulls jobs, runs builds |
| Pastebin with user submissions | ❌ NO | Pull-based, users push data |
| Centralized log aggregation | ✅ YES | Agent tails local logs, ships to server |
| Weather API (fetches from external sources) | ❌ NO | Server fetches, no host access needed |
| Backup orchestration across servers | ✅ YES | Agent runs backup commands locally |
| Git hosting (Gitea, Forgejo) | ❌ NO | Users push/pull via git protocol |

### Project Examples: Agent vs No Agent

**Projects that DO need an agent:**

| Project Type | Example Names | What Agent Does |
|--------------|---------------|-----------------|
| **System Monitoring** | Zabbix, Nagios, Beszel, Netdata | Collects CPU, RAM, disk, network stats from each host |
| **Remote Desktop/Shell** | MeshCentral, RustDesk, Teleport | Provides remote access tunnel from host |
| **Log Management** | Fluentd, Filebeat, Vector, Loki | Tails log files, ships to central server |
| **CI/CD Runners** | GitLab Runner, GitHub Actions Runner, Drone | Pulls jobs from server, executes builds |
| **Backup Agents** | Restic, Borg, Velero, Bacula | Runs backup commands, ships data to server |
| **Config Management** | Puppet Agent, Salt Minion, CFEngine | Pulls and applies configuration from server |
| **Security Scanning** | OSSEC, Wazuh, Falco, Lynis | Monitors files, processes, runs audits |
| **Container Orchestration** | Kubernetes Kubelet, Nomad Client | Runs containers as directed by control plane |
| **Network Monitoring** | Prometheus Node Exporter, Telegraf | Exposes host metrics for scraping |
| **Update Management** | Landscape Client, WSUS Client | Checks for and applies updates |

**Projects that do NOT need an agent:**

| Project Type | Example Names | Why No Agent |
|--------------|---------------|--------------|
| **Content APIs** | Jokes API, Quotes API, Facts API | Data is on server, clients just fetch |
| **Pastebin/URL Shortener** | Hastebin, YOURLS, Shlink | Users push content, server stores it |
| **Git Hosting** | Gitea, Forgejo, GitLab | Git protocol handles push/pull |
| **Image Hosting** | Immich, Photoprism, Piwigo | Users upload, server stores/serves |
| **Chat/Forum** | Mattermost, Discourse, Flarum | Users connect via web/API |
| **Wiki/Docs** | Wiki.js, BookStack, Outline | Users edit via web interface |
| **File Sharing** | Nextcloud, Seafile, FileBrowser | Web/WebDAV uploads, no host access |
| **Media Server** | Jellyfin, Plex, Navidrome | Serves content from local storage |
| **Auth/SSO** | Authentik, Authelia, Keycloak | Applications connect to auth server |
| **Status Pages** | Uptime Kuma, Gatus, Cachet | Server checks endpoints (pull-based) |

### Agent Architecture Decision Tree

```
Does your server need to:
│
├─► Collect data FROM remote hosts (metrics, logs, files)?
│   └─► YES → Agent needed (runs on each host, pushes to server)
│
├─► Execute commands ON remote hosts (shell, backup, updates)?
│   └─► YES → Agent needed (receives commands from server)
│
├─► Run jobs/tasks ON remote machines (builds, scans)?
│   └─► YES → Agent needed (pulls jobs, executes locally)
│
├─► Provide remote access TO hosts (shell, desktop, file transfer)?
│   └─► YES → Agent needed (establishes reverse tunnel)
│
└─► Just serve an API/web interface that clients call?
    └─► NO agent - users/clients connect TO your server
```

### Agent vs Webhook/API Callback

**Don't confuse agents with webhooks:**

| Mechanism | Direction | Use Case |
|-----------|-----------|----------|
| **Agent** | Host → Server (persistent) | Continuous metrics, always-on remote access |
| **Webhook** | External → Server (triggered) | Event notifications, CI triggers |
| **API Poll** | Server → External (scheduled) | Weather data, external service status |

**Agent = persistent daemon on remote host reporting to central server**

### Determining If YOUR Project Needs Agent

Answer these questions for your specific project:

1. **Where does the data originate?**
   - On user devices → No agent (users submit data)
   - On remote servers you manage → Agent likely needed

2. **Who initiates the connection?**
   - User/client initiates → No agent (standard API)
   - Server needs to reach hosts → Agent needed

3. **What runs on remote machines?**
   - Nothing (just users with browsers) → No agent
   - Background daemon collecting/executing → Agent needed

4. **Is it push or pull?**
   - Server pulls from external APIs → No agent
   - Hosts push data to server → Agent needed

### Project Types That Need Agent

| Category | Examples | Agent Purpose |
|----------|----------|---------------|
| **Monitoring** | Zabbix, Nagios, Prometheus Node Exporter | Host metrics, health checks |
| **Remote Management** | MeshCentral, RustDesk, TeamViewer | Remote shell, desktop, file transfer |
| **System Monitor** | Beszel, Netdata, Glances | Real-time system stats |
| **Log Shipping** | Fluentd, Filebeat, Vector | Tail and forward logs |
| **Backup** | Restic, Borg, Duplicati | Execute local backups |
| **Config Management** | Puppet, Ansible (pull mode), Salt | Apply configurations |
| **Security/Compliance** | OSSEC, Wazuh, Lynis | Security scanning, audit |

### Agent Runs on Host, NOT Container (NON-NEGOTIABLE)

**Agents MUST run directly on the host OS, not in containers.**

| Deployment | Supported | Reason |
|------------|-----------|--------|
| Direct on host | ✅ Yes | Full system access, accurate metrics |
| systemd service | ✅ Yes | Preferred for Linux |
| Windows service | ✅ Yes | Preferred for Windows |
| launchd daemon | ✅ Yes | Preferred for macOS |
| Docker container | ❌ No | Limited system visibility |
| Kubernetes pod | ❌ No | Cannot monitor host properly |

### Overview

| Attribute | Value |
|-----------|-------|
| Binary naming | `weather-agent-{os}-{arch}` |
| Examples | `monitor-agent-linux-amd64`, `monitor-agent-windows-arm64` |
| Versioning | Same as server and CLI client |
| Build | Part of same Makefile (`make build` builds all if `src/agent/` exists) |
| Config file | `{config_dir}/agent.yml` (same dir as server) |
| Data directory | `{data_dir}/` (same as server) |
| Database | `{data_dir}/db/agent.db` (if needed, same dir as server) |
| Privileges | **Root/Admin required** (for full system access) |
| Update mechanism | Same as CLI client (self-update) |

### Agent Binary Structure (Same as Server)

**Agent shares the same CLI structure, banner, and modes as the server binary (minus setup token).**

| Component | Server | Agent | Notes |
|-----------|--------|-------|-------|
| Startup banner | ✅ | ✅ | Responsive, terminal-aware |
| Mode line | ✅ | ✅ | Shows production/development |
| Debug flag | ✅ | ✅ | Enables verbose logging |
| Service management | ✅ | ✅ | install/uninstall/start/stop |
| Self-update | ✅ | ✅ | --update flag |
| Setup token | ✅ | ❌ | Agent uses server-issued token |
| Web UI | ✅ | ❌ | Agent is headless |

### Agent Startup Banner

```
┌────────────────────────────────────────┐
│  ███╗   ███╗ ██████╗ ███╗   ██╗        │
│  ████╗ ████║██╔═══██╗████╗  ██║        │
│  ██╔████╔██║██║   ██║██╔██╗ ██║        │
│  ██║╚██╔╝██║██║   ██║██║╚██╗██║        │
│  ██║ ╚═╝ ██║╚██████╔╝██║ ╚████║        │
│  ╚═╝     ╚═╝ ╚═════╝ ╚═╝  ╚═══╝        │
│                                  AGENT │
└────────────────────────────────────────┘

🤖 monitor-agent v1.0.0
🔒 Running in mode: production

📡 Server: https://monitor.example.com
🏷️  Hostname: web-server-01
🏷️  Tags: production, web-tier

✅ Connected to server
```

**Compact banner (60-79 cols):**
```
🤖 monitor-agent v1.0.0
🔒 Mode: production
📡 https://monitor.example.com
🏷️  web-server-01
✅ Connected
```

**Minimal banner (<60 cols):**
```
monitor-agent 1.0.0
web-server-01 → monitor.example.com
Connected
```

### Agent Flags (NON-NEGOTIABLE)

**Same flag style as server binary, EXCEPT no `--port` or `--address` (agents don't serve web).**

| Server Flag | Agent | Reason |
|-------------|-------|--------|
| `--port` | ❌ No | Agent doesn't serve HTTP |
| `--address` | ❌ No | Agent doesn't listen for connections |
| `--config` | ✅ Yes | Same config directory |
| `--data` | ✅ Yes | Same data directory |
| `--status` | ✅ Yes | Health check (exit 0=healthy, 1=unhealthy) |
| `--service` | ✅ Yes | Service management |
| `--update` | ✅ Yes | Self-update |

```bash
# Information
--help, -h                    # Show help
--version, -v                 # Show version (same format as server)
--shell completions [SHELL]   # Print shell completions (auto-detect if SHELL omitted)
--shell init [SHELL]          # Print shell init command (auto-detect if SHELL omitted)
--status                      # Show status and health (exit 0=healthy, 1=unhealthy)

# Configuration
--config {path}               # Config directory (default: {config_dir})
--data {path}                 # Data directory override
--log {path}                  # Log directory override

# Connection (can also be set in agent.yml)
--server {url}                # Server URL to connect to
--token {token}               # Authentication token (from server)

# Runtime
--mode {production|development}  # Force mode (auto-detected by default)
--debug                       # Enable debug logging (implies development features)

# Commands (subcommands like server)
status                        # Show agent status
test                          # Test server connection
register                      # Interactive registration with server

# Service management (same as server)
--service {install|uninstall|start|stop|restart|status}

# Updates (same as server/CLI)
--update [check|yes]          # Check for or perform self-update
```

### Agent --help Output

```bash
$ weather-agent --help
weather-agent {projectversion} - Agent for weather

Usage:
  weather-agent [flags]
  weather-agent [command]

Commands:
  status                        Show agent status
  test                          Test server connection
  register                      Interactive registration

Flags:
  -h, --help                        Show help
  -v, --version                     Show version
      --shell completions [SHELL]   Print shell completions (auto-detect if SHELL omitted)
      --shell init [SHELL]          Print shell init command (auto-detect if SHELL omitted)

      --config DIR                  Config directory
      --data DIR                    Data directory
      --log DIR                     Log directory
      --server URL                  Server URL to connect to
      --token TOKEN                 Authentication token

      --mode {production|development}  Application mode
      --debug                       Enable debug mode
      --status                      Show agent health

      --service CMD                 Service management (install|uninstall|start|stop|restart)
      --update [CMD]                Check/perform self-update

Shells: bash, zsh, fish, sh, dash, ksh, powershell, pwsh
```

### Agent Commands (NON-NEGOTIABLE)

**Agent has subcommands similar to server:**

```bash
# Default: run agent (foreground)
weather-agent

# Status: show current agent status
weather-agent status
  Agent: monitor-agent v1.0.0
  Hostname: web-server-01
  Server: https://monitor.example.com
  Status: Connected (5m 32s)
  Last Report: 2025-01-15 10:30:00
  Next Report: 2025-01-15 10:31:00

# Test: verify server connection
weather-agent test
  Testing connection to https://monitor.example.com...
  ✅ Connection successful
  ✅ Authentication valid
  ✅ Agent registered

# Connect: one-liner from server panel (preferred)
weather-agent --server https://monitor.example.com --token adm_agt_abc123def456...
  Connecting to https://monitor.example.com...
  ✅ Connection successful
  ✅ Token validated
  ✅ Agent registered as "web-server-01"

  Config saved to: /etc/projectorg/projectname/agent.yml
  Installing service...
  ✅ Service installed and started

  Agent is now sending data to server for admin scope.

# Service management
weather-agent --service install   # Install as system service
weather-agent --service start     # Start service
weather-agent --service stop      # Stop service
weather-agent --service status    # Show service status
weather-agent --service uninstall # Remove service
```

### Agent Setup Process (NON-NEGOTIABLE)

**Agent setup is initiated from the SERVER admin panel, NOT via setup token:**

```
┌─────────────────────────────────────────────────────────────┐
│                    AGENT SETUP FLOW                         │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  1. Generate token (admin/user/org panel)                   │
│     └─→ Server generates complete command string            │
│     └─→ Display one-liner with [Copy to Clipboard]          │
│                                                             │
│  2. On Target Host (one command)                            │
│     └─→ Paste and run the one-liner:                        │
│         weather-agent --server {url} --token {token}  │
│     └─→ Agent connects, registers, saves config             │
│     └─→ Server shows notification: "{name} has connected"   │
│                                                             │
│  3. Agent auto-starts and sends data                        │
│     └─→ Agent installs itself as service (if root)          │
│     └─→ Begins sending data to server                       │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**Server generates the complete command:**
```go
func GenerateAgentCommand(serverURL, token string) string {
    return fmt.Sprintf("%s-agent --server %s --token %s",
        projectName, serverURL, token)
}
```

### Agent Token Format

**Agent tokens are scoped to their owner (admin, user, or org):**

| Scope | Token Prefix | Issued By | Route |
|-------|--------------|-----------|-------|
| Admin | `adm_agt_` | Admin panel | `/api/v1/admin/server/agents/*` |
| User | `usr_agt_` | User settings | `/api/v1/users/agents/*` |
| Org | `org_agt_` | Org settings | `/api/v1/orgs/{slug}/agents/*` |

```go
// Agent token generation (server-side) - scoped by owner type
func GenerateAgentToken(scope AgentScope) string {
    switch scope {
    case ScopeAdmin:
        return "adm_agt_" + generateSecureRandom(32)
    case ScopeUser:
        return "usr_agt_" + generateSecureRandom(32)
    case ScopeOrg:
        return "org_agt_" + generateSecureRandom(32)
    }
    return ""
}
```

### Agent Registration API

**Same pattern for all scopes (see PART 16 for full API):**

**Endpoint:** `POST {base}/register` (where {base} = scope route)

| Scope | Endpoint |
|-------|----------|
| Admin | `POST /api/v1/admin/server/agents/register` |
| User | `POST /api/v1/users/agents/register` |
| Org | `POST /api/v1/orgs/{slug}/agents/register` |

**Request:**
```json
{
  "token": "adm_agt_abc123def456ghi789jkl012mno345pqr678",
  "hostname": "web-server-01",
  "os": "linux",
  "arch": "amd64",
  "version": "1.0.0",
  "tags": ["production", "web-tier"]
}
```

**Response (success):**
```json
{
  "ok": true,
  "data": {
    "agent_id": "uuid-here",
    "name": "web-server-01",
    "scope": "admin",
    "server_time": "2025-01-15T10:00:00Z"
  }
}
```

**Response (error):**
```json
{
  "ok": false,
  "error": "TOKEN_INVALID",
  "message": "Agent token is invalid or expired"
}
```

### agent.yml Configuration (NON-NEGOTIABLE)

**EVERYTHING must be configurable via agent.yml. Sane defaults match server where applicable.**

**File: `{config_dir}/agent.yml`** (same directory as server.yml)

```yaml
# /etc/apimgr/weather/agent.yml (root)
# ~/.config/apimgr/weather/agent.yml (user)
# Agent configuration - ALL options with defaults

# Server connection
server:
  primary: ""                      # Server URL (required, set during registration)
  cluster: []                      # Auto-discovered cluster nodes
  timeout: 30                      # Request timeout in seconds (match server default)
  retry: 3                         # Retry attempts on failure
  retry_delay: 5                   # Seconds between retries
  reconnect_delay: 10              # Seconds before reconnect attempt

# Authentication
auth:
  token: ""                        # Agent token ({scope}_agt_xxx, see PART 11)
  token_file: ""                   # Read token from file instead

# Agent identity
identity:
  hostname: ""                     # Hostname (auto-detect if empty)
  display_name: ""                 # Friendly name (defaults to hostname)
  tags: []                         # Tags for grouping ["production", "web-tier"]
  labels: {}                       # Key-value labels {environment: prod, tier: web}

# Data collection (project-specific)
collection:
  enabled: true                    # Enable data collection
  interval: 60                     # Collection interval in seconds
  batch_size: 100                  # Max items per batch
  buffer_size: 1000                # Max buffered items if offline

# Logging
logging:
  level: info                      # debug, info, warn, error (match server default)
  file: ""                         # Log file path (empty = {log_dir}/agent.log)
  max_size: 10                     # Max log file size in MB (match server default)
  max_files: 5                     # Max log files to keep (match server default)

# Health reporting
health:
  enabled: true                    # Report agent health to server
  interval: 30                     # Health check interval in seconds

# Debug
debug: false                       # Enable debug mode (same as --debug)

# Mode (auto-detected, can override)
mode: ""                           # production, development (empty = auto-detect)
```

**Config precedence (highest to lowest):**

| Priority | Source | Example |
|----------|--------|---------|
| 1 | CLI flag | `--server https://...` |
| 2 | Environment variable | `WEATHER_AGENT_SERVER=https://...` |
| 3 | Config file | `server.primary: https://...` |
| 4 | Compiled default | (none for server, must be configured) |

**Environment variable mapping:**
```bash
# Pattern: WEATHER_AGENT_{KEY} or WEATHER_{KEY}
WEATHER_AGENT_SERVER_PRIMARY="https://example.com"
WEATHER_AGENT_TOKEN="adm_agt_abc123..."
WEATHER_AGENT_HOSTNAME="web-server-01"
WEATHER_AGENT_COLLECTION_INTERVAL=30
WEATHER_DEBUG=true
```

### Agent Cluster Failover (NON-NEGOTIABLE)

**Agents MUST support automatic cluster failover. Everything is automatic.**

| Feature | Behavior |
|---------|----------|
| **Node discovery** | Agent calls `/api/v1/healthz` on connect |
| **Auto-update** | `server.cluster` updated from `cluster.nodes` in response |
| **Failover** | If primary fails, try cluster nodes in order |
| **Reconnect** | When primary recovers, switch back automatically |
| **No manual config** | Cluster list maintained automatically |

**Failover Flow:**
```
1. Agent connects to server.primary
2. Agent calls GET /api/v1/healthz
3. Agent reads cluster.primary and cluster.nodes from response
4. Agent saves to server.primary and server.cluster in agent.yml
5. If primary fails:
   a. Try each node in server.cluster
   b. First successful = new active connection
   c. Continue trying primary in background
6. When primary recovers:
   a. Switch back to primary
   b. Update cluster list (may have changed)
```

**Agent Startup Sequence:**
```
1. Load agent.yml
2. Try server.primary
3. If fails → try server.cluster nodes
4. Once connected → GET /api/v1/healthz
5. Update server.primary and server.cluster from response
6. Begin normal operation
```

### Shared Directories with Server (NON-NEGOTIABLE)

**Agent uses the SAME directory structure as server:**

| Directory | Path | Shared With |
|-----------|------|-------------|
| Config | `{config_dir}/` | Server (agent.yml alongside server.yml) |
| Data | `{data_dir}/` | Server |
| Database | `{data_dir}/db/agent.db` | Server uses `server.db` in same dir |
| Logs | `{log_dir}/agent.log` | Server uses `server.log` in same dir |
| Cache | `{cache_dir}/` | Server |

**Same privilege escalation as server (see PART 24)** - agent requires root/admin for full system access.

### Agent vs CLI Client vs Server

| Aspect | Server | CLI Client | Agent |
|--------|--------|------------|-------|
| **Runs as** | Service/daemon | Interactive/one-shot | Service/daemon |
| **Purpose** | Serve API, web UI | User interaction | Data collection |
| **Initiated by** | System startup | User | System startup |
| **Connection** | Listens for connections | Connects to server | Connects to server |
| **Lifetime** | Long-running | Short-lived | Long-running |
| **User interaction** | Web UI, API | Terminal, TUI | None (headless) |
| **Updates** | Manual or scheduled | Manual | Auto or server-pushed |

### Agent Directory Structure

**Source Code:**
```
src/
├── server/               # Server-specific code
├── client/               # CLI-specific code (if present)
└── agent/                # Agent-specific code
    ├── collector/        # Data collectors
    │   ├── collector.go
    │   ├── cpu.go
    │   ├── memory.go
    │   ├── disk.go
    │   └── network.go
    ├── reporter/         # Server reporting
    │   └── reporter.go
    ├── service/          # OS service management
    │   ├── service.go
    │   ├── linux.go
    │   ├── windows.go
    │   └── darwin.go
    └── updater/          # Self-update logic
        └── updater.go
```

### Build Output

**`make build` automatically builds all components if their source directories exist:**

```
binaries/
├── weather                         # Host server - for local testing
├── weather-cli                     # Host CLI (if src/client/ exists)
├── weather-agent                   # Host agent (if src/agent/ exists)
├── weather-linux-amd64             # Server
├── weather-linux-arm64
├── weather-cli-linux-amd64         # CLI (if src/client/ exists)
├── weather-cli-linux-arm64
├── weather-agent-linux-amd64       # Agent (if src/agent/ exists)
├── weather-agent-linux-arm64
├── weather-agent-windows-amd64.exe
├── weather-agent-darwin-amd64
└── weather-agent-darwin-arm64
```

**See PART 26 (Makefile) for full build details.**

---



# PART 37: PROJECT-SPECIFIC SECTIONS (NON-NEGOTIABLE)

**This section defines WHAT your project does (business logic, intent, unique features), NOT HOW to implement it.**

**PART 37 is NON-NEGOTIABLE.** The business logic, data models, and rules defined here are the authoritative specification for this project. Implementation must match exactly.

---

## IDEA.md: The Project Idea File

**The project idea (business logic, features) is stored in `{projectdir}/IDEA.md`, separate from the specification.**

| File | Contains | Updates When |
|------|----------|--------------|
| `AI.md` | HOW - Implementation patterns (PARTS 0-36) | Rarely - spec changes |
| `IDEA.md` | WHAT - Project idea, data, features | Features added/changed |

**IDEA.md Structure:**
```markdown
# weather - Project Idea

## Purpose
{What does this project do? One paragraph.}

## Target Users
{Who uses this? List 2-5 user types.}

## Features
{List of features with brief descriptions}

## Data Models
{Define business data structures - fields and meaning}

## Business Rules
{Validation, constraints, logic rules}

## Endpoints
{WHAT endpoints exist and WHAT they do - NOT route structure}

## Data Sources
{Where data comes from, update frequency}
```

**Cross-Reference Rules:**
- AI.md PART 37 references IDEA.md for business logic
- IDEA.md references AI.md PARTS for implementation patterns
- Both files MUST stay in sync

**IDEA.md Sync Rules (NON-NEGOTIABLE):**

| Rule | Description |
|------|-------------|
| **Always current** | IDEA.md must reflect the current project vision |
| **Feature added** | Update IDEA.md immediately |
| **Feature changed** | Update IDEA.md to reflect new vision |
| **Feature removed** | Remove from IDEA.md |
| **SPEC wins** | If IDEA.md conflicts with SPEC, update IDEA.md |

**IDEA.md Must Follow SPEC:**

IDEA.md describes WHAT, but must use spec-compliant terminology:

| IDEA.md Says | SPEC Says | Fix IDEA.md To |
|--------------|-----------|----------------|
| `/login` | Auth routes at `/auth/*` | `/auth/login` |
| `/api/users` | API at `/api/v1/*` | `/api/v1/users` |
| `password` field | Argon2id hashing | (no change - WHAT not HOW) |
| `admin page` | Admin at `/admin/*` | `/admin` dashboard |

**Rule:** IDEA.md contains the project vision using spec-compliant route names, terminology, and patterns. When SPEC defines HOW something works, IDEA.md adopts that terminology but only describes WHAT it does.

**For Existing Projects Without IDEA.md:**
```
1. Audit codebase → extract business logic
2. Create IDEA.md with project idea
3. Update AI.md PART 37 to reference IDEA.md
4. Verify code matches IDEA.md specification
```

---

## ⚠️ CRITICAL: Business Logic Only

**PARTS 0-36 define HOW to build (standards, patterns, structure).**
**PART 37 defines WHAT this specific project does (business logic, unique features).**
**IDEA.md contains the actual project idea - PART 37 references it.**

**PART 37 should contain:**
- ✓ Business purpose and intent
- ✓ Unique data structures and models
- ✓ Business rules and validation logic
- ✓ Data sources and content
- ✓ Special algorithms or logic
- ✓ Project-specific features

**PART 37 should NOT contain:**
- ✗ Route implementation details (follow PART 14: API STRUCTURE)
- ✗ HTML/CSS/frontend patterns (follow PART 16: WEB FRONTEND)
- ✗ Config file format/structure (follow PART 5: CONFIGURATION)
- ✗ Database table schemas (follow PART 10: DATABASE & CLUSTER)
- ✗ Authentication patterns (follow PART 17 for admin auth, PART 33: MULTI-USER for regular users)
- ✗ Testing approaches (follow PART 29: TESTING & DEVELOPMENT)

**Rule: AI reads PART 37 for business logic, then implements using standards from PARTS 1-36.**

---

## Project Business Purpose

{Describe WHAT this project does - its purpose, target users, unique value}

**Example (Jokes API):**
```
Purpose: Provide random programming jokes via API and web interface

Target Users:
- Developers looking for humor during coding
- Slack bots needing joke content
- Websites wanting random developer jokes

Unique Value:
- Curated database of high-quality programming jokes
- No low-quality or offensive content
- Category-based filtering
- No-repeat tracking for better UX
```

## Business Logic & Rules

{Define unique business rules, validation, constraints}

**Example (Jokes API):**
```
Business Rules:
- Jokes must be programming-related or developer humor
- Maximum joke length: 500 characters
- Minimum rating to display: 3.0 stars (configurable)
- NSFW content hidden by default (requires ?nsfw=true flag)
- Random selection excludes last 100 shown (no immediate repeats)
- Categories are predefined (no custom categories allowed)
- All jokes reviewed before inclusion

Validation:
- Category must exist in categories list
- Rating must be 1.0-5.0
- Text cannot be empty
- ID must be unique
```

## Data Models

{Define business data structures - what fields exist and mean, NOT database schema}

**Example (Jokes API):**
```go
// Joke represents a single joke entry
type Joke struct {
    // Unique identifier
    ID       string   `json:"id"`
    // The joke content
    Text     string   `json:"text"`
    // programming, puns, dad-jokes
    Category string   `json:"category"`
    // 1.0-5.0 stars
    Rating   float64  `json:"rating"`
    // Searchable tags
    Tags     []string `json:"tags"`
    // Safe-for-work flag
    NSFW     bool     `json:"nsfw"`
    // Joke attribution
    Author   string   `json:"author"`
}

// Category represents a joke category
type Category struct {
    ID          string `json:"id"`
    Name        string `json:"name"`
    Description string `json:"description"`
    // Number of jokes in category
    Count       int    `json:"count"`
}
```

## Data Sources

{Define where data comes from, update frequency, format}

**Example (Jokes API):**
```
Data Sources:
- jokes.json: 5000+ curated programming jokes (embedded in binary)
- categories.json: List of valid categories (embedded in binary)
- blocklist.json: Filtered/banned content (embedded in binary)

Update Strategy:
- Data files embedded at build time
- Updates require new release
- No runtime data modification (read-only)

Data Location:
- src/data/jokes.json (committed to repo)
- src/data/categories.json (committed to repo)
```

## Project-Specific Endpoints Summary

{List WHAT endpoints exist and WHAT they do - NOT route structure or response format}

**Endpoint Implementation Rules:**

| Endpoint Type | Implementation Rules | Notes |
|---------------|---------------------|-------|
| **Standard API** | Follow PART 14: API STRUCTURE | `/api/v1/*` patterns, response formats |
| **Frontend** | Follow PART 16: WEB FRONTEND | HTML templates, themes, accessibility |
| **Compatibility** | Follow PART 14: External API Compatibility | External services ONLY - match their exact format |
| **Legacy** | **NEVER KEEP** | Old/changed/removed endpoints - DELETE them |

**Terminology:**
- **Compatibility** = External service endpoints (pastebin.com, microbin, etc.) - match their API format
- **Legacy** = Old, changed, or removed endpoints from YOUR project - NEVER keep, always DELETE

**PART 37 describes WHAT endpoints do (business purpose). PARTs 14/16 define HOW to implement them.**

**Example 1 (Jokes API - Read-Only Data):**
```
Endpoints Purpose:
- Random joke: Get a random joke (with optional category filter)
- Search: Find jokes by keyword in text
- By category: Get random joke from specific category
- List categories: Show available categories with counts

Business Behavior:
- Random endpoint uses weighted selection (higher rated = more likely)
- Search is case-insensitive, matches text and tags
- Category filter requires valid category ID
- All endpoints support pagination (if returning lists)
```

**Example 2 (Weather API - External Data Integration):**
```
Endpoints Purpose:
- Current weather: Get current conditions for location
- Forecast: Get 7-day forecast for location
- Alerts: Get active weather alerts for region
- Search locations: Find cities/coordinates

Business Behavior:
- Caches weather data for 15 minutes (reduce external API calls)
- Accepts city name, ZIP code, or lat/long coordinates
- Returns data in metric or imperial units (user preference)
- Includes data attribution (external API source)
- Falls back to cached data if external API unavailable
```

**Example 3 (User Directory - Full CRUD):**
```
Endpoints Purpose:
- List users: Paginated user list with filtering/sorting
- Get user: Retrieve user profile by ID or username
- Create user: Register new user account
- Update user: Modify user profile/settings
- Delete user: Remove user account (soft delete)
- Search users: Find users by name, email, tags

Business Behavior:
- Username must be unique (3-20 chars, alphanumeric)
- Email validation with verification requirement
- Profile fields: name, bio, avatar, social links
- Privacy settings: public, private, unlisted
- Soft delete preserves data for 30 days before permanent deletion
```

**Example 4 (Link Shortener - URL Mapping):**
```
Endpoints Purpose:
- Create short link: Generate short URL for long URL
- Resolve short link: Redirect short URL to destination
- Link stats: View click count, referrers, locations
- Update destination: Change where short link points
- Delete link: Remove short URL

Business Behavior:
- Short codes: 6-character alphanumeric (62^6 = 56B possible)
- Custom slugs allowed (user-defined short codes)
- Expiration support (optional TTL for links)
- Click tracking (timestamp, IP, user-agent, referrer)
- QR code generation for each short link
```

## Extended Node Functions (If Applicable)

**Only define if nodes do MORE than config sync. Most projects leave this empty.**

{Describe what nodes manage beyond config sync, if anything}

| Function | Description |
|----------|-------------|
| {function} | {what nodes do} |

**Examples:**
- Watchtower-type: Nodes manage Docker hosts (update containers, monitor health)
- Monitoring app: Nodes monitor remote servers (collect metrics, send alerts)
- DNS server: Nodes provide HA failover (automatic DNS resolution failover)

## High Availability Requirements (If Applicable)

**Only define if this app requires HA. Most projects (Jokes, Quotes, etc.) do NOT need HA.**

{Describe HA requirements if this is a specialized app}

| Requirement | Description |
|-------------|-------------|
| Failover type | {automatic/manual} |
| Recovery time | {target RTO} |
| Data sync | {sync strategy} |

**Leave empty for apps that only need clustering (config sync).**

## Notes

{Any additional notes, decisions, or context for this project}

---


# FINAL CHECKPOINT: COMPLIANCE CHECKLIST

---

## FOR AI ASSISTANTS (STRICT RULES)

**These rules are NON-NEGOTIABLE. Violation is unacceptable.**

### Document Rules

- [ ] **AI.md is the ONLY project specification** - nothing else
- [ ] **IDEA.md is the project vision** - WHAT (must follow SPEC, SPEC wins conflicts)
- [ ] **PARTS 0-36 are READ-ONLY** - implementation patterns, never modify
- [ ] **PART 37 is the project spec** - update when features change
- [ ] Keep AI.md in sync with PROJECT STATE
- [ ] Keep IDEA.md in sync with current project vision
- [ ] Use TODO.AI.md for tasks when 3+ items
- [ ] Use PLAN.AI.md for implementation planning

### Behavior Rules

- [ ] **NEVER assume or guess** - ask questions when unclear
- [ ] **NEVER skip steps** - follow specifications exactly
- [ ] **NEVER add features not requested** - implement what is specified
- [ ] **NEVER use deprecated patterns** - check the spec for current standards
- [ ] **ALWAYS verify before modifying** - read existing code first
- [ ] **ALWAYS use exact naming** - config paths, routes, file names as specified
- [ ] **ALWAYS check cross-references** - ensure consistency across sections

### Code Rules

- [ ] CGO_ENABLED=0 - no exceptions, static binaries only
- [ ] No external runtime dependencies - everything embedded
- [ ] Use ONLY approved libraries (see PART 5)
- [ ] Follow exact config paths: `server.xxx`, not variations
- [ ] Follow exact route patterns: `/api/v1/admin/server/xxx`
- [ ] Token prefixes: `adm_` (admin), `usr_` (user), `org_` (org)
- [ ] Setup token: 32 hex chars, no dashes

### Container Rules

**Building (ALWAYS Docker):**
- [ ] **NEVER run `go build` on host** - ALWAYS use Docker `golang:alpine`
- [ ] **NEVER run `go test` on host** - ALWAYS use Docker `golang:alpine`
- [ ] **NEVER run `go run` on host** - ALWAYS use Docker `golang:alpine`

**Testing (Docker OR Incus):**
- [ ] **Quick tests** - Docker `alpine:latest` for unit tests, CI/CD
- [ ] **Full OS tests** - Incus `debian:latest` for systemd (PREFERRED)
- [ ] **NEVER run binaries on host** - use Docker or Incus container

**Debugging (Incus Preferred):**
- [ ] **Incus** for interactive debugging (full OS, persistent, SSH-able)
- [ ] **Docker** for quick ephemeral checks only

### AI as Beta Tester

- [ ] **Goal is to BREAK things** - try edge cases, invalid inputs, stress tests
- [ ] **Then FIX them** - don't just report bugs, implement fixes
- [ ] **Verify fixes** - re-test to confirm the fix works
- [ ] See PART 29: TESTING & DEVELOPMENT for full procedures

### API & Endpoints

- [ ] **Compatibility = external services** - pastebin.com, microbin, etc. (match their format)
- [ ] **Legacy = NEVER KEEP** - old/changed/removed endpoints from YOUR project = DELETE
- [ ] **No backwards compatibility shims** - no redirects, no deprecation periods
- [ ] See PART 14: API STRUCTURE for full rules

### When Starting Work

1. Read AI.md completely - this is the ONLY project specification
2. Read TODO.AI.md for current tasks (if exists)
3. Identify the specific task/section
4. Check for cross-references to other sections
5. Ask clarifying questions BEFORE implementing
6. Implement exactly as specified
7. Verify consistency with related sections
8. Update TODO.AI.md when tasks complete

### Quick Reference - Critical Rules

**Container-Only (NO HOST EXECUTION):**
| NEVER | ALWAYS |
|-------|--------|
| `go build` on host | `make dev` or `make host` or `make build` |
| `go test` on host | `make test` (includes coverage enforcement) |
| `go mod tidy` on host | Handled by `make build/host/dev` automatically |
| `./binaries/weather` on host | Run binary inside Docker/Incus container |
| Go installed on host | Use Makefile targets (they use Docker internally) |

**GODIR (Go Module Cache):**
```bash
GODIR := $(HOME)/.local/share/go        # Host path for Go module cache
GOCACHE := $(HOME)/.local/share/go/build  # Host path for build cache
# Mount in Docker: -v $(GODIR):/go -v $(GOCACHE):/root/.cache/go-build
```

**Temp Directory Workflow:**
| NEVER | ALWAYS |
|-------|--------|
| `docker compose up` in project dir | Use temp directory workflow |
| Runtime data in project directory | `/tmp/apimgr/weather-XXXXXX/` |
| `mktemp -d` (bare) | `mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}/$WEATHER-XXXXXX"` |
| `/tmp/myfile` | `/tmp/apimgr/weather-XXXXXX/myfile` |

```bash
# Temp dir workflow
TEMP_DIR=$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}/$WEATHER-XXXXXX")
mkdir -p "$TEMP_DIR/rootfs/config" "$TEMP_DIR/rootfs/data"
cp docker/docker-compose.yml "$TEMP_DIR/"
cd "$TEMP_DIR" && docker compose up -d
```

**Project Directory Rules:**
| NEVER Create | Reason |
|--------------|--------|
| `config/`, `data/`, `logs/`, `cache/` | Runtime dirs go to temp/OS paths |
| `server.yml`, `cli.yml` | Generated at runtime, not in repo |
| `rootfs/` in project root | Only in `docker/rootfs/` for build overlay |
| `.env` with secrets | Use environment variables or admin panel |

**Config Files:**
- NEVER in repository - generated at RUNTIME
- Binary creates on first run with sane defaults
- User edits generated file or uses admin panel

**Testing:**
| Type | Container | Purpose |
|------|-----------|---------|
| Build | Docker `golang:alpine` | Compile Go code |
| Unit tests | Docker `golang:alpine` | `go test ./...` |
| Integration | Docker `alpine:latest` OR Incus `debian:latest` | Full server tests |
| Full OS/systemd | Incus `debian:latest` (PREFERRED) | Services, real environment |

**Makefile Targets:**
```bash
make dev    # Quick build → temp dir (no version info)
make build  # Full build → binaries/ (with ldflags)
make test   # Run tests in container
make docker # Build Docker image
```

**Cryptography:**
| Use | For |
|-----|-----|
| Argon2id | Password hashing |
| SHA-256 | Token hashing, checksums |
| Ed25519 | Signing (if needed) |
| AES-256-GCM | Encryption (if needed) |

**File Locations:**
| Type | Development/Test | Production |
|------|------------------|------------|
| Config | `/tmp/{org}/{proj}-XXX/rootfs/config/` | `/etc/{org}/{proj}/` (Linux) |
| Data | `/tmp/{org}/{proj}-XXX/rootfs/data/` | `/var/lib/{org}/{proj}/` (Linux) |
| Binary | `binaries/weather` | `/usr/local/bin/weather` |

---

## DETAILED VERIFICATION BY PART

### Phase 1: Foundation (PARTS 0-6)

**PART 0-2: Meta & Rules**
- [ ] AI.md exists and is the ONLY project specification
- [ ] PARTS 0-36 are treated as READ-ONLY
- [ ] PART 37 contains project-specific business logic
- [ ] MIT License in LICENSE.md
- [ ] All embedded library licenses listed
- [ ] No proprietary dependencies

**PART 3: Project Structure**
- [ ] `src/` directory exists with proper layout
- [ ] `src/config/config.go` - Configuration package
- [ ] `src/mode/mode.go` - Application modes
- [ ] `src/paths/paths.go` - Path resolution
- [ ] `src/ssl/ssl.go` - SSL/TLS handling
- [ ] `src/scheduler/scheduler.go` - Background tasks
- [ ] `src/service/service.go` - Service management
- [ ] `src/admin/` - Admin panel package
- [ ] `src/server/` - HTTP server with subdirs
- [ ] `docker/` - Docker configuration
- [ ] `docs/` - ReadTheDocs documentation only
- [ ] `tests/` - Test files and scripts
- [ ] No `pkg/`, `internal/`, `cmd/` directories

**PART 4: OS-Specific Paths**
- [ ] Linux paths: `/etc/`, `/var/lib/`, `/var/log/`, `/var/cache/`
- [ ] macOS paths: `~/Library/Application Support/`
- [ ] Windows paths: `%APPDATA%\`, `%LOCALAPPDATA%\`
- [ ] BSD paths: Same as Linux
- [ ] Docker paths: `/config/`, `/data/`
- [ ] Root vs user path detection works
- [ ] All path functions use `apimgr/weather` structure

**PART 5: Configuration**
- [ ] Config file: `server.yml` (not .yaml, not .json)
- [ ] Hierarchy: CLI flags > env vars > file > defaults
- [ ] Environment prefix: `WEATHER_`
- [ ] Boolean values: true/false, yes/no, 1/0, on/off all work
- [ ] All config values have sane defaults
- [ ] Unknown config keys are ERRORS, not ignored
- [ ] Config validation on load
- [ ] Approved libraries only (see PART 5 list)

**PART 6: Application Modes**
- [ ] Production mode: Default, optimized, no debug
- [ ] Development mode: Verbose logging, debug endpoints
- [ ] Mode detection: env var, CLI flag, config file
- [ ] Debug endpoints disabled in production
- [ ] `/debug/pprof/` only in development mode

### Phase 2: Binary Core (PARTS 7-9)

**PART 7: Binary Requirements**
- [ ] CGO_ENABLED=0 - Static binary, no exceptions
- [ ] Single binary with ALL assets embedded
- [ ] No external runtime dependencies
- [ ] Builds for 8 platforms (4 OS × 2 arch)
- [ ] Binary handles ALL initialization (no setup scripts)
- [ ] Creates directories on first run
- [ ] Sets permissions based on run context
- [ ] Runs as root or user correctly

**PART 8: Server Binary CLI**
- [ ] `--help` - Shows help (no privileges needed)
- [ ] `--version` - Shows version (no privileges needed)
- [ ] `--config {path}` - Config directory
- [ ] `--data {path}` - Data directory
- [ ] `--cache {path}` - Cache directory
- [ ] `--log {path}` - Log directory
- [ ] `--backup {path}` - Backup directory
- [ ] `--pid {path}` - PID file path
- [ ] `--address {addr}` - Listen address
- [ ] `--port {port}` - Listen port
- [ ] `--mode {mode}` - Application mode
- [ ] `--status` - Show running status
- [ ] `--daemon` - Daemonize (detach)
- [ ] `--debug` - Enable debug mode
- [ ] `--service {cmd}` - Service management
- [ ] `--maintenance {cmd}` - Maintenance operations
- [ ] `--update {cmd}` - Update operations
- [ ] Binary naming rules followed (user can rename)

**PART 9: Error Handling & Caching**
- [ ] Consistent error response format (JSON)
- [ ] Error codes are stable and documented
- [ ] Stack traces only in development mode
- [ ] Cache headers set correctly
- [ ] ETag support for cacheable resources
- [ ] Cache-Control headers appropriate per resource type

### Phase 3: Data Layer (PARTS 10-11)

**PART 10: Database & Cluster**
- [ ] SQLite default for single-node
- [ ] PostgreSQL/MySQL for cluster mode
- [ ] CREATE TABLE IF NOT EXISTS pattern
- [ ] Automatic migrations on startup
- [ ] No manual schema creation required
- [ ] Cluster-aware task locking (when applicable)
- [ ] Connection pooling configured
- [ ] Prepared statements used (no SQL injection)

**PART 11: Security & Logging**
- [ ] All security headers set (CSP, X-Frame-Options, etc.)
- [ ] HSTS enabled when SSL active
- [ ] Rate limiting enabled and configurable
- [ ] Audit logging to audit.log (JSON format)
- [ ] Security events logged to security.log
- [ ] No sensitive data in logs
- [ ] Log rotation configured
- [ ] Log levels: debug, info, warn, error

### Phase 4: Server Core (PARTS 12-14)

**PART 12: Server Configuration**
- [ ] All server settings in `server.yml`
- [ ] Runtime reload of safe settings
- [ ] Restart required clearly documented
- [ ] Valkey/Redis configuration (if applicable)
- [ ] Cluster configuration (if applicable)

**PART 13: Health & Versioning**
- [ ] `/healthz` endpoint exists (frontend - smart detection)
- [ ] `/api/v1/healthz` endpoint exists (API - supports .txt)
- [ ] Returns 200 OK when healthy
- [ ] Smart detection: browser → HTML, CLI → text
- [ ] Extended healthz response includes:
  - [ ] version, go_version, build info
  - [ ] cluster (enabled, status, primary, nodes, role)
  - [ ] features (multi_user, organizations, tor, geoip, metrics)
  - [ ] checks (database, cache, disk, scheduler, cluster)
  - [ ] stats (requests_total, requests_24h, active_connections)
- [ ] NEVER expose sensitive data (tokens, credentials, paths, internal IPs)
- [ ] `release.txt` contains version
- [ ] Semantic versioning: MAJOR.MINOR.PATCH
- [ ] Version exposed in `/healthz` response
- [ ] Version exposed in `--version` output
- [ ] `--status` flag returns exit 0 (healthy) or 1 (unhealthy)

**PART 14: API Structure**
- [ ] REST API at `/api/v1/`
- [ ] Consistent response format
- [ ] Proper HTTP status codes
- [ ] Pagination for list endpoints
- [ ] Filter/sort/search parameters
- [ ] Rate limiting per endpoint type
- [ ] API versioning in URL path
- [ ] No breaking changes without major version bump

### Phase 5: Auth & Security (PARTS 15-16)

**PART 15: SSL/TLS & Let's Encrypt**
- [ ] Let's Encrypt HTTP-01 challenge
- [ ] Let's Encrypt TLS-ALPN-01 challenge
- [ ] Let's Encrypt DNS-01 challenge (optional)
- [ ] Manual certificate support
- [ ] Auto-renewal via scheduler
- [ ] Certificate monitoring/expiry alerts
- [ ] HSTS headers when SSL enabled
- [ ] Redirect HTTP to HTTPS option

**PART 16: Web Frontend**
- [ ] Homepage at `/`
- [ ] Theme system: light, dark, auto
- [ ] Dark theme is DEFAULT
- [ ] Theme toggle in UI
- [ ] Theme persisted in localStorage
- [ ] NO inline CSS - external stylesheets only
- [ ] NO JavaScript alerts - toast notifications
- [ ] Mobile-first responsive design
- [ ] WCAG 2.1 AA accessibility
- [ ] Semantic HTML structure
- [ ] Keyboard navigation works
- [ ] Screen reader compatible
- [ ] Color contrast meets AA standards (both themes)

### Phase 6: Admin & Email (PARTS 17-18)

**PART 17: Admin Panel**
- [ ] Admin UI at `/{admin_path}`
- [ ] Admin API at `/api/v1/{admin_path}/`
- [ ] First-run setup wizard
- [ ] All settings configurable via UI
- [ ] Settings organized by category
- [ ] Real-time validation feedback
- [ ] Confirmation for destructive actions
- [ ] Same theme system as main UI
- [ ] Activity/audit log viewer
- [ ] System status dashboard

**PART 18: Email & Notifications**
- [ ] SMTP configuration in admin
- [ ] Email disabled gracefully if no SMTP
- [ ] Customizable email templates
- [ ] WebUI notifications always available
- [ ] Email queue with retry logic
- [ ] Email logging (success/failure)

### Phase 7: Features (PARTS 19-22)

**PART 19: Scheduler**
- [ ] Built-in scheduler always running
- [ ] Backup: 02:00 daily (configurable)
- [ ] SSL renewal: 03:00 daily
- [ ] GeoIP update: 03:00 Sunday
- [ ] Session cleanup: hourly
- [ ] Cluster-aware task locking
- [ ] Scheduler status in admin panel
- [ ] Manual task trigger option

**PART 20: GeoIP**
- [ ] MaxMind GeoLite2 database support
- [ ] Auto-download and update
- [ ] Country blocking capability
- [ ] IP lookup API endpoint
- [ ] Graceful degradation if unavailable

**PART 21: Metrics**
- [ ] Prometheus metrics at `/metrics`
- [ ] Request count, latency, errors
- [ ] System metrics (memory, goroutines)
- [ ] Custom business metrics
- [ ] Metrics endpoint authentication option

**PART 22: Backup & Restore**
- [ ] Automatic daily backups (backup_daily task at 02:00)
- [ ] Optional hourly incremental (backup_hourly task, disabled by default)
- [ ] Backup encryption (AES-256-GCM) - optional unless compliance enabled
- [ ] If compliance enabled, encryption REQUIRED (backups blocked without password)
- [ ] Configurable retention: max_backups (default: 1), keep_weekly/monthly/yearly (default: 0)
- [ ] `--maintenance backup` works
- [ ] `--maintenance restore {file}` works (prompts for password if encrypted)
- [ ] Backup includes: database, config, uploads
- [ ] Restore is atomic (all or nothing)
- [ ] **Backup verification after creation** (checksum, decrypt, extract, DB integrity)
- [ ] **Daily incremental** `weather-daily.tar.gz[.enc]` always valid
- [ ] **Hourly incremental** `weather-hourly.tar.gz[.enc]` (if enabled)
- [ ] **Cluster mode**: each node maintains own valid backups (max_backups per node)

### Phase 8: Maintenance (PARTS 23-26)

**PART 23: Update Command**
- [ ] `--update check` - Check for updates
- [ ] `--update yes` - Perform update
- [ ] `--update branch {name}` - Switch branch
- [ ] Update channels: stable, beta, daily
- [ ] Rollback capability
- [ ] Update notifications in admin

**PART 24: Privilege Escalation & Service**
- [ ] Privilege escalation for protected operations
- [ ] Clear privilege requirements documented
- [ ] sudo/runas prompts when needed
- [ ] Service operations require appropriate rights

**PART 25: Service Support**
- [ ] `--service install` - Install as service
- [ ] `--service uninstall` - Remove service
- [ ] `--service start/stop/restart/reload`
- [ ] Linux: systemd service file
- [ ] macOS: launchd plist
- [ ] Windows: Windows Service
- [ ] BSD: rc.d script

**PART 26: Makefile**
- [ ] `make build` - Build binary
- [ ] `make test` - Run tests
- [ ] `make docker` - Build Docker image
- [ ] `make release` - Create release
- [ ] `make clean` - Clean build artifacts
- [ ] `make all` - Full build
- [ ] Cross-compilation targets
- [ ] Version injection at build time

### Phase 9: Build & Deploy (PARTS 27-29)

**PART 27: Docker**
- [ ] Multi-stage Dockerfile
- [ ] Alpine base image
- [ ] tini as init process
- [ ] Runs as root (app manages user/permissions at runtime)
- [ ] Proper labels (OCI standard)
- [ ] Health check in Dockerfile
- [ ] docker-compose.yml for production
- [ ] docker-compose.dev.yml for development
- [ ] docker-compose.test.yml for testing
- [ ] Volume mounts for config/data

**PART 28: CI/CD Workflows**
- [ ] release.yml - Stable releases
- [ ] beta.yml - Beta releases
- [ ] daily.yml - Nightly builds
- [ ] docker.yml - Docker image builds
- [ ] All 8 platform builds
- [ ] Automated testing in CI
- [ ] Release artifacts uploaded
- [ ] Docker images pushed to registry

**PART 29: Testing & Development**
- [ ] Unit tests exist
- [ ] Integration tests exist
- [ ] tests/run_tests.sh - Auto-detect environment
- [ ] tests/docker.sh - Docker-based tests
- [ ] tests/incus.sh - Incus-based tests
- [ ] All tests pass in CI
- [ ] Test coverage measured
- [ ] API testing included
- [ ] Beta testing procedures documented

### Phase 10: Documentation (PARTS 30-31)

**PART 30: ReadTheDocs Documentation**
- [ ] docs/ directory for MkDocs only
- [ ] mkdocs.yml in project root
- [ ] .readthedocs.yaml in project root
- [ ] docs/requirements.txt with dependencies
- [ ] MkDocs Material theme
- [ ] Theme toggle (light/dark/auto, dark default)
- [ ] Required pages exist:
  - [ ] docs/index.md
  - [ ] docs/installation.md
  - [ ] docs/configuration.md
  - [ ] docs/api.md
  - [ ] docs/admin.md
  - [ ] docs/development.md
- [ ] ReadTheDocs builds successfully
- [ ] Documentation badge in README.md

**PART 31: I18N & A11Y**
- [ ] Internationalization framework (if applicable)
- [ ] RTL language support (if applicable)
- [ ] WCAG 2.1 AA compliance
- [ ] Accessibility testing performed

### Phase 11: Optional Features (PARTS 32-36)

**PART 32: Tor Hidden Service**
- [ ] Auto-enabled when tor binary found
- [ ] Dedicated tor process (not system tor)
- [ ] .onion address generation
- [ ] Vanity address generation option
- [ ] Tor status in admin panel
- [ ] Tor data in `{data_dir}/tor/`
- [ ] Tor fields in `/api/v1/healthz`:
  - [ ] `features.tor.enabled` (yes/no)
  - [ ] `features.tor.running` (yes/no)
  - [ ] `features.tor.status` (healthy/error:{message})
  - [ ] `features.tor.hostname` ({onion_address})

**PART 33: Multi-User** (if applicable)
- [ ] User registration flow
- [ ] User authentication (session-based for UI)
- [ ] API authentication (bearer token)
- [ ] Token prefixes: `usr_` (user) with properties (name, scope, expiration)
- [ ] Session management implemented
- [ ] 2FA support: TOTP and WebAuthn
- [ ] Password requirements enforced

**PART 34: Organizations** (if applicable)
- [ ] Org creation and management
- [ ] Member roles and permissions
- [ ] Org-level settings
- [ ] Org API tokens

**PART 35: Custom Domains** (if applicable)
- [ ] Custom domain configuration
- [ ] SSL for custom domains
- [ ] DNS verification
- [ ] Domain management in admin

**PART 36: CLI Client & Agent** (if applicable)

*CLI Client:*
- [ ] Binary: `weather-cli`
- [ ] Same version as server
- [ ] CLI mode (standard commands)
- [ ] TUI mode (interactive)
- [ ] Config: `~/.config/apimgr/weather/cli.yml`
- [ ] Theme matching server (dark default)
- [ ] Cluster failover support:
  - [ ] `server.primary` and `server.cluster` in cli.yml
  - [ ] Auto-discover nodes from `/api/v1/healthz`
  - [ ] Auto-update cli.yml with discovered nodes
  - [ ] Automatic failover to next node if primary fails

*Agent (only for monitoring/remote management projects):*
- [ ] Binary: `weather-agent`
- [ ] Runs on host, NOT in container
- [ ] Same version as server
- [ ] Systemd/launchd/Windows service support
- [ ] Config: `/etc/apimgr/weather/agent.yml`
- [ ] Connects to central server
- [ ] Same flags as server EXCEPT no `--port`/`--address` (agents don't serve HTTP)
- [ ] Cluster failover support:
  - [ ] `server.primary` and `server.cluster` in agent.yml
  - [ ] Auto-discover nodes from `/api/v1/healthz`
  - [ ] Auto-update agent.yml with discovered nodes
  - [ ] Automatic failover to next node if primary fails

### Phase 12: Project-Specific (PART 37)

**PART 37: Project-Specific**
- [ ] Business logic documented
- [ ] Data models defined
- [ ] API endpoints specified
- [ ] Configuration options listed
- [ ] No implementation details (use PARTS 0-36)

---

## SECURITY AUDIT CHECKLIST

### Authentication & Authorization

- [ ] No hardcoded credentials in code
- [ ] Passwords hashed with Argon2id (NEVER bcrypt)
- [ ] Session tokens are cryptographically random
- [ ] Session expiration enforced
- [ ] CSRF protection on all forms
- [ ] API authentication on all protected endpoints
- [ ] Rate limiting prevents brute force
- [ ] Account lockout after failed attempts
- [ ] Privilege escalation properly controlled

### Input Validation

- [ ] All user input validated server-side
- [ ] SQL injection prevented (parameterized queries)
- [ ] XSS prevented (output encoding)
- [ ] Command injection prevented (no shell exec with user input)
- [ ] Path traversal prevented (canonicalized paths)
- [ ] File upload restrictions enforced
- [ ] Content-Type validation
- [ ] Size limits on all inputs

### Network Security

- [ ] HTTPS enforced in production
- [ ] HSTS header set
- [ ] Secure cookies (HttpOnly, Secure, SameSite)
- [ ] CORS properly configured
- [ ] No sensitive data in URLs
- [ ] API keys not logged
- [ ] Error messages don't leak internals

### Security Headers

- [ ] Content-Security-Policy
- [ ] X-Frame-Options: DENY
- [ ] X-Content-Type-Options: nosniff
- [ ] X-XSS-Protection: 1; mode=block
- [ ] Referrer-Policy: strict-origin-when-cross-origin
- [ ] Permissions-Policy (as appropriate)

### Data Protection

- [ ] Sensitive data encrypted at rest
- [ ] Backups encrypted
- [ ] No sensitive data in logs
- [ ] PII handled according to policy
- [ ] Data retention policies implemented
- [ ] Secure deletion when required

### Two-Factor Authentication (2FA)

- [ ] TOTP support (RFC 6238)
- [ ] WebAuthn/Passkeys support (FIDO2)
- [ ] 2FA prompt on first login (can skip)
- [ ] Remember device option (configurable, default 30 days)
- [ ] Recovery codes generated on 2FA setup
- [ ] 2FA can be disabled (requires password confirmation)
- [ ] Trusted device management in settings

### Token Security

- [ ] Token prefixes enforced: `adm_` (admin), `usr_` (user), `org_` (org)
- [ ] Agent token prefixes enforced: `adm_agt_`, `usr_agt_`, `org_agt_` (scoped to owner)
- [ ] Setup token: 32 hex characters, no dashes
- [ ] Tokens hashed before storage (SHA-256)
- [ ] Token expiration enforced
- [ ] Token revocation works immediately
- [ ] No tokens in logs or error messages

### Admin vs User Separation

- [ ] Server admins in separate table (`admins`)
- [ ] Regular users in separate table (`users`)
- [ ] Separate session tables (`admin_sessions`, `user_sessions`)
- [ ] Admin routes protected (`/{admin_path}/*`)
- [ ] No privilege escalation path from user to admin

---

## API COMPLIANCE CHECKLIST

### Route Compliance (MANDATORY)

- [ ] ALL API routes are versioned (`/api/v1/...`)
- [ ] ALL resource names are plural (`users`, not `user`)
- [ ] ALL routes are lowercase
- [ ] Multi-word routes use hyphens (`api-keys`, not `api_keys`)
- [ ] No trailing slashes on routes
- [ ] No verbs in routes (use HTTP methods)
- [ ] Every API route has corresponding frontend route
- [ ] Frontend routes match API structure (`/users` ↔ `/api/v1/users`)
- [ ] Frontend is fully functional (not just display)
- [ ] All CRUD operations work from both frontend and API
- [ ] No orphan routes (frontend-only or API-only)
- [ ] Routes follow scope rules (`/auth/`, `/users/`, `/orgs/`, `/admin/`)

### REST API (`/api/v1/`)

- [ ] Consistent URL patterns
- [ ] Proper HTTP methods (GET, POST, PUT, PATCH, DELETE)
- [ ] Correct status codes (200, 201, 204, 400, 401, 403, 404, 500)
- [ ] JSON response format consistent
- [ ] Error responses include code, message, details
- [ ] Pagination: limit, offset, total
- [ ] Filtering: query parameters
- [ ] Sorting: sort, order parameters
- [ ] HATEOAS links (optional but recommended)

### OpenAPI/Swagger (`/openapi`)

- [ ] Swagger UI accessible
- [ ] OpenAPI spec at `/openapi.json`
- [ ] All endpoints documented
- [ ] Request/response schemas defined
- [ ] Authentication documented
- [ ] Examples provided
- [ ] Theme matches project theme

### GraphQL (`/graphql`)

- [ ] GraphQL endpoint accessible
- [ ] GraphiQL/Playground available
- [ ] Schema matches REST API capabilities
- [ ] Authentication integrated
- [ ] Query complexity limits
- [ ] Introspection disabled in production (optional)
- [ ] Theme matches project theme

### Content Negotiation

- [ ] Accept header respected
- [ ] JSON default for API
- [ ] HTML default for frontend
- [ ] Plain text via .txt extension or Accept header
- [ ] CLI tools get text output automatically

---

## PERFORMANCE CHECKLIST

### Response Times

- [ ] Health check < 10ms
- [ ] Simple API calls < 100ms
- [ ] Complex queries < 500ms
- [ ] Page loads < 1s (first contentful paint)

### Resource Usage

- [ ] Memory usage reasonable
- [ ] No memory leaks
- [ ] Goroutine count stable
- [ ] Connection pool sized correctly
- [ ] File handles closed properly

### Caching

- [ ] Static assets cached (1 year)
- [ ] API responses cached where appropriate
- [ ] ETags used for conditional requests
- [ ] Cache-Control headers correct
- [ ] CDN-friendly headers

### Database

- [ ] Indexes on frequently queried columns
- [ ] N+1 query problems avoided
- [ ] Connection pooling configured
- [ ] Query timeouts set
- [ ] Slow query logging enabled

---

## DOCKER CHECKLIST

### Dockerfile Requirements

- [ ] Multi-stage build (builder + runtime)
- [ ] Alpine base image for runtime
- [ ] `tini` as init process (PID 1)
- [ ] Runs as root (app manages user/permissions at runtime)
- [ ] HEALTHCHECK instruction present
- [ ] OCI labels (org.opencontainers.image.*)
- [ ] No secrets in image layers
- [ ] Minimal image size

### Docker Compose Files

- [ ] `docker-compose.yml` - Production deployment
- [ ] `docker-compose.dev.yml` - Development (hot reload)
- [ ] `docker-compose.test.yml` - Testing
- [ ] Volume mounts for `/config` and `/data`
- [ ] Proper network configuration
- [ ] Health checks use `--status` flag (exit 0=healthy, 1=unhealthy)

### Container Behavior

- [ ] Logs to stdout/stderr (container captures)
- [ ] Graceful shutdown on SIGTERM
- [ ] Environment variables for configuration
- [ ] Single process per container
- [ ] Stateless (data in volumes)

---

## CI/CD CHECKLIST

### Workflow Files

- [ ] `release.yml` - Stable releases (tag trigger)
- [ ] `beta.yml` - Beta releases (branch trigger)
- [ ] `daily.yml` - Nightly builds (cron + push)
- [ ] `docker.yml` - Docker image builds

### Build Requirements

- [ ] All 8 platforms built (4 OS × 2 arch)
- [ ] CGO_ENABLED=0 for all builds
- [ ] Version injected via ldflags
- [ ] Checksums generated (SHA256)
- [ ] Artifacts uploaded to release

### Docker Publishing

- [ ] Multi-arch images (amd64, arm64)
- [ ] Tagged by version and latest
- [ ] Pushed to registry (ghcr.io or project registry)
- [ ] Manifest lists for multi-arch

### Quality Gates

- [ ] Tests pass before release
- [ ] License check passes (no GPL/AGPL)
- [ ] Build succeeds on all platforms
- [ ] Docker image builds successfully

---

## THEME/UI CHECKLIST

### Theme System

- [ ] Dark theme is DEFAULT
- [ ] Light theme available
- [ ] Auto theme (system preference)
- [ ] Theme persisted in localStorage
- [ ] Theme toggle in UI
- [ ] Same theme system everywhere

### Theme Coverage

- [ ] Web frontend uses theme
- [ ] Admin panel uses theme
- [ ] Swagger UI uses theme
- [ ] GraphQL Playground uses theme
- [ ] ReadTheDocs uses theme
- [ ] CLI TUI uses theme (if applicable)

### CSS Requirements

- [ ] NO inline styles
- [ ] External stylesheets only
- [ ] CSS variables for theme colors
- [ ] Same color scheme across all UIs
- [ ] `theme-dark` / `theme-light` classes on `<html>`

### Accessibility (WCAG 2.1 AA)

- [ ] Color contrast meets AA (both themes)
- [ ] Keyboard navigation works
- [ ] Screen reader compatible
- [ ] Focus indicators visible
- [ ] Alt text on images
- [ ] Form labels properly associated
- [ ] Skip to content link

### Responsive Design

- [ ] Mobile-first approach
- [ ] Works on all screen sizes
- [ ] Touch-friendly controls
- [ ] No horizontal scroll on mobile

---

## FOR HUMANS (PROJECT CHECKLIST)

### Project Files

- [ ] `AI.md` - Complete project specification (required, THE spec - HOW)
- [ ] `IDEA.md` - Project vision document (optional, WHAT - must follow SPEC)
- [ ] `TODO.AI.md` - Task tracking (when needed)
- [ ] `PLAN.AI.md` - Implementation plan (optional, if exists this is THE plan)
- [ ] `README.md` - User documentation (required)
- [ ] `LICENSE.md` - License file (required)
- [ ] `Makefile` - Build targets (required)
- [ ] `docker/Dockerfile` - Container build (required)
- [ ] `go.mod` / `go.sum` - Go modules (required)
- [ ] `.github/workflows/` or `.gitea/workflows/` - CI/CD (required)

### Licensing & Features

- [ ] MIT License for all project code
- [ ] 3rd party licenses listed in LICENSE.md
- [ ] 100% free and open source - no paid tiers
- [ ] No feature gating - ALL features available to ALL users
- [ ] No "pro", "premium", "enterprise" editions
- [ ] No license keys or activation required
- [ ] Rate limits OK (server protection), usage limits NOT OK (monetization)

### Development

- [ ] All 4 OSes: Linux, macOS, BSD, Windows
- [ ] Both architectures: AMD64, ARM64
- [ ] CGO_ENABLED=0 for static binaries
- [ ] Single binary with embedded assets
- [ ] No external runtime dependencies

### Configuration

- [ ] Config file: `server.yml` (not .yaml)
- [ ] Environment variables: `WEATHER_xxx`
- [ ] CLI flags override env, env overrides file
- [ ] Boolean accepts: true/false, yes/no, 1/0, on/off
- [ ] Sane defaults for everything

### Frontend

- [ ] Frontend required for ALL projects
- [ ] Project-wide theme system: light/dark/auto (dark is default)
- [ ] Themes apply everywhere: web UI, admin, Swagger, GraphQL, ReadTheDocs
- [ ] NO inline CSS - external stylesheets only
- [ ] NO JavaScript alerts - use toast notifications
- [ ] Mobile-first responsive design
- [ ] WCAG 2.1 AA accessibility (both light and dark themes)

### API

- [ ] REST API at `/api/v1/`
- [ ] Swagger UI at `/openapi`
- [ ] OpenAPI spec at `/openapi.json` (JSON only, no YAML)
- [ ] GraphQL at `/graphql` (synced with REST)
- [ ] Health check at `/healthz` (extended response with cluster info)
- [ ] Health check includes cluster.nodes for agent/CLI failover

### Admin Panel

- [ ] Web UI at `/admin` (session auth)
- [ ] API at `/api/v1/admin/` (bearer token auth)
- [ ] First-run setup wizard
- [ ] All settings configurable via UI

### Server CLI

- [ ] `--help`, `--version` - no privileges needed
- [ ] `--status` - show running status
- [ ] `--config` - specify config file
- [ ] `--service` - install/start/stop/restart/uninstall
- [ ] `--maintenance` - backup/restore/setup
- [ ] `--update` - check/yes/branch

### Database

- [ ] SQLite for local/single-node (default)
- [ ] PostgreSQL/MySQL for cluster mode
- [ ] Self-creating schema (CREATE TABLE IF NOT EXISTS)
- [ ] Automatic migrations on startup

### Scheduler

- [ ] Built-in scheduler (always running)
- [ ] Backup: 02:00 daily
- [ ] SSL renewal: 03:00 daily
- [ ] GeoIP update: 03:00 Sunday
- [ ] Session cleanup: hourly
- [ ] Cluster-aware task locking

### Backup & Restore

- [ ] Automatic daily backups (configurable)
- [ ] Encrypted backups (AES-256-GCM) - optional unless compliance enabled
- [ ] Compliance mode requires encryption (backups blocked without password)
- [ ] Max 4 backups retained (default)
- [ ] Restore via CLI: `--maintenance restore` (prompts for password if encrypted)
- [ ] Backup verification after creation (all backups must be 100% valid)
- [ ] Daily incremental: `weather-daily.tar.gz[.enc]` always exists
- [ ] Cluster: each node maintains own valid backups

### Email & Notifications

- [ ] SMTP required for email features
- [ ] No SMTP = email features disabled (not hidden errors)
- [ ] Customizable email templates
- [ ] WebUI notifications always available

### SSL/TLS

- [ ] Let's Encrypt support (HTTP-01, TLS-ALPN-01, DNS-01)
- [ ] Manual certificate support
- [ ] Auto-renewal via scheduler
- [ ] HSTS when SSL enabled

### Security

- [ ] All security headers (CSP, X-Frame-Options, etc.)
- [ ] Rate limiting enabled
- [ ] Audit logging
- [ ] 2FA support (TOTP, WebAuthn)
- [ ] Session management

### Logging

- [ ] access.log, server.log, error.log, audit.log, security.log
- [ ] Configurable formats and rotation
- [ ] Audit log: JSON only, daily rotation

### Build & Deploy

- [ ] Makefile: build, release, docker, test
- [ ] CI/CD: release, beta, daily, docker workflows
- [ ] 8 platform builds (4 OS × 2 arch)
- [ ] Docker: Alpine base, tini init, runs as root

### Building & Testing

**Building (ALWAYS Docker):**
- [ ] ALL builds use Docker `golang:alpine` - NEVER on host
- [ ] `go build`, `go test`, `go run` - ALWAYS in Docker

**Testing (Docker OR Incus):**
- [ ] Quick tests: Docker `alpine:latest`
- [ ] Full OS tests: Incus `debian:latest` (PREFERRED for systemd)
- [ ] ALL binaries run in containers - never host
- [ ] `tests/run_tests.sh` - auto-detects Incus or Docker
- [ ] `tests/docker.sh` - Docker-based tests
- [ ] `tests/incus.sh` - Incus-based tests (full systemd)

**Debugging:**
- [ ] Incus preferred (full OS, persistent, SSH-able)
- [ ] Docker for quick ephemeral checks only

### Documentation

- [ ] `docs/` directory ONLY for ReadTheDocs (MkDocs) - nothing else
- [ ] `mkdocs.yml` in project root
- [ ] `.readthedocs.yaml` in project root
- [ ] `docs/requirements.txt` with dependencies
- [ ] MkDocs Material theme with light/dark/auto toggle (dark default)
- [ ] `docs/stylesheets/dark.css` (OPTIONAL for dark theme customization)
- [ ] `docs/stylesheets/light.css` (OPTIONAL for light theme customization)
- [ ] Required pages: index, installation, configuration, api, admin, development
- [ ] ReadTheDocs URL: `https://apimgr-weather.readthedocs.io`
- [ ] Documentation badge in README.md

### CLI Client (if applicable)

- [ ] Binary: `weather-cli`
- [ ] Same version as server
- [ ] Standard CLI + TUI modes
- [ ] Config: `~/.config/apimgr/weather/cli.yml`
- [ ] Dark theme for TUI (matching project theme)
- [ ] Built alongside server
- [ ] Cluster failover (auto-discover from `/api/v1/healthz`)

### Tor (if tor binary installed)

- [ ] Auto-enabled when tor binary found
- [ ] Dedicated tor process (not system tor)
- [ ] .onion address management
- [ ] Vanity address generation
- [ ] Status in healthz: enabled, running, status, hostname

### Optional Features

- [ ] Custom domains (per-project decision)
- [ ] Multi-user mode (per-project decision)
- [ ] Organizations (per-project decision)
- [ ] Cluster mode (when HA needed)

---

**END OF SPECIFICATION**

**ALL sections marked NON-NEGOTIABLE must be implemented exactly as specified.**

**When in doubt:**
- **AI:** Re-read AI.md (HOW), IDEA.md (WHAT), and TODO.AI.md. Ask questions. Never assume.
- **Humans:** Re-read AI.md. Update IDEA.md for vision changes, TODO.AI.md for tasks. Ask AI to clarify.

---

# APPENDIX A: INTEGRATION NOTES

# Integration Notes for Existing Projects

**Use this prompt when integrating this specification into an EXISTING project.**

---

## Prompt for AI Assistants

When integrating this specification into an existing project:

### Phase 1: Assessment (Read-Only)

1. **Read the entire AI.md specification** (this file)
2. **Read the existing project codebase** - understand current structure
3. **Identify gaps** between current state and specification requirements
4. **Create TODO.AI.md** with comprehensive task list organized by priority:
   - **Critical (P0)**: Security issues, data loss risks, broken functionality
   - **High (P1)**: Missing NON-NEGOTIABLE requirements
   - **Medium (P2)**: Structural improvements, standardization
   - **Low (P3)**: Nice-to-have features, documentation improvements

### Phase 2: Planning

1. **Do NOT start making changes yet**
2. **Review TODO.AI.md with the human** - get approval on priorities
3. **Ask clarifying questions:**
   - Are there existing features that should be preserved?
   - Are there breaking changes acceptable?
   - What is the migration timeline (can it be done incrementally)?
   - Are there production systems that need careful migration?
4. **Create a migration plan** for each major change
5. **Identify risks** - data migration, API breaking changes, downtime requirements

### Phase 3: Incremental Implementation

**NEVER attempt to fix everything at once. Work incrementally:**

1. **Start with Critical (P0) items**
   - Security vulnerabilities
   - Data integrity issues
   - Broken functionality

2. **Then High (P1) NON-NEGOTIABLE items**
   - Work in small, testable increments
   - One subsystem at a time
   - Ensure each change is tested before moving on

3. **Then Medium (P2) improvements**
   - Structural reorganization
   - Standardization of patterns

4. **Finally Low (P3) enhancements**
   - Documentation
   - Nice-to-have features

### Phase 4: Validation

After each significant change:

1. **Test thoroughly** - verify nothing broke
2. **Update TODO.AI.md** - mark items complete
3. **Update AI.md** - reflect current project state
4. **Document breaking changes** - if any
5. **Get human approval** before proceeding to next phase

---

## Common Integration Patterns

### Pattern 1: File Structure Migration

**If project has non-standard structure:**

1. Create new `src/` directory structure per spec
2. Move files incrementally (one package at a time)
3. Update imports after each move
4. Test after each move
5. Delete old structure only when new structure is fully working

### Pattern 2: Configuration Migration

**If project uses different config format:**

1. Add config migration utility: `--migrate-config old.conf new.yml`
2. Document migration in README/docs
3. Run migration on first startup (auto-detect old format)
4. DELETE old config after successful migration
5. New installs use new format only

### Pattern 3: API Migration

**If project has existing API that doesn't match spec:**

1. Implement new spec-compliant API at `/api/v1/`
2. **DELETE old endpoints** - no deprecation periods, no shims
3. Document breaking changes clearly in release notes
4. Provide one-time migration script if data format changed
5. Clients must update - this is expected for major versions

### Pattern 4: Database Schema Migration

**If project has existing database:**

1. **NEVER break existing data**
2. Create migration scripts in `src/migration/`
3. Use proper migration tool or SQL migration files
4. Test migrations on backup data first
5. Provide rollback capability
6. Document breaking schema changes

---

## Critical Rules for Integration

| Rule | Description |
|------|-------------|
| **NEVER break production** | Integration should be incremental and safe |
| **NEVER lose data** | Migrations must preserve all existing data |
| **NEVER remove features** | Unless explicitly approved by human |
| **ALWAYS test** | Every change must be tested before proceeding |
| **ALWAYS backup** | Before major structural changes |
| **ALWAYS document** | Breaking changes, migrations, deletions |
| **ALWAYS ask** | When unsure about preserving existing behavior |

---

## Red Flags (Stop and Ask Human)

Stop immediately and ask the human if you encounter:

- Existing data that might be lost
- Breaking API changes affecting external users
- Configuration changes requiring manual migration
- File structure changes affecting deployed systems
- Security changes that might break authentication
- Database schema changes without clear migration path
- Removal of features currently in use

---

## Integration Checklist

Before starting integration:

- [ ] Have you read the ENTIRE AI.md specification?
- [ ] Have you read and understood the existing codebase?
- [ ] Have you created a comprehensive TODO.AI.md with prioritized tasks?
- [ ] Have you reviewed the TODO.AI.md with the human?
- [ ] Have you identified all risks and breaking changes?
- [ ] Have you planned for data migration (if needed)?
- [ ] Have you planned for incremental rollout?
- [ ] Do you have a rollback plan for each major change?

**If you answered NO to any of the above, DO NOT START IMPLEMENTATION.**

---

## Example TODO.AI.md for Integration

```markdown
# Integration Tasks for weather

## Critical (P0) - Do First

- [ ] Fix SQL injection vulnerability in user search (line 234)
- [ ] Add missing input validation on admin endpoints
- [ ] Fix session management security issue

## High (P1) - NON-NEGOTIABLE Requirements

### File Structure
- [ ] Create src/ directory structure per spec
- [ ] Move main.go to src/main.go
- [ ] Create src/config/ package
- [ ] Create src/server/ package
- [ ] Create src/swagger/ package (NEW)
- [ ] Create src/graphql/ package (NEW)
- [ ] Update all imports

### Configuration
- [ ] Migrate config.json to server.yml format
- [ ] Add environment variable support
- [ ] Add CLI flag overrides
- [ ] Create migration utility

### API
- [ ] Add Swagger/OpenAPI support (NEW)
- [ ] Add GraphQL support (NEW)
- [ ] Ensure REST API matches spec patterns

## Medium (P2) - Standardization

- [ ] Standardize error handling per spec
- [ ] Add comprehensive logging per spec
- [ ] Implement project-wide theme system (light/dark/auto)
- [ ] Add health check endpoint format per spec

## Low (P3) - Documentation

- [ ] Create docs/ directory for ReadTheDocs
- [ ] Write docs/index.md
- [ ] Write docs/installation.md
- [ ] Configure mkdocs.yml
```

---

## Remember

**Integration is a PROCESS, not a single change.**

- Work incrementally
- Test continuously
- Document everything
- Get approval at each phase
- Preserve existing functionality unless explicitly changing it
- NEVER rush integration to "get it done faster"

---

---

# APPENDIX B: BOOTSTRAP NOTES

# Bootstrap Notes for New Projects

**Use this prompt when creating a NEW project from scratch.**

---

## Prompt for AI Assistants

When bootstrapping a new project from this specification:

### Phase 1: Project Initialization

1. **Confirm project details:**
   - Project name: `weather`
   - Organization: `apimgr`
   - Description: What does this project do?
   - Primary purpose: What problem does it solve?

2. **Create directory structure:**
   ```bash
   mkdir -p weather
   cd weather

   # Create all required directories
   mkdir -p src/{config,server,swagger,graphql,mode,paths,ssl,scheduler,service,admin}
   mkdir -p src/server/{handler,service,model,store,template}
   mkdir -p docker/rootfs/usr/local/bin
   mkdir -p docs/stylesheets
   mkdir -p tests
   mkdir -p scripts
   mkdir -p .github/workflows
   ```

3. **Create AI.md:**
   - Ask human to provide AI.md for the new project
   - Verify all `{variables}` are replaced with actual values
   - Verify PART 37 is filled in with project details

4. **Create foundational files:**
   ```bash
   # Required files
   touch README.md
   touch LICENSE.md
   touch Makefile
   touch Jenkinsfile
   touch release.txt
   touch TODO.AI.md
   touch .gitignore

   # Docker files
   touch docker/Dockerfile
   touch docker/docker-compose.yml
   touch docker/docker-compose.dev.yml
   touch docker/docker-compose.test.yml
   touch docker/rootfs/usr/local/bin/entrypoint.sh

   # ReadTheDocs files
   touch mkdocs.yml
   touch .readthedocs.yaml
   touch docs/index.md
   touch docs/installation.md
   touch docs/configuration.md
   touch docs/api.md
   touch docs/admin.md
   touch docs/development.md
   touch docs/requirements.txt
   touch docs/stylesheets/dark.css
   touch docs/stylesheets/light.css

   # CI/CD
   touch .github/workflows/release.yml
   touch .github/workflows/beta.yml
   touch .github/workflows/daily.yml
   touch .github/workflows/docker.yml
   ```

### Phase 2: Core Implementation Order

**Implement in this specific order for best results:**

#### Step 1: Basic Structure (PARTS 1-5)

1. **Initialize Go module:**
   ```bash
   go mod init github.com/apimgr/weather
   ```

2. **Create src/main.go** - Minimal entry point
3. **Create src/config/config.go** - Configuration loading
4. **Create src/mode/mode.go** - Application mode detection
5. **Create src/paths/paths.go** - Path resolution

**Test:** Binary should compile and show version

#### Step 2: Server Foundation (PARTS 6-10)

1. **Create src/server/server.go** - HTTP server setup
2. **Create src/server/handler/health.go** - Health check
3. **Add CLI flags** per PART 8 specification
4. **Add service support** per PART 24
5. **Create Makefile** per PART 26

**Test:** Server starts and responds to `/healthz`

#### Step 3: Docker & CI/CD (PARTS 27-28)

1. **Create docker/Dockerfile** - Multi-stage build
2. **Create docker-compose files** - Production, dev, test
3. **Create entrypoint.sh** - Container initialization
4. **Create .github/workflows/** - All CI/CD workflows
5. **Create Makefile targets** - build, docker, release

**Test:** Docker build succeeds, container runs

#### Step 4: Web Frontend (PART 16)

1. **Create src/server/template/** - HTML templates
2. **Embed templates in server.go**
3. **Implement theme system** (light/dark/auto)
4. **Create homepage route** - `/` endpoint
5. **Test responsive design**

**Test:** Homepage loads with working theme toggle

#### Step 5: Admin Panel (PART 17)

1. **Create src/admin/admin.go** - Admin package
2. **Create admin templates** - UI pages
3. **Create admin handlers** - Routes and logic
4. **Implement first-run setup wizard**
5. **Add all admin configuration pages**

**Test:** Admin panel accessible at `/admin`

#### Step 6: API Layer (PART 14)

1. **Create src/server/handler/api.go** - REST API handlers
2. **Create src/swagger/swagger.go** - OpenAPI/Swagger
3. **Create src/graphql/graphql.go** - GraphQL API
4. **Ensure all three APIs are in sync**
5. **Apply theme to Swagger/GraphQL UIs**

**Test:** All three APIs work (REST, Swagger, GraphQL)

#### Step 7: Core Features (PARTS 9-13, 15, 18-25, 29, 31-32)

Implement remaining required parts:
1. **PART 9:** Error Handling & Caching
2. **PART 10:** Database & Cluster
3. **PART 11:** Security & Logging
4. **PART 12:** Server Configuration
5. **PART 13:** Health & Versioning
6. **PART 15:** SSL/TLS & Let's Encrypt
7. **PART 18:** Email & Notifications
8. **PART 19:** Scheduler
9. **PART 20:** GeoIP
10. **PART 21:** Metrics
11. **PART 22:** Backup & Restore
12. **PART 23:** Update Command
13. **PART 24:** Privilege Escalation & Service
14. **PART 25:** Service Support
15. **PART 29:** Testing & Development
16. **PART 31:** I18N & A11Y
17. **PART 32:** Tor Hidden Service

**Test after each part:** Verify the feature works before moving to next

#### Step 8: Optional Features (PARTS 33-36)

Implement as needed for your project:
1. **PART 33:** Multi-User (if project needs regular user accounts)
2. **PART 34:** Organizations (requires PART 33 first)
3. **PART 35:** Custom Domains (if users/orgs need branded domains)
4. **PART 36:** CLI Client (if project needs command-line tool)

#### Step 9: Documentation (PART 30)

1. **Create all docs/*.md files**
2. **Configure mkdocs.yml**
3. **Configure .readthedocs.yaml**
4. **Add docs/requirements.txt**
5. **Create theme CSS files**
6. **Test local MkDocs build:** `mkdocs serve`

**Test:** Documentation builds and deploys to ReadTheDocs

#### Step 10: Project-Specific (PART 37)

1. **Fill in PART 37 in AI.md** - Define project-specific endpoints, data, config
2. **Implement project-specific features**
3. **Add project-specific tests**
4. **Update documentation with project specifics**

**Test:** All project-specific functionality works

### Phase 3: Polish & Release

1. **Run full test suite** - Ensure everything works
2. **Build all 8 platforms** - Verify cross-platform builds
3. **Test Docker images** - All compose files work
4. **Complete README.md** - Production-first documentation
5. **Complete LICENSE.md** - Include all embedded licenses
6. **Final compliance check** - Review FINAL CHECKPOINT checklist
7. **Create initial release** - Tag v0.1.0

---

## Bootstrap Checklist

### Before You Start

- [ ] Have you read the ENTIRE AI.md specification?
- [ ] Do you understand the project purpose and scope?
- [ ] Have you confirmed all project details (name, org, description)?
- [ ] Have you asked clarifying questions about project-specific requirements?

### Foundation (Must Complete First)

- [ ] Directory structure created per spec
- [ ] AI.md created and customized
- [ ] go.mod initialized
- [ ] .gitignore created with proper rules
- [ ] Basic src/main.go exists
- [ ] src/config/config.go exists
- [ ] Project compiles successfully

### Core Features (In Order)

- [ ] Server starts and responds to requests
- [ ] Health check endpoint works
- [ ] CLI flags work per spec
- [ ] Configuration loading works (file, env, flags)
- [ ] Logging configured properly
- [ ] Admin panel accessible
- [ ] First-run setup wizard works
- [ ] REST API endpoints defined
- [ ] Swagger UI accessible at /openapi
- [ ] GraphQL accessible at /graphql
- [ ] All three APIs in sync

### Infrastructure

- [ ] Docker builds successfully
- [ ] Docker Compose files work (prod, dev, test)
- [ ] CI/CD workflows configured
- [ ] Automated builds work
- [ ] Multi-platform builds work (8 platforms)

### Documentation

- [ ] README.md complete
- [ ] LICENSE.md complete with embedded licenses
- [ ] docs/ directory structure created
- [ ] All required .md files in docs/
- [ ] mkdocs.yml configured
- [ ] ReadTheDocs configured
- [ ] Documentation builds successfully

### Final Validation

- [ ] All NON-NEGOTIABLE requirements met
- [ ] All FINAL CHECKPOINT items checked
- [ ] No TODO items marked as critical/blocker
- [ ] All tests pass
- [ ] All 8 platform builds succeed
- [ ] Docker images build and run
- [ ] Documentation published

---

## Common Mistakes When Bootstrapping

| Mistake | Why It's Wrong | Correct Approach |
|---------|----------------|------------------|
| Starting with project-specific features | Wastes time if foundation is wrong | Build foundation first (config, server, admin) |
| Skipping admin panel | Hard to configure without UI | Build admin panel early |
| Implementing all APIs at once | Easy to get out of sync | Start with REST, then add Swagger, then GraphQL |
| Not testing incrementally | Find bugs too late | Test after each major component |
| Hardcoding values | Makes project inflexible | Use configuration from day 1 |
| Skipping documentation | Users can't use the project | Write docs as you build |
| Building for one platform only | Fails CI/CD | Test multi-platform early |
| Ignoring theme system | Hard to retrofit later | Implement themes from start |

---

## Time-Saving Tips

1. **Use existing projects as reference:**
   - Look at jokes, quotes, or other apimgr projects
   - Copy patterns that match the spec
   - Adapt to your project's needs

2. **Leverage templates:**
   - Use spec templates for Docker, CI/CD, configs
   - Don't reinvent - copy and customize

3. **Build iteratively:**
   - Get basic version working first
   - Add features incrementally
   - Test continuously

4. **Focus on NON-NEGOTIABLE items first:**
   - Optional features can wait
   - Core requirements must be solid

---

## Success Criteria

A successfully bootstrapped project should:

✅ Compile to a single static binary for all 8 platforms
✅ Run in Docker with proper configuration
✅ Have working web UI with theme support (light/dark/auto)
✅ Have working admin panel with all config options
✅ Expose REST, Swagger, AND GraphQL APIs (all in sync)
✅ Have comprehensive documentation on ReadTheDocs
✅ Pass all CI/CD workflows
✅ Follow every NON-NEGOTIABLE requirement in AI.md
✅ Be ready for v0.1.0 release

---

## Getting Help

When stuck:

1. **Re-read the relevant PART** in AI.md
2. **Check existing projects** in apimgr for working examples
3. **Ask specific questions** about unclear requirements
4. **Propose solutions** for human review

**NEVER guess or assume** - always ask when uncertain.

---
